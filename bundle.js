require=(function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
const stdlibs = require('./stdlibs.json')

const Ast = require('../dist/lntoamm/Ast')
const Module = require('../dist/lntoamm/Module').default
const Scope = require('../dist/lntoamm/Scope').default
const opcodeScope = require('../dist/lntoamm/opcodes').default.exportScope

module.exports = {
  loadStdModules: (modules) => {
    const stdAsts = Object.keys(stdlibs).map(n => ({
      name: n,
      ast: Ast.fromString(stdlibs[n]),
    }))
    // Load the rootScope first, all the others depend on it
    let rootModule
    stdAsts.forEach((moduleAst) => {
      if (moduleAst.name == 'root.ln') {
        rootModule = Module.populateModule('<root>', moduleAst.ast, opcodeScope, true)
        Module.getAllModules()['<root>'] = rootModule
      }
    })
    // Now load the remainig modules based on the root scope
    stdAsts.forEach((moduleAst) => {
      if (moduleAst.name != 'root.ln') {
        moduleAst.name = '@std/' + moduleAst.name.replace(/.ln$/, '')
        const stdModule = Module.populateModule(
          moduleAst.name,
          moduleAst.ast,
          rootModule.exportScope,
          true
        )
        Module.getAllModules()[moduleAst.name] = stdModule
      }
    })
  },
}

},{"../dist/lntoamm/Ast":10,"../dist/lntoamm/Module":14,"../dist/lntoamm/Scope":16,"../dist/lntoamm/opcodes":22,"./stdlibs.json":2}],2:[function(require,module,exports){
module.exports={"app.ln":"/**\n * @std/app - The entrypoint for CLI apps\n */\n\n// The `start` event with a signature like `event start` but has special meaning in the runtime\nexport start\n\n// The `stdout` event\nexport event stdout: string\n\n// `@std/app` has access to a special `stdoutp` opcode to trigger stdout writing\non stdout fn (out: string) = stdoutp(out);\n\n// The `print` function converts its input to a string, appends a newline, and sends it to `stdout`\nexport fn print(out: Stringifiable) {\n  emit stdout out.toString() + \"\\n\";\n}\n\n// The `exit` event\nexport event exit: int8\n\n// `@std/app` has access to a special `exitop` opcode to trigger the exit behavior\non exit fn (status: int8) = exitop(status);\n\n// The `stderr` event\nexport event stderr: string\n\n// `@std/app` has access to a special `stderrp` opcode to trigger stderr writing\non stderr fn (err: string) = stderrp(err);\n\n// The `eprint` function converts its input to a string, appends a newline, and sends it to `stderr`\nexport fn eprint(err: Stringifiable) {\n  emit stderr err.toString() + \"\\n\";\n}\n","cmd.ln":"/**\n * @std/cmd - The entrypoint for working with command line processes.\n */\n\nexport fn exec(n: string) = execop(n);","datastore.ln":"/**\n * @std/datastore - Shared mutable state with controlled access\n */\n\n// Just syntactic sugar to seem less stringly-typed than it is\nexport fn namespace(ns: string) = ns\n\n// The set function to store shared data\nexport fn set(ns: string, key: string, val: any) = dssetv(ns, key, val);\nexport fn set(ns: string, key: string, val: int8) = dssetf(ns, key, val);\nexport fn set(ns: string, key: string, val: int16) = dssetf(ns, key, val);\nexport fn set(ns: string, key: string, val: int32) = dssetf(ns, key, val);\nexport fn set(ns: string, key: string, val: int64) = dssetf(ns, key, val);\nexport fn set(ns: string, key: string, val: float32) = dssetf(ns, key, val);\nexport fn set(ns: string, key: string, val: float64) = dssetf(ns, key, val);\nexport fn set(ns: string, key: string, val: bool) = dssetf(ns, key, val);\n\n// The has function to test if a shared key exists\nexport fn has(ns: string, key: string): bool = dshas(ns, key);\n\n// The del function to remove a shared key\nexport fn del(ns: string, key: string): bool = dsdel(ns, key);\n\n// The getOr function to get a value or the return the provided default\nexport fn getOr(ns: string, key: string, default: any) {\n  return dsgetv(ns, key).getOr(default);\n}\nexport fn getOr(ns: string, key: string, default: int8) {\n  return dsgetf(ns, key).getOr(default);\n}\nexport fn getOr(ns: string, key: string, default: int16) {\n  return dsgetf(ns, key).getOr(default);\n}\nexport fn getOr(ns: string, key: string, default: int32) {\n  return dsgetf(ns, key).getOr(default);\n}\nexport fn getOr(ns: string, key: string, default: int64) {\n  return dsgetf(ns, key).getOr(default);\n}\nexport fn getOr(ns: string, key: string, default: float32) {\n  return dsgetf(ns, key).getOr(default);\n}\nexport fn getOr(ns: string, key: string, default: float64) {\n  return dsgetf(ns, key).getOr(default);\n}\nexport fn getOr(ns: string, key: string, default: bool) {\n  return dsgetf(ns, key).getOr(default);\n}\n","deps.ln":"from @std/app import start, print, exit\nfrom @std/cmd import exec\n\n/**\n * @std/deps - The entrypoint to install dependencies for an alan program\n */\n\n// The `install` event\nexport event install: void\n\n// The `add` function takes a string that describes a .git repository and install it in /dependencies\nexport fn add(remote: string) {\n  // TODO implement proper error handling\n  const parts = remote.split('/');\n  const repo = parts[length(parts) - 1] || '';\n  const group = parts[parts.length() - 2] || '';\n  const dest = '/dependencies/' + group + '/' + repo;\n  const rm = exec('rm -rf .' + dest);\n  const git = exec('git clone ' + remote + ' .' + dest);\n  print(git.stderr);\n  const rm2 = exec('rm -rf .' + dest + '/.git');\n}\n\n// The `commit` function takes no arguments. Currently just causes the application to quit, but\n// eventually would be the point where the dependencies defined by the calls to `add` could be\n// compared against the currently-installed dependencies, and a faster install would be possible\nexport fn commit() {\n  emit exit 0;\n}\n\n// Emit the `install` event on app `start`\non start {\n  // TODO: optimize to parse the existing dependencies tree, if any, to build up a list of dependencies\n  // that are already installed so calls by the user to install them again (assuming the version is identical)\n  // are skipped, calls to upgrade or install new dependencies are performed, and then the remaining list\n  // of dependencies at the end are removed.\n  exec('rm -rf dependencies');\n  exec('mkdir dependencies');\n  emit install;\n}\n","http.ln":"/**\n * @std/http - Built-in client and server for http\n */\n\n/**\n * HTTP Client\n */\n\nexport fn get(url: string) = httpget(url);\nexport fn post(url: string, payload: string) = httppost(url, payload);\n\n/**\n * HTTP Server\n */\n\n// The InternalRequest type for inbound http requests\ntype InternalRequest {\n  url: string,\n  headers: Array<KeyVal<string, string>>,\n  body: string,\n  connId: int64,\n}\n\n// The InternalResponse type for inbount http requests\ntype InternalResponse {\n  status: int64,\n  headers: Array<KeyVal<string, string>>,\n  body: string,\n  connId: int64,\n}\n\n// The exposed Request type\nexport type Request {\n  url: string,\n  headers: HashMap<string, string>,\n  body: string,\n}\n\n// The exposed Response type\nexport type Response {\n  status: int64,\n  headers: HashMap<string, string>,\n  body: string,\n  connId: int64,\n}\n\n// The roll-up Connection type with both\nexport type Connection {\n  req: Request,\n  res: Response,\n}\n\n// The connection event\nexport event connection: Connection\n\n// The special connection event with a signature like `event __conn: InternalConnection`\n// This wrapper function takes the internal connection object, converts it to the user-friendly\n// connection object, and then emits it on a new event for user code to pick up\non __conn fn (conn: InternalRequest) {\n  emit connection new Connection {\n    req: new Request {\n      url: conn.url,\n      headers: toHashMap(conn.headers),\n      body: conn.body,\n    },\n    res: new Response {\n      status: 200, // If not set by the user, assume they meant it to be good\n      headers: newHashMap('Content-Length', '0'), // If not set by the user, assume no data\n      body: '', // If not set by the user, assume no data\n      connId: conn.connId,\n    },\n  };\n}\n\n// The listen function tells the http server to start up and listen on the given port\n// For now only one http server per application, a macro system is necessary to improve this\n// Returns a Result with either an 'ok' string or an error\nexport fn listen(port: int64) = httplsn(port);\n\n// The body function sets the body for a Response, sets the Content-Length header, and retuns the\n// Response for chaining needs\nexport fn body(res: Response, body: string) {\n  res.body = body;\n  const len = body.length();\n  set(res.headers, 'Content-Length', len.toString());\n  return res;\n}\n\n// The status function sets the status of the response\nexport fn status(res: Response, status: int64) {\n  res.status = status;\n  return res;\n}\n\n// The send function converts the response object into an internal response object and passed that\n// back to the HTTP server. A Result type with either an 'ok' string or an error is returned\nexport fn send(res: Response): Result<string> {\n  const ires = new InternalResponse {\n    status: res.status,\n    headers: res.headers.keyVal,\n    body: res.body,\n    connId: res.connId,\n  };\n  return httpsend(ires);\n}","root.ln":"/**\n * The root scope. These definitions are automatically available from every module.\n * These are almost entirely wrappers around runtime opcodes to provide a friendlier\n * name and using function dispatch based on input arguments to pick the correct opcode.\n */\n\n// TODO: See about making an export block scope so we don't have to write `export` so much\n\n// Export all of the built-in types\nexport void\nexport int8\nexport int16\nexport int32\nexport int64\nexport float32\nexport float64\nexport bool\nexport string\nexport function // TODO: Make the function type more explicit than this\nexport Array\nexport Error\nexport Maybe\nexport Result\nexport Either\n\n// Type aliasing of int64 and float64 to just int and float, as these are the default types\nexport type int = int64\nexport type float = float64\n\n// Default Interfaces\nexport interface any {}\nexport interface anythingElse = any // Same as `any` but doesn't match with it\nexport interface Stringifiable {\n  toString(Stringifiable): string,\n}\nexport interface Orderable {\n  lt(Orderable, Orderable): bool,\n  lte(Orderable, Orderable): bool,\n  gt(Orderable, Orderable): bool,\n  gte(Orderable, Orderable): bool,\n}\nexport interface canFloat64 {\n  toFloat64(canFloat64): float64\n}\nexport interface canInt64 {\n  toInt64(canInt64): int64\n}\n\n// Type conversion functions\nexport fn toFloat64(n: int8) = i8f64(n);\nexport fn toFloat64(n: int16) = i16f64(n);\nexport fn toFloat64(n: int32) = i32f64(n);\nexport fn toFloat64(n: int64) = i64f64(n);\nexport fn toFloat64(n: float32) = f32f64(n);\nexport fn toFloat64(n: float64) = n;\nexport fn toFloat64(n: string) = strf64(n);\nexport fn toFloat64(n: bool) = boolf64(n);\n\nexport fn toFloat32(n: int8) = i8f32(n);\nexport fn toFloat32(n: int16) = i16f32(n);\nexport fn toFloat32(n: int32) = i32f32(n);\nexport fn toFloat32(n: int64) = i64f32(n);\nexport fn toFloat32(n: float32) = n;\nexport fn toFloat32(n: float64) = f64f32(n);\nexport fn toFloat32(n: string) = strf32(n);\nexport fn toFloat32(n: bool) = boolf32(n);\n\nexport fn toInt64(n: int8) = i8i64(n);\nexport fn toInt64(n: int16) = i16i64(n);\nexport fn toInt64(n: int32) = i32i64(n);\nexport fn toInt64(n: int64) = n;\nexport fn toInt64(n: float32) = f32i64(n);\nexport fn toInt64(n: float64) = f64i64(n);\nexport fn toInt64(n: string) = stri64(n);\nexport fn toInt64(n: bool) = booli64(n);\n\nexport fn toInt32(n: int8) = i8i32(n);\nexport fn toInt32(n: int16) = i16i32(n);\nexport fn toInt32(n: int32) = n;\nexport fn toInt32(n: int64) = i64i32(n);\nexport fn toInt32(n: float32) = f32i32(n);\nexport fn toInt32(n: float64) = f64i32(n);\nexport fn toInt32(n: string) = stri32(n);\nexport fn toInt32(n: bool) = booli32(n);\n\nexport fn toInt16(n: int8) = i8i16(n);\nexport fn toInt16(n: int16) = n;\nexport fn toInt16(n: int32) = i32i16(n);\nexport fn toInt16(n: int64) = i64i16(n);\nexport fn toInt16(n: float32) = f32i16(n);\nexport fn toInt16(n: float64) = f64i16(n);\nexport fn toInt16(n: string) = stri16(n);\nexport fn toInt16(n: bool) = booli16(n);\n\nexport fn toInt8(n: int8) = n;\nexport fn toInt8(n: int16) = i16i8(n);\nexport fn toInt8(n: int32) = i32i8(n);\nexport fn toInt8(n: int64) = i64i8(n);\nexport fn toInt8(n: float32) = f32i8(n);\nexport fn toInt8(n: float64) = f64i8(n);\nexport fn toInt8(n: string) = stri8(n);\nexport fn toInt8(n: bool) = booli8(n);\n\nexport fn toBool(n: int8) = i8bool(n);\nexport fn toBool(n: int16) = i16bool(n);\nexport fn toBool(n: int32) = i32bool(n);\nexport fn toBool(n: int64) = i64bool(n);\nexport fn toBool(n: float32) = f32bool(n);\nexport fn toBool(n: float64) = f64bool(n);\nexport fn toBool(n: string) = strbool(n);\nexport fn toBool(n: bool) = n;\n\nexport fn toString(n: int8) = i8str(n);\nexport fn toString(n: int16) = i16str(n);\nexport fn toString(n: int32) = i32str(n);\nexport fn toString(n: int64) = i64str(n);\nexport fn toString(n: float32) = f32str(n);\nexport fn toString(n: float64) = f64str(n);\nexport fn toString(n: string) = n;\nexport fn toString(n: bool) = boolstr(n);\n\n// Type alias conversion functions\nexport fn toFloat(n: canFloat64): float = toFloat64(n)\nexport fn toInt(n: canInt64): int = toInt64(n) \n\n// Arithmetic functions\nexport fn add(a: int8, b: int8) = addi8(a, b);\nexport fn add(a: int16, b: int16) = addi16(a, b);\nexport fn add(a: int32, b: int32) = addi32(a, b);\nexport fn add(a: int64, b: int64) = addi64(a, b);\nexport fn add(a: float32, b: float32) = addf32(a, b);\nexport fn add(a: float64, b: float64) = addf64(a, b);\n\nexport fn sub(a: int8, b: int8) = subi8(a, b);\nexport fn sub(a: int16, b: int16) = subi16(a, b);\nexport fn sub(a: int32, b: int32) = subi32(a, b);\nexport fn sub(a: int64, b: int64) = subi64(a, b);\nexport fn sub(a: float32, b: float32) = subf32(a, b);\nexport fn sub(a: float64, b: float64) = subf64(a, b);\n\nexport fn negate(n: int8) = negi8(n);\nexport fn negate(n: int16) = negi16(n);\nexport fn negate(n: int32) = negi32(n);\nexport fn negate(n: int64) = negi64(n);\nexport fn negate(n: float32) = negf32(n);\nexport fn negate(n: float64) = negf64(n);\n\nexport fn abs(n: int8) = absi8(n);\nexport fn abs(n: int16) = absi16(n);\nexport fn abs(n: int32) = absi32(n);\nexport fn abs(n: int64) = absi64(n);\nexport fn abs(n: float32) = absf32(n);\nexport fn abs(n: float64) = absf64(n);\n\nexport fn mul(a: int8, b: int8) = muli8(a, b);\nexport fn mul(a: int16, b: int16) = muli16(a, b);\nexport fn mul(a: int32, b: int32) = muli32(a, b);\nexport fn mul(a: int64, b: int64) = muli64(a, b);\nexport fn mul(a: float32, b: float32) = mulf32(a, b);\nexport fn mul(a: float64, b: float64) = mulf64(a, b);\n\nexport fn div(a: int8, b: int8) = divi8(a, b);\nexport fn div(a: int16, b: int16) = divi16(a, b);\nexport fn div(a: int32, b: int32) = divi32(a, b);\nexport fn div(a: int64, b: int64) = divi64(a, b);\nexport fn div(a: float32, b: float32) = divf32(a, b);\nexport fn div(a: float64, b: float64) = divf64(a, b);\n\nexport fn mod(a: int8, b: int8) = modi8(a, b);\nexport fn mod(a: int16, b: int16) = modi16(a, b);\nexport fn mod(a: int32, b: int32) = modi32(a, b);\nexport fn mod(a: int64, b: int64) = modi64(a, b);\n\nexport fn pow(a: int8, b: int8) = powi8(a, b);\nexport fn pow(a: int16, b: int16) = powi16(a, b);\nexport fn pow(a: int32, b: int32) = powi32(a, b);\nexport fn pow(a: int64, b: int64) = powi64(a, b);\nexport fn pow(a: float32, b: float32) = powf32(a, b);\nexport fn pow(a: float64, b: float64) = powf64(a, b);\n\nexport fn sqrt(n: float32) = sqrtf32(n);\nexport fn sqrt(n: float64) = sqrtf64(n);\n\nexport fn min(x: Orderable, y: Orderable): Orderable {\n  return cond(lte(x, y), [x, y]);\n}\nexport fn max(x: Orderable, y: Orderable): Orderable {\n  return cond(gte(x, y), [x, y]);\n}\n\n// Boolean and bitwise functions\nexport fn and(a: int8, b: int8) = andi8(a, b);\nexport fn and(a: int16, b: int16) = andi16(a, b);\nexport fn and(a: int32, b: int32) = andi32(a, b);\nexport fn and(a: int64, b: int64) = andi64(a, b);\nexport fn and(a: bool, b: bool) = andbool(a, b);\n\nexport fn or(a: int8, b: int8) = ori8(a, b);\nexport fn or(a: int16, b: int16) = ori16(a, b);\nexport fn or(a: int32, b: int32) = ori32(a, b);\nexport fn or(a: int64, b: int64) = ori64(a, b);\nexport fn or(a: bool, b: bool) = orbool(a, b);\n\nexport fn xor(a: int8, b: int8) = xori8(a, b);\nexport fn xor(a: int16, b: int16) = xori16(a, b);\nexport fn xor(a: int32, b: int32) = xori32(a, b);\nexport fn xor(a: int64, b: int64) = xori64(a, b);\nexport fn xor(a: bool, b: bool) = xorbool(a, b);\n\nexport fn not(n: int8) = noti8(n);\nexport fn not(n: int16) = noti16(n);\nexport fn not(n: int32) = noti32(n);\nexport fn not(n: int64) = noti64(n);\nexport fn not(n: bool) = notbool(n);\n\nexport fn nand(a: int8, b: int8) = nandi8(a, b);\nexport fn nand(a: int16, b: int16) = nandi16(a, b);\nexport fn nand(a: int32, b: int32) = nandi32(a, b);\nexport fn nand(a: int64, b: int64) = nandi64(a, b);\nexport fn nand(a: bool, b: bool) = nandboo(a, b);\n\nexport fn nor(a: int8, b: int8) = nori8(a, b);\nexport fn nor(a: int16, b: int16) = nori16(a, b);\nexport fn nor(a: int32, b: int32) = nori32(a, b);\nexport fn nor(a: int64, b: int64) = nori64(a, b);\nexport fn nor(a: bool, b: bool) = norbool(a, b);\n\nexport fn xnor(a: int8, b: int8) = xnori8(a, b);\nexport fn xnor(a: int16, b: int16) = xnori16(a, b);\nexport fn xnor(a: int32, b: int32) = xnori32(a, b);\nexport fn xnor(a: int64, b: int64) = xnori64(a, b);\nexport fn xnor(a: bool, b: bool) = xnorboo(a, b);\n\n// Equality and order functions\nexport fn eq(a: int8, b: int8) = eqi8(a, b);\nexport fn eq(a: int16, b: int16) = eqi16(a, b);\nexport fn eq(a: int32, b: int32) = eqi32(a, b);\nexport fn eq(a: int64, b: int64) = eqi64(a, b);\nexport fn eq(a: float32, b: float32) = eqf32(a, b);\nexport fn eq(a: float64, b: float64) = eqf64(a, b);\nexport fn eq(a: string, b: string) = eqstr(a, b);\nexport fn eq(a: bool, b: bool) = eqbool(a, b);\n\nexport fn neq(a: int8, b: int8) = neqi8(a, b);\nexport fn neq(a: int16, b: int16) = neqi16(a, b);\nexport fn neq(a: int32, b: int32) = neqi32(a, b);\nexport fn neq(a: int64, b: int64) = neqi64(a, b);\nexport fn neq(a: float32, b: float32) = neqf32(a, b);\nexport fn neq(a: float64, b: float64) = neqf64(a, b);\nexport fn neq(a: string, b: string) = neqstr(a, b);\nexport fn neq(a: bool, b: bool) = neqbool(a, b);\n\nexport fn lt(a: int8, b: int8) = lti8(a, b);\nexport fn lt(a: int16, b: int16) = lti16(a, b);\nexport fn lt(a: int32, b: int32) = lti32(a, b);\nexport fn lt(a: int64, b: int64) = lti64(a, b);\nexport fn lt(a: float32, b: float32) = ltf32(a, b);\nexport fn lt(a: float64, b: float64) = ltf64(a, b);\nexport fn lt(a: string, b: string) = ltstr(a, b);\n\nexport fn lte(a: int8, b: int8) = ltei8(a, b);\nexport fn lte(a: int16, b: int16) = ltei16(a, b);\nexport fn lte(a: int32, b: int32) = ltei32(a, b);\nexport fn lte(a: int64, b: int64) = ltei64(a, b);\nexport fn lte(a: float32, b: float32) = ltef32(a, b);\nexport fn lte(a: float64, b: float64) = ltef64(a, b);\nexport fn lte(a: string, b: string) = ltestr(a, b);\n\nexport fn gt(a: int8, b: int8) = gti8(a, b);\nexport fn gt(a: int16, b: int16) = gti16(a, b);\nexport fn gt(a: int32, b: int32) = gti32(a, b);\nexport fn gt(a: int64, b: int64) = gti64(a, b);\nexport fn gt(a: float32, b: float32) = gtf32(a, b);\nexport fn gt(a: float64, b: float64) = gtf64(a, b);\nexport fn gt(a: string, b: string) = gtstr(a, b);\n\nexport fn gte(a: int8, b: int8) = gtei8(a, b);\nexport fn gte(a: int16, b: int16) = gtei16(a, b);\nexport fn gte(a: int32, b: int32) = gtei32(a, b);\nexport fn gte(a: int64, b: int64) = gtei64(a, b);\nexport fn gte(a: float32, b: float32) = gtef32(a, b);\nexport fn gte(a: float64, b: float64) = gtef64(a, b);\nexport fn gte(a: string, b: string) = gtestr(a, b);\n\n// Wait functions\nexport fn wait(n: int8) = waitop(i8i64(n));\nexport fn wait(n: int16) = waitop(i16i64(n));\nexport fn wait(n: int32) = waitop(i32i64(n));\nexport fn wait(n: int64) = waitop(n);\n\n// String functions\nexport fn concat(a: string, b: string) = catstr(a, b);\nexport split // opcode with signature `fn split(str: string, spl: string): Array<string>`\nexport fn repeat(s: string, n: int64) = repstr(s, n);\n// export fn template(str: string, map: Map<string, string>) = templ(str, map)\nexport matches // opcode with signature `fn matches(s: string, t: string): bool`\nexport fn index(s: string, t: string) = indstr(s, t);\nexport fn length(s: string) = lenstr(s);\nexport trim // opcode with signature `fn trim(s: string): string`\n\n// Array functions\nexport fn concat(a: Array<any>, b: Array<any>) = catarr(a, b);\nexport fn repeat(arr: Array<any>, n: int64) = reparr(arr, n);\nexport fn index(arr: Array<any>, val: any) = indarrv(arr, val);\nexport fn index(arr: Array<int8>, val: int8) = indarrf(arr, val);\nexport fn index(arr: Array<int16>, val: int16) = indarrf(arr, val);\nexport fn index(arr: Array<int32>, val: int32) = indarrf(arr, val);\nexport fn index(arr: Array<int64>, val: int64) = indarrf(arr, val);\nexport fn index(arr: Array<float32>, val: float32) = indarrf(arr, val);\nexport fn index(arr: Array<float64>, val: float64) = indarrf(arr, val);\nexport fn index(arr: Array<bool>, val: bool) = indarrf(arr, val);\nexport fn has(arr: Array<any>, val: any) = indarrv(arr, val).isOk();\nexport fn has(arr: Array<int8>, val: int8) = indarrf(arr, val).isOk();\nexport fn has(arr: Array<int16>, val: int16) = indarrf(arr, val).isOk();\nexport fn has(arr: Array<int32>, val: int32) = indarrf(arr, val).isOk();\nexport fn has(arr: Array<int64>, val: int64) = indarrf(arr, val).isOk();\nexport fn has(arr: Array<float32>, val: float32) = indarrf(arr, val).isOk();\nexport fn has(arr: Array<float64>, val: float64) = indarrf(arr, val).isOk();\nexport fn has(arr: Array<bool>, val: bool) = indarrf(arr, val).isOk();\nexport fn length(arr: Array<any>) = lenarr(arr);\nexport fn push(arr: Array<any>, val: any) {\n  pusharr(arr, val, 0);\n  return arr;\n}\nexport fn push(arr: Array<int8>, val: int8) {\n  pusharr(arr, val, 8);\n  return arr;\n}\nexport fn push(arr: Array<int16>, val: int16) {\n  pusharr(arr, val, 8);\n  return arr;\n}\nexport fn push(arr: Array<int32>, val: int32) {\n  pusharr(arr, val, 8);\n  return arr;\n}\nexport fn push(arr: Array<int64>, val: int64) {\n  pusharr(arr, val, 8);\n  return arr;\n}\nexport fn push(arr: Array<float32>, val: float32) {\n  pusharr(arr, val, 8);\n  return arr;\n}\nexport fn push(arr: Array<float64>, val: float64) {\n  pusharr(arr, val, 8);\n  return arr;\n}\nexport fn push(arr: Array<bool>, val: bool) {\n  pusharr(arr, val, 8);\n  return arr;\n}\nexport fn pop(arr: Array<any>) = poparr(arr);\nexport each // parallel opcode with signature `fn each(arr: Array<any>, cb: function): void`\nexport fn eachLin(arr: Array<any>, cb: function): void = eachl(arr, cb);\nexport map // parallel opcode with signature `fn map(arr: Array<any>, cb: function): Array<any>`\nexport fn mapLin(arr: Array<any>, cb: function): Array<anythingElse> = mapl(arr, cb);\n/**\n * Unlike the other array functions, reduce is sequential by default and parallelism must be opted\n * in. This is due to the fact that parallelism requires the reducer function to be commutative or\n * associative, otherwise it will return different values on each run, and the compiler has no way\n * to guarantee that your reducer function is commutative or associative.\n *\n * There are four reduce functions instead of two as expected, because a reducer that reduces into\n * the same datatype requires less work than one that reduces into a new datatype. To reduce into a\n * new datatype you need an initial value in that new datatype that the reducer can provide to the\n * first reduction call to \"get the ball rolling.\" And there are extra constraints if you want the\n * reducer to run in parallel: that initial value will be used multiple times for each of the\n * parallel threads of computation, so that initial value has to be idempotent for it to work. Then\n * you're left with multiple reduced results that cannot be combined with each other with the main\n * reducer, so you need to provide a second reducer function that takes the resulting datatype and\n * can combine them with each other successfully, and that one *also* needs to be a commutative or\n * associative function.\n *\n * The complexities involved in writing a parallel reducer are why we decided to make the sequential\n * version the default, as the extra overhead is not something most developers are used to, whether\n * they hail from the functional programming world or the imperative world.\n *\n * On that note, you'll notice that the opcodes are named after `reduce` and `fold`. This is the\n * naming scheme that functional language programmers would be used to, but Java and Javascript\n * combined them both as `reduce`, so we have maintained that convention as we expect fewer people\n * needing to adapt to that change, it being a change they're likely already familiar with, and\n * noting that an extra argument that makes it equivalent to `fold` is easier than trying to find\n * the 3 or 4 arg variant under a different name.\n */\nexport fn reduce(arr: Array<any>, cb: function): any = reducel(arr, cb);\nexport fn reducePar(arr: Array<any>, cb: function): any = reducep(arr, cb);\n/**\n * This type is used to reduce the number of arguments passed to the opcodes, which can only take 2\n * arguments if they return a value, or 3 arguments if they are a side-effect-only opcode, and is an\n * implementation detail of the 3 and 4 arg reduce functions.\n */\ntype InitialReduce<T, U> {\n  arr: Array<T>,\n  initial: U,\n}\nexport fn reduce(arr: Array<any>, cb: function, initial: anythingElse): anythingElse {\n  const args = new InitialReduce<any, anythingElse> {\n    arr: arr,\n    initial: initial,\n  };\n  return foldl(args, cb);\n}\nexport fn reducePar(arr: Array<any>, transformer: function, merger: function, initial: anythingElse): anythingElse {\n  const args = new InitialReduce<any, anythingElse> {\n    arr: arr,\n    initial: initial,\n  };\n  const intermediate = foldp(args, transformer);\n  return reducep(intermediate, merger);\n}\nexport filter // opcode with signature `fn filter(arr: Array<any>, cb: function): Array<any>`\nexport find // opcode with signature `fn find(arr: Array<any>, cb: function): Result<any>`\nexport fn findLin(arr: Array<any>, cb: function): Result<any> = findl(arr, cb);\nexport every // parallel opcode with signature `fn every(arr: Array<any>, cb: function): bool`\nexport fn everyLin(arr: Array<any>, cb: function): bool = everyl(arr, cb);\nexport some // parallel opcode with signature `fn some(arr: Array<any>, cb: function): bool`\nexport fn someLin(arr: Array<any>, cb: function): bool = somel(arr, cb);\nexport join // opcode with signature `fn join(arr: Array<string>, sep: string): string`\nexport fn delete(arr: Array<any>, idx: int64): Result<any> = delindx(arr, idx);\nexport fn set(arr: Array<any>, idx: int64, val: any) {\n  if (idx < 0) | (idx > arr.length()) {\n    return err('array out-of-bounds access');\n  } else {\n    copytov(arr, idx, val);\n    return some(arr);\n  }\n}\nexport fn set(arr: Array<int8>, idx: int64, val: int8) {\n  if (idx < 0) | (idx > arr.length()) {\n    return err('array out-of-bounds access');\n  } else {\n    copytof(arr, idx, val);\n    return some(arr);\n  }\n}\nexport fn set(arr: Array<int16>, idx: int64, val: int16) {\n  if (idx < 0) | (idx > arr.length()) {\n    return err('array out-of-bounds access');\n  } else {\n    copytof(arr, idx, val);\n    return some(arr);\n  }\n}\nexport fn set(arr: Array<int32>, idx: int64, val: int32) {\n  if (idx < 0) | (idx > arr.length()) {\n    return err('array out-of-bounds access');\n  } else {\n    copytof(arr, idx, val);\n    return some(arr);\n  }\n}\nexport fn set(arr: Array<int64>, idx: int64, val: int64) {\n  if (idx < 0) | (idx > arr.length()) {\n    return err('array out-of-bounds access');\n  } else {\n    copytof(arr, idx, val);\n    return some(arr);\n  }\n}\nexport fn set(arr: Array<float32>, idx: int64, val: float32) {\n  if (idx < 0) | (idx > arr.length()) {\n    return err('array out-of-bounds access');\n  } else {\n    copytof(arr, idx, val);\n    return some(arr);\n  }\n}\nexport fn set(arr: Array<float64>, idx: int64, val: float64) {\n  if (idx < 0) | (idx > arr.length()) {\n    return err('array out-of-bounds access');\n  } else {\n    copytof(arr, idx, val);\n    return some(arr);\n  }\n}\nexport fn set(arr: Array<bool>, idx: int64, val: bool) {\n  if (idx < 0) | (idx > arr.length()) {\n    return err('array out-of-bounds access');\n  } else {\n    copytof(arr, idx, val);\n    return some(arr);\n  }\n}\n\n// Ternary functions\nexport fn pair(trueval: any, falseval: any) = new Array<any> [ trueval, falseval ];\nexport fn cond(c: bool, options: Array<any>) = getR(options[1.sub(c.toInt64())]);\nexport fn cond(c: bool, optional: function): void = condfn(c, optional);\n\n// \"clone\" function useful for hoisting assignments and making duplicates\nexport fn clone(a: any) = copyarr(a);\nexport fn clone(a: Array<any>) = copyarr(a);\nexport fn clone(a: void) = copyvoid(a); // TODO: Eliminate this, covering up a weird error\nexport fn clone() = zeroed(); // TODO: Used for conditionals, eliminate with more clever compiler\nexport fn clone(a: int8) = copyi8(a);\nexport fn clone(a: int16) = copyi16(a);\nexport fn clone(a: int32) = copyi32(a);\nexport fn clone(a: int64) = copyi64(a);\nexport fn clone(a: float32) = copyf32(a);\nexport fn clone(a: float64) = copyf64(a);\nexport fn clone(a: bool) = copybool(a);\nexport fn clone(a: string) = copystr(a);\n\n// Error, Maybe, Result, and Either types and functions\nexport error // opcode with signature `fn error(string): Error`\nexport fn ref(a: any) = refv(a);\nexport fn ref(a: void) = reff(a);\nexport fn ref(a: int8) = reff(a);\nexport fn ref(a: int16) = reff(a);\nexport fn ref(a: int32) = reff(a);\nexport fn ref(a: int64) = reff(a);\nexport fn ref(a: float32) = reff(a);\nexport fn ref(a: float64) = reff(a);\nexport fn ref(a: bool) = reff(a);\nexport noerr // opcode with signature `fn noerr(): Error`\nexport fn toString(err: Error) = errorstr(err);\n\nexport fn some(val: any) = someM(val, 0);\nexport fn some(val: int8) = someM(val, 8);\nexport fn some(val: int16) = someM(val, 8);\nexport fn some(val: int32) = someM(val, 8);\nexport fn some(val: int64) = someM(val, 8);\nexport fn some(val: float32) = someM(val, 8);\nexport fn some(val: float64) = someM(val, 8);\nexport fn some(val: bool) = someM(val, 8);\nexport fn none() = noneM();\nexport isSome // opcode with signature `fn isSome(Maybe<any>): bool`\nexport isNone // opcode with signature `fn isNone(Maybe<any>): bool`\nexport fn getOr(maybe: Maybe<any>, default: any) = getOrM(maybe, default);\n\nexport fn ok(val: any) = okR(val, 0);\nexport fn ok(val: int8) = okR(val, 8);\nexport fn ok(val: int16) = okR(val, 8);\nexport fn ok(val: int32) = okR(val, 8);\nexport fn ok(val: int64) = okR(val, 8);\nexport fn ok(val: float32) = okR(val, 8);\nexport fn ok(val: float64) = okR(val, 8);\nexport fn ok(val: bool) = okR(val, 8);\nexport err // opcode with signature `fn err(string): Result<any>`\nexport isOk // opcode with signature `fn isOk(Result<any>): bool`\nexport isErr // opcode with signature `fn isErr(Result<any>: bool`\nexport fn getOr(result: Result<any>, default: any) = getOrR(result, default);\nexport fn getOr(result: Result<any>, default: string) = getOrRS(result, default);\nexport getErr // opcode with signature `fn getErr(Result<any>, Error): Error`\nexport fn toString(n: Result<Stringifiable>): string {\n  if n.isOk() {\n    return n.getR().toString();\n  } else {\n    return n.getErr(noerr()).toString();\n  }\n}\nexport fn getOrExit(result: Result<any>): any {\n  if result.isErr() {\n    stderrp(result.toString());\n    exitop(1.toInt8());\n  } else {\n    return result.getR();\n  }\n}\n\nexport fn main(val: any) = mainE(val, 0);\nexport fn main(val: int8) = mainE(val, 8);\nexport fn main(val: int16) = mainE(val, 8);\nexport fn main(val: int32) = mainE(val, 8);\nexport fn main(val: int64) = mainE(val, 8);\nexport fn main(val: float32) = mainE(val, 8);\nexport fn main(val: float64) = mainE(val, 8);\nexport fn main(val: bool) = mainE(val, 8);\nexport fn alt(val: any) = altE(val, 0);\nexport fn alt(val: int8) = altE(val, 8);\nexport fn alt(val: int16) = altE(val, 8);\nexport fn alt(val: int32) = altE(val, 8);\nexport fn alt(val: int64) = altE(val, 8);\nexport fn alt(val: float32) = altE(val, 8);\nexport fn alt(val: float64) = altE(val, 8);\nexport fn alt(val: bool) = altE(val, 8);\nexport isMain // opcode with signature `fn isMain(Either<any, anythingElse>): bool`\nexport isAlt // opcode with signature `fn isAlt(Either<any, anythingElse): bool`\nexport fn getMainOr(either: Either<any, anythingElse>, default: any) = mainOr(either, default);\nexport fn getAltOr(either: Either<any, anythingElse>, default: anythingElse) = altOr(either, default);\n\n// toHash functions for all data types\nexport fn toHash(val: any) = hashv(val);\nexport fn toHash(val: int8) = hashf(val);\nexport fn toHash(val: int16) = hashf(val);\nexport fn toHash(val: int32) = hashf(val);\nexport fn toHash(val: int64) = hashf(val);\nexport fn toHash(val: float32) = hashf(val);\nexport fn toHash(val: float64) = hashf(val);\nexport fn toHash(val: bool) = hashf(val);\n\n// HashMap implementation\nexport type KeyVal<K, V> {\n  key: K,\n  val: V,\n}\n\nexport interface Hashable {\n  toHash(Hashable): int64,\n  eq(Hashable, Hashable): bool,\n}\n\nexport type HashMap<K, V> {\n  keyVal: Array<KeyVal<K, V>>,\n  lookup: Array<Array<int64>>,\n}\n\nexport fn keyVal(hm: HashMap<Hashable, any>) = hm.keyVal;\nexport fn keys(hm: HashMap<Hashable, any>): Array<Hashable> = map(hm.keyVal, fn (kv: KeyVal<Hashable, any>): Hashable = kv.key);\nexport fn vals(hm: HashMap<Hashable, any>): Array<any> = map(hm.keyVal, fn (kv: KeyVal<Hashable, any>): any = kv.val);\nexport fn length(hm: HashMap<Hashable, any>): int64 = length(hm.keyVal);\n\nexport fn get(hm: HashMap<Hashable, any>, key: Hashable): any {\n  const hash = key.toHash().abs() % length(hm.lookup);\n  const list = getR(hm.lookup[hash]);\n  const index = list.find(fn (i: int64): Array<int64> {\n    const kv = getR(hm.keyVal[i]);\n    return eq(kv.key, key);\n  });\n  if index.isOk() {\n    const i = index.getOr(0);\n    const kv = getR(hm.keyVal[i]);\n    return ok(kv.val);\n  } else {\n    return err('key not found');\n  }\n}\n\nexport fn set(hm: HashMap<Hashable, any>, key: Hashable, val: any): HashMap<Hashable, any> {\n  const kv = new KeyVal<Hashable, any> {\n    key: key,\n    val: val,\n  };\n  const index = length(hm.keyVal);\n  push(hm.keyVal, kv);\n  const hash = key.toHash().abs() % length(hm.lookup);\n  const list = getR(hm.lookup[hash]);\n  if list.length() == 8 {\n    // Rebucket everything\n    const lookupLen = length(hm.lookup) * 2;\n    hm.lookup = new Array<Array<int64>> [ new Array<int64> [], ] * lookupLen;\n    eachl(hm.keyVal, fn (kv: KeyVal<Hashable, any>, i: int64) {\n      const hash = toHash(kv.key).abs() % lookupLen;\n      const list = getR(hm.lookup[hash]);\n      list.push(i);\n    });\n  } else if list.find(fn (idx: int64): bool {\n    const rec = hm.keyVal[idx].getR();\n    return eq(rec.key, key);\n  }).isOk() {\n    list.eachLin(fn (idx: int64, i: int64) {\n      const rec = hm.keyVal[idx].getR();\n      if eq(rec.key, key) {\n        list[i] = index;\n      }\n    });\n  } else {\n    list.push(index);\n  }\n  return hm;\n}\n\nexport fn newHashMap(firstKey: Hashable, firstVal: any): HashMap<Hashable, any> { // TODO: Rust-like fn::<typeA, typeB> syntax?\n  let hm = new HashMap<Hashable, any> {\n    keyVal: new Array<KeyVal<Hashable, any>> [],\n    lookup: new Array<Array<int64>> [ new Array<int64> [] ] * 128, // 1KB of space\n  };\n  return hm.set(firstKey, firstVal);\n}\n\nexport fn toHashMap(kva: Array<KeyVal<Hashable, any>>) {\n  let hm = new HashMap<Hashable, any> {\n    keyVal: kva,\n    lookup: new Array<Array<int64>> [ new Array<int64> [] ] * 128,\n  };\n  kva.eachl(fn (kv: KeyVal<Hashable, any>, i: int64) {\n    const hash = toHash(kv.key).abs() % length(hm.lookup);\n    const list = getR(hm.lookup[hash]);\n    list.push(i);\n  });\n  return hm;\n}\n\n// Tree implementation\n\n// The Tree type houses all of the values attached to a tree in an array and two secondary arrays to\n// hold the metadata on which value is the parent and which are children, if any. The parent value\n// is `-1` if it has no parent and a positive integer otherwise.\nexport type Tree<T> {\n  vals: Array<T>,\n  parents: Array<int64>,\n  children: Array<Array<int64>>,\n}\n\n// The Node type simply holds the index to look into the tree for a particular value-parent-children\n// triplet, where that index is referred to as a node ID. This allows node-based code to be written\n// while not actually having a recursive data structure that a traditional Node type would define.\nexport type Node<T> {\n  id: int64,\n  tree: Tree<T>,\n}\n\nexport fn newTree(rootVal: any): Tree<any> = new Tree<any> {\n  vals: new Array<any> [ rootVal ],\n  parents: new Array<int64> [ -1 ], // The root node has no parent, so its parent ID is -1.\n  children: new Array<Array<int64>> [ new Array<int64> [ ] ],\n};\n\nexport fn getRootNode(t: Tree<any>): Node<any> {\n  if has(t.parents, -1) {\n    return new Node<any> {\n      id: index(t.parents, -1).getOr(0),\n      tree: t,\n    };\n  } else {\n    // Return an invalid node, will behave like an error result\n    return new Node<any> {\n      id: -1,\n      tree: new Tree<any> {\n        vals: new Array<any> [],\n        parents: new Array<int64> [],\n        children: new Array<Array<int64>> [],\n      },\n    };\n  }\n}\n\nexport fn getTree(n: Node<any>): Tree<any> = n.tree;\n\nexport fn length(t: Tree<any>): int64 = length(t.vals);\n\nexport fn getNodeById(t: Tree<any>, i: int64): Node<any> {\n  if length(t.vals).gt(i) {\n    return new Node<any> {\n      id: i,\n      tree: t,\n    };\n  } else {\n    // Return an invalid node, will behave like an error result\n    return new Node<any> {\n      id: -1,\n      tree: new Tree<any> {\n        vals: new Array<any> [],\n        parents: new Array<int64> [],\n        children: new Array<Array<int64>> [],\n      },\n    };\n  }\n}\n\nexport fn getParent(n: Node<any>): Node<any> {\n  const parentId = getOr(n.tree.parents[n.id], -1);\n  if parentId > -1 {\n    return new Node<any> {\n      id: parentId,\n      tree: n.tree,\n    };\n  } else {\n    // Return an invalid node, will behave like an error result\n    return new Node<any> {\n      id: -1,\n      tree: new Tree<any> {\n        vals: new Array<any> [],\n        parents: new Array<int64> [],\n        children: new Array<Array<int64>> [],\n      },\n    };\n  }\n}\n\nexport fn getChildren(n: Node<any>): Array<Node<any>> {\n  if length(n.tree.vals).gt(n.id) {\n    const childIds = getOr(n.tree.children[n.id], new Array<int64> []);\n    return childIds.filter(fn (id: int64): bool {\n      const parentId = getOr(n.tree.parents[id], -1);\n      return parentId.eq(n.id);\n    }).map(fn (id: int64): Node<any> {\n      return new Node<any> {\n        id: id,\n        tree: n.tree,\n      };\n    });\n  } else {\n    return new Array<Node<any>> [ ];\n  }\n}\n\n// Returns the pruned Tree\nexport fn prune(n: Node<any>): Tree<any> {\n  // adjust parent's children\n  const parentRes = n.tree.parents[n.id];\n  if parentRes.isOk() {\n    const parentId = parentRes.getR();\n    const children = getOr(n.tree.children[parentId], new Array<int64> []);\n    const idxRes = index(children, n.id);\n    if idxRes.isOk() {\n      delete(children, idxRes.getR());\n    }\n  }\n  // This is, unfortunately for now, a sequential algorithm. Hope to figure out a parallel version\n  let nodeStack = new Array<int64> [ n.id ];\n  let rmdIds = new Array<int64> [ ];\n  seqdo(newseq(pow(2, 62)), fn (): bool {\n    // Get the nodeId, exit if none left\n    const nodeRes = nodeStack.pop();\n    if nodeRes.isErr() {\n      return false;\n    }\n    const nodeId = nodeRes.getR();\n    // Push the children onto the stack to process if the node has them\n    const childrenRes = n.tree.children[nodeId];\n    if childrenRes.isOk() {\n      const childrenIds = childrenRes.getR();\n      nodeStack = nodeStack.concat(childrenIds);\n    }\n    const delIdx = nodeId - length(rmdIds);\n    delete(n.tree.vals, delIdx);\n    delete(n.tree.parents, delIdx);\n    delete(n.tree.children, delIdx);\n    push(rmdIds, nodeId);\n    return true;\n  });\n\n  // adjust indices for remaining elements\n  const iters = length(n.tree.parents);\n  seqeach(newseq(iters), fn (i: int64) {\n    const parentId = getOr(n.tree.parents[i], -1);\n    const parentDelta = rmdIds.filter(fn (rmId: int64): bool = parentId > rmId).length();\n    if parentDelta > 0 {\n      set(n.tree.parents, i, parentId - parentDelta);\n    }\n    const children = getOr(n.tree.children[i], new Array<int64> []);\n    const newChildren = children.map(fn (cId: int64): int64 {\n      const delta = rmdIds.filter(fn (rmdId: int64): bool = cId > rmdId).length();\n      if delta > 0 {\n        return cId - delta;\n      }\n      return cId;\n    });\n    set(n.tree.children, i, newChildren);\n  });\n  return n.tree;\n}\n\nexport fn getChildren(t: Tree<any>): Array<Node<any>> = t.getRootNode().getChildren();\n\n// returns the new child node added\nexport fn addChild(n: Node<any>, val: any): Node<any> {\n  const childId = length(n.tree.vals);\n  push(n.tree.vals, val);\n  push(n.tree.parents, n.id);\n  push(n.tree.children, new Array<int64> [ ]);\n  push(getOr(n.tree.children[n.id], new Array<int64> []), childId);\n  return new Node<any> {\n    id: childId,\n    tree: n.tree,\n  };\n}\n\nexport fn addChild(t: Tree<any>, val: any): Node<any> = t.getRootNode().addChild(val);\n\nexport fn addChild(t: Tree<any>, val: Node<any>): Node<any> = t.getRootNode().addChild(val);\n\nexport fn addChild(n: Node<any>, val: Tree<any>): Node<any> = n.addChild(val.getRootNode());\n\nexport fn getOr(n: Node<any>, default: any): any = getOr(n.tree.vals[n.id], default);\n\nexport fn toNodeArray(t: Tree<any>): Array<Node<any>> = map(\n  t.vals,\n  fn (val: any, i: int64): Node<any> = t.getNodeById(i)\n);\n\nexport fn map(t: Tree<any>, mapper: function): Tree<anythingElse> {\n  return new Tree<anythingElse> {\n    vals: t.toNodeArray().map(mapper),\n    parents: clone(t.parents),\n    children: clone(t.children),\n  };\n}\n\nexport fn some(t: Tree<any>, mapper: function): bool = t.toNodeArray().some(mapper);\n\nexport fn every(t: Tree<any>, mapper: function): bool = t.toNodeArray().every(mapper);\n\nexport fn reduce(t: Tree<any>, cb: function, initial: anythingElse): bool = t\n  .toNodeArray()\n  .reduce(cb, initial);\n\nexport fn find(t: Tree<any>, mapper: function): Node<any> {\n  // Return an invalid node, will behave like an error result\n  return t.toNodeArray().find(mapper).getOr(\n    new Node<any> {\n      id: -1,\n      tree: new Tree<any> {\n        vals: new Array<any> [],\n        parents: new Array<int64> [],\n        children: new Array<Array<int64>> [],\n      },\n    }\n  );\n}\n\n// Operator declarations\nexport infix add as + precedence 2\nexport infix concat as + precedence 2\nexport infix sub as - precedence 2\nexport prefix negate as - precedence 1\nexport infix mul as * precedence 3\nexport infix repeat as * precedence 3\nexport infix div as / precedence 3\nexport infix split as / precedence 3\nexport infix mod as % precedence 3\n// export infix template as % precedence 3\nexport infix pow as ** precedence 4\nexport infix and as & precedence 3\nexport infix and as && precedence 3\nexport infix or as | precedence 2\nexport infix or as || precedence 2\nexport infix xor as ^ precedence 2\nexport prefix not as ! precedence 4\nexport infix nand as !& precedence 3\nexport infix nor as !| precedence 2\nexport infix xnor as !^ precedence 2\nexport infix eq as == precedence 1\nexport infix neq as != precedence 1\nexport infix lt as < precedence 1\nexport infix lte as <= precedence 1\nexport infix gt as > precedence 1\nexport infix gte as >= precedence 1\nexport infix matches as ~ precedence 1\nexport infix index as @ precedence 1\nexport prefix length as # precedence 4\nexport prefix trim as ` precedence 4\nexport infix pair as : precedence 5\nexport infix push as : precedence 6\nexport infix cond as ? precedence 0\nexport infix getOr as | precedence 2\nexport infix getOr as || precedence 2\n","seq.ln":"/**\n * @std/seq - Tools for sequential algorithms. Use if you must.\n */\n\n// The `Seq` opaque type used by these algorithms to guarantee halting\nexport Seq\n\n// The `seq` constructor function\nexport fn seq(limit: int64): Seq = newseq(limit);\n\n// A basic iterator function, unlikely to be useful outside of these functions\nexport fn next(seq: Seq): Result<int64> = seqnext(seq);\n\n// An automatic iterator that executes the provided function in sequence until the limit is reached\nexport fn each(seq: Seq, func: function): void = seqeach(seq, func);\n\n// A while loop with an initial conditional check\nexport fn while(seq: Seq, condFn: function, bodyFn: function): void = seqwhile(seq, condFn, bodyFn);\n\n// A do-while loop that returns the conditional check\nexport fn doWhile(seq: Seq, bodyFn: function): void = seqdo(seq, bodyFn);\n\n// Recursive functions in Alan require a \"trampoline\" outside of the grammar of the language to work\n// so a special \"Self\" type exists that internally references the Seq type and the relevant function\n// and provides the mechanism to re-schedule the recursive function to call with a new argument.\nexport Self\n\n// There are two `recurse` functions. The first is on the `self` object that has an internal\n// reference to the relevant seq and recursive function to be called and is meant to be used within\n// the recursive function. The second sets it all off with a sequence operator, the recursive\n// function in question, and the query argument, and is using the first function under the hood.\nexport fn recurse(self: Self, arg: any): Result<anythingElse> = selfrec(self, arg);\nexport fn recurse(seq: Seq, recurseFn: function, arg: any): Result<anythingElse> {\n  let self = seqrec(seq, recurseFn);\n  return selfrec(self, arg);\n}\n\n// TODO: Add the generator piece of the seq rfc\n","trig.ln":"export const e = 2.718281828459045;\nexport const pi = 3.141592653589793;\nexport const tau = 6.283185307179586;\n\nexport fn exp(x: float64) = e ** x;\nexport fn exp(x: float32) = toFloat32(e) ** x;\n\nexport fn ln(x: float64) = lnf64(x);\nexport fn ln(x: float32) = toFloat32(lnf64(toFloat64(x)));\n\nexport fn log(x: float64) = logf64(x);\nexport fn log(x: float32) = toFloat32(logf64(toFloat64(x)));\n\nexport fn sin(x: float64) = sinf64(x);\nexport fn sin(x: float32) = toFloat32(sinf64(toFloat64(x)));\nexport fn sine(x: float64) = sinf64(x);\nexport fn sine(x: float32) = toFloat32(sinf64(toFloat64(x)));\n\nexport fn cos(x: float64) = cosf64(x);\nexport fn cos(x: float32) = toFloat32(cosf64(toFloat64(x)));\nexport fn cosine(x: float64) = cosf64(x);\nexport fn cosine(x: float32) = toFloat32(cosf64(toFloat64(x)));\n\nexport fn tan(x: float64) = tanf64(x);\nexport fn tan(x: float32) = toFloat32(tanf64(toFloat64(x)));\nexport fn tangent(x: float64) = tanf64(x);\nexport fn tangent(x: float32) = toFloat32(tanf64(toFloat64(x)));\n\nexport fn sec(x: float64) = 1.0 / cosf64(x);\nexport fn sec(x: float32) = toFloat32(sec(toFloat64(x)));\nexport fn secant(x: float64) = 1.0 / cosf64(x);\nexport fn secant(x: float32) = toFloat32(secant(toFloat64(x)));\n\nexport fn csc(x: float64) = 1.0 / sinf64(x);\nexport fn csc(x: float32) = toFloat32(csc(toFloat64(x)));\nexport fn cosecant(x: float64) = 1.0 / sinf64(x);\nexport fn cosecant(x: float32) = toFloat32(cosecant(toFloat64(x)));\n\nexport fn cot(x: float64) = 1.0 / tanf64(x);\nexport fn cot(x: float32) = toFloat32(cot(toFloat64(x)));\nexport fn cotangent(x: float64) = 1.0 / tanf64(x);\nexport fn cotangent(x: float32) = toFloat32(cotangent(toFloat64(x)));\n\nexport fn asin(x: float64) = asinf64(x);\nexport fn asin(x: float32) = toFloat32(asinf64(toFloat64(x)));\nexport fn arcsine(x: float64) = asinf64(x);\nexport fn arcsine(x: float32) = toFloat32(asinf64(toFloat64(x)));\n\nexport fn acos(x: float64) = acosf64(x);\nexport fn acos(x: float32) = toFloat32(acosf64(toFloat64(x)));\nexport fn arccosine(x: float64) = acosf64(x);\nexport fn arccosine(x: float32) = toFloat32(acosf64(toFloat64(x)));\n\nexport fn atan(x: float64) = atanf64(x);\nexport fn atan(x: float32) = toFloat32(atanf64(toFloat64(x)));\nexport fn arctangent(x: float64) = atanf64(x);\nexport fn arctangent(x: float32) = toFloat32(atanf64(toFloat64(x)));\n\nexport fn asec(x: float64) = acosf64(1.0 / x);\nexport fn asec(x: float32) = toFloat32(asec(toFloat64(x)));\nexport fn arcsecant(x: float64) = acosf64(1.0 / x);\nexport fn arcsecant(x: float32) = toFloat32(arcsecant(toFloat64(x)));\n\nexport fn acsc(x: float64) = asinf64(1.0 / x);\nexport fn acsc(x: float32) = toFloat32(acsc(toFloat64(x)));\nexport fn arccosecant(x: float64) = asinf64(1.0 / x);\nexport fn arccosecant(x: float32) = toFloat32(arccosecant(toFloat64(x)));\n\nexport fn acot(x: float64) = pi / 2.0 - atanf64(x);\nexport fn acot(x: float32) = toFloat32(acot(toFloat64(x)));\nexport fn arccotangent(x: float64) = pi / 2.0 - atanf64(x);\nexport fn arccotangent(x: float32) = toFloat32(arccotangent(toFloat64(x)));\n\nexport fn ver(x: float64) = 1.0 - cosf64(x);\nexport fn ver(x: float32) = toFloat32(ver(toFloat64(x)));\nexport fn versine(x: float64) = 1.0 - cosf64(x);\nexport fn versine(x: float32) = toFloat32(versine(toFloat64(x)));\n\nexport fn vcs(x: float64) = 1.0 + cosf64(x);\nexport fn vcs(x: float32) = toFloat32(vcs(toFloat64(x)));\nexport fn vercosine(x: float64) = 1.0 + cosf64(x);\nexport fn vercosine(x: float32) = toFloat32(vercosine(toFloat64(x)));\n\nexport fn cvs(x: float64) = 1.0 - sinf64(x);\nexport fn cvs(x: float32) = toFloat32(cvs(toFloat64(x)));\nexport fn coversine(x: float64) = 1.0 - sinf64(x);\nexport fn coversine(x: float32) = toFloat32(coversine(toFloat64(x)));\n\nexport fn cvc(x: float64) = 1.0 + sinf64(x);\nexport fn cvc(x: float32) = toFloat32(cvc(toFloat64(x)));\nexport fn covercosine(x: float64) = 1.0 + sinf64(x);\nexport fn covercosine(x: float32) = toFloat32(covercosine(toFloat64(x)));\n\nexport fn hav(x: float64) = versine(x) / 2.0;\nexport fn hav(x: float32) = toFloat32(hav(toFloat64(x)));\nexport fn haversine(x: float64) = versine(x) / 2.0;\nexport fn haversine(x: float32) = toFloat32(haversine(toFloat64(x)));\n\nexport fn hvc(x: float64) = vercosine(x) / 2.0;\nexport fn hvc(x: float32) = toFloat32(hvc(toFloat64(x)));\nexport fn havercosine(x: float64) = vercosine(x) / 2.0;\nexport fn havercosine(x: float32) = toFloat32(havercosine(toFloat64(x)));\n\nexport fn hcv(x: float64) = coversine(x) / 2.0;\nexport fn hcv(x: float32) = toFloat32(hcv(toFloat64(x)));\nexport fn hacoversine(x: float64) = coversine(x) / 2.0;\nexport fn hacoversine(x: float32) = toFloat32(hacoversine(toFloat64(x)));\n\nexport fn hcc(x: float64) = covercosine(x) / 2.0;\nexport fn hcc(x: float32) = toFloat32(hcc(toFloat64(x)));\nexport fn hacovercosine(x: float64) = covercosine(x) / 2.0;\nexport fn hacovercosine(x: float32) = toFloat32(hacovercosine(toFloat64(x)));\n\nexport fn exs(x: float64) = secant(x) - 1.0;\nexport fn exs(x: float32) = toFloat32(exs(toFloat64(x)));\nexport fn exsecant(x: float64) = secant(x) - 1.0;\nexport fn exsecant(x: float32) = toFloat32(exsecant(toFloat64(x)));\n\nexport fn exc(x: float64) = cosecant(x) - 1.0;\nexport fn exc(x: float32) = toFloat32(exc(toFloat64(x)));\nexport fn excosecant(x: float64) = cosecant(x) - 1.0;\nexport fn excosecant(x: float32) = toFloat32(excosecant(toFloat64(x)));\n\nexport fn crd(x: float64) = 2.0 * sine(x / 2.0);\nexport fn crd(x: float32) = toFloat32(crd(toFloat64(x)));\nexport fn chord(x: float64) = 2.0 * sine(x / 2.0);\nexport fn chord(x: float32) = toFloat32(chord(toFloat64(x)));\n\nexport fn aver(x: float64) = arccosine(1.0 - x);\nexport fn aver(x: float32) = toFloat32(aver(toFloat64(x)));\nexport fn arcversine(x: float64) = arccosine(1.0 - x);\nexport fn arcversine(x: float32) = toFloat32(arcversine(toFloat64(x)));\n\nexport fn avcs(x: float64) = arccosine(x - 1.0);\nexport fn avcs(x: float32) = toFloat32(avcs(toFloat64(x)));\nexport fn arcvercosine(x: float64) = arccosine(x - 1.0);\nexport fn arcvercosine(x: float32) = toFloat32(arcvercosine(toFloat64(x)));\n\nexport fn acvs(x: float64) = arcsine(1.0 - x);\nexport fn acvs(x: float32) = toFloat32(acvs(toFloat64(x)));\nexport fn arccoversine(x: float64) = arcsine(1.0 - x);\nexport fn arccoversine(x: float32) = toFloat32(arccoversine(toFloat64(x)));\n\nexport fn acvc(x: float64) = arcsine(x - 1.0);\nexport fn acvc(x: float32) = toFloat32(acvc(toFloat64(x)));\nexport fn arccovercosine(x: float64) = arcsine(x - 1.0);\nexport fn arccovercosine(x: float32) = toFloat32(arccovercosine(toFloat64(x)));\n\nexport fn ahav(x: float64) = arccosine(1.0 - 2.0 * x);\nexport fn ahav(x: float32) = toFloat32(ahav(toFloat64(x)));\nexport fn archaversine(x: float64) = arccosine(1.0 - 2.0 * x);\nexport fn archaversine(x: float32) = toFloat32(archaversine(toFloat64(x)));\n\nexport fn ahvc(x: float64) = arccosine(2.0 * x - 1.0);\nexport fn ahvc(x: float32) = toFloat32(ahvc(toFloat64(x)));\nexport fn archavercosine(x: float64) = arccosine(2.0 * x - 1.0);\nexport fn archavercosine(x: float32) = toFloat32(archavercosine(toFloat64(x)));\n\nexport fn ahcv(x: float64) = arcsine(1.0 - 2.0 * x);\nexport fn ahcv(x: float32) = toFloat32(ahcv(toFloat64(x)));\nexport fn archacoversine(x: float64) = arcsine(1.0 - 2.0 * x);\nexport fn archacoversine(x: float32) = toFloat32(archacoversine(toFloat64(x)));\n\nexport fn ahcc(x: float64) = arcsine(2.0 * x - 1.0);\nexport fn ahcc(x: float32) = toFloat32(ahcc(toFloat64(x)));\nexport fn archacovercosine(x: float64) = arcsine(2.0 * x - 1.0);\nexport fn archacovercosine(x: float32) = toFloat32(archacovercosine(toFloat64(x)));\n\nexport fn aexs(x: float64) = arccosine(1.0 / (x + 1.0));\nexport fn aexs(x: float32) = toFloat32(aexs(toFloat64(x)));\nexport fn arcexsecant(x: float64) = arccosine(1.0 / (x + 1.0));\nexport fn arcexsecant(x: float32) = toFloat32(arcexsecant(toFloat64(x)));\n\nexport fn aexc(x: float64) = arcsine(1.0 / (x + 1.0));\nexport fn aexc(x: float32) = toFloat32(aexc(toFloat64(x)));\nexport fn arcexcosecant(x: float64) = arcsine(1.0 / (x + 1.0));\nexport fn arcexcosecant(x: float32) = toFloat32(arcexcosecant(toFloat64(x)));\n\nexport fn acrd(x: float64) = 2.0 * arcsine(x / 2.0);\nexport fn acrd(x: float32) = toFloat32(acrd(toFloat64(x)));\nexport fn arcchord(x: float64) = 2.0 * arcsine(x / 2.0);\nexport fn arcchord(x: float32) = toFloat32(arcchord(toFloat64(x)));\n\nexport fn sinh(x: float64) = sinhf64(x);\nexport fn sinh(x: float32) = toFloat32(sinhf64(toFloat64(x)));\nexport fn hyperbolicSine(x: float64) = sinhf64(x);\nexport fn hyperbolicSine(x: float32) = toFloat32(sinhf64(toFloat64(x)));\n\nexport fn cosh(x: float64) = coshf64(x);\nexport fn cosh(x: float32) = toFloat32(coshf64(toFloat64(x)));\nexport fn hyperbolicCosine(x: float64) = coshf64(x);\nexport fn hyperbolicCosine(x: float32) = toFloat32(coshf64(toFloat64(x)));\n\nexport fn tanh(x: float64) = tanhf64(x);\nexport fn tanh(x: float32) = toFloat32(tanhf64(toFloat64(x)));\nexport fn hyperbolicTangent(x: float64) = tanhf64(x);\nexport fn hyperbolicTangent(x: float32) = toFloat32(tanhf64(toFloat64(x)));\n\nexport fn sech(x: float64) = 1.0 / cosh(x);\nexport fn sech(x: float32) = toFloat32(sech(toFloat64(x)));\nexport fn hyperbolicSecant(x: float64) = 1.0 / cosh(x);\nexport fn hyperbolicSecant(x: float32) = toFloat32(hyperbolicSecant(toFloat64(x)));\n\nexport fn csch(x: float64) = 1.0 / sinh(x);\nexport fn csch(x: float32) = toFloat32(cosh(toFloat64(x)));\nexport fn hyperbolicCosecant(x: float64) = 1.0 / sinh(x);\nexport fn hyperbolicCosecant(x: float32) = toFloat32(hyperbolicCosecant(toFloat64(x)));\n\nexport fn coth(x: float64) = 1.0 / tanh(x);\nexport fn coth(x: float32) = toFloat32(coth(toFloat64(x)));\nexport fn hyperbolicCotangent(x: float64) = 1.0 / tanh(x);\nexport fn hyperbolicCotangent(x: float32) = toFloat32(hyperbolicCotangent(toFloat64(x)));\n\nexport fn asinh(x: float64) = ln(x + sqrt(x ** 2.0 + 1.0));\nexport fn asinh(x: float32) = toFloat32(asinh(toFloat64(x)));\nexport fn hyperbolicArcsine(x: float64) = ln(x + sqrt(x ** 2.0 + 1.0));\nexport fn hyperbolicArcsine(x: float32) = toFloat32(hyperbolicArcsine(toFloat64(x)));\n\nexport fn acosh(x: float64) = ln(x + sqrt(x ** 2.0 - 1.0));\nexport fn acosh(x: float32) = toFloat32(acosh(toFloat64(x)));\nexport fn hyperbolicArccosine(x: float64) = ln(x + sqrt(x ** 2.0 - 1.0));\nexport fn hyperbolicArccosine(x: float32) = toFloat32(hyperbolicArccosine(toFloat64(x)));\n\nexport fn atanh(x: float64) = ln((x + 1.0) / (x - 1.0)) / 2.0;\nexport fn atanh(x: float32) = toFloat32(atanh(toFloat64(x)));\nexport fn hyperbolicArctangent(x: float64) = ln((x + 1.0) / (x - 1.0)) / 2.0;\nexport fn hyperbolicArctangent(x: float32) = toFloat32(hyperbolicArctangent(toFloat64(x)));\n\nexport fn asech(x: float64) = ln((1.0 + sqrt(1.0 - x ** 2.0)) / x);\nexport fn asech(x: float32) = toFloat32(asech(toFloat64(x)));\nexport fn hyperbolicArcsecant(x: float64) = ln((1.0 + sqrt(1.0 - x ** 2.0)) / x);\nexport fn hyperbolicArcsecant(x: float32) = toFloat32(hyperbolicArcsecant(toFloat64(x)));\n\nexport fn acsch(x: float64) = ln((1.0 / x) + sqrt(1.0 / x ** 2.0 + 1.0));\nexport fn acsch(x: float32) = toFloat32(acsch(toFloat64(x)));\nexport fn hyperbolicArccosecant(x: float64) = ln((1.0 / x) + sqrt(1.0 / x ** 2.0 + 1.0));\nexport fn hyperbolicArccosecant(x: float32) = toFloat32(hyperbolicArccosecant(toFloat64(x)));\n\nexport fn acoth(x: float64) = ln((x + 1.0) / (x - 1.0)) / 2.0;\nexport fn acoth(x: float32) = toFloat32(acoth(toFloat64(x)));\nexport fn hyperbolicArccotangent(x: float64) = ln((x + 1.0) / (x - 1.0)) / 2.0;\nexport fn hyperbolicArccotangent(x: float32) = toFloat32(hyperbolicArccotangent(toFloat64(x)));\n"}

},{}],3:[function(require,module,exports){
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const lp_1 = require("./lp");
// Defining AMM Tokens
const space = lp_1.Token.build(' ');
const blank = lp_1.OneOrMore.build(space);
const optblank = lp_1.ZeroOrOne.build(blank);
const newline = lp_1.Token.build('\n');
const whitespace = lp_1.OneOrMore.build(lp_1.Or.build([space, newline]));
const colon = lp_1.Token.build(':');
const under = lp_1.Token.build('_');
const negate = lp_1.Token.build('-');
const dot = lp_1.Token.build('.');
const eq = lp_1.Token.build('=');
const openParen = lp_1.Token.build('(');
const closeParen = lp_1.Token.build(')');
const openCurly = lp_1.Token.build('{');
const closeCurly = lp_1.Token.build('}');
const openCaret = lp_1.Token.build('<');
const closeCaret = lp_1.Token.build('>');
const comma = lp_1.Token.build(',');
const optcomma = lp_1.ZeroOrOne.build(comma);
const base10 = lp_1.CharSet.build('0', '9');
const natural = lp_1.OneOrMore.build(base10);
const integer = lp_1.And.build([lp_1.ZeroOrOne.build(negate), natural]);
const real = lp_1.And.build([integer, lp_1.ZeroOrOne.build(lp_1.And.build([dot, natural]))]);
const lower = lp_1.CharSet.build('a', 'z');
const upper = lp_1.CharSet.build('A', 'Z');
const variable = lp_1.And.build([
    lp_1.OneOrMore.build(lp_1.Or.build([under, lower, upper])),
    lp_1.ZeroOrMore.build(lp_1.Or.build([under, lower, upper, natural])),
]);
const exit = lp_1.Token.build('return');
const t = lp_1.Token.build('true');
const f = lp_1.Token.build('false');
const bool = lp_1.Or.build([t, f]);
const voidn = lp_1.Token.build('void');
const emit = lp_1.Token.build('emit');
const letn = lp_1.Token.build('let');
const constn = lp_1.Token.build('const');
const on = lp_1.Token.build('on');
const event = lp_1.Token.build('event');
const fn = lp_1.Token.build('fn');
const quote = lp_1.Token.build('"');
const escapeQuote = lp_1.Token.build('\\"');
const notQuote = lp_1.Not.build('"');
const str = lp_1.And.build([quote, lp_1.ZeroOrMore.build(lp_1.Or.build([escapeQuote, notQuote])), quote]);
const value = lp_1.NamedOr.build({ str, bool, real, integer, });
const decname = variable;
const typename = variable;
const typegenerics = lp_1.NamedAnd.build({
    openCaret,
    generics: lp_1.OneOrMore.build(lp_1.NamedAnd.build({
        a: optblank,
        fulltypename: new lp_1.NulLP(),
        optcomma,
        b: optblank,
    })),
    closeCaret,
});
const fulltypename = lp_1.Or.build([
    lp_1.NamedAnd.build({
        typename,
        opttypegenerics: lp_1.ZeroOrOne.build(lp_1.And.build([optblank, typegenerics])),
    }),
    voidn
]);
// Ugly hackery around circular dependency
typegenerics.and.generics.oneOrMore[0].and.fulltypename = fulltypename;
const emits = lp_1.NamedAnd.build({ emit, blank, variable, value: lp_1.ZeroOrOne.build(lp_1.NamedAnd.build({
        blank, variable
    })) });
const events = lp_1.NamedAnd.build({ event, blank, variable, a: optblank, colon, b: optblank, fulltypename });
const exits = lp_1.NamedAnd.build({ exit, blank, variable, a: optblank });
const calllist = lp_1.ZeroOrMore.build(lp_1.NamedAnd.build({ variable, optcomma, optblank }));
const calls = lp_1.NamedAnd.build({
    variable,
    a: optblank,
    openParen,
    b: optblank,
    calllist,
    c: optblank,
    closeParen
});
const assignables = lp_1.NamedOr.build({
    functions: new lp_1.NulLP(),
    calls,
    value,
    variable,
});
const constdeclaration = lp_1.NamedAnd.build({
    constn,
    a: blank,
    decname,
    b: optblank,
    colon,
    c: optblank,
    fulltypename,
    d: blank,
    eq,
    e: blank,
    assignables,
});
const letdeclaration = lp_1.NamedAnd.build({
    letn,
    a: blank,
    decname,
    b: optblank,
    colon,
    c: optblank,
    fulltypename,
    d: blank,
    eq,
    e: blank,
    assignables,
});
const declarations = lp_1.NamedOr.build({ constdeclaration, letdeclaration });
const assignments = lp_1.NamedAnd.build({ decname, a: blank, eq, b: blank, assignables, });
const statements = lp_1.OneOrMore.build(lp_1.NamedOr.build({
    declarations,
    assignments,
    calls,
    emits,
    exits,
    whitespace,
}));
const functionbody = lp_1.NamedAnd.build({
    openCurly,
    statements,
    closeCurly,
});
const arg = lp_1.NamedAnd.build({ variable, a: optblank, colon, b: optblank, fulltypename, });
const functions = lp_1.NamedAnd.build({
    fn,
    blank,
    openParen,
    args: lp_1.And.build([
        lp_1.ZeroOrMore.build(lp_1.NamedAnd.build({ arg, a: optblank, comma, b: optblank })),
        lp_1.ZeroOrOne.build(lp_1.NamedAnd.build({ arg, optblank, }))
    ]),
    closeParen,
    a: optblank,
    colon,
    b: optblank,
    fulltypename,
    c: optblank,
    functionbody,
});
assignables.or.functions = functions;
const handler = lp_1.NamedAnd.build({ on, a: blank, variable, b: blank, functions, });
const amm = lp_1.NamedAnd.build({
    a: optblank,
    globalMem: lp_1.ZeroOrMore.build(lp_1.Or.build([constdeclaration, whitespace])),
    eventDec: lp_1.ZeroOrMore.build(lp_1.Or.build([events, whitespace])),
    handlers: lp_1.OneOrMore.build(lp_1.Or.build([handler, whitespace])),
});
exports.default = amm;

},{"./lp":23}],4:[function(require,module,exports){
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.fromString = exports.fromFile = void 0;
const lp_1 = require("./lp");
const amm_1 = require("./amm");
// This project depends on BigNum and associated support in Node's Buffer, so must be >= Node 10.20
// and does not work in the browser. It would be possible to implement a browser-compatible version
// but there is no need for it and it would make it harder to work with.
const ceil8 = (n) => Math.ceil(n / 8) * 8;
const CLOSURE_ARG_MEM_START = BigInt(Math.pow(-2, 63));
const loadGlobalMem = (globalMemAst, addressMap) => {
    const globalMem = {};
    let currentOffset = -1;
    for (const globalConst of globalMemAst) {
        const rec = globalConst.get();
        if (!(rec instanceof lp_1.NamedAnd))
            continue;
        let val;
        switch (rec.get('fulltypename').t.trim()) {
            case "int64":
                val = rec.get('assignables').t.trim() + 'i64';
                globalMem[`@${currentOffset}`] = val;
                addressMap[rec.get('decname').t] = currentOffset;
                currentOffset -= 8;
                break;
            case "float64":
                val = rec.get('assignables').t.trim() + 'f64';
                globalMem[`@${currentOffset}`] = val;
                addressMap[rec.get('decname').t] = currentOffset;
                currentOffset -= 8;
                break;
            case "string":
                let str;
                try {
                    // Will fail on strings with escape chars
                    str = JSON.parse(rec.get('assignables').t.trim());
                }
                catch (e) {
                    // Hackery to get these strings to work
                    str = JSON.stringify(rec.get('assignables').t.trim().replace(/^["']/, '').replace(/["']$/, ''));
                }
                let len = ceil8(str.length) + 8;
                val = rec.get('assignables').t.trim();
                globalMem[`@${currentOffset}`] = val;
                addressMap[rec.get('decname').t] = currentOffset;
                currentOffset -= len;
                break;
            case "bool":
                val = rec.get('assignables').t.trim();
                globalMem[`@${currentOffset}`] = val;
                addressMap[rec.get('decname').t] = currentOffset;
                currentOffset -= 8;
                break;
            default:
                throw new Error(rec.get('fulltypename').t + ' not yet implemented');
        }
    }
    return globalMem;
};
const loadEventDecs = (eventAst) => {
    const eventMem = {};
    for (const evt of eventAst) {
        const rec = evt.get();
        if (!(rec instanceof lp_1.NamedAnd))
            continue;
        const evtName = rec.get('variable').t.trim();
        const evtSize = rec.get('fulltypename').t.trim() === 'void' ? 0 : [
            'int8', 'int16', 'int32', 'int64', 'float32', 'float64', 'bool',
        ].includes(rec.get('fulltypename').t.trim()) ? 8 : -1;
        eventMem[evtName] = evtSize;
    }
    return eventMem;
};
const getFunctionbodyMem = (functionbody) => {
    let memSize = 0;
    const addressMap = {};
    for (const statement of functionbody.get('statements').getAll()) {
        if (statement.has('declarations')) {
            if (statement.get('declarations').has('constdeclaration')) {
                if (statement.get('declarations').get('constdeclaration').get('assignables').has('functions')) {
                    // Because closures re-use their parent memory space, their own memory needs to be included
                    const closureMem = getFunctionbodyMem(statement
                        .get('declarations')
                        .get('constdeclaration')
                        .get('assignables')
                        .get('functions')
                        .get('functionbody'));
                    Object.keys(closureMem.addressMap).forEach(name => addressMap[name] = closureMem.addressMap[name] + memSize);
                    memSize += closureMem.memSize;
                }
                else {
                    addressMap[statement.get('declarations').get('constdeclaration').get('decname').t.trim()] = memSize;
                    memSize += 1;
                }
            }
            else {
                addressMap[statement.get('declarations').get('letdeclaration').get('decname').t.trim()] = memSize;
                memSize += 1;
            }
        }
    }
    return {
        memSize,
        addressMap,
    };
};
const getHandlersMem = (handlers) => handlers
    .map(h => h.get())
    .filter(h => h instanceof lp_1.NamedAnd)
    .map(handler => {
    const handlerMem = getFunctionbodyMem(handler.get('functions').get('functionbody'));
    let arg = handler.get('functions').get('args').get(0).get(0).get('arg');
    if (arg instanceof lp_1.NulLP) {
        arg = handler.get('functions').get('args').get(1).get('arg');
    }
    if (!(arg instanceof lp_1.NulLP)) {
        // Increase the memory usage and shift *everything* down, then add the new address
        handlerMem.memSize += 1;
        Object.keys(handlerMem.addressMap).forEach(name => handlerMem.addressMap[name] += 1);
        handlerMem.addressMap[arg.get('variable').t.trim()] = 0;
    }
    return handlerMem;
});
const closuresFromDeclaration = (declaration, closureMem, eventDecs, addressMap, 
// For each scope branch, determine a unique argument rereference so nested scopes can access
// parent scope arguments
argRerefOffset, scope) => {
    const name = declaration.get('constdeclaration').get('decname').t.trim();
    const fn = declaration.get('constdeclaration').get('assignables').get('functions');
    let fnArgs = [];
    fn.get('args').getAll()[0].getAll().forEach((argdef) => {
        fnArgs.push(argdef.get('arg').get('variable').t);
    });
    if (fn.get('args').getAll()[1].has()) {
        fnArgs.push(...fn.get('args').getAll()[1].getAll().map(t => t.get('variable').t));
        fnArgs = fnArgs.filter(t => t !== '');
    }
    fnArgs.forEach(arg => {
        addressMap[arg + name] = CLOSURE_ARG_MEM_START + BigInt(argRerefOffset);
        argRerefOffset++;
    });
    const allStatements = declaration
        .get('constdeclaration')
        .get('assignables')
        .get('functions')
        .get('functionbody')
        .get('statements')
        .getAll();
    const statements = allStatements.filter(statement => !(statement.has('declarations') &&
        statement.get('declarations').has('constdeclaration') &&
        statement.get('declarations').get('constdeclaration').get('assignables').has('functions')));
    const otherClosures = allStatements.filter(statement => statement.has('declarations') &&
        statement.get('declarations').has('constdeclaration') &&
        statement.get('declarations').get('constdeclaration').get('assignables').has('functions')).map(s => closuresFromDeclaration(s.get('declarations'), closureMem, eventDecs, addressMap, argRerefOffset, [name, ...scope,])).reduce((obj, rec) => ({
        ...obj,
        ...rec,
    }), {});
    eventDecs[name] = 0;
    return {
        [name]: {
            name,
            fn,
            statements,
            closureMem,
            scope: [name, ...scope,],
        },
        ...otherClosures,
    };
};
const extractClosures = (handlers, handlerMem, eventDecs, addressMap) => {
    let closures = {};
    let recs = handlers.filter(h => h.get() instanceof lp_1.NamedAnd);
    for (let i = 0; i < recs.length; i++) {
        const rec = recs[i].get();
        const closureMem = handlerMem[i];
        for (const statement of rec.get('functions').get('functionbody').get('statements').getAll()) {
            if (statement.has('declarations') &&
                statement.get('declarations').has('constdeclaration') &&
                statement.get('declarations').get('constdeclaration').get('assignables').has('functions')) {
                // It's a closure, first try to extract any inner closures it may have
                const innerClosures = closuresFromDeclaration(statement.get('declarations'), closureMem, eventDecs, addressMap, 5, []);
                closures = {
                    ...closures,
                    ...innerClosures,
                };
            }
        }
    }
    return Object.values(closures);
};
class Statement {
    constructor(fn, inArgs, outArg, line, deps) {
        this.fn = fn;
        this.inArgs = inArgs;
        this.outArg = outArg;
        this.line = line;
        this.deps = deps;
    }
    toString() {
        let s = '';
        if (this.outArg !== null) {
            s += `${this.outArg} = `;
        }
        s += `${this.fn}(${this.inArgs.join(', ')}) #${this.line}`;
        if (this.deps.length > 0) {
            s += ` <- [${this.deps.map(d => `#${d}`).join(', ')}]`;
        }
        return s;
    }
}
const loadStatements = (statements, localMem, globalMem, fn, fnName, isClosure, closureScope) => {
    let vec = [];
    let line = 0;
    let localMemToLine = {};
    statements = statements.filter(s => !s.has('whitespace'));
    let fnArgs = [];
    fn.get('args').getAll()[0].getAll().forEach((argdef) => {
        fnArgs.push(argdef.get('arg').get('variable').t);
    });
    if (fn.get('args').getAll()[1].has()) {
        fnArgs.push(...fn.get('args').getAll()[1].getAll().map(t => t.get('variable').t));
        fnArgs = fnArgs.filter(t => t !== '');
    }
    fnArgs.forEach((arg, i) => {
        if (globalMem.hasOwnProperty(arg + fnName)) {
            let resultAddress = globalMem[arg + fnName];
            let val = CLOSURE_ARG_MEM_START + BigInt(1) + BigInt(i);
            let s = new Statement('refv', [`@${val}`, '@0'], `@${resultAddress}`, line, []);
            vec.push(s);
            line += 1;
        }
    });
    for (let idx = 0; idx < statements.length; idx++) {
        const statement = statements[idx];
        if (statement.has('declarations') &&
            statement.get('declarations').has('constdeclaration') &&
            statement.get('declarations').get('constdeclaration').get('assignables').has('functions')) {
            // It's a closure, skip it
            continue;
        }
        const hasClosureArgs = isClosure && fnArgs.length > 0;
        let s;
        if (statement.has('declarations')) {
            const dec = statement.get('declarations').has('constdeclaration') ?
                statement.get('declarations').get('constdeclaration') :
                statement.get('declarations').get('letdeclaration');
            let resultAddress = localMem[dec.get('decname').t.trim()];
            localMemToLine[dec.get('decname').t.trim()] = line;
            const assignables = dec.get('assignables');
            if (assignables.has('functions')) {
                throw new Error("This shouldn't be possible!");
            }
            else if (assignables.has('calls')) {
                const call = assignables.get('calls');
                const fnName = call.get('variable').t.trim();
                const vars = (call.has('calllist') ? call.get('calllist').getAll() : []).map(v => v.get('variable').t.trim());
                const args = vars.map(v => {
                    if (localMem.hasOwnProperty(v)) {
                        return localMem[v];
                    }
                    else if (globalMem.hasOwnProperty(v)) {
                        return globalMem[v];
                    }
                    else if (Object.keys(globalMem).some(k => closureScope.map(s => v + s).includes(k))) {
                        return globalMem[closureScope.map(s => v + s).find(k => Object.keys(globalMem).includes(k))];
                    }
                    else if (hasClosureArgs) {
                        return CLOSURE_ARG_MEM_START + BigInt(1) + BigInt(fnArgs.indexOf(v));
                    }
                    else {
                        return v;
                    }
                }).map(a => typeof a === 'string' ? a : `@${a}`);
                while (args.length < 2)
                    args.push('@0');
                s = new Statement(fnName, args, `@${resultAddress}`, line, []);
            }
            else if (assignables.has('value')) {
                // Only required for `let` statements
                let fn;
                let val;
                switch (dec.get('fulltypename').t.trim()) {
                    case 'int64':
                        fn = 'seti64';
                        val = assignables.t + 'i64';
                        break;
                    case 'int32':
                        fn = 'seti32';
                        val = assignables.t + 'i32';
                        break;
                    case 'int16':
                        fn = 'seti16';
                        val = assignables.t + 'i16';
                        break;
                    case 'int8':
                        fn = 'seti8';
                        val = assignables.t + 'i8';
                        break;
                    case 'float64':
                        fn = 'setf64';
                        val = assignables.t + 'f64';
                        break;
                    case 'float32':
                        fn = 'setf32';
                        val = assignables.t + 'f32';
                        break;
                    case 'bool':
                        fn = 'setbool';
                        val = assignables.t === 'true' ? '1i8' : '0i8'; // Bools are bytes in the runtime
                        break;
                    case 'string':
                        fn = 'setestr';
                        val = '0i64';
                        break;
                    default:
                        throw new Error(`Unsupported variable type ${dec.get('fulltypename').t}`);
                }
                s = new Statement(fn, [val, '@0'], `@${resultAddress}`, line, []);
            }
            else if (assignables.has('variable')) {
                throw new Error('This should have been squashed');
            }
        }
        else if (statement.has('assignments')) {
            const asgn = statement.get('assignments');
            const resultAddress = localMem[asgn.get('decname').t.trim()];
            localMemToLine[resultAddress] = line;
            const assignables = asgn.get('assignables');
            if (assignables.has('functions')) {
                throw new Error("This shouldn't be possible!");
            }
            else if (assignables.has('calls')) {
                const call = assignables.get('calls');
                const fnName = call.get('variable').t.trim();
                const vars = (call.has('calllist') ? call.get('calllist').getAll() : []).map(v => v.get('variable').t.trim());
                const hasClosureArgs = isClosure && vars.length > 0;
                const args = vars.map(v => {
                    if (localMem.hasOwnProperty(v)) {
                        return localMem[v];
                    }
                    else if (globalMem.hasOwnProperty(v)) {
                        return globalMem[v];
                    }
                    else if (Object.keys(globalMem).some(k => closureScope.map(s => v + s).includes(k))) {
                        return globalMem[closureScope.map(s => v + s).find(k => Object.keys(globalMem).includes(k))];
                    }
                    else if (hasClosureArgs) {
                        return CLOSURE_ARG_MEM_START + BigInt(1) + BigInt(fnArgs.indexOf(v));
                    }
                    else
                        return v;
                }).map(a => typeof a === 'string' ? a : `@${a}`);
                while (args.length < 2)
                    args.push('@0');
                s = new Statement(fnName, args, `@${resultAddress}`, line, []);
            }
            else if (assignables.has('value')) {
                // Only required for `let` statements
                let fn;
                let val;
                // TODO: Relying on little-endian trimming integers correctly and doesn't support float32
                // correctly. Need to find the correct type data from the original variable.
                const valStr = assignables.t;
                if (valStr[0] === '"' || valStr[0] === "'") { // It's a string, which doesn't work here...
                    fn = 'setestr';
                    val = '0i64';
                }
                else if (valStr[0] === 't' || valStr[0] === 'f') { // It's a bool
                    fn = 'setbool';
                    val = assignables.t === 'true' ? '1i8' : '0i8'; // Bools are bytes in the runtime
                }
                else if (valStr.indexOf('.') > -1) { // It's a floating point number, assume 64-bit
                    fn = 'setf64';
                    val = valStr + 'f64';
                }
                else { // It's an integer. i64 will "work" for now
                    fn = 'seti64';
                    val = valStr + 'i64';
                }
                s = new Statement(fn, [val, '@0'], `@${resultAddress}`, line, []);
            }
            else if (assignables.has('variable')) {
                throw new Error('This should have been squashed');
            }
        }
        else if (statement.has('calls')) {
            const call = statement.get('calls');
            const fnName = call.get('variable').t.trim();
            const vars = (call.has('calllist') ? call.get('calllist').getAll() : []).map(v => v.get('variable').t.trim());
            const hasClosureArgs = isClosure && vars.length > 0;
            const args = vars.map(v => {
                if (localMem.hasOwnProperty(v)) {
                    return localMem[v];
                }
                else if (globalMem.hasOwnProperty(v)) {
                    return globalMem[v];
                }
                else if (Object.keys(globalMem).some(k => closureScope.map(s => v + s).includes(k))) {
                    return globalMem[closureScope.map(s => v + s).find(k => Object.keys(globalMem).includes(k))];
                }
                else if (hasClosureArgs) {
                    return CLOSURE_ARG_MEM_START + BigInt(1) + BigInt(fnArgs.indexOf(v));
                }
                else
                    return v;
            }).map(a => typeof a === 'string' ? a : `@${a}`);
            while (args.length < 3)
                args.push('@0');
            s = new Statement(fnName, args, null, line, []);
        }
        else if (statement.has('emits')) {
            const emit = statement.get('emits');
            const evtName = emit.get('variable').t.trim();
            const payloadVar = emit.has('value') ? emit.get('value').t.trim() : undefined;
            const payload = !payloadVar ?
                0 :
                localMem.hasOwnProperty(payloadVar) ?
                    localMem[payloadVar] :
                    globalMem.hasOwnProperty(payloadVar) ?
                        globalMem[payloadVar] :
                        payloadVar;
            s = new Statement('emit', [evtName, typeof payload === 'string' ? payload : `@${payload}`], null, line, []);
        }
        else if (statement.has('exits')) {
            const exit = statement.get('exits');
            const exitVar = exit.get('variable').t.trim();
            let exitVarType = localMem.hasOwnProperty(exitVar) ? 'variable' : (globalMem.hasOwnProperty(exitVar) && typeof globalMem[exitVar] !== 'string' ?
                'fixed' : 'variable');
            const vars = [exitVar];
            const args = vars.map(v => {
                if (localMem.hasOwnProperty(v)) {
                    return localMem[v];
                }
                else if (globalMem.hasOwnProperty(v)) {
                    return globalMem[v];
                }
                else if (Object.keys(globalMem).some(k => closureScope.map(s => v + s).includes(k))) {
                    return globalMem[closureScope.map(s => v + s).find(k => Object.keys(globalMem).includes(k))];
                }
                else if (hasClosureArgs) {
                    return CLOSURE_ARG_MEM_START + BigInt(1) + BigInt(fnArgs.indexOf(v));
                }
                else
                    return v;
            }).map(a => typeof a === 'string' ? a : `@${a}`);
            while (args.length < 2)
                args.push('@0');
            const ref = exitVarType === 'variable' ? 'refv' : 'reff';
            s = new Statement(ref, args, `@${CLOSURE_ARG_MEM_START}`, line, []);
        }
        vec.push(s);
        line += 1;
    }
    return vec;
};
class Block {
    constructor(type, name, memSize, statements, deps) {
        this.type = type;
        this.name = name;
        this.memSize = memSize;
        this.statements = statements;
        this.deps = deps;
    }
    toString() {
        let b = `${this.type} for ${this.name} with size ${this.memSize}\n`;
        this.statements.forEach(s => b += `  ${s.toString()}\n`);
        return b;
    }
}
const loadHandlers = (handlers, handlerMem, globalMem) => {
    const vec = [];
    const recs = handlers.filter(h => h.get() instanceof lp_1.NamedAnd);
    for (let i = 0; i < recs.length; i++) {
        const handler = recs[i].get();
        const eventName = handler.get('variable').t.trim();
        const memSize = handlerMem[i].memSize;
        const localMem = handlerMem[i].addressMap;
        const h = new Block('handler', eventName, memSize, loadStatements(handler.get('functions').get('functionbody').get('statements').getAll(), localMem, globalMem, handler.get('functions'), eventName, false, []), []);
        vec.push(h);
    }
    return vec;
};
const loadClosures = (closures, globalMem) => {
    const vec = [];
    for (let i = 0; i < closures.length; i++) {
        const closure = closures[i];
        const eventName = closure.name;
        const memSize = closure.closureMem.memSize;
        const localMem = closure.closureMem.addressMap;
        const c = new Block('closure', eventName, memSize, loadStatements(closure.statements, localMem, globalMem, closure.fn, eventName, true, closure.scope), []);
        vec.push(c);
    }
    return vec;
};
// Perform basic dependency stitching within a single block, but also attach unknown dependencies
// to the block object for later "stitching"
const innerBlockDeps = (block) => {
    const depMap = {};
    let lastEmit = null;
    const statements = block.statements;
    for (const s of statements) {
        for (const a of s.inArgs) {
            if (depMap.hasOwnProperty(a)) {
                s.deps.push(depMap[a]);
            }
            else if (/^@/.test(a)) {
                block.deps.push(a);
            }
        }
        if (s.fn === 'emit') {
            if (lastEmit !== null) {
                s.deps.push(lastEmit);
            }
            lastEmit = s.line;
        }
        if (s.outArg !== null) {
            depMap[s.outArg] = s.line;
        }
    }
    return block;
};
// Use the unknown dependencies attached to the block scope and attach them in the outer level
// TODO: Handle dependencies many nested levels deep, perhaps with an iterative approach?
const closureDeps = (blocks) => {
    const blockMap = {};
    for (const b of blocks) {
        blockMap[b.name] = b;
    }
    const blockNames = Object.keys(blockMap);
    for (const b of blocks) {
        let argMap = {};
        for (const s of b.statements) {
            if (s.outArg !== null) {
                argMap[s.outArg] = s.line;
            }
            for (const a of s.inArgs) {
                if (blockNames.includes(a)) {
                    const blockDeps = blockMap[a].deps;
                    for (const bd of blockDeps) {
                        if (argMap.hasOwnProperty(bd)) {
                            s.deps.push(argMap[bd]);
                        }
                    }
                }
            }
            s.deps = [...new Set(s.deps)]; // Dedupe the final dependencies list
        }
    }
    return blocks;
};
const ammToAga = (amm) => {
    // Declare the AGA header
    let outStr = 'Alan Graphcode Assembler v0.0.1\n\n';
    // Get the global memory and the memory address map (var name to address ID)
    const addressMap = {};
    const globalMem = loadGlobalMem(amm.get('globalMem').getAll(), addressMap);
    if (Object.keys(globalMem).length > 0) {
        // Output the global memory
        outStr += 'globalMem\n';
        Object.keys(globalMem).forEach(addr => outStr += `  ${addr}: ${globalMem[addr]}\n`);
        outStr += '\n';
    }
    // Load the events, get the event id offset (for reuse with closures) and the event declarations
    let eventDecs = loadEventDecs(amm.get('eventDec').getAll());
    // Determine the amount of memory to allocate per handler and map declarations to addresses
    const handlerMem = getHandlersMem(amm.get('handlers').getAll());
    const closures = extractClosures(amm.get('handlers').getAll(), handlerMem, eventDecs, addressMap);
    // Make sure closures are accessible as addresses for statements to use
    closures.forEach((c) => addressMap[c.name] = c.name);
    // Then output the custom events, which may include closures, if needed
    if (Object.keys(eventDecs).length > 0) {
        outStr += 'customEvents\n';
        Object.keys(eventDecs).forEach(evt => outStr += `  ${evt}: ${eventDecs[evt]}\n`);
        outStr += '\n';
    }
    // Load the handlers and load the closures (as handlers) if present
    const handlerVec = loadHandlers(amm.get('handlers').getAll(), handlerMem, addressMap);
    const closureVec = loadClosures(closures, addressMap);
    const blockVec = closureDeps([...handlerVec, ...closureVec].map(b => innerBlockDeps(b)))
        .map(b => b.toString());
    outStr += blockVec.join('\n');
    return outStr;
};
exports.fromFile = (filename) => {
    const lp = new lp_1.LP(filename);
    const ast = amm_1.default.apply(lp);
    if (ast instanceof Error) {
        throw ast;
    }
    return ammToAga(ast);
};
exports.fromString = (str) => {
    const lp = lp_1.LP.fromText(str);
    const ast = amm_1.default.apply(lp);
    if (ast instanceof Error) {
        throw ast;
    }
    return ammToAga(ast);
};

},{"./amm":3,"./lp":23}],5:[function(require,module,exports){
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.fromString = exports.fromFile = void 0;
const alan_js_runtime_1 = require("alan-js-runtime");
const lp_1 = require("./lp");
const amm_1 = require("./amm");
const callToJsText = (call) => {
    const args = call.has('calllist') ?
        call.get('calllist').getAll().map(r => r.get('variable').t).join(', ') : "";
    const opcode = call.get('variable').t;
    return alan_js_runtime_1.asyncopcodes.includes(opcode) ? `await r.${opcode}(${args})` : `r.${opcode}(${args})`;
};
const functionbodyToJsText = (fnbody, indent) => {
    let outText = "";
    for (const statement of fnbody.get('statements').getAll()) {
        outText += indent + "  "; // For legibility of the output
        if (statement.has('declarations')) {
            if (statement.get('declarations').has('constdeclaration')) {
                const dec = statement.get('declarations').get('constdeclaration');
                outText += `const ${dec.get('decname').t} = ${assignableToJsText(dec.get('assignables'), indent)}\n`;
            }
            else if (statement.get('declarations').has('letdeclaration')) {
                const dec = statement.get('declarations').get('letdeclaration');
                outText += `let ${dec.get('decname').t} = ${assignableToJsText(dec.get('assignables'), indent)}\n`;
            }
        }
        else if (statement.has('assignments')) {
            const assign = statement.get('assignments');
            outText += `${assign.get('decname').t} = ${assignableToJsText(assign.get('assignables'), indent)}\n`;
        }
        else if (statement.has('calls')) {
            outText += `${callToJsText(statement.get('calls'))}\n`;
        }
        else if (statement.has('emits')) {
            const emit = statement.get('emits');
            const name = emit.get('variable').t;
            const arg = emit.has('value') ? emit.get('value').get('variable').t : 'undefined';
            outText += `r.emit('${name}', ${arg})\n`;
        }
        else if (statement.has('exits')) {
            outText += `${statement.get('exits').t.trim()}\n`;
        }
    }
    return outText;
};
const assignableToJsText = (assignable, indent) => {
    let outText = "";
    if (assignable.has('functions')) {
        const args = assignable.get('functions').get('args');
        const argnames = [];
        for (const arg of args.get(0).getAll()) {
            argnames.push(arg.get('arg').get('variable').t);
        }
        if (args.get(1)) {
            argnames.push(args.get(1).get('arg').get('variable').t);
        }
        outText += `async (${argnames.join(', ')}) => {\n`;
        outText += functionbodyToJsText(assignable.get('functions').get('functionbody'), indent + "  ");
        outText += indent + '  }'; // End this closure
    }
    else if (assignable.has('calls')) {
        outText += callToJsText(assignable.get('calls'));
    }
    else if (assignable.has('variable')) {
        outText += assignable.get('variable').t;
    }
    else if (assignable.has('value')) {
        outText += assignable.get('value').t;
    }
    return outText;
};
const ammToJsText = (amm) => {
    let outFile = "const r = require('alan-js-runtime')\n";
    // Where we're going we don't need types, so skipping that entire section
    // First convert all of the global constants to javascript
    for (const globalConst of amm.get('globalMem').getAll()) {
        const rec = globalConst.get();
        if (!(rec instanceof lp_1.NamedAnd))
            continue;
        outFile +=
            `const ${rec.get('decname').t} = ${assignableToJsText(rec.get('assignables'), '')}\n`;
    }
    // We can also skip the event declarations because they are lazily bound by EventEmitter
    // Now we convert the handlers to Javascript. This is the vast majority of the work
    for (const handler of amm.get('handlers').getAll()) {
        const rec = handler.get();
        if (!(rec instanceof lp_1.NamedAnd))
            continue;
        let arg = rec.get('functions').get('args').get(0).get(0).get('arg');
        if (arg instanceof lp_1.NulLP) {
            arg = rec.get('functions').get('args').get(1).get('arg');
        }
        const eventVarName = !(arg instanceof lp_1.NulLP) ?
            arg.get('variable').t : "";
        outFile += `r.on('${rec.get('variable').t}', async (${eventVarName}) => {\n`;
        outFile += functionbodyToJsText(rec.get('functions').get('functionbody'), '');
        outFile += '})\n'; // End this handler
    }
    outFile += "r.emit('_start', undefined)\n"; // Let's get it started in here
    return outFile;
};
exports.fromFile = (filename) => {
    const lp = new lp_1.LP(filename);
    const ast = amm_1.default.apply(lp);
    if (ast instanceof Error) {
        throw ast;
    }
    return ammToJsText(ast);
};
exports.fromString = (str) => {
    const lp = lp_1.LP.fromText(str);
    const ast = amm_1.default.apply(lp);
    if (ast instanceof Error) {
        throw ast;
    }
    return ammToJsText(ast);
};

},{"./amm":3,"./lp":23,"alan-js-runtime":"alan-js-runtime"}],6:[function(require,module,exports){
// Generated from Ln.g4 by ANTLR 4.7.2
// jshint ignore: start
var antlr4 = require('antlr4/index');
var serializedATN = ["\u0003\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964",
    "\u0002/\u015f\b\u0001\u0004\u0002\t\u0002\u0004\u0003\t\u0003\u0004",
    "\u0004\t\u0004\u0004\u0005\t\u0005\u0004\u0006\t\u0006\u0004\u0007\t",
    "\u0007\u0004\b\t\b\u0004\t\t\t\u0004\n\t\n\u0004\u000b\t\u000b\u0004",
    "\f\t\f\u0004\r\t\r\u0004\u000e\t\u000e\u0004\u000f\t\u000f\u0004\u0010",
    "\t\u0010\u0004\u0011\t\u0011\u0004\u0012\t\u0012\u0004\u0013\t\u0013",
    "\u0004\u0014\t\u0014\u0004\u0015\t\u0015\u0004\u0016\t\u0016\u0004\u0017",
    "\t\u0017\u0004\u0018\t\u0018\u0004\u0019\t\u0019\u0004\u001a\t\u001a",
    "\u0004\u001b\t\u001b\u0004\u001c\t\u001c\u0004\u001d\t\u001d\u0004\u001e",
    "\t\u001e\u0004\u001f\t\u001f\u0004 \t \u0004!\t!\u0004\"\t\"\u0004#",
    "\t#\u0004$\t$\u0004%\t%\u0004&\t&\u0004\'\t\'\u0004(\t(\u0004)\t)\u0004",
    "*\t*\u0004+\t+\u0004,\t,\u0004-\t-\u0004.\t.\u0003\u0002\u0003\u0002",
    "\u0003\u0002\u0003\u0002\u0003\u0002\u0003\u0002\u0003\u0002\u0003\u0003",
    "\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0004\u0003\u0004",
    "\u0003\u0004\u0003\u0004\u0003\u0004\u0003\u0005\u0003\u0005\u0003\u0005",
    "\u0003\u0006\u0003\u0006\u0003\u0006\u0003\u0006\u0003\u0006\u0003\u0006",
    "\u0003\u0007\u0003\u0007\u0003\u0007\u0003\b\u0003\b\u0003\b\u0003\b",
    "\u0003\b\u0003\b\u0003\b\u0003\t\u0003\t\u0003\t\u0003\t\u0003\t\u0003",
    "\t\u0003\n\u0003\n\u0003\n\u0003\n\u0003\u000b\u0003\u000b\u0003\u000b",
    "\u0003\u000b\u0003\u000b\u0003\u000b\u0003\u000b\u0003\f\u0003\f\u0003",
    "\f\u0003\f\u0003\f\u0003\r\u0003\r\u0003\r\u0003\u000e\u0003\u000e\u0003",
    "\u000e\u0003\u000e\u0003\u000e\u0003\u000e\u0003\u000e\u0003\u000e\u0003",
    "\u000e\u0005\u000e\u00a4\n\u000e\u0003\u000f\u0003\u000f\u0003\u000f",
    "\u0003\u000f\u0003\u000f\u0003\u000f\u0003\u000f\u0003\u0010\u0003\u0010",
    "\u0003\u0010\u0003\u0010\u0003\u0010\u0003\u0010\u0003\u0011\u0003\u0011",
    "\u0003\u0011\u0003\u0011\u0003\u0011\u0003\u0011\u0003\u0011\u0003\u0011",
    "\u0003\u0011\u0003\u0011\u0003\u0011\u0003\u0012\u0003\u0012\u0003\u0012",
    "\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0014",
    "\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0015\u0003\u0015\u0003\u0015",
    "\u0003\u0015\u0003\u0015\u0003\u0015\u0003\u0015\u0003\u0015\u0003\u0015",
    "\u0003\u0015\u0003\u0016\u0003\u0016\u0007\u0016\u00d6\n\u0016\f\u0016",
    "\u000e\u0016\u00d9\u000b\u0016\u0003\u0017\u0003\u0017\u0003\u0018\u0003",
    "\u0018\u0003\u0019\u0003\u0019\u0003\u001a\u0003\u001a\u0003\u001b\u0003",
    "\u001b\u0003\u001c\u0003\u001c\u0003\u001d\u0003\u001d\u0003\u001e\u0003",
    "\u001e\u0003\u001f\u0003\u001f\u0003 \u0003 \u0003!\u0003!\u0003\"\u0003",
    "\"\u0003\"\u0003#\u0003#\u0003#\u0003#\u0003$\u0003$\u0003%\u0003%\u0003",
    "&\u0003&\u0003\'\u0003\'\u0003\'\u0005\'\u0101\n\'\u0003(\u0006(\u0104",
    "\n(\r(\u000e(\u0105\u0003)\u0003)\u0003)\u0003)\u0006)\u010c\n)\r)\u000e",
    ")\u010d\u0003)\u0003)\u0003*\u0003*\u0003*\u0003*\u0003*\u0003*\u0007",
    "*\u0118\n*\f*\u000e*\u011b\u000b*\u0003*\u0003*\u0003*\u0003*\u0003",
    "*\u0003+\u0003+\u0007+\u0124\n+\f+\u000e+\u0127\u000b+\u0003+\u0003",
    "+\u0003+\u0007+\u012c\n+\f+\u000e+\u012f\u000b+\u0003+\u0005+\u0132",
    "\n+\u0003,\u0003,\u0003,\u0003,\u0006,\u0138\n,\r,\u000e,\u0139\u0003",
    ",\u0005,\u013d\n,\u0003,\u0006,\u0140\n,\r,\u000e,\u0141\u0003,\u0003",
    ",\u0006,\u0146\n,\r,\u000e,\u0147\u0005,\u014a\n,\u0005,\u014c\n,\u0003",
    "-\u0003-\u0007-\u0150\n-\f-\u000e-\u0153\u000b-\u0003.\u0006.\u0156",
    "\n.\r.\u000e.\u0157\u0003.\u0007.\u015b\n.\f.\u000e.\u015e\u000b.\u0002",
    "\u0002/\u0003\u0003\u0005\u0004\u0007\u0005\t\u0006\u000b\u0007\r\b",
    "\u000f\t\u0011\n\u0013\u000b\u0015\f\u0017\r\u0019\u000e\u001b\u000f",
    "\u001d\u0010\u001f\u0011!\u0012#\u0013%\u0014\'\u0015)\u0016+\u0017",
    "-\u0018/\u00191\u001a3\u001b5\u001c7\u001d9\u001e;\u001f= ?!A\"C#E$",
    "G%I&K\'M(O)Q*S+U,W-Y.[/\u0003\u0002\u0010\u0004\u0002\f\f\u000f\u000f",
    "\u0004\u0002\u000b\u000b\"\"\u0003\u000211\u0003\u0002,,\u0003\u0002",
    "$$\u0003\u0002))\u0005\u00022;CHch\u0003\u0002//\u0003\u00022;\u0003",
    "\u000200\r\u0002##%(,-/1<<>?AB``bb~~\u0080\u0080\f\u0002##%(,-/1<<>",
    "B``bb~~\u0080\u0080\u0005\u0002C\\aac|\u0006\u00022;C\\aac|\u0002\u0171",
    "\u0002\u0003\u0003\u0002\u0002\u0002\u0002\u0005\u0003\u0002\u0002\u0002",
    "\u0002\u0007\u0003\u0002\u0002\u0002\u0002\t\u0003\u0002\u0002\u0002",
    "\u0002\u000b\u0003\u0002\u0002\u0002\u0002\r\u0003\u0002\u0002\u0002",
    "\u0002\u000f\u0003\u0002\u0002\u0002\u0002\u0011\u0003\u0002\u0002\u0002",
    "\u0002\u0013\u0003\u0002\u0002\u0002\u0002\u0015\u0003\u0002\u0002\u0002",
    "\u0002\u0017\u0003\u0002\u0002\u0002\u0002\u0019\u0003\u0002\u0002\u0002",
    "\u0002\u001b\u0003\u0002\u0002\u0002\u0002\u001d\u0003\u0002\u0002\u0002",
    "\u0002\u001f\u0003\u0002\u0002\u0002\u0002!\u0003\u0002\u0002\u0002",
    "\u0002#\u0003\u0002\u0002\u0002\u0002%\u0003\u0002\u0002\u0002\u0002",
    "\'\u0003\u0002\u0002\u0002\u0002)\u0003\u0002\u0002\u0002\u0002+\u0003",
    "\u0002\u0002\u0002\u0002-\u0003\u0002\u0002\u0002\u0002/\u0003\u0002",
    "\u0002\u0002\u00021\u0003\u0002\u0002\u0002\u00023\u0003\u0002\u0002",
    "\u0002\u00025\u0003\u0002\u0002\u0002\u00027\u0003\u0002\u0002\u0002",
    "\u00029\u0003\u0002\u0002\u0002\u0002;\u0003\u0002\u0002\u0002\u0002",
    "=\u0003\u0002\u0002\u0002\u0002?\u0003\u0002\u0002\u0002\u0002A\u0003",
    "\u0002\u0002\u0002\u0002C\u0003\u0002\u0002\u0002\u0002E\u0003\u0002",
    "\u0002\u0002\u0002G\u0003\u0002\u0002\u0002\u0002I\u0003\u0002\u0002",
    "\u0002\u0002K\u0003\u0002\u0002\u0002\u0002M\u0003\u0002\u0002\u0002",
    "\u0002O\u0003\u0002\u0002\u0002\u0002Q\u0003\u0002\u0002\u0002\u0002",
    "S\u0003\u0002\u0002\u0002\u0002U\u0003\u0002\u0002\u0002\u0002W\u0003",
    "\u0002\u0002\u0002\u0002Y\u0003\u0002\u0002\u0002\u0002[\u0003\u0002",
    "\u0002\u0002\u0003]\u0003\u0002\u0002\u0002\u0005d\u0003\u0002\u0002",
    "\u0002\u0007i\u0003\u0002\u0002\u0002\tn\u0003\u0002\u0002\u0002\u000b",
    "q\u0003\u0002\u0002\u0002\rw\u0003\u0002\u0002\u0002\u000fz\u0003\u0002",
    "\u0002\u0002\u0011\u0081\u0003\u0002\u0002\u0002\u0013\u0087\u0003\u0002",
    "\u0002\u0002\u0015\u008b\u0003\u0002\u0002\u0002\u0017\u0092\u0003\u0002",
    "\u0002\u0002\u0019\u0097\u0003\u0002\u0002\u0002\u001b\u00a3\u0003\u0002",
    "\u0002\u0002\u001d\u00a5\u0003\u0002\u0002\u0002\u001f\u00ac\u0003\u0002",
    "\u0002\u0002!\u00b2\u0003\u0002\u0002\u0002#\u00bd\u0003\u0002\u0002",
    "\u0002%\u00c0\u0003\u0002\u0002\u0002\'\u00c5\u0003\u0002\u0002\u0002",
    ")\u00c9\u0003\u0002\u0002\u0002+\u00d3\u0003\u0002\u0002\u0002-\u00da",
    "\u0003\u0002\u0002\u0002/\u00dc\u0003\u0002\u0002\u00021\u00de\u0003",
    "\u0002\u0002\u00023\u00e0\u0003\u0002\u0002\u00025\u00e2\u0003\u0002",
    "\u0002\u00027\u00e4\u0003\u0002\u0002\u00029\u00e6\u0003\u0002\u0002",
    "\u0002;\u00e8\u0003\u0002\u0002\u0002=\u00ea\u0003\u0002\u0002\u0002",
    "?\u00ec\u0003\u0002\u0002\u0002A\u00ee\u0003\u0002\u0002\u0002C\u00f0",
    "\u0003\u0002\u0002\u0002E\u00f3\u0003\u0002\u0002\u0002G\u00f7\u0003",
    "\u0002\u0002\u0002I\u00f9\u0003\u0002\u0002\u0002K\u00fb\u0003\u0002",
    "\u0002\u0002M\u0100\u0003\u0002\u0002\u0002O\u0103\u0003\u0002\u0002",
    "\u0002Q\u0107\u0003\u0002\u0002\u0002S\u0111\u0003\u0002\u0002\u0002",
    "U\u0131\u0003\u0002\u0002\u0002W\u014b\u0003\u0002\u0002\u0002Y\u014d",
    "\u0003\u0002\u0002\u0002[\u0155\u0003\u0002\u0002\u0002]^\u0007k\u0002",
    "\u0002^_\u0007o\u0002\u0002_`\u0007r\u0002\u0002`a\u0007q\u0002\u0002",
    "ab\u0007t\u0002\u0002bc\u0007v\u0002\u0002c\u0004\u0003\u0002\u0002",
    "\u0002de\u0007h\u0002\u0002ef\u0007t\u0002\u0002fg\u0007q\u0002\u0002",
    "gh\u0007o\u0002\u0002h\u0006\u0003\u0002\u0002\u0002ij\u0007v\u0002",
    "\u0002jk\u0007{\u0002\u0002kl\u0007r\u0002\u0002lm\u0007g\u0002\u0002",
    "m\b\u0003\u0002\u0002\u0002no\u0007h\u0002\u0002op\u0007p\u0002\u0002",
    "p\n\u0003\u0002\u0002\u0002qr\u0007g\u0002\u0002rs\u0007x\u0002\u0002",
    "st\u0007g\u0002\u0002tu\u0007p\u0002\u0002uv\u0007v\u0002\u0002v\f\u0003",
    "\u0002\u0002\u0002wx\u0007q\u0002\u0002xy\u0007p\u0002\u0002y\u000e",
    "\u0003\u0002\u0002\u0002z{\u0007g\u0002\u0002{|\u0007z\u0002\u0002|",
    "}\u0007r\u0002\u0002}~\u0007q\u0002\u0002~\u007f\u0007t\u0002\u0002",
    "\u007f\u0080\u0007v\u0002\u0002\u0080\u0010\u0003\u0002\u0002\u0002",
    "\u0081\u0082\u0007e\u0002\u0002\u0082\u0083\u0007q\u0002\u0002\u0083",
    "\u0084\u0007p\u0002\u0002\u0084\u0085\u0007u\u0002\u0002\u0085\u0086",
    "\u0007v\u0002\u0002\u0086\u0012\u0003\u0002\u0002\u0002\u0087\u0088",
    "\u0007n\u0002\u0002\u0088\u0089\u0007g\u0002\u0002\u0089\u008a\u0007",
    "v\u0002\u0002\u008a\u0014\u0003\u0002\u0002\u0002\u008b\u008c\u0007",
    "t\u0002\u0002\u008c\u008d\u0007g\u0002\u0002\u008d\u008e\u0007v\u0002",
    "\u0002\u008e\u008f\u0007w\u0002\u0002\u008f\u0090\u0007t\u0002\u0002",
    "\u0090\u0091\u0007p\u0002\u0002\u0091\u0016\u0003\u0002\u0002\u0002",
    "\u0092\u0093\u0007g\u0002\u0002\u0093\u0094\u0007o\u0002\u0002\u0094",
    "\u0095\u0007k\u0002\u0002\u0095\u0096\u0007v\u0002\u0002\u0096\u0018",
    "\u0003\u0002\u0002\u0002\u0097\u0098\u0007c\u0002\u0002\u0098\u0099",
    "\u0007u\u0002\u0002\u0099\u001a\u0003\u0002\u0002\u0002\u009a\u009b",
    "\u0007v\u0002\u0002\u009b\u009c\u0007t\u0002\u0002\u009c\u009d\u0007",
    "w\u0002\u0002\u009d\u00a4\u0007g\u0002\u0002\u009e\u009f\u0007h\u0002",
    "\u0002\u009f\u00a0\u0007c\u0002\u0002\u00a0\u00a1\u0007n\u0002\u0002",
    "\u00a1\u00a2\u0007u\u0002\u0002\u00a2\u00a4\u0007g\u0002\u0002\u00a3",
    "\u009a\u0003\u0002\u0002\u0002\u00a3\u009e\u0003\u0002\u0002\u0002\u00a4",
    "\u001c\u0003\u0002\u0002\u0002\u00a5\u00a6\u0007r\u0002\u0002\u00a6",
    "\u00a7\u0007t\u0002\u0002\u00a7\u00a8\u0007g\u0002\u0002\u00a8\u00a9",
    "\u0007h\u0002\u0002\u00a9\u00aa\u0007k\u0002\u0002\u00aa\u00ab\u0007",
    "z\u0002\u0002\u00ab\u001e\u0003\u0002\u0002\u0002\u00ac\u00ad\u0007",
    "k\u0002\u0002\u00ad\u00ae\u0007p\u0002\u0002\u00ae\u00af\u0007h\u0002",
    "\u0002\u00af\u00b0\u0007k\u0002\u0002\u00b0\u00b1\u0007z\u0002\u0002",
    "\u00b1 \u0003\u0002\u0002\u0002\u00b2\u00b3\u0007r\u0002\u0002\u00b3",
    "\u00b4\u0007t\u0002\u0002\u00b4\u00b5\u0007g\u0002\u0002\u00b5\u00b6",
    "\u0007e\u0002\u0002\u00b6\u00b7\u0007g\u0002\u0002\u00b7\u00b8\u0007",
    "f\u0002\u0002\u00b8\u00b9\u0007g\u0002\u0002\u00b9\u00ba\u0007p\u0002",
    "\u0002\u00ba\u00bb\u0007e\u0002\u0002\u00bb\u00bc\u0007g\u0002\u0002",
    "\u00bc\"\u0003\u0002\u0002\u0002\u00bd\u00be\u0007k\u0002\u0002\u00be",
    "\u00bf\u0007h\u0002\u0002\u00bf$\u0003\u0002\u0002\u0002\u00c0\u00c1",
    "\u0007g\u0002\u0002\u00c1\u00c2\u0007n\u0002\u0002\u00c2\u00c3\u0007",
    "u\u0002\u0002\u00c3\u00c4\u0007g\u0002\u0002\u00c4&\u0003\u0002\u0002",
    "\u0002\u00c5\u00c6\u0007p\u0002\u0002\u00c6\u00c7\u0007g\u0002\u0002",
    "\u00c7\u00c8\u0007y\u0002\u0002\u00c8(\u0003\u0002\u0002\u0002\u00c9",
    "\u00ca\u0007k\u0002\u0002\u00ca\u00cb\u0007p\u0002\u0002\u00cb\u00cc",
    "\u0007v\u0002\u0002\u00cc\u00cd\u0007g\u0002\u0002\u00cd\u00ce\u0007",
    "t\u0002\u0002\u00ce\u00cf\u0007h\u0002\u0002\u00cf\u00d0\u0007c\u0002",
    "\u0002\u00d0\u00d1\u0007e\u0002\u0002\u00d1\u00d2\u0007g\u0002\u0002",
    "\u00d2*\u0003\u0002\u0002\u0002\u00d3\u00d7\u0007.\u0002\u0002\u00d4",
    "\u00d6\u0005O(\u0002\u00d5\u00d4\u0003\u0002\u0002\u0002\u00d6\u00d9",
    "\u0003\u0002\u0002\u0002\u00d7\u00d5\u0003\u0002\u0002\u0002\u00d7\u00d8",
    "\u0003\u0002\u0002\u0002\u00d8,\u0003\u0002\u0002\u0002\u00d9\u00d7",
    "\u0003\u0002\u0002\u0002\u00da\u00db\u0007}\u0002\u0002\u00db.\u0003",
    "\u0002\u0002\u0002\u00dc\u00dd\u0007\u007f\u0002\u0002\u00dd0\u0003",
    "\u0002\u0002\u0002\u00de\u00df\u0007*\u0002\u0002\u00df2\u0003\u0002",
    "\u0002\u0002\u00e0\u00e1\u0007+\u0002\u0002\u00e14\u0003\u0002\u0002",
    "\u0002\u00e2\u00e3\u0007>\u0002\u0002\u00e36\u0003\u0002\u0002\u0002",
    "\u00e4\u00e5\u0007@\u0002\u0002\u00e58\u0003\u0002\u0002\u0002\u00e6",
    "\u00e7\u0007]\u0002\u0002\u00e7:\u0003\u0002\u0002\u0002\u00e8\u00e9",
    "\u0007_\u0002\u0002\u00e9<\u0003\u0002\u0002\u0002\u00ea\u00eb\u0007",
    "0\u0002\u0002\u00eb>\u0003\u0002\u0002\u0002\u00ec\u00ed\u0007?\u0002",
    "\u0002\u00ed@\u0003\u0002\u0002\u0002\u00ee\u00ef\u0007B\u0002\u0002",
    "\u00efB\u0003\u0002\u0002\u0002\u00f0\u00f1\u00070\u0002\u0002\u00f1",
    "\u00f2\u00071\u0002\u0002\u00f2D\u0003\u0002\u0002\u0002\u00f3\u00f4",
    "\u00070\u0002\u0002\u00f4\u00f5\u00070\u0002\u0002\u00f5\u00f6\u0007",
    "1\u0002\u0002\u00f6F\u0003\u0002\u0002\u0002\u00f7\u00f8\u00071\u0002",
    "\u0002\u00f8H\u0003\u0002\u0002\u0002\u00f9\u00fa\u0007<\u0002\u0002",
    "\u00faJ\u0003\u0002\u0002\u0002\u00fb\u00fc\u0007=\u0002\u0002\u00fc",
    "L\u0003\u0002\u0002\u0002\u00fd\u0101\t\u0002\u0002\u0002\u00fe\u00ff",
    "\u0007\u000f\u0002\u0002\u00ff\u0101\u0007\f\u0002\u0002\u0100\u00fd",
    "\u0003\u0002\u0002\u0002\u0100\u00fe\u0003\u0002\u0002\u0002\u0101N",
    "\u0003\u0002\u0002\u0002\u0102\u0104\t\u0003\u0002\u0002\u0103\u0102",
    "\u0003\u0002\u0002\u0002\u0104\u0105\u0003\u0002\u0002\u0002\u0105\u0103",
    "\u0003\u0002\u0002\u0002\u0105\u0106\u0003\u0002\u0002\u0002\u0106P",
    "\u0003\u0002\u0002\u0002\u0107\u0108\u00071\u0002\u0002\u0108\u0109",
    "\u00071\u0002\u0002\u0109\u010b\u0003\u0002\u0002\u0002\u010a\u010c",
    "\n\u0002\u0002\u0002\u010b\u010a\u0003\u0002\u0002\u0002\u010c\u010d",
    "\u0003\u0002\u0002\u0002\u010d\u010b\u0003\u0002\u0002\u0002\u010d\u010e",
    "\u0003\u0002\u0002\u0002\u010e\u010f\u0003\u0002\u0002\u0002\u010f\u0110",
    "\b)\u0002\u0002\u0110R\u0003\u0002\u0002\u0002\u0111\u0112\u00071\u0002",
    "\u0002\u0112\u0113\u0007,\u0002\u0002\u0113\u0119\u0003\u0002\u0002",
    "\u0002\u0114\u0115\u0007,\u0002\u0002\u0115\u0118\n\u0004\u0002\u0002",
    "\u0116\u0118\n\u0005\u0002\u0002\u0117\u0114\u0003\u0002\u0002\u0002",
    "\u0117\u0116\u0003\u0002\u0002\u0002\u0118\u011b\u0003\u0002\u0002\u0002",
    "\u0119\u0117\u0003\u0002\u0002\u0002\u0119\u011a\u0003\u0002\u0002\u0002",
    "\u011a\u011c\u0003\u0002\u0002\u0002\u011b\u0119\u0003\u0002\u0002\u0002",
    "\u011c\u011d\u0007,\u0002\u0002\u011d\u011e\u00071\u0002\u0002\u011e",
    "\u011f\u0003\u0002\u0002\u0002\u011f\u0120\b*\u0002\u0002\u0120T\u0003",
    "\u0002\u0002\u0002\u0121\u0125\u0007$\u0002\u0002\u0122\u0124\n\u0006",
    "\u0002\u0002\u0123\u0122\u0003\u0002\u0002\u0002\u0124\u0127\u0003\u0002",
    "\u0002\u0002\u0125\u0123\u0003\u0002\u0002\u0002\u0125\u0126\u0003\u0002",
    "\u0002\u0002\u0126\u0128\u0003\u0002\u0002\u0002\u0127\u0125\u0003\u0002",
    "\u0002\u0002\u0128\u0132\u0007$\u0002\u0002\u0129\u012d\u0007)\u0002",
    "\u0002\u012a\u012c\n\u0007\u0002\u0002\u012b\u012a\u0003\u0002\u0002",
    "\u0002\u012c\u012f\u0003\u0002\u0002\u0002\u012d\u012b\u0003\u0002\u0002",
    "\u0002\u012d\u012e\u0003\u0002\u0002\u0002\u012e\u0130\u0003\u0002\u0002",
    "\u0002\u012f\u012d\u0003\u0002\u0002\u0002\u0130\u0132\u0007)\u0002",
    "\u0002\u0131\u0121\u0003\u0002\u0002\u0002\u0131\u0129\u0003\u0002\u0002",
    "\u0002\u0132V\u0003\u0002\u0002\u0002\u0133\u0134\u00072\u0002\u0002",
    "\u0134\u0135\u0007z\u0002\u0002\u0135\u0137\u0003\u0002\u0002\u0002",
    "\u0136\u0138\t\b\u0002\u0002\u0137\u0136\u0003\u0002\u0002\u0002\u0138",
    "\u0139\u0003\u0002\u0002\u0002\u0139\u0137\u0003\u0002\u0002\u0002\u0139",
    "\u013a\u0003\u0002\u0002\u0002\u013a\u014c\u0003\u0002\u0002\u0002\u013b",
    "\u013d\t\t\u0002\u0002\u013c\u013b\u0003\u0002\u0002\u0002\u013c\u013d",
    "\u0003\u0002\u0002\u0002\u013d\u013f\u0003\u0002\u0002\u0002\u013e\u0140",
    "\t\n\u0002\u0002\u013f\u013e\u0003\u0002\u0002\u0002\u0140\u0141\u0003",
    "\u0002\u0002\u0002\u0141\u013f\u0003\u0002\u0002\u0002\u0141\u0142\u0003",
    "\u0002\u0002\u0002\u0142\u0149\u0003\u0002\u0002\u0002\u0143\u0145\t",
    "\u000b\u0002\u0002\u0144\u0146\t\n\u0002\u0002\u0145\u0144\u0003\u0002",
    "\u0002\u0002\u0146\u0147\u0003\u0002\u0002\u0002\u0147\u0145\u0003\u0002",
    "\u0002\u0002\u0147\u0148\u0003\u0002\u0002\u0002\u0148\u014a\u0003\u0002",
    "\u0002\u0002\u0149\u0143\u0003\u0002\u0002\u0002\u0149\u014a\u0003\u0002",
    "\u0002\u0002\u014a\u014c\u0003\u0002\u0002\u0002\u014b\u0133\u0003\u0002",
    "\u0002\u0002\u014b\u013c\u0003\u0002\u0002\u0002\u014cX\u0003\u0002",
    "\u0002\u0002\u014d\u0151\t\f\u0002\u0002\u014e\u0150\t\r\u0002\u0002",
    "\u014f\u014e\u0003\u0002\u0002\u0002\u0150\u0153\u0003\u0002\u0002\u0002",
    "\u0151\u014f\u0003\u0002\u0002\u0002\u0151\u0152\u0003\u0002\u0002\u0002",
    "\u0152Z\u0003\u0002\u0002\u0002\u0153\u0151\u0003\u0002\u0002\u0002",
    "\u0154\u0156\t\u000e\u0002\u0002\u0155\u0154\u0003\u0002\u0002\u0002",
    "\u0156\u0157\u0003\u0002\u0002\u0002\u0157\u0155\u0003\u0002\u0002\u0002",
    "\u0157\u0158\u0003\u0002\u0002\u0002\u0158\u015c\u0003\u0002\u0002\u0002",
    "\u0159\u015b\t\u000f\u0002\u0002\u015a\u0159\u0003\u0002\u0002\u0002",
    "\u015b\u015e\u0003\u0002\u0002\u0002\u015c\u015a\u0003\u0002\u0002\u0002",
    "\u015c\u015d\u0003\u0002\u0002\u0002\u015d\\\u0003\u0002\u0002\u0002",
    "\u015e\u015c\u0003\u0002\u0002\u0002\u0016\u0002\u00a3\u00d7\u0100\u0105",
    "\u010d\u0117\u0119\u0125\u012d\u0131\u0139\u013c\u0141\u0147\u0149\u014b",
    "\u0151\u0157\u015c\u0003\b\u0002\u0002"].join("");
var atn = new antlr4.atn.ATNDeserializer().deserialize(serializedATN);
var decisionsToDFA = atn.decisionToState.map(function (ds, index) { return new antlr4.dfa.DFA(ds, index); });
function LnLexer(input) {
    antlr4.Lexer.call(this, input);
    this._interp = new antlr4.atn.LexerATNSimulator(this, atn, decisionsToDFA, new antlr4.PredictionContextCache());
    return this;
}
LnLexer.prototype = Object.create(antlr4.Lexer.prototype);
LnLexer.prototype.constructor = LnLexer;
Object.defineProperty(LnLexer.prototype, "atn", {
    get: function () {
        return atn;
    }
});
LnLexer.EOF = antlr4.Token.EOF;
LnLexer.IMPORT = 1;
LnLexer.FROM = 2;
LnLexer.TYPE = 3;
LnLexer.FN = 4;
LnLexer.EVENT = 5;
LnLexer.ON = 6;
LnLexer.EXPORT = 7;
LnLexer.CONST = 8;
LnLexer.LET = 9;
LnLexer.RETURN = 10;
LnLexer.EMIT = 11;
LnLexer.AS = 12;
LnLexer.BOOLCONSTANT = 13;
LnLexer.PREFIX = 14;
LnLexer.INFIX = 15;
LnLexer.PRECEDENCE = 16;
LnLexer.IF = 17;
LnLexer.ELSE = 18;
LnLexer.NEW = 19;
LnLexer.INTERFACE = 20;
LnLexer.SEP = 21;
LnLexer.OPENBODY = 22;
LnLexer.CLOSEBODY = 23;
LnLexer.OPENARGS = 24;
LnLexer.CLOSEARGS = 25;
LnLexer.OPENGENERIC = 26;
LnLexer.CLOSEGENERIC = 27;
LnLexer.OPENARRAY = 28;
LnLexer.CLOSEARRAY = 29;
LnLexer.METHODSEP = 30;
LnLexer.EQUALS = 31;
LnLexer.GLOBAL = 32;
LnLexer.CURDIR = 33;
LnLexer.PARDIR = 34;
LnLexer.DIRSEP = 35;
LnLexer.TYPESEP = 36;
LnLexer.EOS = 37;
LnLexer.NEWLINE = 38;
LnLexer.WS = 39;
LnLexer.SINGLELINECOMMENT = 40;
LnLexer.MULTILINECOMMENT = 41;
LnLexer.STRINGCONSTANT = 42;
LnLexer.NUMBERCONSTANT = 43;
LnLexer.GENERALOPERATORS = 44;
LnLexer.VARNAME = 45;
LnLexer.prototype.channelNames = ["DEFAULT_TOKEN_CHANNEL", "HIDDEN"];
LnLexer.prototype.modeNames = ["DEFAULT_MODE"];
LnLexer.prototype.literalNames = [null, "'import'", "'from'", "'type'",
    "'fn'", "'event'", "'on'", "'export'",
    "'const'", "'let'", "'return'", "'emit'",
    "'as'", null, "'prefix'", "'infix'",
    "'precedence'", "'if'", "'else'", "'new'",
    "'interface'", null, "'{'", "'}'", "'('",
    "')'", "'<'", "'>'", "'['", "']'", "'.'",
    "'='", "'@'", "'./'", "'../'", "'/'",
    "':'", "';'"];
LnLexer.prototype.symbolicNames = [null, "IMPORT", "FROM", "TYPE", "FN",
    "EVENT", "ON", "EXPORT", "CONST", "LET",
    "RETURN", "EMIT", "AS", "BOOLCONSTANT",
    "PREFIX", "INFIX", "PRECEDENCE", "IF",
    "ELSE", "NEW", "INTERFACE", "SEP", "OPENBODY",
    "CLOSEBODY", "OPENARGS", "CLOSEARGS",
    "OPENGENERIC", "CLOSEGENERIC", "OPENARRAY",
    "CLOSEARRAY", "METHODSEP", "EQUALS",
    "GLOBAL", "CURDIR", "PARDIR", "DIRSEP",
    "TYPESEP", "EOS", "NEWLINE", "WS", "SINGLELINECOMMENT",
    "MULTILINECOMMENT", "STRINGCONSTANT",
    "NUMBERCONSTANT", "GENERALOPERATORS",
    "VARNAME"];
LnLexer.prototype.ruleNames = ["IMPORT", "FROM", "TYPE", "FN", "EVENT",
    "ON", "EXPORT", "CONST", "LET", "RETURN",
    "EMIT", "AS", "BOOLCONSTANT", "PREFIX",
    "INFIX", "PRECEDENCE", "IF", "ELSE", "NEW",
    "INTERFACE", "SEP", "OPENBODY", "CLOSEBODY",
    "OPENARGS", "CLOSEARGS", "OPENGENERIC",
    "CLOSEGENERIC", "OPENARRAY", "CLOSEARRAY",
    "METHODSEP", "EQUALS", "GLOBAL", "CURDIR",
    "PARDIR", "DIRSEP", "TYPESEP", "EOS", "NEWLINE",
    "WS", "SINGLELINECOMMENT", "MULTILINECOMMENT",
    "STRINGCONSTANT", "NUMBERCONSTANT", "GENERALOPERATORS",
    "VARNAME"];
LnLexer.prototype.grammarFileName = "Ln.g4";
exports.LnLexer = LnLexer;

},{"antlr4/index":66}],7:[function(require,module,exports){
// Generated from Ln.g4 by ANTLR 4.7.2
// jshint ignore: start
var antlr4 = require('antlr4/index');
// This class defines a complete listener for a parse tree produced by LnParser.
function LnListener() {
    antlr4.tree.ParseTreeListener.call(this);
    return this;
}
LnListener.prototype = Object.create(antlr4.tree.ParseTreeListener.prototype);
LnListener.prototype.constructor = LnListener;
// Enter a parse tree produced by LnParser#module.
LnListener.prototype.enterModule = function (ctx) {
};
// Exit a parse tree produced by LnParser#module.
LnListener.prototype.exitModule = function (ctx) {
};
// Enter a parse tree produced by LnParser#blank.
LnListener.prototype.enterBlank = function (ctx) {
};
// Exit a parse tree produced by LnParser#blank.
LnListener.prototype.exitBlank = function (ctx) {
};
// Enter a parse tree produced by LnParser#imports.
LnListener.prototype.enterImports = function (ctx) {
};
// Exit a parse tree produced by LnParser#imports.
LnListener.prototype.exitImports = function (ctx) {
};
// Enter a parse tree produced by LnParser#standardImport.
LnListener.prototype.enterStandardImport = function (ctx) {
};
// Exit a parse tree produced by LnParser#standardImport.
LnListener.prototype.exitStandardImport = function (ctx) {
};
// Enter a parse tree produced by LnParser#fromImport.
LnListener.prototype.enterFromImport = function (ctx) {
};
// Exit a parse tree produced by LnParser#fromImport.
LnListener.prototype.exitFromImport = function (ctx) {
};
// Enter a parse tree produced by LnParser#dependency.
LnListener.prototype.enterDependency = function (ctx) {
};
// Exit a parse tree produced by LnParser#dependency.
LnListener.prototype.exitDependency = function (ctx) {
};
// Enter a parse tree produced by LnParser#localdependency.
LnListener.prototype.enterLocaldependency = function (ctx) {
};
// Exit a parse tree produced by LnParser#localdependency.
LnListener.prototype.exitLocaldependency = function (ctx) {
};
// Enter a parse tree produced by LnParser#globaldependency.
LnListener.prototype.enterGlobaldependency = function (ctx) {
};
// Exit a parse tree produced by LnParser#globaldependency.
LnListener.prototype.exitGlobaldependency = function (ctx) {
};
// Enter a parse tree produced by LnParser#types.
LnListener.prototype.enterTypes = function (ctx) {
};
// Exit a parse tree produced by LnParser#types.
LnListener.prototype.exitTypes = function (ctx) {
};
// Enter a parse tree produced by LnParser#typename.
LnListener.prototype.enterTypename = function (ctx) {
};
// Exit a parse tree produced by LnParser#typename.
LnListener.prototype.exitTypename = function (ctx) {
};
// Enter a parse tree produced by LnParser#typegenerics.
LnListener.prototype.enterTypegenerics = function (ctx) {
};
// Exit a parse tree produced by LnParser#typegenerics.
LnListener.prototype.exitTypegenerics = function (ctx) {
};
// Enter a parse tree produced by LnParser#fulltypename.
LnListener.prototype.enterFulltypename = function (ctx) {
};
// Exit a parse tree produced by LnParser#fulltypename.
LnListener.prototype.exitFulltypename = function (ctx) {
};
// Enter a parse tree produced by LnParser#typebody.
LnListener.prototype.enterTypebody = function (ctx) {
};
// Exit a parse tree produced by LnParser#typebody.
LnListener.prototype.exitTypebody = function (ctx) {
};
// Enter a parse tree produced by LnParser#typeline.
LnListener.prototype.enterTypeline = function (ctx) {
};
// Exit a parse tree produced by LnParser#typeline.
LnListener.prototype.exitTypeline = function (ctx) {
};
// Enter a parse tree produced by LnParser#typelist.
LnListener.prototype.enterTypelist = function (ctx) {
};
// Exit a parse tree produced by LnParser#typelist.
LnListener.prototype.exitTypelist = function (ctx) {
};
// Enter a parse tree produced by LnParser#arglist.
LnListener.prototype.enterArglist = function (ctx) {
};
// Exit a parse tree produced by LnParser#arglist.
LnListener.prototype.exitArglist = function (ctx) {
};
// Enter a parse tree produced by LnParser#functions.
LnListener.prototype.enterFunctions = function (ctx) {
};
// Exit a parse tree produced by LnParser#functions.
LnListener.prototype.exitFunctions = function (ctx) {
};
// Enter a parse tree produced by LnParser#fullfunctionbody.
LnListener.prototype.enterFullfunctionbody = function (ctx) {
};
// Exit a parse tree produced by LnParser#fullfunctionbody.
LnListener.prototype.exitFullfunctionbody = function (ctx) {
};
// Enter a parse tree produced by LnParser#functionbody.
LnListener.prototype.enterFunctionbody = function (ctx) {
};
// Exit a parse tree produced by LnParser#functionbody.
LnListener.prototype.exitFunctionbody = function (ctx) {
};
// Enter a parse tree produced by LnParser#statements.
LnListener.prototype.enterStatements = function (ctx) {
};
// Exit a parse tree produced by LnParser#statements.
LnListener.prototype.exitStatements = function (ctx) {
};
// Enter a parse tree produced by LnParser#declarations.
LnListener.prototype.enterDeclarations = function (ctx) {
};
// Exit a parse tree produced by LnParser#declarations.
LnListener.prototype.exitDeclarations = function (ctx) {
};
// Enter a parse tree produced by LnParser#constdeclaration.
LnListener.prototype.enterConstdeclaration = function (ctx) {
};
// Exit a parse tree produced by LnParser#constdeclaration.
LnListener.prototype.exitConstdeclaration = function (ctx) {
};
// Enter a parse tree produced by LnParser#letdeclaration.
LnListener.prototype.enterLetdeclaration = function (ctx) {
};
// Exit a parse tree produced by LnParser#letdeclaration.
LnListener.prototype.exitLetdeclaration = function (ctx) {
};
// Enter a parse tree produced by LnParser#assignments.
LnListener.prototype.enterAssignments = function (ctx) {
};
// Exit a parse tree produced by LnParser#assignments.
LnListener.prototype.exitAssignments = function (ctx) {
};
// Enter a parse tree produced by LnParser#baseassignable.
LnListener.prototype.enterBaseassignable = function (ctx) {
};
// Exit a parse tree produced by LnParser#baseassignable.
LnListener.prototype.exitBaseassignable = function (ctx) {
};
// Enter a parse tree produced by LnParser#withoperators.
LnListener.prototype.enterWithoperators = function (ctx) {
};
// Exit a parse tree produced by LnParser#withoperators.
LnListener.prototype.exitWithoperators = function (ctx) {
};
// Enter a parse tree produced by LnParser#assignables.
LnListener.prototype.enterAssignables = function (ctx) {
};
// Exit a parse tree produced by LnParser#assignables.
LnListener.prototype.exitAssignables = function (ctx) {
};
// Enter a parse tree produced by LnParser#objectliterals.
LnListener.prototype.enterObjectliterals = function (ctx) {
};
// Exit a parse tree produced by LnParser#objectliterals.
LnListener.prototype.exitObjectliterals = function (ctx) {
};
// Enter a parse tree produced by LnParser#assignablelist.
LnListener.prototype.enterAssignablelist = function (ctx) {
};
// Exit a parse tree produced by LnParser#assignablelist.
LnListener.prototype.exitAssignablelist = function (ctx) {
};
// Enter a parse tree produced by LnParser#typeassignlist.
LnListener.prototype.enterTypeassignlist = function (ctx) {
};
// Exit a parse tree produced by LnParser#typeassignlist.
LnListener.prototype.exitTypeassignlist = function (ctx) {
};
// Enter a parse tree produced by LnParser#literaldec.
LnListener.prototype.enterLiteraldec = function (ctx) {
};
// Exit a parse tree produced by LnParser#literaldec.
LnListener.prototype.exitLiteraldec = function (ctx) {
};
// Enter a parse tree produced by LnParser#arraybase.
LnListener.prototype.enterArraybase = function (ctx) {
};
// Exit a parse tree produced by LnParser#arraybase.
LnListener.prototype.exitArraybase = function (ctx) {
};
// Enter a parse tree produced by LnParser#arrayliteral.
LnListener.prototype.enterArrayliteral = function (ctx) {
};
// Exit a parse tree produced by LnParser#arrayliteral.
LnListener.prototype.exitArrayliteral = function (ctx) {
};
// Enter a parse tree produced by LnParser#typebase.
LnListener.prototype.enterTypebase = function (ctx) {
};
// Exit a parse tree produced by LnParser#typebase.
LnListener.prototype.exitTypebase = function (ctx) {
};
// Enter a parse tree produced by LnParser#typeliteral.
LnListener.prototype.enterTypeliteral = function (ctx) {
};
// Exit a parse tree produced by LnParser#typeliteral.
LnListener.prototype.exitTypeliteral = function (ctx) {
};
// Enter a parse tree produced by LnParser#fncall.
LnListener.prototype.enterFncall = function (ctx) {
};
// Exit a parse tree produced by LnParser#fncall.
LnListener.prototype.exitFncall = function (ctx) {
};
// Enter a parse tree produced by LnParser#exits.
LnListener.prototype.enterExits = function (ctx) {
};
// Exit a parse tree produced by LnParser#exits.
LnListener.prototype.exitExits = function (ctx) {
};
// Enter a parse tree produced by LnParser#emits.
LnListener.prototype.enterEmits = function (ctx) {
};
// Exit a parse tree produced by LnParser#emits.
LnListener.prototype.exitEmits = function (ctx) {
};
// Enter a parse tree produced by LnParser#conditionals.
LnListener.prototype.enterConditionals = function (ctx) {
};
// Exit a parse tree produced by LnParser#conditionals.
LnListener.prototype.exitConditionals = function (ctx) {
};
// Enter a parse tree produced by LnParser#blocklikes.
LnListener.prototype.enterBlocklikes = function (ctx) {
};
// Exit a parse tree produced by LnParser#blocklikes.
LnListener.prototype.exitBlocklikes = function (ctx) {
};
// Enter a parse tree produced by LnParser#constants.
LnListener.prototype.enterConstants = function (ctx) {
};
// Exit a parse tree produced by LnParser#constants.
LnListener.prototype.exitConstants = function (ctx) {
};
// Enter a parse tree produced by LnParser#operators.
LnListener.prototype.enterOperators = function (ctx) {
};
// Exit a parse tree produced by LnParser#operators.
LnListener.prototype.exitOperators = function (ctx) {
};
// Enter a parse tree produced by LnParser#operatormapping.
LnListener.prototype.enterOperatormapping = function (ctx) {
};
// Exit a parse tree produced by LnParser#operatormapping.
LnListener.prototype.exitOperatormapping = function (ctx) {
};
// Enter a parse tree produced by LnParser#fntoop.
LnListener.prototype.enterFntoop = function (ctx) {
};
// Exit a parse tree produced by LnParser#fntoop.
LnListener.prototype.exitFntoop = function (ctx) {
};
// Enter a parse tree produced by LnParser#opprecedence.
LnListener.prototype.enterOpprecedence = function (ctx) {
};
// Exit a parse tree produced by LnParser#opprecedence.
LnListener.prototype.exitOpprecedence = function (ctx) {
};
// Enter a parse tree produced by LnParser#events.
LnListener.prototype.enterEvents = function (ctx) {
};
// Exit a parse tree produced by LnParser#events.
LnListener.prototype.exitEvents = function (ctx) {
};
// Enter a parse tree produced by LnParser#eventref.
LnListener.prototype.enterEventref = function (ctx) {
};
// Exit a parse tree produced by LnParser#eventref.
LnListener.prototype.exitEventref = function (ctx) {
};
// Enter a parse tree produced by LnParser#handlers.
LnListener.prototype.enterHandlers = function (ctx) {
};
// Exit a parse tree produced by LnParser#handlers.
LnListener.prototype.exitHandlers = function (ctx) {
};
// Enter a parse tree produced by LnParser#interfaces.
LnListener.prototype.enterInterfaces = function (ctx) {
};
// Exit a parse tree produced by LnParser#interfaces.
LnListener.prototype.exitInterfaces = function (ctx) {
};
// Enter a parse tree produced by LnParser#interfacebody.
LnListener.prototype.enterInterfacebody = function (ctx) {
};
// Exit a parse tree produced by LnParser#interfacebody.
LnListener.prototype.exitInterfacebody = function (ctx) {
};
// Enter a parse tree produced by LnParser#interfacelist.
LnListener.prototype.enterInterfacelist = function (ctx) {
};
// Exit a parse tree produced by LnParser#interfacelist.
LnListener.prototype.exitInterfacelist = function (ctx) {
};
// Enter a parse tree produced by LnParser#interfaceline.
LnListener.prototype.enterInterfaceline = function (ctx) {
};
// Exit a parse tree produced by LnParser#interfaceline.
LnListener.prototype.exitInterfaceline = function (ctx) {
};
// Enter a parse tree produced by LnParser#functiontypeline.
LnListener.prototype.enterFunctiontypeline = function (ctx) {
};
// Exit a parse tree produced by LnParser#functiontypeline.
LnListener.prototype.exitFunctiontypeline = function (ctx) {
};
// Enter a parse tree produced by LnParser#functiontype.
LnListener.prototype.enterFunctiontype = function (ctx) {
};
// Exit a parse tree produced by LnParser#functiontype.
LnListener.prototype.exitFunctiontype = function (ctx) {
};
// Enter a parse tree produced by LnParser#operatortypeline.
LnListener.prototype.enterOperatortypeline = function (ctx) {
};
// Exit a parse tree produced by LnParser#operatortypeline.
LnListener.prototype.exitOperatortypeline = function (ctx) {
};
// Enter a parse tree produced by LnParser#leftarg.
LnListener.prototype.enterLeftarg = function (ctx) {
};
// Exit a parse tree produced by LnParser#leftarg.
LnListener.prototype.exitLeftarg = function (ctx) {
};
// Enter a parse tree produced by LnParser#rightarg.
LnListener.prototype.enterRightarg = function (ctx) {
};
// Exit a parse tree produced by LnParser#rightarg.
LnListener.prototype.exitRightarg = function (ctx) {
};
// Enter a parse tree produced by LnParser#propertytypeline.
LnListener.prototype.enterPropertytypeline = function (ctx) {
};
// Exit a parse tree produced by LnParser#propertytypeline.
LnListener.prototype.exitPropertytypeline = function (ctx) {
};
// Enter a parse tree produced by LnParser#exports.
LnListener.prototype.enterExports = function (ctx) {
};
// Exit a parse tree produced by LnParser#exports.
LnListener.prototype.exitExports = function (ctx) {
};
// Enter a parse tree produced by LnParser#varlist.
LnListener.prototype.enterVarlist = function (ctx) {
};
// Exit a parse tree produced by LnParser#varlist.
LnListener.prototype.exitVarlist = function (ctx) {
};
// Enter a parse tree produced by LnParser#renameablevar.
LnListener.prototype.enterRenameablevar = function (ctx) {
};
// Exit a parse tree produced by LnParser#renameablevar.
LnListener.prototype.exitRenameablevar = function (ctx) {
};
// Enter a parse tree produced by LnParser#varop.
LnListener.prototype.enterVarop = function (ctx) {
};
// Exit a parse tree produced by LnParser#varop.
LnListener.prototype.exitVarop = function (ctx) {
};
// Enter a parse tree produced by LnParser#varn.
LnListener.prototype.enterVarn = function (ctx) {
};
// Exit a parse tree produced by LnParser#varn.
LnListener.prototype.exitVarn = function (ctx) {
};
// Enter a parse tree produced by LnParser#varsegment.
LnListener.prototype.enterVarsegment = function (ctx) {
};
// Exit a parse tree produced by LnParser#varsegment.
LnListener.prototype.exitVarsegment = function (ctx) {
};
// Enter a parse tree produced by LnParser#arrayaccess.
LnListener.prototype.enterArrayaccess = function (ctx) {
};
// Exit a parse tree produced by LnParser#arrayaccess.
LnListener.prototype.exitArrayaccess = function (ctx) {
};
exports.LnListener = LnListener;

},{"antlr4/index":66}],8:[function(require,module,exports){
// Generated from Ln.g4 by ANTLR 4.7.2
// jshint ignore: start
var antlr4 = require('antlr4/index');
var LnListener = require('./LnListener').LnListener;
var grammarFileName = "Ln.g4";
var serializedATN = ["\u0003\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964",
    "\u0003/\u04cc\u0004\u0002\t\u0002\u0004\u0003\t\u0003\u0004\u0004\t",
    "\u0004\u0004\u0005\t\u0005\u0004\u0006\t\u0006\u0004\u0007\t\u0007\u0004",
    "\b\t\b\u0004\t\t\t\u0004\n\t\n\u0004\u000b\t\u000b\u0004\f\t\f\u0004",
    "\r\t\r\u0004\u000e\t\u000e\u0004\u000f\t\u000f\u0004\u0010\t\u0010\u0004",
    "\u0011\t\u0011\u0004\u0012\t\u0012\u0004\u0013\t\u0013\u0004\u0014\t",
    "\u0014\u0004\u0015\t\u0015\u0004\u0016\t\u0016\u0004\u0017\t\u0017\u0004",
    "\u0018\t\u0018\u0004\u0019\t\u0019\u0004\u001a\t\u001a\u0004\u001b\t",
    "\u001b\u0004\u001c\t\u001c\u0004\u001d\t\u001d\u0004\u001e\t\u001e\u0004",
    "\u001f\t\u001f\u0004 \t \u0004!\t!\u0004\"\t\"\u0004#\t#\u0004$\t$\u0004",
    "%\t%\u0004&\t&\u0004\'\t\'\u0004(\t(\u0004)\t)\u0004*\t*\u0004+\t+\u0004",
    ",\t,\u0004-\t-\u0004.\t.\u0004/\t/\u00040\t0\u00041\t1\u00042\t2\u0004",
    "3\t3\u00044\t4\u00045\t5\u00046\t6\u00047\t7\u00048\t8\u00049\t9\u0004",
    ":\t:\u0004;\t;\u0004<\t<\u0004=\t=\u0004>\t>\u0004?\t?\u0004@\t@\u0004",
    "A\tA\u0004B\tB\u0003\u0002\u0007\u0002\u0086\n\u0002\f\u0002\u000e\u0002",
    "\u0089\u000b\u0002\u0003\u0002\u0007\u0002\u008c\n\u0002\f\u0002\u000e",
    "\u0002\u008f\u000b\u0002\u0003\u0002\u0003\u0002\u0003\u0002\u0003\u0002",
    "\u0003\u0002\u0003\u0002\u0003\u0002\u0003\u0002\u0003\u0002\u0003\u0002",
    "\u0003\u0002\u0006\u0002\u009c\n\u0002\r\u0002\u000e\u0002\u009d\u0006",
    "\u0002\u00a0\n\u0002\r\u0002\u000e\u0002\u00a1\u0003\u0002\u0005\u0002",
    "\u00a5\n\u0002\u0003\u0003\u0003\u0003\u0003\u0004\u0003\u0004\u0005",
    "\u0004\u00ab\n\u0004\u0003\u0005\u0003\u0005\u0003\u0005\u0003\u0005",
    "\u0003\u0005\u0003\u0005\u0003\u0005\u0005\u0005\u00b4\n\u0005\u0003",
    "\u0005\u0003\u0005\u0007\u0005\u00b8\n\u0005\f\u0005\u000e\u0005\u00bb",
    "\u000b\u0005\u0003\u0006\u0003\u0006\u0003\u0006\u0003\u0006\u0003\u0006",
    "\u0003\u0006\u0003\u0006\u0003\u0006\u0003\u0006\u0007\u0006\u00c6\n",
    "\u0006\f\u0006\u000e\u0006\u00c9\u000b\u0006\u0003\u0007\u0003\u0007",
    "\u0005\u0007\u00cd\n\u0007\u0003\b\u0003\b\u0006\b\u00d1\n\b\r\b\u000e",
    "\b\u00d2\u0003\b\u0003\b\u0006\b\u00d7\n\b\r\b\u000e\b\u00d8\u0005\b",
    "\u00db\n\b\u0003\t\u0003\t\u0006\t\u00df\n\t\r\t\u000e\t\u00e0\u0003",
    "\n\u0003\n\u0006\n\u00e5\n\n\r\n\u000e\n\u00e6\u0003\n\u0003\n\u0007",
    "\n\u00eb\n\n\f\n\u000e\n\u00ee\u000b\n\u0003\n\u0005\n\u00f1\n\n\u0003",
    "\n\u0006\n\u00f4\n\n\r\n\u000e\n\u00f5\u0003\n\u0003\n\u0003\n\u0007",
    "\n\u00fb\n\n\f\n\u000e\n\u00fe\u000b\n\u0003\n\u0005\n\u0101\n\n\u0003",
    "\u000b\u0003\u000b\u0003\u000b\u0005\u000b\u0106\n\u000b\u0003\f\u0003",
    "\f\u0007\f\u010a\n\f\f\f\u000e\f\u010d\u000b\f\u0003\f\u0003\f\u0007",
    "\f\u0111\n\f\f\f\u000e\f\u0114\u000b\f\u0003\f\u0003\f\u0007\f\u0118",
    "\n\f\f\f\u000e\f\u011b\u000b\f\u0003\f\u0003\f\u0007\f\u011f\n\f\f\f",
    "\u000e\f\u0122\u000b\f\u0007\f\u0124\n\f\f\f\u000e\f\u0127\u000b\f\u0003",
    "\f\u0003\f\u0003\r\u0003\r\u0007\r\u012d\n\r\f\r\u000e\r\u0130\u000b",
    "\r\u0003\r\u0005\r\u0133\n\r\u0003\u000e\u0003\u000e\u0007\u000e\u0137",
    "\n\u000e\f\u000e\u000e\u000e\u013a\u000b\u000e\u0003\u000e\u0003\u000e",
    "\u0007\u000e\u013e\n\u000e\f\u000e\u000e\u000e\u0141\u000b\u000e\u0003",
    "\u000e\u0003\u000e\u0003\u000f\u0003\u000f\u0007\u000f\u0147\n\u000f",
    "\f\u000f\u000e\u000f\u014a\u000b\u000f\u0003\u000f\u0003\u000f\u0007",
    "\u000f\u014e\n\u000f\f\u000f\u000e\u000f\u0151\u000b\u000f\u0003\u000f",
    "\u0003\u000f\u0003\u0010\u0003\u0010\u0007\u0010\u0157\n\u0010\f\u0010",
    "\u000e\u0010\u015a\u000b\u0010\u0003\u0010\u0003\u0010\u0007\u0010\u015e",
    "\n\u0010\f\u0010\u000e\u0010\u0161\u000b\u0010\u0003\u0010\u0003\u0010",
    "\u0007\u0010\u0165\n\u0010\f\u0010\u000e\u0010\u0168\u000b\u0010\u0007",
    "\u0010\u016a\n\u0010\f\u0010\u000e\u0010\u016d\u000b\u0010\u0003\u0010",
    "\u0005\u0010\u0170\n\u0010\u0003\u0011\u0003\u0011\u0007\u0011\u0174",
    "\n\u0011\f\u0011\u000e\u0011\u0177\u000b\u0011\u0003\u0011\u0003\u0011",
    "\u0007\u0011\u017b\n\u0011\f\u0011\u000e\u0011\u017e\u000b\u0011\u0003",
    "\u0011\u0003\u0011\u0003\u0011\u0003\u0011\u0007\u0011\u0184\n\u0011",
    "\f\u0011\u000e\u0011\u0187\u000b\u0011\u0003\u0011\u0003\u0011\u0007",
    "\u0011\u018b\n\u0011\f\u0011\u000e\u0011\u018e\u000b\u0011\u0003\u0011",
    "\u0007\u0011\u0191\n\u0011\f\u0011\u000e\u0011\u0194\u000b\u0011\u0003",
    "\u0012\u0003\u0012\u0006\u0012\u0198\n\u0012\r\u0012\u000e\u0012\u0199",
    "\u0003\u0012\u0003\u0012\u0007\u0012\u019e\n\u0012\f\u0012\u000e\u0012",
    "\u01a1\u000b\u0012\u0005\u0012\u01a3\n\u0012\u0003\u0012\u0003\u0012",
    "\u0005\u0012\u01a7\n\u0012\u0003\u0012\u0003\u0012\u0007\u0012\u01ab",
    "\n\u0012\f\u0012\u000e\u0012\u01ae\u000b\u0012\u0003\u0012\u0005\u0012",
    "\u01b1\n\u0012\u0003\u0012\u0003\u0012\u0005\u0012\u01b5\n\u0012\u0003",
    "\u0012\u0003\u0012\u0007\u0012\u01b9\n\u0012\f\u0012\u000e\u0012\u01bc",
    "\u000b\u0012\u0005\u0012\u01be\n\u0012\u0005\u0012\u01c0\n\u0012\u0003",
    "\u0012\u0003\u0012\u0005\u0012\u01c4\n\u0012\u0003\u0013\u0003\u0013",
    "\u0003\u0013\u0007\u0013\u01c9\n\u0013\f\u0013\u000e\u0013\u01cc\u000b",
    "\u0013\u0003\u0013\u0005\u0013\u01cf\n\u0013\u0003\u0014\u0003\u0014",
    "\u0006\u0014\u01d3\n\u0014\r\u0014\u000e\u0014\u01d4\u0003\u0014\u0007",
    "\u0014\u01d8\n\u0014\f\u0014\u000e\u0014\u01db\u000b\u0014\u0003\u0014",
    "\u0003\u0014\u0003\u0015\u0007\u0015\u01e0\n\u0015\f\u0015\u000e\u0015",
    "\u01e3\u000b\u0015\u0003\u0015\u0003\u0015\u0003\u0015\u0003\u0015\u0003",
    "\u0015\u0003\u0015\u0003\u0015\u0003\u0015\u0005\u0015\u01ed\n\u0015",
    "\u0003\u0016\u0003\u0016\u0005\u0016\u01f1\n\u0016\u0003\u0016\u0003",
    "\u0016\u0003\u0017\u0003\u0017\u0007\u0017\u01f7\n\u0017\f\u0017\u000e",
    "\u0017\u01fa\u000b\u0017\u0003\u0017\u0003\u0017\u0007\u0017\u01fe\n",
    "\u0017\f\u0017\u000e\u0017\u0201\u000b\u0017\u0003\u0017\u0003\u0017",
    "\u0005\u0017\u0205\n\u0017\u0003\u0017\u0005\u0017\u0208\n\u0017\u0003",
    "\u0017\u0007\u0017\u020b\n\u0017\f\u0017\u000e\u0017\u020e\u000b\u0017",
    "\u0003\u0017\u0003\u0017\u0007\u0017\u0212\n\u0017\f\u0017\u000e\u0017",
    "\u0215\u000b\u0017\u0003\u0017\u0003\u0017\u0003\u0018\u0003\u0018\u0007",
    "\u0018\u021b\n\u0018\f\u0018\u000e\u0018\u021e\u000b\u0018\u0003\u0018",
    "\u0003\u0018\u0007\u0018\u0222\n\u0018\f\u0018\u000e\u0018\u0225\u000b",
    "\u0018\u0003\u0018\u0003\u0018\u0005\u0018\u0229\n\u0018\u0003\u0018",
    "\u0005\u0018\u022c\n\u0018\u0003\u0018\u0007\u0018\u022f\n\u0018\f\u0018",
    "\u000e\u0018\u0232\u000b\u0018\u0003\u0018\u0003\u0018\u0007\u0018\u0236",
    "\n\u0018\f\u0018\u000e\u0018\u0239\u000b\u0018\u0003\u0018\u0003\u0018",
    "\u0003\u0019\u0003\u0019\u0007\u0019\u023f\n\u0019\f\u0019\u000e\u0019",
    "\u0242\u000b\u0019\u0003\u0019\u0003\u0019\u0007\u0019\u0246\n\u0019",
    "\f\u0019\u000e\u0019\u0249\u000b\u0019\u0003\u0019\u0003\u0019\u0003",
    "\u0019\u0003\u001a\u0003\u001a\u0003\u001a\u0003\u001a\u0003\u001a\u0003",
    "\u001a\u0005\u001a\u0254\n\u001a\u0003\u001b\u0003\u001b\u0007\u001b",
    "\u0258\n\u001b\f\u001b\u000e\u001b\u025b\u000b\u001b\u0006\u001b\u025d",
    "\n\u001b\r\u001b\u000e\u001b\u025e\u0003\u001b\u0005\u001b\u0262\n\u001b",
    "\u0003\u001c\u0003\u001c\u0007\u001c\u0266\n\u001c\f\u001c\u000e\u001c",
    "\u0269\u000b\u001c\u0003\u001c\u0007\u001c\u026c\n\u001c\f\u001c\u000e",
    "\u001c\u026f\u000b\u001c\u0003\u001d\u0003\u001d\u0005\u001d\u0273\n",
    "\u001d\u0003\u001e\u0003\u001e\u0007\u001e\u0277\n\u001e\f\u001e\u000e",
    "\u001e\u027a\u000b\u001e\u0003\u001e\u0003\u001e\u0007\u001e\u027e\n",
    "\u001e\f\u001e\u000e\u001e\u0281\u000b\u001e\u0003\u001e\u0003\u001e",
    "\u0007\u001e\u0285\n\u001e\f\u001e\u000e\u001e\u0288\u000b\u001e\u0007",
    "\u001e\u028a\n\u001e\f\u001e\u000e\u001e\u028d\u000b\u001e\u0003\u001e",
    "\u0005\u001e\u0290\n\u001e\u0003\u001f\u0003\u001f\u0007\u001f\u0294",
    "\n\u001f\f\u001f\u000e\u001f\u0297\u000b\u001f\u0003\u001f\u0003\u001f",
    "\u0007\u001f\u029b\n\u001f\f\u001f\u000e\u001f\u029e\u000b\u001f\u0003",
    "\u001f\u0003\u001f\u0007\u001f\u02a2\n\u001f\f\u001f\u000e\u001f\u02a5",
    "\u000b\u001f\u0003\u001f\u0003\u001f\u0007\u001f\u02a9\n\u001f\f\u001f",
    "\u000e\u001f\u02ac\u000b\u001f\u0003\u001f\u0003\u001f\u0007\u001f\u02b0",
    "\n\u001f\f\u001f\u000e\u001f\u02b3\u000b\u001f\u0003\u001f\u0003\u001f",
    "\u0007\u001f\u02b7\n\u001f\f\u001f\u000e\u001f\u02ba\u000b\u001f\u0003",
    "\u001f\u0003\u001f\u0007\u001f\u02be\n\u001f\f\u001f\u000e\u001f\u02c1",
    "\u000b\u001f\u0007\u001f\u02c3\n\u001f\f\u001f\u000e\u001f\u02c6\u000b",
    "\u001f\u0003\u001f\u0005\u001f\u02c9\n\u001f\u0003 \u0003 \u0007 \u02cd",
    "\n \f \u000e \u02d0\u000b \u0003 \u0003 \u0007 \u02d4\n \f \u000e \u02d7",
    "\u000b \u0003!\u0003!\u0007!\u02db\n!\f!\u000e!\u02de\u000b!\u0003!",
    "\u0005!\u02e1\n!\u0003!\u0007!\u02e4\n!\f!\u000e!\u02e7\u000b!\u0003",
    "!\u0003!\u0003\"\u0003\"\u0003\"\u0003\"\u0005\"\u02ef\n\"\u0003#\u0003",
    "#\u0007#\u02f3\n#\f#\u000e#\u02f6\u000b#\u0003#\u0003#\u0007#\u02fa",
    "\n#\f#\u000e#\u02fd\u000b#\u0003#\u0003#\u0003$\u0003$\u0003$\u0003",
    "%\u0003%\u0007%\u0306\n%\f%\u000e%\u0309\u000b%\u0003%\u0005%\u030c",
    "\n%\u0003%\u0007%\u030f\n%\f%\u000e%\u0312\u000b%\u0003%\u0003%\u0003",
    "&\u0003&\u0007&\u0318\n&\f&\u000e&\u031b\u000b&\u0003&\u0003&\u0007",
    "&\u031f\n&\f&\u000e&\u0322\u000b&\u0005&\u0324\n&\u0003&\u0003&\u0003",
    "\'\u0003\'\u0007\'\u032a\n\'\f\'\u000e\'\u032d\u000b\'\u0003\'\u0003",
    "\'\u0007\'\u0331\n\'\f\'\u000e\'\u0334\u000b\'\u0003\'\u0003\'\u0007",
    "\'\u0338\n\'\f\'\u000e\'\u033b\u000b\'\u0005\'\u033d\n\'\u0003\'\u0003",
    "\'\u0003(\u0003(\u0007(\u0343\n(\f(\u000e(\u0346\u000b(\u0003(\u0003",
    "(\u0007(\u034a\n(\f(\u000e(\u034d\u000b(\u0003(\u0003(\u0007(\u0351",
    "\n(\f(\u000e(\u0354\u000b(\u0003(\u0003(\u0007(\u0358\n(\f(\u000e(\u035b",
    "\u000b(\u0003(\u0003(\u0005(\u035f\n(\u0005(\u0361\n(\u0003)\u0003)",
    "\u0003)\u0005)\u0366\n)\u0003*\u0003*\u0003+\u0003+\u0003+\u0003+\u0006",
    "+\u036e\n+\r+\u000e+\u036f\u0003+\u0006+\u0373\n+\r+\u000e+\u0374\u0003",
    "+\u0007+\u0378\n+\f+\u000e+\u037b\u000b+\u0003+\u0006+\u037e\n+\r+\u000e",
    "+\u037f\u0005+\u0382\n+\u0003+\u0003+\u0005+\u0386\n+\u0003,\u0003,",
    "\u0003,\u0003,\u0003,\u0003,\u0003,\u0003,\u0003,\u0003,\u0005,\u0392",
    "\n,\u0003-\u0003-\u0003-\u0003-\u0003-\u0003-\u0003.\u0003.\u0003.\u0003",
    ".\u0003/\u0003/\u0007/\u03a0\n/\f/\u000e/\u03a3\u000b/\u0003/\u0003",
    "/\u0007/\u03a7\n/\f/\u000e/\u03aa\u000b/\u0003/\u0003/\u0007/\u03ae",
    "\n/\f/\u000e/\u03b1\u000b/\u0003/\u0003/\u00030\u00030\u00031\u0003",
    "1\u00061\u03b9\n1\r1\u000e1\u03ba\u00031\u00031\u00061\u03bf\n1\r1\u000e",
    "1\u03c0\u00031\u00031\u00031\u00051\u03c6\n1\u00032\u00032\u00072\u03ca",
    "\n2\f2\u000e2\u03cd\u000b2\u00032\u00032\u00072\u03d1\n2\f2\u000e2\u03d4",
    "\u000b2\u00032\u00032\u00032\u00072\u03d9\n2\f2\u000e2\u03dc\u000b2",
    "\u00032\u00052\u03df\n2\u00033\u00033\u00053\u03e3\n3\u00033\u00073",
    "\u03e6\n3\f3\u000e3\u03e9\u000b3\u00033\u00033\u00034\u00074\u03ee\n",
    "4\f4\u000e4\u03f1\u000b4\u00034\u00034\u00074\u03f5\n4\f4\u000e4\u03f8",
    "\u000b4\u00034\u00034\u00074\u03fc\n4\f4\u000e4\u03ff\u000b4\u00034",
    "\u00034\u00074\u0403\n4\f4\u000e4\u0406\u000b4\u00074\u0408\n4\f4\u000e",
    "4\u040b\u000b4\u00034\u00054\u040e\n4\u00035\u00035\u00035\u00055\u0413",
    "\n5\u00036\u00036\u00076\u0417\n6\f6\u000e6\u041a\u000b6\u00036\u0003",
    "6\u00037\u00037\u00077\u0420\n7\f7\u000e7\u0423\u000b7\u00037\u0003",
    "7\u00077\u0427\n7\f7\u000e7\u042a\u000b7\u00037\u00037\u00077\u042e",
    "\n7\f7\u000e7\u0431\u000b7\u00037\u00037\u00077\u0435\n7\f7\u000e7\u0438",
    "\u000b7\u00077\u043a\n7\f7\u000e7\u043d\u000b7\u00037\u00037\u00057",
    "\u0441\n7\u00037\u00037\u00077\u0445\n7\f7\u000e7\u0448\u000b7\u0003",
    "7\u00037\u00038\u00038\u00078\u044e\n8\f8\u000e8\u0451\u000b8\u0005",
    "8\u0453\n8\u00038\u00038\u00078\u0457\n8\f8\u000e8\u045a\u000b8\u0003",
    "8\u00038\u00078\u045e\n8\f8\u000e8\u0461\u000b8\u00038\u00038\u0007",
    "8\u0465\n8\f8\u000e8\u0468\u000b8\u00038\u00038\u00039\u00039\u0003",
    ":\u0003:\u0003;\u0003;\u0007;\u0472\n;\f;\u000e;\u0475\u000b;\u0003",
    ";\u0003;\u0007;\u0479\n;\f;\u000e;\u047c\u000b;\u0003;\u0003;\u0003",
    "<\u0003<\u0006<\u0482\n<\r<\u000e<\u0483\u0003<\u0003<\u0003<\u0003",
    "<\u0003<\u0003<\u0003<\u0003<\u0003<\u0005<\u048f\n<\u0003=\u0003=\u0003",
    "=\u0007=\u0494\n=\f=\u000e=\u0497\u000b=\u0003>\u0003>\u0006>\u049b",
    "\n>\r>\u000e>\u049c\u0003>\u0003>\u0006>\u04a1\n>\r>\u000e>\u04a2\u0003",
    ">\u0005>\u04a6\n>\u0003?\u0003?\u0005?\u04aa\n?\u0003@\u0006@\u04ad",
    "\n@\r@\u000e@\u04ae\u0003A\u0003A\u0007A\u04b3\nA\fA\u000eA\u04b6\u000b",
    "A\u0003A\u0003A\u0005A\u04ba\nA\u0003B\u0003B\u0007B\u04be\nB\fB\u000e",
    "B\u04c1\u000bB\u0003B\u0003B\u0007B\u04c5\nB\fB\u000eB\u04c8\u000bB",
    "\u0003B\u0003B\u0003B\u0002\u0002C\u0002\u0004\u0006\b\n\f\u000e\u0010",
    "\u0012\u0014\u0016\u0018\u001a\u001c\u001e \"$&(*,.02468:<>@BDFHJLN",
    "PRTVXZ\\^`bdfhjlnprtvxz|~\u0080\u0082\u0002\u0007\u0003\u0002()\u0004",
    "\u0002%%//\u0004\u0002\u000f\u000f,-\u0003\u0002\u0010\u0011\u0004\u0002",
    "\u0006\u0006//\u0002\u0555\u0002\u00a4\u0003\u0002\u0002\u0002\u0004",
    "\u00a6\u0003\u0002\u0002\u0002\u0006\u00aa\u0003\u0002\u0002\u0002\b",
    "\u00ac\u0003\u0002\u0002\u0002\n\u00bc\u0003\u0002\u0002\u0002\f\u00cc",
    "\u0003\u0002\u0002\u0002\u000e\u00da\u0003\u0002\u0002\u0002\u0010\u00dc",
    "\u0003\u0002\u0002\u0002\u0012\u00e2\u0003\u0002\u0002\u0002\u0014\u0102",
    "\u0003\u0002\u0002\u0002\u0016\u0107\u0003\u0002\u0002\u0002\u0018\u012a",
    "\u0003\u0002\u0002\u0002\u001a\u0134\u0003\u0002\u0002\u0002\u001c\u0144",
    "\u0003\u0002\u0002\u0002\u001e\u0154\u0003\u0002\u0002\u0002 \u0171",
    "\u0003\u0002\u0002\u0002\"\u0195\u0003\u0002\u0002\u0002$\u01ce\u0003",
    "\u0002\u0002\u0002&\u01d0\u0003\u0002\u0002\u0002(\u01e1\u0003\u0002",
    "\u0002\u0002*\u01f0\u0003\u0002\u0002\u0002,\u01f4\u0003\u0002\u0002",
    "\u0002.\u0218\u0003\u0002\u0002\u00020\u023c\u0003\u0002\u0002\u0002",
    "2\u0253\u0003\u0002\u0002\u00024\u0261\u0003\u0002\u0002\u00026\u0263",
    "\u0003\u0002\u0002\u00028\u0272\u0003\u0002\u0002\u0002:\u0274\u0003",
    "\u0002\u0002\u0002<\u0291\u0003\u0002\u0002\u0002>\u02ca\u0003\u0002",
    "\u0002\u0002@\u02d8\u0003\u0002\u0002\u0002B\u02ee\u0003\u0002\u0002",
    "\u0002D\u02f0\u0003\u0002\u0002\u0002F\u0300\u0003\u0002\u0002\u0002",
    "H\u0303\u0003\u0002\u0002\u0002J\u0315\u0003\u0002\u0002\u0002L\u0327",
    "\u0003\u0002\u0002\u0002N\u0340\u0003\u0002\u0002\u0002P\u0365\u0003",
    "\u0002\u0002\u0002R\u0367\u0003\u0002\u0002\u0002T\u0385\u0003\u0002",
    "\u0002\u0002V\u0387\u0003\u0002\u0002\u0002X\u0393\u0003\u0002\u0002",
    "\u0002Z\u0399\u0003\u0002\u0002\u0002\\\u039d\u0003\u0002\u0002\u0002",
    "^\u03b4\u0003\u0002\u0002\u0002`\u03b6\u0003\u0002\u0002\u0002b\u03c7",
    "\u0003\u0002\u0002\u0002d\u03e0\u0003\u0002\u0002\u0002f\u03ef\u0003",
    "\u0002\u0002\u0002h\u0412\u0003\u0002\u0002\u0002j\u0414\u0003\u0002",
    "\u0002\u0002l\u041d\u0003\u0002\u0002\u0002n\u0452\u0003\u0002\u0002",
    "\u0002p\u046b\u0003\u0002\u0002\u0002r\u046d\u0003\u0002\u0002\u0002",
    "t\u046f\u0003\u0002\u0002\u0002v\u047f\u0003\u0002\u0002\u0002x\u0490",
    "\u0003\u0002\u0002\u0002z\u0498\u0003\u0002\u0002\u0002|\u04a9\u0003",
    "\u0002\u0002\u0002~\u04ac\u0003\u0002\u0002\u0002\u0080\u04b9\u0003",
    "\u0002\u0002\u0002\u0082\u04bb\u0003\u0002\u0002\u0002\u0084\u0086\u0005",
    "\u0004\u0003\u0002\u0085\u0084\u0003\u0002\u0002\u0002\u0086\u0089\u0003",
    "\u0002\u0002\u0002\u0087\u0085\u0003\u0002\u0002\u0002\u0087\u0088\u0003",
    "\u0002\u0002\u0002\u0088\u008d\u0003\u0002\u0002\u0002\u0089\u0087\u0003",
    "\u0002\u0002\u0002\u008a\u008c\u0005\u0006\u0004\u0002\u008b\u008a\u0003",
    "\u0002\u0002\u0002\u008c\u008f\u0003\u0002\u0002\u0002\u008d\u008b\u0003",
    "\u0002\u0002\u0002\u008d\u008e\u0003\u0002\u0002\u0002\u008e\u009f\u0003",
    "\u0002\u0002\u0002\u008f\u008d\u0003\u0002\u0002\u0002\u0090\u00a0\u0005",
    "\u0012\n\u0002\u0091\u0092\u0005,\u0017\u0002\u0092\u0093\u0007\'\u0002",
    "\u0002\u0093\u00a0\u0003\u0002\u0002\u0002\u0094\u00a0\u0005\"\u0012",
    "\u0002\u0095\u00a0\u0005V,\u0002\u0096\u00a0\u0005\\/\u0002\u0097\u00a0",
    "\u0005`1\u0002\u0098\u00a0\u0005b2\u0002\u0099\u00a0\u0005v<\u0002\u009a",
    "\u009c\u0005\u0004\u0003\u0002\u009b\u009a\u0003\u0002\u0002\u0002\u009c",
    "\u009d\u0003\u0002\u0002\u0002\u009d\u009b\u0003\u0002\u0002\u0002\u009d",
    "\u009e\u0003\u0002\u0002\u0002\u009e\u00a0\u0003\u0002\u0002\u0002\u009f",
    "\u0090\u0003\u0002\u0002\u0002\u009f\u0091\u0003\u0002\u0002\u0002\u009f",
    "\u0094\u0003\u0002\u0002\u0002\u009f\u0095\u0003\u0002\u0002\u0002\u009f",
    "\u0096\u0003\u0002\u0002\u0002\u009f\u0097\u0003\u0002\u0002\u0002\u009f",
    "\u0098\u0003\u0002\u0002\u0002\u009f\u0099\u0003\u0002\u0002\u0002\u009f",
    "\u009b\u0003\u0002\u0002\u0002\u00a0\u00a1\u0003\u0002\u0002\u0002\u00a1",
    "\u009f\u0003\u0002\u0002\u0002\u00a1\u00a2\u0003\u0002\u0002\u0002\u00a2",
    "\u00a5\u0003\u0002\u0002\u0002\u00a3\u00a5\u0007\u0002\u0002\u0003\u00a4",
    "\u0087\u0003\u0002\u0002\u0002\u00a4\u00a3\u0003\u0002\u0002\u0002\u00a5",
    "\u0003\u0003\u0002\u0002\u0002\u00a6\u00a7\t\u0002\u0002\u0002\u00a7",
    "\u0005\u0003\u0002\u0002\u0002\u00a8\u00ab\u0005\b\u0005\u0002\u00a9",
    "\u00ab\u0005\n\u0006\u0002\u00aa\u00a8\u0003\u0002\u0002\u0002\u00aa",
    "\u00a9\u0003\u0002\u0002\u0002\u00ab\u0007\u0003\u0002\u0002\u0002\u00ac",
    "\u00ad\u0007\u0003\u0002\u0002\u00ad\u00ae\u0007)\u0002\u0002\u00ae",
    "\u00b3\u0005\f\u0007\u0002\u00af\u00b0\u0007)\u0002\u0002\u00b0\u00b1",
    "\u0007\u000e\u0002\u0002\u00b1\u00b2\u0007)\u0002\u0002\u00b2\u00b4",
    "\u0007/\u0002\u0002\u00b3\u00af\u0003\u0002\u0002\u0002\u00b3\u00b4",
    "\u0003\u0002\u0002\u0002\u00b4\u00b5\u0003\u0002\u0002\u0002\u00b5\u00b9",
    "\u0007(\u0002\u0002\u00b6\u00b8\u0005\u0004\u0003\u0002\u00b7\u00b6",
    "\u0003\u0002\u0002\u0002\u00b8\u00bb\u0003\u0002\u0002\u0002\u00b9\u00b7",
    "\u0003\u0002\u0002\u0002\u00b9\u00ba\u0003\u0002\u0002\u0002\u00ba\t",
    "\u0003\u0002\u0002\u0002\u00bb\u00b9\u0003\u0002\u0002\u0002\u00bc\u00bd",
    "\u0007\u0004\u0002\u0002\u00bd\u00be\u0007)\u0002\u0002\u00be\u00bf",
    "\u0005\f\u0007\u0002\u00bf\u00c0\u0007)\u0002\u0002\u00c0\u00c1\u0007",
    "\u0003\u0002\u0002\u00c1\u00c2\u0007)\u0002\u0002\u00c2\u00c3\u0005",
    "x=\u0002\u00c3\u00c7\u0007(\u0002\u0002\u00c4\u00c6\u0005\u0004\u0003",
    "\u0002\u00c5\u00c4\u0003\u0002\u0002\u0002\u00c6\u00c9\u0003\u0002\u0002",
    "\u0002\u00c7\u00c5\u0003\u0002\u0002\u0002\u00c7\u00c8\u0003\u0002\u0002",
    "\u0002\u00c8\u000b\u0003\u0002\u0002\u0002\u00c9\u00c7\u0003\u0002\u0002",
    "\u0002\u00ca\u00cd\u0005\u000e\b\u0002\u00cb\u00cd\u0005\u0010\t\u0002",
    "\u00cc\u00ca\u0003\u0002\u0002\u0002\u00cc\u00cb\u0003\u0002\u0002\u0002",
    "\u00cd\r\u0003\u0002\u0002\u0002\u00ce\u00d0\u0007#\u0002\u0002\u00cf",
    "\u00d1\t\u0003\u0002\u0002\u00d0\u00cf\u0003\u0002\u0002\u0002\u00d1",
    "\u00d2\u0003\u0002\u0002\u0002\u00d2\u00d0\u0003\u0002\u0002\u0002\u00d2",
    "\u00d3\u0003\u0002\u0002\u0002\u00d3\u00db\u0003\u0002\u0002\u0002\u00d4",
    "\u00d6\u0007$\u0002\u0002\u00d5\u00d7\t\u0003\u0002\u0002\u00d6\u00d5",
    "\u0003\u0002\u0002\u0002\u00d7\u00d8\u0003\u0002\u0002\u0002\u00d8\u00d6",
    "\u0003\u0002\u0002\u0002\u00d8\u00d9\u0003\u0002\u0002\u0002\u00d9\u00db",
    "\u0003\u0002\u0002\u0002\u00da\u00ce\u0003\u0002\u0002\u0002\u00da\u00d4",
    "\u0003\u0002\u0002\u0002\u00db\u000f\u0003\u0002\u0002\u0002\u00dc\u00de",
    "\u0007\"\u0002\u0002\u00dd\u00df\t\u0003\u0002\u0002\u00de\u00dd\u0003",
    "\u0002\u0002\u0002\u00df\u00e0\u0003\u0002\u0002\u0002\u00e0\u00de\u0003",
    "\u0002\u0002\u0002\u00e0\u00e1\u0003\u0002\u0002\u0002\u00e1\u0011\u0003",
    "\u0002\u0002\u0002\u00e2\u00e4\u0007\u0005\u0002\u0002\u00e3\u00e5\u0005",
    "\u0004\u0003\u0002\u00e4\u00e3\u0003\u0002\u0002\u0002\u00e5\u00e6\u0003",
    "\u0002\u0002\u0002\u00e6\u00e4\u0003\u0002\u0002\u0002\u00e6\u00e7\u0003",
    "\u0002\u0002\u0002\u00e7\u00e8\u0003\u0002\u0002\u0002\u00e8\u00f0\u0005",
    "\u0014\u000b\u0002\u00e9\u00eb\u0005\u0004\u0003\u0002\u00ea\u00e9\u0003",
    "\u0002\u0002\u0002\u00eb\u00ee\u0003\u0002\u0002\u0002\u00ec\u00ea\u0003",
    "\u0002\u0002\u0002\u00ec\u00ed\u0003\u0002\u0002\u0002\u00ed\u00ef\u0003",
    "\u0002\u0002\u0002\u00ee\u00ec\u0003\u0002\u0002\u0002\u00ef\u00f1\u0005",
    "\u0016\f\u0002\u00f0\u00ec\u0003\u0002\u0002\u0002\u00f0\u00f1\u0003",
    "\u0002\u0002\u0002\u00f1\u00f3\u0003\u0002\u0002\u0002\u00f2\u00f4\u0005",
    "\u0004\u0003\u0002\u00f3\u00f2\u0003\u0002\u0002\u0002\u00f4\u00f5\u0003",
    "\u0002\u0002\u0002\u00f5\u00f3\u0003\u0002\u0002\u0002\u00f5\u00f6\u0003",
    "\u0002\u0002\u0002\u00f6\u0100\u0003\u0002\u0002\u0002\u00f7\u0101\u0005",
    "\u001a\u000e\u0002\u00f8\u00fc\u0007!\u0002\u0002\u00f9\u00fb\u0005",
    "\u0004\u0003\u0002\u00fa\u00f9\u0003\u0002\u0002\u0002\u00fb\u00fe\u0003",
    "\u0002\u0002\u0002\u00fc\u00fa\u0003\u0002\u0002\u0002\u00fc\u00fd\u0003",
    "\u0002\u0002\u0002\u00fd\u00ff\u0003\u0002\u0002\u0002\u00fe\u00fc\u0003",
    "\u0002\u0002\u0002\u00ff\u0101\u0005\u0018\r\u0002\u0100\u00f7\u0003",
    "\u0002\u0002\u0002\u0100\u00f8\u0003\u0002\u0002\u0002\u0101\u0013\u0003",
    "\u0002\u0002\u0002\u0102\u0105\u0007/\u0002\u0002\u0103\u0104\u0007",
    " \u0002\u0002\u0104\u0106\u0007/\u0002\u0002\u0105\u0103\u0003\u0002",
    "\u0002\u0002\u0105\u0106\u0003\u0002\u0002\u0002\u0106\u0015\u0003\u0002",
    "\u0002\u0002\u0107\u010b\u0007\u001c\u0002\u0002\u0108\u010a\u0005\u0004",
    "\u0003\u0002\u0109\u0108\u0003\u0002\u0002\u0002\u010a\u010d\u0003\u0002",
    "\u0002\u0002\u010b\u0109\u0003\u0002\u0002\u0002\u010b\u010c\u0003\u0002",
    "\u0002\u0002\u010c\u010e\u0003\u0002\u0002\u0002\u010d\u010b\u0003\u0002",
    "\u0002\u0002\u010e\u0112\u0005\u0018\r\u0002\u010f\u0111\u0005\u0004",
    "\u0003\u0002\u0110\u010f\u0003\u0002\u0002\u0002\u0111\u0114\u0003\u0002",
    "\u0002\u0002\u0112\u0110\u0003\u0002\u0002\u0002\u0112\u0113\u0003\u0002",
    "\u0002\u0002\u0113\u0125\u0003\u0002\u0002\u0002\u0114\u0112\u0003\u0002",
    "\u0002\u0002\u0115\u0119\u0007\u0017\u0002\u0002\u0116\u0118\u0005\u0004",
    "\u0003\u0002\u0117\u0116\u0003\u0002\u0002\u0002\u0118\u011b\u0003\u0002",
    "\u0002\u0002\u0119\u0117\u0003\u0002\u0002\u0002\u0119\u011a\u0003\u0002",
    "\u0002\u0002\u011a\u011c\u0003\u0002\u0002\u0002\u011b\u0119\u0003\u0002",
    "\u0002\u0002\u011c\u0120\u0005\u0018\r\u0002\u011d\u011f\u0005\u0004",
    "\u0003\u0002\u011e\u011d\u0003\u0002\u0002\u0002\u011f\u0122\u0003\u0002",
    "\u0002\u0002\u0120\u011e\u0003\u0002\u0002\u0002\u0120\u0121\u0003\u0002",
    "\u0002\u0002\u0121\u0124\u0003\u0002\u0002\u0002\u0122\u0120\u0003\u0002",
    "\u0002\u0002\u0123\u0115\u0003\u0002\u0002\u0002\u0124\u0127\u0003\u0002",
    "\u0002\u0002\u0125\u0123\u0003\u0002\u0002\u0002\u0125\u0126\u0003\u0002",
    "\u0002\u0002\u0126\u0128\u0003\u0002\u0002\u0002\u0127\u0125\u0003\u0002",
    "\u0002\u0002\u0128\u0129\u0007\u001d\u0002\u0002\u0129\u0017\u0003\u0002",
    "\u0002\u0002\u012a\u0132\u0005\u0014\u000b\u0002\u012b\u012d\u0005\u0004",
    "\u0003\u0002\u012c\u012b\u0003\u0002\u0002\u0002\u012d\u0130\u0003\u0002",
    "\u0002\u0002\u012e\u012c\u0003\u0002\u0002\u0002\u012e\u012f\u0003\u0002",
    "\u0002\u0002\u012f\u0131\u0003\u0002\u0002\u0002\u0130\u012e\u0003\u0002",
    "\u0002\u0002\u0131\u0133\u0005\u0016\f\u0002\u0132\u012e\u0003\u0002",
    "\u0002\u0002\u0132\u0133\u0003\u0002\u0002\u0002\u0133\u0019\u0003\u0002",
    "\u0002\u0002\u0134\u0138\u0007\u0018\u0002\u0002\u0135\u0137\u0005\u0004",
    "\u0003\u0002\u0136\u0135\u0003\u0002\u0002\u0002\u0137\u013a\u0003\u0002",
    "\u0002\u0002\u0138\u0136\u0003\u0002\u0002\u0002\u0138\u0139\u0003\u0002",
    "\u0002\u0002\u0139\u013b\u0003\u0002\u0002\u0002\u013a\u0138\u0003\u0002",
    "\u0002\u0002\u013b\u013f\u0005\u001e\u0010\u0002\u013c\u013e\u0005\u0004",
    "\u0003\u0002\u013d\u013c\u0003\u0002\u0002\u0002\u013e\u0141\u0003\u0002",
    "\u0002\u0002\u013f\u013d\u0003\u0002\u0002\u0002\u013f\u0140\u0003\u0002",
    "\u0002\u0002\u0140\u0142\u0003\u0002\u0002\u0002\u0141\u013f\u0003\u0002",
    "\u0002\u0002\u0142\u0143\u0007\u0019\u0002\u0002\u0143\u001b\u0003\u0002",
    "\u0002\u0002\u0144\u0148\u0007/\u0002\u0002\u0145\u0147\u0005\u0004",
    "\u0003\u0002\u0146\u0145\u0003\u0002\u0002\u0002\u0147\u014a\u0003\u0002",
    "\u0002\u0002\u0148\u0146\u0003\u0002\u0002\u0002\u0148\u0149\u0003\u0002",
    "\u0002\u0002\u0149\u014b\u0003\u0002\u0002\u0002\u014a\u0148\u0003\u0002",
    "\u0002\u0002\u014b\u014f\u0007&\u0002\u0002\u014c\u014e\u0005\u0004",
    "\u0003\u0002\u014d\u014c\u0003\u0002\u0002\u0002\u014e\u0151\u0003\u0002",
    "\u0002\u0002\u014f\u014d\u0003\u0002\u0002\u0002\u014f\u0150\u0003\u0002",
    "\u0002\u0002\u0150\u0152\u0003\u0002\u0002\u0002\u0151\u014f\u0003\u0002",
    "\u0002\u0002\u0152\u0153\u0005\u0018\r\u0002\u0153\u001d\u0003\u0002",
    "\u0002\u0002\u0154\u0158\u0005\u001c\u000f\u0002\u0155\u0157\u0005\u0004",
    "\u0003\u0002\u0156\u0155\u0003\u0002\u0002\u0002\u0157\u015a\u0003\u0002",
    "\u0002\u0002\u0158\u0156\u0003\u0002\u0002\u0002\u0158\u0159\u0003\u0002",
    "\u0002\u0002\u0159\u016b\u0003\u0002\u0002\u0002\u015a\u0158\u0003\u0002",
    "\u0002\u0002\u015b\u015f\u0007\u0017\u0002\u0002\u015c\u015e\u0005\u0004",
    "\u0003\u0002\u015d\u015c\u0003\u0002\u0002\u0002\u015e\u0161\u0003\u0002",
    "\u0002\u0002\u015f\u015d\u0003\u0002\u0002\u0002\u015f\u0160\u0003\u0002",
    "\u0002\u0002\u0160\u0162\u0003\u0002\u0002\u0002\u0161\u015f\u0003\u0002",
    "\u0002\u0002\u0162\u0166\u0005\u001c\u000f\u0002\u0163\u0165\u0005\u0004",
    "\u0003\u0002\u0164\u0163\u0003\u0002\u0002\u0002\u0165\u0168\u0003\u0002",
    "\u0002\u0002\u0166\u0164\u0003\u0002\u0002\u0002\u0166\u0167\u0003\u0002",
    "\u0002\u0002\u0167\u016a\u0003\u0002\u0002\u0002\u0168\u0166\u0003\u0002",
    "\u0002\u0002\u0169\u015b\u0003\u0002\u0002\u0002\u016a\u016d\u0003\u0002",
    "\u0002\u0002\u016b\u0169\u0003\u0002\u0002\u0002\u016b\u016c\u0003\u0002",
    "\u0002\u0002\u016c\u016f\u0003\u0002\u0002\u0002\u016d\u016b\u0003\u0002",
    "\u0002\u0002\u016e\u0170\u0007\u0017\u0002\u0002\u016f\u016e\u0003\u0002",
    "\u0002\u0002\u016f\u0170\u0003\u0002\u0002\u0002\u0170\u001f\u0003\u0002",
    "\u0002\u0002\u0171\u0175\u0007/\u0002\u0002\u0172\u0174\u0005\u0004",
    "\u0003\u0002\u0173\u0172\u0003\u0002\u0002\u0002\u0174\u0177\u0003\u0002",
    "\u0002\u0002\u0175\u0173\u0003\u0002\u0002\u0002\u0175\u0176\u0003\u0002",
    "\u0002\u0002\u0176\u0178\u0003\u0002\u0002\u0002\u0177\u0175\u0003\u0002",
    "\u0002\u0002\u0178\u017c\u0007&\u0002\u0002\u0179\u017b\u0005\u0004",
    "\u0003\u0002\u017a\u0179\u0003\u0002\u0002\u0002\u017b\u017e\u0003\u0002",
    "\u0002\u0002\u017c\u017a\u0003\u0002\u0002\u0002\u017c\u017d\u0003\u0002",
    "\u0002\u0002\u017d\u017f\u0003\u0002\u0002\u0002\u017e\u017c\u0003\u0002",
    "\u0002\u0002\u017f\u0192\u0005\u0018\r\u0002\u0180\u0181\u0007\u0017",
    "\u0002\u0002\u0181\u0185\u0007/\u0002\u0002\u0182\u0184\u0005\u0004",
    "\u0003\u0002\u0183\u0182\u0003\u0002\u0002\u0002\u0184\u0187\u0003\u0002",
    "\u0002\u0002\u0185\u0183\u0003\u0002\u0002\u0002\u0185\u0186\u0003\u0002",
    "\u0002\u0002\u0186\u0188\u0003\u0002\u0002\u0002\u0187\u0185\u0003\u0002",
    "\u0002\u0002\u0188\u018c\u0007&\u0002\u0002\u0189\u018b\u0005\u0004",
    "\u0003\u0002\u018a\u0189\u0003\u0002\u0002\u0002\u018b\u018e\u0003\u0002",
    "\u0002\u0002\u018c\u018a\u0003\u0002\u0002\u0002\u018c\u018d\u0003\u0002",
    "\u0002\u0002\u018d\u018f\u0003\u0002\u0002\u0002\u018e\u018c\u0003\u0002",
    "\u0002\u0002\u018f\u0191\u0005\u0018\r\u0002\u0190\u0180\u0003\u0002",
    "\u0002\u0002\u0191\u0194\u0003\u0002\u0002\u0002\u0192\u0190\u0003\u0002",
    "\u0002\u0002\u0192\u0193\u0003\u0002\u0002\u0002\u0193!\u0003\u0002",
    "\u0002\u0002\u0194\u0192\u0003\u0002\u0002\u0002\u0195\u0197\u0007\u0006",
    "\u0002\u0002\u0196\u0198\u0005\u0004\u0003\u0002\u0197\u0196\u0003\u0002",
    "\u0002\u0002\u0198\u0199\u0003\u0002\u0002\u0002\u0199\u0197\u0003\u0002",
    "\u0002\u0002\u0199\u019a\u0003\u0002\u0002\u0002\u019a\u01bf\u0003\u0002",
    "\u0002\u0002\u019b\u019f\u0007/\u0002\u0002\u019c\u019e\u0005\u0004",
    "\u0003\u0002\u019d\u019c\u0003\u0002\u0002\u0002\u019e\u01a1\u0003\u0002",
    "\u0002\u0002\u019f\u019d\u0003\u0002\u0002\u0002\u019f\u01a0\u0003\u0002",
    "\u0002\u0002\u01a0\u01a3\u0003\u0002\u0002\u0002\u01a1\u019f\u0003\u0002",
    "\u0002\u0002\u01a2\u019b\u0003\u0002\u0002\u0002\u01a2\u01a3\u0003\u0002",
    "\u0002\u0002\u01a3\u01a4\u0003\u0002\u0002\u0002\u01a4\u01a6\u0007\u001a",
    "\u0002\u0002\u01a5\u01a7\u0005 \u0011\u0002\u01a6\u01a5\u0003\u0002",
    "\u0002\u0002\u01a6\u01a7\u0003\u0002\u0002\u0002\u01a7\u01a8\u0003\u0002",
    "\u0002\u0002\u01a8\u01ac\u0007\u001b\u0002\u0002\u01a9\u01ab\u0005\u0004",
    "\u0003\u0002\u01aa\u01a9\u0003\u0002\u0002\u0002\u01ab\u01ae\u0003\u0002",
    "\u0002\u0002\u01ac\u01aa\u0003\u0002\u0002\u0002\u01ac\u01ad\u0003\u0002",
    "\u0002\u0002\u01ad\u01bd\u0003\u0002\u0002\u0002\u01ae\u01ac\u0003\u0002",
    "\u0002\u0002\u01af\u01b1\u0005\u0004\u0003\u0002\u01b0\u01af\u0003\u0002",
    "\u0002\u0002\u01b0\u01b1\u0003\u0002\u0002\u0002\u01b1\u01b2\u0003\u0002",
    "\u0002\u0002\u01b2\u01b4\u0007&\u0002\u0002\u01b3\u01b5\u0005\u0004",
    "\u0003\u0002\u01b4\u01b3\u0003\u0002\u0002\u0002\u01b4\u01b5\u0003\u0002",
    "\u0002\u0002\u01b5\u01b6\u0003\u0002\u0002\u0002\u01b6\u01ba\u0005\u0018",
    "\r\u0002\u01b7\u01b9\u0005\u0004\u0003\u0002\u01b8\u01b7\u0003\u0002",
    "\u0002\u0002\u01b9\u01bc\u0003\u0002\u0002\u0002\u01ba\u01b8\u0003\u0002",
    "\u0002\u0002\u01ba\u01bb\u0003\u0002\u0002\u0002\u01bb\u01be\u0003\u0002",
    "\u0002\u0002\u01bc\u01ba\u0003\u0002\u0002\u0002\u01bd\u01b0\u0003\u0002",
    "\u0002\u0002\u01bd\u01be\u0003\u0002\u0002\u0002\u01be\u01c0\u0003\u0002",
    "\u0002\u0002\u01bf\u01a2\u0003\u0002\u0002\u0002\u01bf\u01c0\u0003\u0002",
    "\u0002\u0002\u01c0\u01c1\u0003\u0002\u0002\u0002\u01c1\u01c3\u0005$",
    "\u0013\u0002\u01c2\u01c4\u0007\'\u0002\u0002\u01c3\u01c2\u0003\u0002",
    "\u0002\u0002\u01c3\u01c4\u0003\u0002\u0002\u0002\u01c4#\u0003\u0002",
    "\u0002\u0002\u01c5\u01cf\u0005&\u0014\u0002\u01c6\u01ca\u0007!\u0002",
    "\u0002\u01c7\u01c9\u0005\u0004\u0003\u0002\u01c8\u01c7\u0003\u0002\u0002",
    "\u0002\u01c9\u01cc\u0003\u0002\u0002\u0002\u01ca\u01c8\u0003\u0002\u0002",
    "\u0002\u01ca\u01cb\u0003\u0002\u0002\u0002\u01cb\u01cd\u0003\u0002\u0002",
    "\u0002\u01cc\u01ca\u0003\u0002\u0002\u0002\u01cd\u01cf\u00056\u001c",
    "\u0002\u01ce\u01c5\u0003\u0002\u0002\u0002\u01ce\u01c6\u0003\u0002\u0002",
    "\u0002\u01cf%\u0003\u0002\u0002\u0002\u01d0\u01d2\u0007\u0018\u0002",
    "\u0002\u01d1\u01d3\u0005(\u0015\u0002\u01d2\u01d1\u0003\u0002\u0002",
    "\u0002\u01d3\u01d4\u0003\u0002\u0002\u0002\u01d4\u01d2\u0003\u0002\u0002",
    "\u0002\u01d4\u01d5\u0003\u0002\u0002\u0002\u01d5\u01d9\u0003\u0002\u0002",
    "\u0002\u01d6\u01d8\u0005\u0004\u0003\u0002\u01d7\u01d6\u0003\u0002\u0002",
    "\u0002\u01d8\u01db\u0003\u0002\u0002\u0002\u01d9\u01d7\u0003\u0002\u0002",
    "\u0002\u01d9\u01da\u0003\u0002\u0002\u0002\u01da\u01dc\u0003\u0002\u0002",
    "\u0002\u01db\u01d9\u0003\u0002\u0002\u0002\u01dc\u01dd\u0007\u0019\u0002",
    "\u0002\u01dd\'\u0003\u0002\u0002\u0002\u01de\u01e0\u0005\u0004\u0003",
    "\u0002\u01df\u01de\u0003\u0002\u0002\u0002\u01e0\u01e3\u0003\u0002\u0002",
    "\u0002\u01e1\u01df\u0003\u0002\u0002\u0002\u01e1\u01e2\u0003\u0002\u0002",
    "\u0002\u01e2\u01ec\u0003\u0002\u0002\u0002\u01e3\u01e1\u0003\u0002\u0002",
    "\u0002\u01e4\u01ed\u0005*\u0016\u0002\u01e5\u01ed\u0005J&\u0002\u01e6",
    "\u01ed\u0005L\'\u0002\u01e7\u01ed\u0005N(\u0002\u01e8\u01ed\u00050\u0019",
    "\u0002\u01e9\u01ea\u00056\u001c\u0002\u01ea\u01eb\u0007\'\u0002\u0002",
    "\u01eb\u01ed\u0003\u0002\u0002\u0002\u01ec\u01e4\u0003\u0002\u0002\u0002",
    "\u01ec\u01e5\u0003\u0002\u0002\u0002\u01ec\u01e6\u0003\u0002\u0002\u0002",
    "\u01ec\u01e7\u0003\u0002\u0002\u0002\u01ec\u01e8\u0003\u0002\u0002\u0002",
    "\u01ec\u01e9\u0003\u0002\u0002\u0002\u01ed)\u0003\u0002\u0002\u0002",
    "\u01ee\u01f1\u0005,\u0017\u0002\u01ef\u01f1\u0005.\u0018\u0002\u01f0",
    "\u01ee\u0003\u0002\u0002\u0002\u01f0\u01ef\u0003\u0002\u0002\u0002\u01f1",
    "\u01f2\u0003\u0002\u0002\u0002\u01f2\u01f3\u0007\'\u0002\u0002\u01f3",
    "+\u0003\u0002\u0002\u0002\u01f4\u01f8\u0007\n\u0002\u0002\u01f5\u01f7",
    "\u0005\u0004\u0003\u0002\u01f6\u01f5\u0003\u0002\u0002\u0002\u01f7\u01fa",
    "\u0003\u0002\u0002\u0002\u01f8\u01f6\u0003\u0002\u0002\u0002\u01f8\u01f9",
    "\u0003\u0002\u0002\u0002\u01f9\u01fb\u0003\u0002\u0002\u0002\u01fa\u01f8",
    "\u0003\u0002\u0002\u0002\u01fb\u01ff\u0007/\u0002\u0002\u01fc\u01fe",
    "\u0005\u0004\u0003\u0002\u01fd\u01fc\u0003\u0002\u0002\u0002\u01fe\u0201",
    "\u0003\u0002\u0002\u0002\u01ff\u01fd\u0003\u0002\u0002\u0002\u01ff\u0200",
    "\u0003\u0002\u0002\u0002\u0200\u0207\u0003\u0002\u0002\u0002\u0201\u01ff",
    "\u0003\u0002\u0002\u0002\u0202\u0204\u0007&\u0002\u0002\u0203\u0205",
    "\u0005\u0004\u0003\u0002\u0204\u0203\u0003\u0002\u0002\u0002\u0204\u0205",
    "\u0003\u0002\u0002\u0002\u0205\u0206\u0003\u0002\u0002\u0002\u0206\u0208",
    "\u0005\u0018\r\u0002\u0207\u0202\u0003\u0002\u0002\u0002\u0207\u0208",
    "\u0003\u0002\u0002\u0002\u0208\u020c\u0003\u0002\u0002\u0002\u0209\u020b",
    "\u0005\u0004\u0003\u0002\u020a\u0209\u0003\u0002\u0002\u0002\u020b\u020e",
    "\u0003\u0002\u0002\u0002\u020c\u020a\u0003\u0002\u0002\u0002\u020c\u020d",
    "\u0003\u0002\u0002\u0002\u020d\u020f\u0003\u0002\u0002\u0002\u020e\u020c",
    "\u0003\u0002\u0002\u0002\u020f\u0213\u0007!\u0002\u0002\u0210\u0212",
    "\u0005\u0004\u0003\u0002\u0211\u0210\u0003\u0002\u0002\u0002\u0212\u0215",
    "\u0003\u0002\u0002\u0002\u0213\u0211\u0003\u0002\u0002\u0002\u0213\u0214",
    "\u0003\u0002\u0002\u0002\u0214\u0216\u0003\u0002\u0002\u0002\u0215\u0213",
    "\u0003\u0002\u0002\u0002\u0216\u0217\u00056\u001c\u0002\u0217-\u0003",
    "\u0002\u0002\u0002\u0218\u021c\u0007\u000b\u0002\u0002\u0219\u021b\u0005",
    "\u0004\u0003\u0002\u021a\u0219\u0003\u0002\u0002\u0002\u021b\u021e\u0003",
    "\u0002\u0002\u0002\u021c\u021a\u0003\u0002\u0002\u0002\u021c\u021d\u0003",
    "\u0002\u0002\u0002\u021d\u021f\u0003\u0002\u0002\u0002\u021e\u021c\u0003",
    "\u0002\u0002\u0002\u021f\u0223\u0007/\u0002\u0002\u0220\u0222\u0005",
    "\u0004\u0003\u0002\u0221\u0220\u0003\u0002\u0002\u0002\u0222\u0225\u0003",
    "\u0002\u0002\u0002\u0223\u0221\u0003\u0002\u0002\u0002\u0223\u0224\u0003",
    "\u0002\u0002\u0002\u0224\u022b\u0003\u0002\u0002\u0002\u0225\u0223\u0003",
    "\u0002\u0002\u0002\u0226\u0228\u0007&\u0002\u0002\u0227\u0229\u0005",
    "\u0004\u0003\u0002\u0228\u0227\u0003\u0002\u0002\u0002\u0228\u0229\u0003",
    "\u0002\u0002\u0002\u0229\u022a\u0003\u0002\u0002\u0002\u022a\u022c\u0005",
    "\u0018\r\u0002\u022b\u0226\u0003\u0002\u0002\u0002\u022b\u022c\u0003",
    "\u0002\u0002\u0002\u022c\u0230\u0003\u0002\u0002\u0002\u022d\u022f\u0005",
    "\u0004\u0003\u0002\u022e\u022d\u0003\u0002\u0002\u0002\u022f\u0232\u0003",
    "\u0002\u0002\u0002\u0230\u022e\u0003\u0002\u0002\u0002\u0230\u0231\u0003",
    "\u0002\u0002\u0002\u0231\u0233\u0003\u0002\u0002\u0002\u0232\u0230\u0003",
    "\u0002\u0002\u0002\u0233\u0237\u0007!\u0002\u0002\u0234\u0236\u0005",
    "\u0004\u0003\u0002\u0235\u0234\u0003\u0002\u0002\u0002\u0236\u0239\u0003",
    "\u0002\u0002\u0002\u0237\u0235\u0003\u0002\u0002\u0002\u0237\u0238\u0003",
    "\u0002\u0002\u0002\u0238\u023a\u0003\u0002\u0002\u0002\u0239\u0237\u0003",
    "\u0002\u0002\u0002\u023a\u023b\u00056\u001c\u0002\u023b/\u0003\u0002",
    "\u0002\u0002\u023c\u0240\u0005~@\u0002\u023d\u023f\u0005\u0004\u0003",
    "\u0002\u023e\u023d\u0003\u0002\u0002\u0002\u023f\u0242\u0003\u0002\u0002",
    "\u0002\u0240\u023e\u0003\u0002\u0002\u0002\u0240\u0241\u0003\u0002\u0002",
    "\u0002\u0241\u0243\u0003\u0002\u0002\u0002\u0242\u0240\u0003\u0002\u0002",
    "\u0002\u0243\u0247\u0007!\u0002\u0002\u0244\u0246\u0005\u0004\u0003",
    "\u0002\u0245\u0244\u0003\u0002\u0002\u0002\u0246\u0249\u0003\u0002\u0002",
    "\u0002\u0247\u0245\u0003\u0002\u0002\u0002\u0247\u0248\u0003\u0002\u0002",
    "\u0002\u0248\u024a\u0003\u0002\u0002\u0002\u0249\u0247\u0003\u0002\u0002",
    "\u0002\u024a\u024b\u00056\u001c\u0002\u024b\u024c\u0007\'\u0002\u0002",
    "\u024c1\u0003\u0002\u0002\u0002\u024d\u0254\u0007 \u0002\u0002\u024e",
    "\u0254\u0007/\u0002\u0002\u024f\u0254\u0005R*\u0002\u0250\u0254\u0005",
    "\"\u0012\u0002\u0251\u0254\u0005H%\u0002\u0252\u0254\u00058\u001d\u0002",
    "\u0253\u024d\u0003\u0002\u0002\u0002\u0253\u024e\u0003\u0002\u0002\u0002",
    "\u0253\u024f\u0003\u0002\u0002\u0002\u0253\u0250\u0003\u0002\u0002\u0002",
    "\u0253\u0251\u0003\u0002\u0002\u0002\u0253\u0252\u0003\u0002\u0002\u0002",
    "\u02543\u0003\u0002\u0002\u0002\u0255\u0259\u00052\u001a\u0002\u0256",
    "\u0258\u0005\u0004\u0003\u0002\u0257\u0256\u0003\u0002\u0002\u0002\u0258",
    "\u025b\u0003\u0002\u0002\u0002\u0259\u0257\u0003\u0002\u0002\u0002\u0259",
    "\u025a\u0003\u0002\u0002\u0002\u025a\u025d\u0003\u0002\u0002\u0002\u025b",
    "\u0259\u0003\u0002\u0002\u0002\u025c\u0255\u0003\u0002\u0002\u0002\u025d",
    "\u025e\u0003\u0002\u0002\u0002\u025e\u025c\u0003\u0002\u0002\u0002\u025e",
    "\u025f\u0003\u0002\u0002\u0002\u025f\u0262\u0003\u0002\u0002\u0002\u0260",
    "\u0262\u0005T+\u0002\u0261\u025c\u0003\u0002\u0002\u0002\u0261\u0260",
    "\u0003\u0002\u0002\u0002\u02625\u0003\u0002\u0002\u0002\u0263\u026d",
    "\u00054\u001b\u0002\u0264\u0266\u0005\u0004\u0003\u0002\u0265\u0264",
    "\u0003\u0002\u0002\u0002\u0266\u0269\u0003\u0002\u0002\u0002\u0267\u0265",
    "\u0003\u0002\u0002\u0002\u0267\u0268\u0003\u0002\u0002\u0002\u0268\u026a",
    "\u0003\u0002\u0002\u0002\u0269\u0267\u0003\u0002\u0002\u0002\u026a\u026c",
    "\u00054\u001b\u0002\u026b\u0267\u0003\u0002\u0002\u0002\u026c\u026f",
    "\u0003\u0002\u0002\u0002\u026d\u026b\u0003\u0002\u0002\u0002\u026d\u026e",
    "\u0003\u0002\u0002\u0002\u026e7\u0003\u0002\u0002\u0002\u026f\u026d",
    "\u0003\u0002\u0002\u0002\u0270\u0273\u0005B\"\u0002\u0271\u0273\u0005",
    "F$\u0002\u0272\u0270\u0003\u0002\u0002\u0002\u0272\u0271\u0003\u0002",
    "\u0002\u0002\u02739\u0003\u0002\u0002\u0002\u0274\u0278\u00056\u001c",
    "\u0002\u0275\u0277\u0005\u0004\u0003\u0002\u0276\u0275\u0003\u0002\u0002",
    "\u0002\u0277\u027a\u0003\u0002\u0002\u0002\u0278\u0276\u0003\u0002\u0002",
    "\u0002\u0278\u0279\u0003\u0002\u0002\u0002\u0279\u028b\u0003\u0002\u0002",
    "\u0002\u027a\u0278\u0003\u0002\u0002\u0002\u027b\u027f\u0007\u0017\u0002",
    "\u0002\u027c\u027e\u0005\u0004\u0003\u0002\u027d\u027c\u0003\u0002\u0002",
    "\u0002\u027e\u0281\u0003\u0002\u0002\u0002\u027f\u027d\u0003\u0002\u0002",
    "\u0002\u027f\u0280\u0003\u0002\u0002\u0002\u0280\u0282\u0003\u0002\u0002",
    "\u0002\u0281\u027f\u0003\u0002\u0002\u0002\u0282\u0286\u00056\u001c",
    "\u0002\u0283\u0285\u0005\u0004\u0003\u0002\u0284\u0283\u0003\u0002\u0002",
    "\u0002\u0285\u0288\u0003\u0002\u0002\u0002\u0286\u0284\u0003\u0002\u0002",
    "\u0002\u0286\u0287\u0003\u0002\u0002\u0002\u0287\u028a\u0003\u0002\u0002",
    "\u0002\u0288\u0286\u0003\u0002\u0002\u0002\u0289\u027b\u0003\u0002\u0002",
    "\u0002\u028a\u028d\u0003\u0002\u0002\u0002\u028b\u0289\u0003\u0002\u0002",
    "\u0002\u028b\u028c\u0003\u0002\u0002\u0002\u028c\u028f\u0003\u0002\u0002",
    "\u0002\u028d\u028b\u0003\u0002\u0002\u0002\u028e\u0290\u0007\u0017\u0002",
    "\u0002\u028f\u028e\u0003\u0002\u0002\u0002\u028f\u0290\u0003\u0002\u0002",
    "\u0002\u0290;\u0003\u0002\u0002\u0002\u0291\u0295\u0007/\u0002\u0002",
    "\u0292\u0294\u0005\u0004\u0003\u0002\u0293\u0292\u0003\u0002\u0002\u0002",
    "\u0294\u0297\u0003\u0002\u0002\u0002\u0295\u0293\u0003\u0002\u0002\u0002",
    "\u0295\u0296\u0003\u0002\u0002\u0002\u0296\u0298\u0003\u0002\u0002\u0002",
    "\u0297\u0295\u0003\u0002\u0002\u0002\u0298\u029c\u0007&\u0002\u0002",
    "\u0299\u029b\u0005\u0004\u0003\u0002\u029a\u0299\u0003\u0002\u0002\u0002",
    "\u029b\u029e\u0003\u0002\u0002\u0002\u029c\u029a\u0003\u0002\u0002\u0002",
    "\u029c\u029d\u0003\u0002\u0002\u0002\u029d\u029f\u0003\u0002\u0002\u0002",
    "\u029e\u029c\u0003\u0002\u0002\u0002\u029f\u02a3\u00056\u001c\u0002",
    "\u02a0\u02a2\u0005\u0004\u0003\u0002\u02a1\u02a0\u0003\u0002\u0002\u0002",
    "\u02a2\u02a5\u0003\u0002\u0002\u0002\u02a3\u02a1\u0003\u0002\u0002\u0002",
    "\u02a3\u02a4\u0003\u0002\u0002\u0002\u02a4\u02c4\u0003\u0002\u0002\u0002",
    "\u02a5\u02a3\u0003\u0002\u0002\u0002\u02a6\u02aa\u0007\u0017\u0002\u0002",
    "\u02a7\u02a9\u0005\u0004\u0003\u0002\u02a8\u02a7\u0003\u0002\u0002\u0002",
    "\u02a9\u02ac\u0003\u0002\u0002\u0002\u02aa\u02a8\u0003\u0002\u0002\u0002",
    "\u02aa\u02ab\u0003\u0002\u0002\u0002\u02ab\u02ad\u0003\u0002\u0002\u0002",
    "\u02ac\u02aa\u0003\u0002\u0002\u0002\u02ad\u02b1\u0007/\u0002\u0002",
    "\u02ae\u02b0\u0005\u0004\u0003\u0002\u02af\u02ae\u0003\u0002\u0002\u0002",
    "\u02b0\u02b3\u0003\u0002\u0002\u0002\u02b1\u02af\u0003\u0002\u0002\u0002",
    "\u02b1\u02b2\u0003\u0002\u0002\u0002\u02b2\u02b4\u0003\u0002\u0002\u0002",
    "\u02b3\u02b1\u0003\u0002\u0002\u0002\u02b4\u02b8\u0007&\u0002\u0002",
    "\u02b5\u02b7\u0005\u0004\u0003\u0002\u02b6\u02b5\u0003\u0002\u0002\u0002",
    "\u02b7\u02ba\u0003\u0002\u0002\u0002\u02b8\u02b6\u0003\u0002\u0002\u0002",
    "\u02b8\u02b9\u0003\u0002\u0002\u0002\u02b9\u02bb\u0003\u0002\u0002\u0002",
    "\u02ba\u02b8\u0003\u0002\u0002\u0002\u02bb\u02bf\u00056\u001c\u0002",
    "\u02bc\u02be\u0005\u0004\u0003\u0002\u02bd\u02bc\u0003\u0002\u0002\u0002",
    "\u02be\u02c1\u0003\u0002\u0002\u0002\u02bf\u02bd\u0003\u0002\u0002\u0002",
    "\u02bf\u02c0\u0003\u0002\u0002\u0002\u02c0\u02c3\u0003\u0002\u0002\u0002",
    "\u02c1\u02bf\u0003\u0002\u0002\u0002\u02c2\u02a6\u0003\u0002\u0002\u0002",
    "\u02c3\u02c6\u0003\u0002\u0002\u0002\u02c4\u02c2\u0003\u0002\u0002\u0002",
    "\u02c4\u02c5\u0003\u0002\u0002\u0002\u02c5\u02c8\u0003\u0002\u0002\u0002",
    "\u02c6\u02c4\u0003\u0002\u0002\u0002\u02c7\u02c9\u0007\u0017\u0002\u0002",
    "\u02c8\u02c7\u0003\u0002\u0002\u0002\u02c8\u02c9\u0003\u0002\u0002\u0002",
    "\u02c9=\u0003\u0002\u0002\u0002\u02ca\u02ce\u0007\u0015\u0002\u0002",
    "\u02cb\u02cd\u0007)\u0002\u0002\u02cc\u02cb\u0003\u0002\u0002\u0002",
    "\u02cd\u02d0\u0003\u0002\u0002\u0002\u02ce\u02cc\u0003\u0002\u0002\u0002",
    "\u02ce\u02cf\u0003\u0002\u0002\u0002\u02cf\u02d1\u0003\u0002\u0002\u0002",
    "\u02d0\u02ce\u0003\u0002\u0002\u0002\u02d1\u02d5\u0005\u0018\r\u0002",
    "\u02d2\u02d4\u0007)\u0002\u0002\u02d3\u02d2\u0003\u0002\u0002\u0002",
    "\u02d4\u02d7\u0003\u0002\u0002\u0002\u02d5\u02d3\u0003\u0002\u0002\u0002",
    "\u02d5\u02d6\u0003\u0002\u0002\u0002\u02d6?\u0003\u0002\u0002\u0002",
    "\u02d7\u02d5\u0003\u0002\u0002\u0002\u02d8\u02dc\u0007\u001e\u0002\u0002",
    "\u02d9\u02db\u0005\u0004\u0003\u0002\u02da\u02d9\u0003\u0002\u0002\u0002",
    "\u02db\u02de\u0003\u0002\u0002\u0002\u02dc\u02da\u0003\u0002\u0002\u0002",
    "\u02dc\u02dd\u0003\u0002\u0002\u0002\u02dd\u02e0\u0003\u0002\u0002\u0002",
    "\u02de\u02dc\u0003\u0002\u0002\u0002\u02df\u02e1\u0005:\u001e\u0002",
    "\u02e0\u02df\u0003\u0002\u0002\u0002\u02e0\u02e1\u0003\u0002\u0002\u0002",
    "\u02e1\u02e5\u0003\u0002\u0002\u0002\u02e2\u02e4\u0005\u0004\u0003\u0002",
    "\u02e3\u02e2\u0003\u0002\u0002\u0002\u02e4\u02e7\u0003\u0002\u0002\u0002",
    "\u02e5\u02e3\u0003\u0002\u0002\u0002\u02e5\u02e6\u0003\u0002\u0002\u0002",
    "\u02e6\u02e8\u0003\u0002\u0002\u0002\u02e7\u02e5\u0003\u0002\u0002\u0002",
    "\u02e8\u02e9\u0007\u001f\u0002\u0002\u02e9A\u0003\u0002\u0002\u0002",
    "\u02ea\u02ef\u0005@!\u0002\u02eb\u02ec\u0005> \u0002\u02ec\u02ed\u0005",
    "@!\u0002\u02ed\u02ef\u0003\u0002\u0002\u0002\u02ee\u02ea\u0003\u0002",
    "\u0002\u0002\u02ee\u02eb\u0003\u0002\u0002\u0002\u02efC\u0003\u0002",
    "\u0002\u0002\u02f0\u02f4\u0007\u0018\u0002\u0002\u02f1\u02f3\u0005\u0004",
    "\u0003\u0002\u02f2\u02f1\u0003\u0002\u0002\u0002\u02f3\u02f6\u0003\u0002",
    "\u0002\u0002\u02f4\u02f2\u0003\u0002\u0002\u0002\u02f4\u02f5\u0003\u0002",
    "\u0002\u0002\u02f5\u02f7\u0003\u0002\u0002\u0002\u02f6\u02f4\u0003\u0002",
    "\u0002\u0002\u02f7\u02fb\u0005<\u001f\u0002\u02f8\u02fa\u0005\u0004",
    "\u0003\u0002\u02f9\u02f8\u0003\u0002\u0002\u0002\u02fa\u02fd\u0003\u0002",
    "\u0002\u0002\u02fb\u02f9\u0003\u0002\u0002\u0002\u02fb\u02fc\u0003\u0002",
    "\u0002\u0002\u02fc\u02fe\u0003\u0002\u0002\u0002\u02fd\u02fb\u0003\u0002",
    "\u0002\u0002\u02fe\u02ff\u0007\u0019\u0002\u0002\u02ffE\u0003\u0002",
    "\u0002\u0002\u0300\u0301\u0005> \u0002\u0301\u0302\u0005D#\u0002\u0302",
    "G\u0003\u0002\u0002\u0002\u0303\u0307\u0007\u001a\u0002\u0002\u0304",
    "\u0306\u0005\u0004\u0003\u0002\u0305\u0304\u0003\u0002\u0002\u0002\u0306",
    "\u0309\u0003\u0002\u0002\u0002\u0307\u0305\u0003\u0002\u0002\u0002\u0307",
    "\u0308\u0003\u0002\u0002\u0002\u0308\u030b\u0003\u0002\u0002\u0002\u0309",
    "\u0307\u0003\u0002\u0002\u0002\u030a\u030c\u0005:\u001e\u0002\u030b",
    "\u030a\u0003\u0002\u0002\u0002\u030b\u030c\u0003\u0002\u0002\u0002\u030c",
    "\u0310\u0003\u0002\u0002\u0002\u030d\u030f\u0005\u0004\u0003\u0002\u030e",
    "\u030d\u0003\u0002\u0002\u0002\u030f\u0312\u0003\u0002\u0002\u0002\u0310",
    "\u030e\u0003\u0002\u0002\u0002\u0310\u0311\u0003\u0002\u0002\u0002\u0311",
    "\u0313\u0003\u0002\u0002\u0002\u0312\u0310\u0003\u0002\u0002\u0002\u0313",
    "\u0314\u0007\u001b\u0002\u0002\u0314I\u0003\u0002\u0002\u0002\u0315",
    "\u0323\u0007\f\u0002\u0002\u0316\u0318\u0005\u0004\u0003\u0002\u0317",
    "\u0316\u0003\u0002\u0002\u0002\u0318\u031b\u0003\u0002\u0002\u0002\u0319",
    "\u0317\u0003\u0002\u0002\u0002\u0319\u031a\u0003\u0002\u0002\u0002\u031a",
    "\u031c\u0003\u0002\u0002\u0002\u031b\u0319\u0003\u0002\u0002\u0002\u031c",
    "\u0320\u00056\u001c\u0002\u031d\u031f\u0005\u0004\u0003\u0002\u031e",
    "\u031d\u0003\u0002\u0002\u0002\u031f\u0322\u0003\u0002\u0002\u0002\u0320",
    "\u031e\u0003\u0002\u0002\u0002\u0320\u0321\u0003\u0002\u0002\u0002\u0321",
    "\u0324\u0003\u0002\u0002\u0002\u0322\u0320\u0003\u0002\u0002\u0002\u0323",
    "\u0319\u0003\u0002\u0002\u0002\u0323\u0324\u0003\u0002\u0002\u0002\u0324",
    "\u0325\u0003\u0002\u0002\u0002\u0325\u0326\u0007\'\u0002\u0002\u0326",
    "K\u0003\u0002\u0002\u0002\u0327\u032b\u0007\r\u0002\u0002\u0328\u032a",
    "\u0005\u0004\u0003\u0002\u0329\u0328\u0003\u0002\u0002\u0002\u032a\u032d",
    "\u0003\u0002\u0002\u0002\u032b\u0329\u0003\u0002\u0002\u0002\u032b\u032c",
    "\u0003\u0002\u0002\u0002\u032c\u032e\u0003\u0002\u0002\u0002\u032d\u032b",
    "\u0003\u0002\u0002\u0002\u032e\u033c\u0005^0\u0002\u032f\u0331\u0005",
    "\u0004\u0003\u0002\u0330\u032f\u0003\u0002\u0002\u0002\u0331\u0334\u0003",
    "\u0002\u0002\u0002\u0332\u0330\u0003\u0002\u0002\u0002\u0332\u0333\u0003",
    "\u0002\u0002\u0002\u0333\u0335\u0003\u0002\u0002\u0002\u0334\u0332\u0003",
    "\u0002\u0002\u0002\u0335\u0339\u00056\u001c\u0002\u0336\u0338\u0005",
    "\u0004\u0003\u0002\u0337\u0336\u0003\u0002\u0002\u0002\u0338\u033b\u0003",
    "\u0002\u0002\u0002\u0339\u0337\u0003\u0002\u0002\u0002\u0339\u033a\u0003",
    "\u0002\u0002\u0002\u033a\u033d\u0003\u0002\u0002\u0002\u033b\u0339\u0003",
    "\u0002\u0002\u0002\u033c\u0332\u0003\u0002\u0002\u0002\u033c\u033d\u0003",
    "\u0002\u0002\u0002\u033d\u033e\u0003\u0002\u0002\u0002\u033e\u033f\u0007",
    "\'\u0002\u0002\u033fM\u0003\u0002\u0002\u0002\u0340\u0344\u0007\u0013",
    "\u0002\u0002\u0341\u0343\u0005\u0004\u0003\u0002\u0342\u0341\u0003\u0002",
    "\u0002\u0002\u0343\u0346\u0003\u0002\u0002\u0002\u0344\u0342\u0003\u0002",
    "\u0002\u0002\u0344\u0345\u0003\u0002\u0002\u0002\u0345\u0347\u0003\u0002",
    "\u0002\u0002\u0346\u0344\u0003\u0002\u0002\u0002\u0347\u034b\u00056",
    "\u001c\u0002\u0348\u034a\u0005\u0004\u0003\u0002\u0349\u0348\u0003\u0002",
    "\u0002\u0002\u034a\u034d\u0003\u0002\u0002\u0002\u034b\u0349\u0003\u0002",
    "\u0002\u0002\u034b\u034c\u0003\u0002\u0002\u0002\u034c\u034e\u0003\u0002",
    "\u0002\u0002\u034d\u034b\u0003\u0002\u0002\u0002\u034e\u0360\u0005P",
    ")\u0002\u034f\u0351\u0005\u0004\u0003\u0002\u0350\u034f\u0003\u0002",
    "\u0002\u0002\u0351\u0354\u0003\u0002\u0002\u0002\u0352\u0350\u0003\u0002",
    "\u0002\u0002\u0352\u0353\u0003\u0002\u0002\u0002\u0353\u0355\u0003\u0002",
    "\u0002\u0002\u0354\u0352\u0003\u0002\u0002\u0002\u0355\u0359\u0007\u0014",
    "\u0002\u0002\u0356\u0358\u0005\u0004\u0003\u0002\u0357\u0356\u0003\u0002",
    "\u0002\u0002\u0358\u035b\u0003\u0002\u0002\u0002\u0359\u0357\u0003\u0002",
    "\u0002\u0002\u0359\u035a\u0003\u0002\u0002\u0002\u035a\u035e\u0003\u0002",
    "\u0002\u0002\u035b\u0359\u0003\u0002\u0002\u0002\u035c\u035f\u0005N",
    "(\u0002\u035d\u035f\u0005P)\u0002\u035e\u035c\u0003\u0002\u0002\u0002",
    "\u035e\u035d\u0003\u0002\u0002\u0002\u035f\u0361\u0003\u0002\u0002\u0002",
    "\u0360\u0352\u0003\u0002\u0002\u0002\u0360\u0361\u0003\u0002\u0002\u0002",
    "\u0361O\u0003\u0002\u0002\u0002\u0362\u0366\u0005\"\u0012\u0002\u0363",
    "\u0366\u0005&\u0014\u0002\u0364\u0366\u0005^0\u0002\u0365\u0362\u0003",
    "\u0002\u0002\u0002\u0365\u0363\u0003\u0002\u0002\u0002\u0365\u0364\u0003",
    "\u0002\u0002\u0002\u0366Q\u0003\u0002\u0002\u0002\u0367\u0368\t\u0004",
    "\u0002\u0002\u0368S\u0003\u0002\u0002\u0002\u0369\u0386\u0007.\u0002",
    "\u0002\u036a\u0386\u0007&\u0002\u0002\u036b\u0386\u0007\u001c\u0002",
    "\u0002\u036c\u036e\u0007\u001d\u0002\u0002\u036d\u036c\u0003\u0002\u0002",
    "\u0002\u036e\u036f\u0003\u0002\u0002\u0002\u036f\u036d\u0003\u0002\u0002",
    "\u0002\u036f\u0370\u0003\u0002\u0002\u0002\u0370\u0381\u0003\u0002\u0002",
    "\u0002\u0371\u0373\u0007!\u0002\u0002\u0372\u0371\u0003\u0002\u0002",
    "\u0002\u0373\u0374\u0003\u0002\u0002\u0002\u0374\u0372\u0003\u0002\u0002",
    "\u0002\u0374\u0375\u0003\u0002\u0002\u0002\u0375\u0379\u0003\u0002\u0002",
    "\u0002\u0376\u0378\u0007.\u0002\u0002\u0377\u0376\u0003\u0002\u0002",
    "\u0002\u0378\u037b\u0003\u0002\u0002\u0002\u0379\u0377\u0003\u0002\u0002",
    "\u0002\u0379\u037a\u0003\u0002\u0002\u0002\u037a\u0382\u0003\u0002\u0002",
    "\u0002\u037b\u0379\u0003\u0002\u0002\u0002\u037c\u037e\u0007.\u0002",
    "\u0002\u037d\u037c\u0003\u0002\u0002\u0002\u037e\u037f\u0003\u0002\u0002",
    "\u0002\u037f\u037d\u0003\u0002\u0002\u0002\u037f\u0380\u0003\u0002\u0002",
    "\u0002\u0380\u0382\u0003\u0002\u0002\u0002\u0381\u0372\u0003\u0002\u0002",
    "\u0002\u0381\u037d\u0003\u0002\u0002\u0002\u0381\u0382\u0003\u0002\u0002",
    "\u0002\u0382\u0386\u0003\u0002\u0002\u0002\u0383\u0386\u0007\"\u0002",
    "\u0002\u0384\u0386\u0007%\u0002\u0002\u0385\u0369\u0003\u0002\u0002",
    "\u0002\u0385\u036a\u0003\u0002\u0002\u0002\u0385\u036b\u0003\u0002\u0002",
    "\u0002\u0385\u036d\u0003\u0002\u0002\u0002\u0385\u0383\u0003\u0002\u0002",
    "\u0002\u0385\u0384\u0003\u0002\u0002\u0002\u0386U\u0003\u0002\u0002",
    "\u0002\u0387\u0388\t\u0005\u0002\u0002\u0388\u0391\u0007)\u0002\u0002",
    "\u0389\u038a\u0005X-\u0002\u038a\u038b\u0007)\u0002\u0002\u038b\u038c",
    "\u0005Z.\u0002\u038c\u0392\u0003\u0002\u0002\u0002\u038d\u038e\u0005",
    "Z.\u0002\u038e\u038f\u0007)\u0002\u0002\u038f\u0390\u0005X-\u0002\u0390",
    "\u0392\u0003\u0002\u0002\u0002\u0391\u0389\u0003\u0002\u0002\u0002\u0391",
    "\u038d\u0003\u0002\u0002\u0002\u0392W\u0003\u0002\u0002\u0002\u0393",
    "\u0394\u0005^0\u0002\u0394\u0395\u0007)\u0002\u0002\u0395\u0396\u0007",
    "\u000e\u0002\u0002\u0396\u0397\u0007)\u0002\u0002\u0397\u0398\u0005",
    "T+\u0002\u0398Y\u0003\u0002\u0002\u0002\u0399\u039a\u0007\u0012\u0002",
    "\u0002\u039a\u039b\u0007)\u0002\u0002\u039b\u039c\u0007-\u0002\u0002",
    "\u039c[\u0003\u0002\u0002\u0002\u039d\u03a1\u0007\u0007\u0002\u0002",
    "\u039e\u03a0\u0005\u0004\u0003\u0002\u039f\u039e\u0003\u0002\u0002\u0002",
    "\u03a0\u03a3\u0003\u0002\u0002\u0002\u03a1\u039f\u0003\u0002\u0002\u0002",
    "\u03a1\u03a2\u0003\u0002\u0002\u0002\u03a2\u03a4\u0003\u0002\u0002\u0002",
    "\u03a3\u03a1\u0003\u0002\u0002\u0002\u03a4\u03a8\u0007/\u0002\u0002",
    "\u03a5\u03a7\u0005\u0004\u0003\u0002\u03a6\u03a5\u0003\u0002\u0002\u0002",
    "\u03a7\u03aa\u0003\u0002\u0002\u0002\u03a8\u03a6\u0003\u0002\u0002\u0002",
    "\u03a8\u03a9\u0003\u0002\u0002\u0002\u03a9\u03ab\u0003\u0002\u0002\u0002",
    "\u03aa\u03a8\u0003\u0002\u0002\u0002\u03ab\u03af\u0007&\u0002\u0002",
    "\u03ac\u03ae\u0005\u0004\u0003\u0002\u03ad\u03ac\u0003\u0002\u0002\u0002",
    "\u03ae\u03b1\u0003\u0002\u0002\u0002\u03af\u03ad\u0003\u0002\u0002\u0002",
    "\u03af\u03b0\u0003\u0002\u0002\u0002\u03b0\u03b2\u0003\u0002\u0002\u0002",
    "\u03b1\u03af\u0003\u0002\u0002\u0002\u03b2\u03b3\u0005\u0018\r\u0002",
    "\u03b3]\u0003\u0002\u0002\u0002\u03b4\u03b5\u0005\u0014\u000b\u0002",
    "\u03b5_\u0003\u0002\u0002\u0002\u03b6\u03b8\u0007\b\u0002\u0002\u03b7",
    "\u03b9\u0005\u0004\u0003\u0002\u03b8\u03b7\u0003\u0002\u0002\u0002\u03b9",
    "\u03ba\u0003\u0002\u0002\u0002\u03ba\u03b8\u0003\u0002\u0002\u0002\u03ba",
    "\u03bb\u0003\u0002\u0002\u0002\u03bb\u03bc\u0003\u0002\u0002\u0002\u03bc",
    "\u03be\u0005^0\u0002\u03bd\u03bf\u0005\u0004\u0003\u0002\u03be\u03bd",
    "\u0003\u0002\u0002\u0002\u03bf\u03c0\u0003\u0002\u0002\u0002\u03c0\u03be",
    "\u0003\u0002\u0002\u0002\u03c0\u03c1\u0003\u0002\u0002\u0002\u03c1\u03c5",
    "\u0003\u0002\u0002\u0002\u03c2\u03c6\u0005\"\u0012\u0002\u03c3\u03c6",
    "\u0005\u0014\u000b\u0002\u03c4\u03c6\u0005&\u0014\u0002\u03c5\u03c2",
    "\u0003\u0002\u0002\u0002\u03c5\u03c3\u0003\u0002\u0002\u0002\u03c5\u03c4",
    "\u0003\u0002\u0002\u0002\u03c6a\u0003\u0002\u0002\u0002\u03c7\u03cb",
    "\u0007\u0016\u0002\u0002\u03c8\u03ca\u0007)\u0002\u0002\u03c9\u03c8",
    "\u0003\u0002\u0002\u0002\u03ca\u03cd\u0003\u0002\u0002\u0002\u03cb\u03c9",
    "\u0003\u0002\u0002\u0002\u03cb\u03cc\u0003\u0002\u0002\u0002\u03cc\u03ce",
    "\u0003\u0002\u0002\u0002\u03cd\u03cb\u0003\u0002\u0002\u0002\u03ce\u03d2",
    "\u0007/\u0002\u0002\u03cf\u03d1\u0007)\u0002\u0002\u03d0\u03cf\u0003",
    "\u0002\u0002\u0002\u03d1\u03d4\u0003\u0002\u0002\u0002\u03d2\u03d0\u0003",
    "\u0002\u0002\u0002\u03d2\u03d3\u0003\u0002\u0002\u0002\u03d3\u03de\u0003",
    "\u0002\u0002\u0002\u03d4\u03d2\u0003\u0002\u0002\u0002\u03d5\u03df\u0005",
    "d3\u0002\u03d6\u03da\u0007!\u0002\u0002\u03d7\u03d9\u0005\u0004\u0003",
    "\u0002\u03d8\u03d7\u0003\u0002\u0002\u0002\u03d9\u03dc\u0003\u0002\u0002",
    "\u0002\u03da\u03d8\u0003\u0002\u0002\u0002\u03da\u03db\u0003\u0002\u0002",
    "\u0002\u03db\u03dd\u0003\u0002\u0002\u0002\u03dc\u03da\u0003\u0002\u0002",
    "\u0002\u03dd\u03df\u0007/\u0002\u0002\u03de\u03d5\u0003\u0002\u0002",
    "\u0002\u03de\u03d6\u0003\u0002\u0002\u0002\u03dfc\u0003\u0002\u0002",
    "\u0002\u03e0\u03e2\u0007\u0018\u0002\u0002\u03e1\u03e3\u0005f4\u0002",
    "\u03e2\u03e1\u0003\u0002\u0002\u0002\u03e2\u03e3\u0003\u0002\u0002\u0002",
    "\u03e3\u03e7\u0003\u0002\u0002\u0002\u03e4\u03e6\u0005\u0004\u0003\u0002",
    "\u03e5\u03e4\u0003\u0002\u0002\u0002\u03e6\u03e9\u0003\u0002\u0002\u0002",
    "\u03e7\u03e5\u0003\u0002\u0002\u0002\u03e7\u03e8\u0003\u0002\u0002\u0002",
    "\u03e8\u03ea\u0003\u0002\u0002\u0002\u03e9\u03e7\u0003\u0002\u0002\u0002",
    "\u03ea\u03eb\u0007\u0019\u0002\u0002\u03ebe\u0003\u0002\u0002\u0002",
    "\u03ec\u03ee\u0005\u0004\u0003\u0002\u03ed\u03ec\u0003\u0002\u0002\u0002",
    "\u03ee\u03f1\u0003\u0002\u0002\u0002\u03ef\u03ed\u0003\u0002\u0002\u0002",
    "\u03ef\u03f0\u0003\u0002\u0002\u0002\u03f0\u03f2\u0003\u0002\u0002\u0002",
    "\u03f1\u03ef\u0003\u0002\u0002\u0002\u03f2\u03f6\u0005h5\u0002\u03f3",
    "\u03f5\u0005\u0004\u0003\u0002\u03f4\u03f3\u0003\u0002\u0002\u0002\u03f5",
    "\u03f8\u0003\u0002\u0002\u0002\u03f6\u03f4\u0003\u0002\u0002\u0002\u03f6",
    "\u03f7\u0003\u0002\u0002\u0002\u03f7\u0409\u0003\u0002\u0002\u0002\u03f8",
    "\u03f6\u0003\u0002\u0002\u0002\u03f9\u03fd\u0007\u0017\u0002\u0002\u03fa",
    "\u03fc\u0005\u0004\u0003\u0002\u03fb\u03fa\u0003\u0002\u0002\u0002\u03fc",
    "\u03ff\u0003\u0002\u0002\u0002\u03fd\u03fb\u0003\u0002\u0002\u0002\u03fd",
    "\u03fe\u0003\u0002\u0002\u0002\u03fe\u0400\u0003\u0002\u0002\u0002\u03ff",
    "\u03fd\u0003\u0002\u0002\u0002\u0400\u0404\u0005h5\u0002\u0401\u0403",
    "\u0005\u0004\u0003\u0002\u0402\u0401\u0003\u0002\u0002\u0002\u0403\u0406",
    "\u0003\u0002\u0002\u0002\u0404\u0402\u0003\u0002\u0002\u0002\u0404\u0405",
    "\u0003\u0002\u0002\u0002\u0405\u0408\u0003\u0002\u0002\u0002\u0406\u0404",
    "\u0003\u0002\u0002\u0002\u0407\u03f9\u0003\u0002\u0002\u0002\u0408\u040b",
    "\u0003\u0002\u0002\u0002\u0409\u0407\u0003\u0002\u0002\u0002\u0409\u040a",
    "\u0003\u0002\u0002\u0002\u040a\u040d\u0003\u0002\u0002\u0002\u040b\u0409",
    "\u0003\u0002\u0002\u0002\u040c\u040e\u0007\u0017\u0002\u0002\u040d\u040c",
    "\u0003\u0002\u0002\u0002\u040d\u040e\u0003\u0002\u0002\u0002\u040eg",
    "\u0003\u0002\u0002\u0002\u040f\u0413\u0005j6\u0002\u0410\u0413\u0005",
    "n8\u0002\u0411\u0413\u0005t;\u0002\u0412\u040f\u0003\u0002\u0002\u0002",
    "\u0412\u0410\u0003\u0002\u0002\u0002\u0412\u0411\u0003\u0002\u0002\u0002",
    "\u0413i\u0003\u0002\u0002\u0002\u0414\u0418\t\u0006\u0002\u0002\u0415",
    "\u0417\u0007)\u0002\u0002\u0416\u0415\u0003\u0002\u0002\u0002\u0417",
    "\u041a\u0003\u0002\u0002\u0002\u0418\u0416\u0003\u0002\u0002\u0002\u0418",
    "\u0419\u0003\u0002\u0002\u0002\u0419\u041b\u0003\u0002\u0002\u0002\u041a",
    "\u0418\u0003\u0002\u0002\u0002\u041b\u041c\u0005l7\u0002\u041ck\u0003",
    "\u0002\u0002\u0002\u041d\u0421\u0007\u001a\u0002\u0002\u041e\u0420\u0005",
    "\u0004\u0003\u0002\u041f\u041e\u0003\u0002\u0002\u0002\u0420\u0423\u0003",
    "\u0002\u0002\u0002\u0421\u041f\u0003\u0002\u0002\u0002\u0421\u0422\u0003",
    "\u0002\u0002\u0002\u0422\u0424\u0003\u0002\u0002\u0002\u0423\u0421\u0003",
    "\u0002\u0002\u0002\u0424\u0428\u0005\u0018\r\u0002\u0425\u0427\u0005",
    "\u0004\u0003\u0002\u0426\u0425\u0003\u0002\u0002\u0002\u0427\u042a\u0003",
    "\u0002\u0002\u0002\u0428\u0426\u0003\u0002\u0002\u0002\u0428\u0429\u0003",
    "\u0002\u0002\u0002\u0429\u043b\u0003\u0002\u0002\u0002\u042a\u0428\u0003",
    "\u0002\u0002\u0002\u042b\u042f\u0007\u0017\u0002\u0002\u042c\u042e\u0005",
    "\u0004\u0003\u0002\u042d\u042c\u0003\u0002\u0002\u0002\u042e\u0431\u0003",
    "\u0002\u0002\u0002\u042f\u042d\u0003\u0002\u0002\u0002\u042f\u0430\u0003",
    "\u0002\u0002\u0002\u0430\u0432\u0003\u0002\u0002\u0002\u0431\u042f\u0003",
    "\u0002\u0002\u0002\u0432\u0436\u0005\u0018\r\u0002\u0433\u0435\u0005",
    "\u0004\u0003\u0002\u0434\u0433\u0003\u0002\u0002\u0002\u0435\u0438\u0003",
    "\u0002\u0002\u0002\u0436\u0434\u0003\u0002\u0002\u0002\u0436\u0437\u0003",
    "\u0002\u0002\u0002\u0437\u043a\u0003\u0002\u0002\u0002\u0438\u0436\u0003",
    "\u0002\u0002\u0002\u0439\u042b\u0003\u0002\u0002\u0002\u043a\u043d\u0003",
    "\u0002\u0002\u0002\u043b\u0439\u0003\u0002\u0002\u0002\u043b\u043c\u0003",
    "\u0002\u0002\u0002\u043c\u043e\u0003\u0002\u0002\u0002\u043d\u043b\u0003",
    "\u0002\u0002\u0002\u043e\u0440\u0007\u001b\u0002\u0002\u043f\u0441\u0005",
    "\u0004\u0003\u0002\u0440\u043f\u0003\u0002\u0002\u0002\u0440\u0441\u0003",
    "\u0002\u0002\u0002\u0441\u0442\u0003\u0002\u0002\u0002\u0442\u0446\u0007",
    "&\u0002\u0002\u0443\u0445\u0005\u0004\u0003\u0002\u0444\u0443\u0003",
    "\u0002\u0002\u0002\u0445\u0448\u0003\u0002\u0002\u0002\u0446\u0444\u0003",
    "\u0002\u0002\u0002\u0446\u0447\u0003\u0002\u0002\u0002\u0447\u0449\u0003",
    "\u0002\u0002\u0002\u0448\u0446\u0003\u0002\u0002\u0002\u0449\u044a\u0005",
    "\u0018\r\u0002\u044am\u0003\u0002\u0002\u0002\u044b\u044f\u0005p9\u0002",
    "\u044c\u044e\u0005\u0004\u0003\u0002\u044d\u044c\u0003\u0002\u0002\u0002",
    "\u044e\u0451\u0003\u0002\u0002\u0002\u044f\u044d\u0003\u0002\u0002\u0002",
    "\u044f\u0450\u0003\u0002\u0002\u0002\u0450\u0453\u0003\u0002\u0002\u0002",
    "\u0451\u044f\u0003\u0002\u0002\u0002\u0452\u044b\u0003\u0002\u0002\u0002",
    "\u0452\u0453\u0003\u0002\u0002\u0002\u0453\u0454\u0003\u0002\u0002\u0002",
    "\u0454\u0458\u0005T+\u0002\u0455\u0457\u0005\u0004\u0003\u0002\u0456",
    "\u0455\u0003\u0002\u0002\u0002\u0457\u045a\u0003\u0002\u0002\u0002\u0458",
    "\u0456\u0003\u0002\u0002\u0002\u0458\u0459\u0003\u0002\u0002\u0002\u0459",
    "\u045b\u0003\u0002\u0002\u0002\u045a\u0458\u0003\u0002\u0002\u0002\u045b",
    "\u045f\u0005r:\u0002\u045c\u045e\u0005\u0004\u0003\u0002\u045d\u045c",
    "\u0003\u0002\u0002\u0002\u045e\u0461\u0003\u0002\u0002\u0002\u045f\u045d",
    "\u0003\u0002\u0002\u0002\u045f\u0460\u0003\u0002\u0002\u0002\u0460\u0462",
    "\u0003\u0002\u0002\u0002\u0461\u045f\u0003\u0002\u0002\u0002\u0462\u0466",
    "\u0007&\u0002\u0002\u0463\u0465\u0005\u0004\u0003\u0002\u0464\u0463",
    "\u0003\u0002\u0002\u0002\u0465\u0468\u0003\u0002\u0002\u0002\u0466\u0464",
    "\u0003\u0002\u0002\u0002\u0466\u0467\u0003\u0002\u0002\u0002\u0467\u0469",
    "\u0003\u0002\u0002\u0002\u0468\u0466\u0003\u0002\u0002\u0002\u0469\u046a",
    "\u0005\u0018\r\u0002\u046ao\u0003\u0002\u0002\u0002\u046b\u046c\u0005",
    "\u0018\r\u0002\u046cq\u0003\u0002\u0002\u0002\u046d\u046e\u0005\u0018",
    "\r\u0002\u046es\u0003\u0002\u0002\u0002\u046f\u0473\u0007/\u0002\u0002",
    "\u0470\u0472\u0007)\u0002\u0002\u0471\u0470\u0003\u0002\u0002\u0002",
    "\u0472\u0475\u0003\u0002\u0002\u0002\u0473\u0471\u0003\u0002\u0002\u0002",
    "\u0473\u0474\u0003\u0002\u0002\u0002\u0474\u0476\u0003\u0002\u0002\u0002",
    "\u0475\u0473\u0003\u0002\u0002\u0002\u0476\u047a\u0007&\u0002\u0002",
    "\u0477\u0479\u0007)\u0002\u0002\u0478\u0477\u0003\u0002\u0002\u0002",
    "\u0479\u047c\u0003\u0002\u0002\u0002\u047a\u0478\u0003\u0002\u0002\u0002",
    "\u047a\u047b\u0003\u0002\u0002\u0002\u047b\u047d\u0003\u0002\u0002\u0002",
    "\u047c\u047a\u0003\u0002\u0002\u0002\u047d\u047e\u0005\u0018\r\u0002",
    "\u047eu\u0003\u0002\u0002\u0002\u047f\u0481\u0007\t\u0002\u0002\u0480",
    "\u0482\t\u0002\u0002\u0002\u0481\u0480\u0003\u0002\u0002\u0002\u0482",
    "\u0483\u0003\u0002\u0002\u0002\u0483\u0481\u0003\u0002\u0002\u0002\u0483",
    "\u0484\u0003\u0002\u0002\u0002\u0484\u048e\u0003\u0002\u0002\u0002\u0485",
    "\u048f\u0005^0\u0002\u0486\u048f\u0005\u0012\n\u0002\u0487\u0488\u0005",
    ",\u0017\u0002\u0488\u0489\u0007\'\u0002\u0002\u0489\u048f\u0003\u0002",
    "\u0002\u0002\u048a\u048f\u0005\"\u0012\u0002\u048b\u048f\u0005V,\u0002",
    "\u048c\u048f\u0005\\/\u0002\u048d\u048f\u0005b2\u0002\u048e\u0485\u0003",
    "\u0002\u0002\u0002\u048e\u0486\u0003\u0002\u0002\u0002\u048e\u0487\u0003",
    "\u0002\u0002\u0002\u048e\u048a\u0003\u0002\u0002\u0002\u048e\u048b\u0003",
    "\u0002\u0002\u0002\u048e\u048c\u0003\u0002\u0002\u0002\u048e\u048d\u0003",
    "\u0002\u0002\u0002\u048fw\u0003\u0002\u0002\u0002\u0490\u0495\u0005",
    "z>\u0002\u0491\u0492\u0007\u0017\u0002\u0002\u0492\u0494\u0005z>\u0002",
    "\u0493\u0491\u0003\u0002\u0002\u0002\u0494\u0497\u0003\u0002\u0002\u0002",
    "\u0495\u0493\u0003\u0002\u0002\u0002\u0495\u0496\u0003\u0002\u0002\u0002",
    "\u0496y\u0003\u0002\u0002\u0002\u0497\u0495\u0003\u0002\u0002\u0002",
    "\u0498\u04a5\u0005|?\u0002\u0499\u049b\u0007)\u0002\u0002\u049a\u0499",
    "\u0003\u0002\u0002\u0002\u049b\u049c\u0003\u0002\u0002\u0002\u049c\u049a",
    "\u0003\u0002\u0002\u0002\u049c\u049d\u0003\u0002\u0002\u0002\u049d\u049e",
    "\u0003\u0002\u0002\u0002\u049e\u04a0\u0007\u000e\u0002\u0002\u049f\u04a1",
    "\u0007)\u0002\u0002\u04a0\u049f\u0003\u0002\u0002\u0002\u04a1\u04a2",
    "\u0003\u0002\u0002\u0002\u04a2\u04a0\u0003\u0002\u0002\u0002\u04a2\u04a3",
    "\u0003\u0002\u0002\u0002\u04a3\u04a4\u0003\u0002\u0002\u0002\u04a4\u04a6",
    "\u0005|?\u0002\u04a5\u049a\u0003\u0002\u0002\u0002\u04a5\u04a6\u0003",
    "\u0002\u0002\u0002\u04a6{\u0003\u0002\u0002\u0002\u04a7\u04aa\u0007",
    "/\u0002\u0002\u04a8\u04aa\u0005T+\u0002\u04a9\u04a7\u0003\u0002\u0002",
    "\u0002\u04a9\u04a8\u0003\u0002\u0002\u0002\u04aa}\u0003\u0002\u0002",
    "\u0002\u04ab\u04ad\u0005\u0080A\u0002\u04ac\u04ab\u0003\u0002\u0002",
    "\u0002\u04ad\u04ae\u0003\u0002\u0002\u0002\u04ae\u04ac\u0003\u0002\u0002",
    "\u0002\u04ae\u04af\u0003\u0002\u0002\u0002\u04af\u007f\u0003\u0002\u0002",
    "\u0002\u04b0\u04ba\u0007/\u0002\u0002\u04b1\u04b3\u0005\u0004\u0003",
    "\u0002\u04b2\u04b1\u0003\u0002\u0002\u0002\u04b3\u04b6\u0003\u0002\u0002",
    "\u0002\u04b4\u04b2\u0003\u0002\u0002\u0002\u04b4\u04b5\u0003\u0002\u0002",
    "\u0002\u04b5\u04b7\u0003\u0002\u0002\u0002\u04b6\u04b4\u0003\u0002\u0002",
    "\u0002\u04b7\u04ba\u0007 \u0002\u0002\u04b8\u04ba\u0005\u0082B\u0002",
    "\u04b9\u04b0\u0003\u0002\u0002\u0002\u04b9\u04b4\u0003\u0002\u0002\u0002",
    "\u04b9\u04b8\u0003\u0002\u0002\u0002\u04ba\u0081\u0003\u0002\u0002\u0002",
    "\u04bb\u04bf\u0007\u001e\u0002\u0002\u04bc\u04be\u0007)\u0002\u0002",
    "\u04bd\u04bc\u0003\u0002\u0002\u0002\u04be\u04c1\u0003\u0002\u0002\u0002",
    "\u04bf\u04bd\u0003\u0002\u0002\u0002\u04bf\u04c0\u0003\u0002\u0002\u0002",
    "\u04c0\u04c2\u0003\u0002\u0002\u0002\u04c1\u04bf\u0003\u0002\u0002\u0002",
    "\u04c2\u04c6\u00056\u001c\u0002\u04c3\u04c5\u0007)\u0002\u0002\u04c4",
    "\u04c3\u0003\u0002\u0002\u0002\u04c5\u04c8\u0003\u0002\u0002\u0002\u04c6",
    "\u04c4\u0003\u0002\u0002\u0002\u04c6\u04c7\u0003\u0002\u0002\u0002\u04c7",
    "\u04c9\u0003\u0002\u0002\u0002\u04c8\u04c6\u0003\u0002\u0002\u0002\u04c9",
    "\u04ca\u0007\u001f\u0002\u0002\u04ca\u0083\u0003\u0002\u0002\u0002\u00b0",
    "\u0087\u008d\u009d\u009f\u00a1\u00a4\u00aa\u00b3\u00b9\u00c7\u00cc\u00d2",
    "\u00d8\u00da\u00e0\u00e6\u00ec\u00f0\u00f5\u00fc\u0100\u0105\u010b\u0112",
    "\u0119\u0120\u0125\u012e\u0132\u0138\u013f\u0148\u014f\u0158\u015f\u0166",
    "\u016b\u016f\u0175\u017c\u0185\u018c\u0192\u0199\u019f\u01a2\u01a6\u01ac",
    "\u01b0\u01b4\u01ba\u01bd\u01bf\u01c3\u01ca\u01ce\u01d4\u01d9\u01e1\u01ec",
    "\u01f0\u01f8\u01ff\u0204\u0207\u020c\u0213\u021c\u0223\u0228\u022b\u0230",
    "\u0237\u0240\u0247\u0253\u0259\u025e\u0261\u0267\u026d\u0272\u0278\u027f",
    "\u0286\u028b\u028f\u0295\u029c\u02a3\u02aa\u02b1\u02b8\u02bf\u02c4\u02c8",
    "\u02ce\u02d5\u02dc\u02e0\u02e5\u02ee\u02f4\u02fb\u0307\u030b\u0310\u0319",
    "\u0320\u0323\u032b\u0332\u0339\u033c\u0344\u034b\u0352\u0359\u035e\u0360",
    "\u0365\u036f\u0374\u0379\u037f\u0381\u0385\u0391\u03a1\u03a8\u03af\u03ba",
    "\u03c0\u03c5\u03cb\u03d2\u03da\u03de\u03e2\u03e7\u03ef\u03f6\u03fd\u0404",
    "\u0409\u040d\u0412\u0418\u0421\u0428\u042f\u0436\u043b\u0440\u0446\u044f",
    "\u0452\u0458\u045f\u0466\u0473\u047a\u0483\u048e\u0495\u049c\u04a2\u04a5",
    "\u04a9\u04ae\u04b4\u04b9\u04bf\u04c6"].join("");
var atn = new antlr4.atn.ATNDeserializer().deserialize(serializedATN);
var decisionsToDFA = atn.decisionToState.map(function (ds, index) { return new antlr4.dfa.DFA(ds, index); });
var sharedContextCache = new antlr4.PredictionContextCache();
var literalNames = [null, "'import'", "'from'", "'type'", "'fn'", "'event'",
    "'on'", "'export'", "'const'", "'let'", "'return'",
    "'emit'", "'as'", null, "'prefix'", "'infix'", "'precedence'",
    "'if'", "'else'", "'new'", "'interface'", null, "'{'",
    "'}'", "'('", "')'", "'<'", "'>'", "'['", "']'", "'.'",
    "'='", "'@'", "'./'", "'../'", "'/'", "':'", "';'"];
var symbolicNames = [null, "IMPORT", "FROM", "TYPE", "FN", "EVENT", "ON",
    "EXPORT", "CONST", "LET", "RETURN", "EMIT", "AS",
    "BOOLCONSTANT", "PREFIX", "INFIX", "PRECEDENCE", "IF",
    "ELSE", "NEW", "INTERFACE", "SEP", "OPENBODY", "CLOSEBODY",
    "OPENARGS", "CLOSEARGS", "OPENGENERIC", "CLOSEGENERIC",
    "OPENARRAY", "CLOSEARRAY", "METHODSEP", "EQUALS",
    "GLOBAL", "CURDIR", "PARDIR", "DIRSEP", "TYPESEP",
    "EOS", "NEWLINE", "WS", "SINGLELINECOMMENT", "MULTILINECOMMENT",
    "STRINGCONSTANT", "NUMBERCONSTANT", "GENERALOPERATORS",
    "VARNAME"];
var ruleNames = ["module", "blank", "imports", "standardImport", "fromImport",
    "dependency", "localdependency", "globaldependency",
    "types", "typename", "typegenerics", "fulltypename",
    "typebody", "typeline", "typelist", "arglist", "functions",
    "fullfunctionbody", "functionbody", "statements", "declarations",
    "constdeclaration", "letdeclaration", "assignments",
    "baseassignable", "withoperators", "assignables", "objectliterals",
    "assignablelist", "typeassignlist", "literaldec", "arraybase",
    "arrayliteral", "typebase", "typeliteral", "fncall",
    "exits", "emits", "conditionals", "blocklikes", "constants",
    "operators", "operatormapping", "fntoop", "opprecedence",
    "events", "eventref", "handlers", "interfaces", "interfacebody",
    "interfacelist", "interfaceline", "functiontypeline",
    "functiontype", "operatortypeline", "leftarg", "rightarg",
    "propertytypeline", "exports", "varlist", "renameablevar",
    "varop", "varn", "varsegment", "arrayaccess"];
function LnParser(input) {
    antlr4.Parser.call(this, input);
    this._interp = new antlr4.atn.ParserATNSimulator(this, atn, decisionsToDFA, sharedContextCache);
    this.ruleNames = ruleNames;
    this.literalNames = literalNames;
    this.symbolicNames = symbolicNames;
    return this;
}
LnParser.prototype = Object.create(antlr4.Parser.prototype);
LnParser.prototype.constructor = LnParser;
Object.defineProperty(LnParser.prototype, "atn", {
    get: function () {
        return atn;
    }
});
LnParser.EOF = antlr4.Token.EOF;
LnParser.IMPORT = 1;
LnParser.FROM = 2;
LnParser.TYPE = 3;
LnParser.FN = 4;
LnParser.EVENT = 5;
LnParser.ON = 6;
LnParser.EXPORT = 7;
LnParser.CONST = 8;
LnParser.LET = 9;
LnParser.RETURN = 10;
LnParser.EMIT = 11;
LnParser.AS = 12;
LnParser.BOOLCONSTANT = 13;
LnParser.PREFIX = 14;
LnParser.INFIX = 15;
LnParser.PRECEDENCE = 16;
LnParser.IF = 17;
LnParser.ELSE = 18;
LnParser.NEW = 19;
LnParser.INTERFACE = 20;
LnParser.SEP = 21;
LnParser.OPENBODY = 22;
LnParser.CLOSEBODY = 23;
LnParser.OPENARGS = 24;
LnParser.CLOSEARGS = 25;
LnParser.OPENGENERIC = 26;
LnParser.CLOSEGENERIC = 27;
LnParser.OPENARRAY = 28;
LnParser.CLOSEARRAY = 29;
LnParser.METHODSEP = 30;
LnParser.EQUALS = 31;
LnParser.GLOBAL = 32;
LnParser.CURDIR = 33;
LnParser.PARDIR = 34;
LnParser.DIRSEP = 35;
LnParser.TYPESEP = 36;
LnParser.EOS = 37;
LnParser.NEWLINE = 38;
LnParser.WS = 39;
LnParser.SINGLELINECOMMENT = 40;
LnParser.MULTILINECOMMENT = 41;
LnParser.STRINGCONSTANT = 42;
LnParser.NUMBERCONSTANT = 43;
LnParser.GENERALOPERATORS = 44;
LnParser.VARNAME = 45;
LnParser.RULE_module = 0;
LnParser.RULE_blank = 1;
LnParser.RULE_imports = 2;
LnParser.RULE_standardImport = 3;
LnParser.RULE_fromImport = 4;
LnParser.RULE_dependency = 5;
LnParser.RULE_localdependency = 6;
LnParser.RULE_globaldependency = 7;
LnParser.RULE_types = 8;
LnParser.RULE_typename = 9;
LnParser.RULE_typegenerics = 10;
LnParser.RULE_fulltypename = 11;
LnParser.RULE_typebody = 12;
LnParser.RULE_typeline = 13;
LnParser.RULE_typelist = 14;
LnParser.RULE_arglist = 15;
LnParser.RULE_functions = 16;
LnParser.RULE_fullfunctionbody = 17;
LnParser.RULE_functionbody = 18;
LnParser.RULE_statements = 19;
LnParser.RULE_declarations = 20;
LnParser.RULE_constdeclaration = 21;
LnParser.RULE_letdeclaration = 22;
LnParser.RULE_assignments = 23;
LnParser.RULE_baseassignable = 24;
LnParser.RULE_withoperators = 25;
LnParser.RULE_assignables = 26;
LnParser.RULE_objectliterals = 27;
LnParser.RULE_assignablelist = 28;
LnParser.RULE_typeassignlist = 29;
LnParser.RULE_literaldec = 30;
LnParser.RULE_arraybase = 31;
LnParser.RULE_arrayliteral = 32;
LnParser.RULE_typebase = 33;
LnParser.RULE_typeliteral = 34;
LnParser.RULE_fncall = 35;
LnParser.RULE_exits = 36;
LnParser.RULE_emits = 37;
LnParser.RULE_conditionals = 38;
LnParser.RULE_blocklikes = 39;
LnParser.RULE_constants = 40;
LnParser.RULE_operators = 41;
LnParser.RULE_operatormapping = 42;
LnParser.RULE_fntoop = 43;
LnParser.RULE_opprecedence = 44;
LnParser.RULE_events = 45;
LnParser.RULE_eventref = 46;
LnParser.RULE_handlers = 47;
LnParser.RULE_interfaces = 48;
LnParser.RULE_interfacebody = 49;
LnParser.RULE_interfacelist = 50;
LnParser.RULE_interfaceline = 51;
LnParser.RULE_functiontypeline = 52;
LnParser.RULE_functiontype = 53;
LnParser.RULE_operatortypeline = 54;
LnParser.RULE_leftarg = 55;
LnParser.RULE_rightarg = 56;
LnParser.RULE_propertytypeline = 57;
LnParser.RULE_exports = 58;
LnParser.RULE_varlist = 59;
LnParser.RULE_renameablevar = 60;
LnParser.RULE_varop = 61;
LnParser.RULE_varn = 62;
LnParser.RULE_varsegment = 63;
LnParser.RULE_arrayaccess = 64;
function ModuleContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_module;
    return this;
}
ModuleContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
ModuleContext.prototype.constructor = ModuleContext;
ModuleContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
ModuleContext.prototype.imports = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(ImportsContext);
    }
    else {
        return this.getTypedRuleContext(ImportsContext, i);
    }
};
ModuleContext.prototype.types = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(TypesContext);
    }
    else {
        return this.getTypedRuleContext(TypesContext, i);
    }
};
ModuleContext.prototype.functions = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(FunctionsContext);
    }
    else {
        return this.getTypedRuleContext(FunctionsContext, i);
    }
};
ModuleContext.prototype.operatormapping = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(OperatormappingContext);
    }
    else {
        return this.getTypedRuleContext(OperatormappingContext, i);
    }
};
ModuleContext.prototype.events = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(EventsContext);
    }
    else {
        return this.getTypedRuleContext(EventsContext, i);
    }
};
ModuleContext.prototype.handlers = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(HandlersContext);
    }
    else {
        return this.getTypedRuleContext(HandlersContext, i);
    }
};
ModuleContext.prototype.interfaces = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(InterfacesContext);
    }
    else {
        return this.getTypedRuleContext(InterfacesContext, i);
    }
};
ModuleContext.prototype.exports = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(ExportsContext);
    }
    else {
        return this.getTypedRuleContext(ExportsContext, i);
    }
};
ModuleContext.prototype.constdeclaration = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(ConstdeclarationContext);
    }
    else {
        return this.getTypedRuleContext(ConstdeclarationContext, i);
    }
};
ModuleContext.prototype.EOS = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.EOS);
    }
    else {
        return this.getToken(LnParser.EOS, i);
    }
};
ModuleContext.prototype.EOF = function () {
    return this.getToken(LnParser.EOF, 0);
};
ModuleContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterModule(this);
    }
};
ModuleContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitModule(this);
    }
};
LnParser.ModuleContext = ModuleContext;
LnParser.prototype.module = function () {
    var localctx = new ModuleContext(this, this._ctx, this.state);
    this.enterRule(localctx, 0, LnParser.RULE_module);
    var _la = 0; // Token type
    try {
        this.state = 162;
        this._errHandler.sync(this);
        switch (this._input.LA(1)) {
            case LnParser.IMPORT:
            case LnParser.FROM:
            case LnParser.TYPE:
            case LnParser.FN:
            case LnParser.EVENT:
            case LnParser.ON:
            case LnParser.EXPORT:
            case LnParser.CONST:
            case LnParser.PREFIX:
            case LnParser.INFIX:
            case LnParser.INTERFACE:
            case LnParser.NEWLINE:
            case LnParser.WS:
                this.enterOuterAlt(localctx, 1);
                this.state = 133;
                this._errHandler.sync(this);
                var _alt = this._interp.adaptivePredict(this._input, 0, this._ctx);
                while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
                    if (_alt === 1) {
                        this.state = 130;
                        this.blank();
                    }
                    this.state = 135;
                    this._errHandler.sync(this);
                    _alt = this._interp.adaptivePredict(this._input, 0, this._ctx);
                }
                this.state = 139;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                while (_la === LnParser.IMPORT || _la === LnParser.FROM) {
                    this.state = 136;
                    this.imports();
                    this.state = 141;
                    this._errHandler.sync(this);
                    _la = this._input.LA(1);
                }
                this.state = 157;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                do {
                    this.state = 157;
                    this._errHandler.sync(this);
                    switch (this._input.LA(1)) {
                        case LnParser.TYPE:
                            this.state = 142;
                            this.types();
                            break;
                        case LnParser.CONST:
                            this.state = 143;
                            this.constdeclaration();
                            this.state = 144;
                            this.match(LnParser.EOS);
                            break;
                        case LnParser.FN:
                            this.state = 146;
                            this.functions();
                            break;
                        case LnParser.PREFIX:
                        case LnParser.INFIX:
                            this.state = 147;
                            this.operatormapping();
                            break;
                        case LnParser.EVENT:
                            this.state = 148;
                            this.events();
                            break;
                        case LnParser.ON:
                            this.state = 149;
                            this.handlers();
                            break;
                        case LnParser.INTERFACE:
                            this.state = 150;
                            this.interfaces();
                            break;
                        case LnParser.EXPORT:
                            this.state = 151;
                            this.exports();
                            break;
                        case LnParser.NEWLINE:
                        case LnParser.WS:
                            this.state = 153;
                            this._errHandler.sync(this);
                            var _alt = 1;
                            do {
                                switch (_alt) {
                                    case 1:
                                        this.state = 152;
                                        this.blank();
                                        break;
                                    default:
                                        throw new antlr4.error.NoViableAltException(this);
                                }
                                this.state = 155;
                                this._errHandler.sync(this);
                                _alt = this._interp.adaptivePredict(this._input, 2, this._ctx);
                            } while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER);
                            break;
                        default:
                            throw new antlr4.error.NoViableAltException(this);
                    }
                    this.state = 159;
                    this._errHandler.sync(this);
                    _la = this._input.LA(1);
                } while ((((_la) & ~0x1f) == 0 && ((1 << _la) & ((1 << LnParser.TYPE) | (1 << LnParser.FN) | (1 << LnParser.EVENT) | (1 << LnParser.ON) | (1 << LnParser.EXPORT) | (1 << LnParser.CONST) | (1 << LnParser.PREFIX) | (1 << LnParser.INFIX) | (1 << LnParser.INTERFACE))) !== 0) || _la === LnParser.NEWLINE || _la === LnParser.WS);
                break;
            case LnParser.EOF:
                this.enterOuterAlt(localctx, 2);
                this.state = 161;
                this.match(LnParser.EOF);
                break;
            default:
                throw new antlr4.error.NoViableAltException(this);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function BlankContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_blank;
    return this;
}
BlankContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
BlankContext.prototype.constructor = BlankContext;
BlankContext.prototype.WS = function () {
    return this.getToken(LnParser.WS, 0);
};
BlankContext.prototype.NEWLINE = function () {
    return this.getToken(LnParser.NEWLINE, 0);
};
BlankContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterBlank(this);
    }
};
BlankContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitBlank(this);
    }
};
LnParser.BlankContext = BlankContext;
LnParser.prototype.blank = function () {
    var localctx = new BlankContext(this, this._ctx, this.state);
    this.enterRule(localctx, 2, LnParser.RULE_blank);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 164;
        _la = this._input.LA(1);
        if (!(_la === LnParser.NEWLINE || _la === LnParser.WS)) {
            this._errHandler.recoverInline(this);
        }
        else {
            this._errHandler.reportMatch(this);
            this.consume();
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function ImportsContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_imports;
    return this;
}
ImportsContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
ImportsContext.prototype.constructor = ImportsContext;
ImportsContext.prototype.standardImport = function () {
    return this.getTypedRuleContext(StandardImportContext, 0);
};
ImportsContext.prototype.fromImport = function () {
    return this.getTypedRuleContext(FromImportContext, 0);
};
ImportsContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterImports(this);
    }
};
ImportsContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitImports(this);
    }
};
LnParser.ImportsContext = ImportsContext;
LnParser.prototype.imports = function () {
    var localctx = new ImportsContext(this, this._ctx, this.state);
    this.enterRule(localctx, 4, LnParser.RULE_imports);
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 168;
        this._errHandler.sync(this);
        switch (this._input.LA(1)) {
            case LnParser.IMPORT:
                this.state = 166;
                this.standardImport();
                break;
            case LnParser.FROM:
                this.state = 167;
                this.fromImport();
                break;
            default:
                throw new antlr4.error.NoViableAltException(this);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function StandardImportContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_standardImport;
    return this;
}
StandardImportContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
StandardImportContext.prototype.constructor = StandardImportContext;
StandardImportContext.prototype.IMPORT = function () {
    return this.getToken(LnParser.IMPORT, 0);
};
StandardImportContext.prototype.WS = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.WS);
    }
    else {
        return this.getToken(LnParser.WS, i);
    }
};
StandardImportContext.prototype.dependency = function () {
    return this.getTypedRuleContext(DependencyContext, 0);
};
StandardImportContext.prototype.NEWLINE = function () {
    return this.getToken(LnParser.NEWLINE, 0);
};
StandardImportContext.prototype.AS = function () {
    return this.getToken(LnParser.AS, 0);
};
StandardImportContext.prototype.VARNAME = function () {
    return this.getToken(LnParser.VARNAME, 0);
};
StandardImportContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
StandardImportContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterStandardImport(this);
    }
};
StandardImportContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitStandardImport(this);
    }
};
LnParser.StandardImportContext = StandardImportContext;
LnParser.prototype.standardImport = function () {
    var localctx = new StandardImportContext(this, this._ctx, this.state);
    this.enterRule(localctx, 6, LnParser.RULE_standardImport);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 170;
        this.match(LnParser.IMPORT);
        this.state = 171;
        this.match(LnParser.WS);
        this.state = 172;
        this.dependency();
        this.state = 177;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        if (_la === LnParser.WS) {
            this.state = 173;
            this.match(LnParser.WS);
            this.state = 174;
            this.match(LnParser.AS);
            this.state = 175;
            this.match(LnParser.WS);
            this.state = 176;
            this.match(LnParser.VARNAME);
        }
        this.state = 179;
        this.match(LnParser.NEWLINE);
        this.state = 183;
        this._errHandler.sync(this);
        var _alt = this._interp.adaptivePredict(this._input, 8, this._ctx);
        while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
            if (_alt === 1) {
                this.state = 180;
                this.blank();
            }
            this.state = 185;
            this._errHandler.sync(this);
            _alt = this._interp.adaptivePredict(this._input, 8, this._ctx);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function FromImportContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_fromImport;
    return this;
}
FromImportContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
FromImportContext.prototype.constructor = FromImportContext;
FromImportContext.prototype.FROM = function () {
    return this.getToken(LnParser.FROM, 0);
};
FromImportContext.prototype.WS = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.WS);
    }
    else {
        return this.getToken(LnParser.WS, i);
    }
};
FromImportContext.prototype.dependency = function () {
    return this.getTypedRuleContext(DependencyContext, 0);
};
FromImportContext.prototype.IMPORT = function () {
    return this.getToken(LnParser.IMPORT, 0);
};
FromImportContext.prototype.varlist = function () {
    return this.getTypedRuleContext(VarlistContext, 0);
};
FromImportContext.prototype.NEWLINE = function () {
    return this.getToken(LnParser.NEWLINE, 0);
};
FromImportContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
FromImportContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterFromImport(this);
    }
};
FromImportContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitFromImport(this);
    }
};
LnParser.FromImportContext = FromImportContext;
LnParser.prototype.fromImport = function () {
    var localctx = new FromImportContext(this, this._ctx, this.state);
    this.enterRule(localctx, 8, LnParser.RULE_fromImport);
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 186;
        this.match(LnParser.FROM);
        this.state = 187;
        this.match(LnParser.WS);
        this.state = 188;
        this.dependency();
        this.state = 189;
        this.match(LnParser.WS);
        this.state = 190;
        this.match(LnParser.IMPORT);
        this.state = 191;
        this.match(LnParser.WS);
        this.state = 192;
        this.varlist();
        this.state = 193;
        this.match(LnParser.NEWLINE);
        this.state = 197;
        this._errHandler.sync(this);
        var _alt = this._interp.adaptivePredict(this._input, 9, this._ctx);
        while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
            if (_alt === 1) {
                this.state = 194;
                this.blank();
            }
            this.state = 199;
            this._errHandler.sync(this);
            _alt = this._interp.adaptivePredict(this._input, 9, this._ctx);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function DependencyContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_dependency;
    return this;
}
DependencyContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
DependencyContext.prototype.constructor = DependencyContext;
DependencyContext.prototype.localdependency = function () {
    return this.getTypedRuleContext(LocaldependencyContext, 0);
};
DependencyContext.prototype.globaldependency = function () {
    return this.getTypedRuleContext(GlobaldependencyContext, 0);
};
DependencyContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterDependency(this);
    }
};
DependencyContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitDependency(this);
    }
};
LnParser.DependencyContext = DependencyContext;
LnParser.prototype.dependency = function () {
    var localctx = new DependencyContext(this, this._ctx, this.state);
    this.enterRule(localctx, 10, LnParser.RULE_dependency);
    try {
        this.state = 202;
        this._errHandler.sync(this);
        switch (this._input.LA(1)) {
            case LnParser.CURDIR:
            case LnParser.PARDIR:
                this.enterOuterAlt(localctx, 1);
                this.state = 200;
                this.localdependency();
                break;
            case LnParser.GLOBAL:
                this.enterOuterAlt(localctx, 2);
                this.state = 201;
                this.globaldependency();
                break;
            default:
                throw new antlr4.error.NoViableAltException(this);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function LocaldependencyContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_localdependency;
    return this;
}
LocaldependencyContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
LocaldependencyContext.prototype.constructor = LocaldependencyContext;
LocaldependencyContext.prototype.CURDIR = function () {
    return this.getToken(LnParser.CURDIR, 0);
};
LocaldependencyContext.prototype.VARNAME = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.VARNAME);
    }
    else {
        return this.getToken(LnParser.VARNAME, i);
    }
};
LocaldependencyContext.prototype.DIRSEP = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.DIRSEP);
    }
    else {
        return this.getToken(LnParser.DIRSEP, i);
    }
};
LocaldependencyContext.prototype.PARDIR = function () {
    return this.getToken(LnParser.PARDIR, 0);
};
LocaldependencyContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterLocaldependency(this);
    }
};
LocaldependencyContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitLocaldependency(this);
    }
};
LnParser.LocaldependencyContext = LocaldependencyContext;
LnParser.prototype.localdependency = function () {
    var localctx = new LocaldependencyContext(this, this._ctx, this.state);
    this.enterRule(localctx, 12, LnParser.RULE_localdependency);
    var _la = 0; // Token type
    try {
        this.state = 216;
        this._errHandler.sync(this);
        switch (this._input.LA(1)) {
            case LnParser.CURDIR:
                this.enterOuterAlt(localctx, 1);
                this.state = 204;
                this.match(LnParser.CURDIR);
                this.state = 206;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                do {
                    this.state = 205;
                    _la = this._input.LA(1);
                    if (!(_la === LnParser.DIRSEP || _la === LnParser.VARNAME)) {
                        this._errHandler.recoverInline(this);
                    }
                    else {
                        this._errHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 208;
                    this._errHandler.sync(this);
                    _la = this._input.LA(1);
                } while (_la === LnParser.DIRSEP || _la === LnParser.VARNAME);
                break;
            case LnParser.PARDIR:
                this.enterOuterAlt(localctx, 2);
                this.state = 210;
                this.match(LnParser.PARDIR);
                this.state = 212;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                do {
                    this.state = 211;
                    _la = this._input.LA(1);
                    if (!(_la === LnParser.DIRSEP || _la === LnParser.VARNAME)) {
                        this._errHandler.recoverInline(this);
                    }
                    else {
                        this._errHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 214;
                    this._errHandler.sync(this);
                    _la = this._input.LA(1);
                } while (_la === LnParser.DIRSEP || _la === LnParser.VARNAME);
                break;
            default:
                throw new antlr4.error.NoViableAltException(this);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function GlobaldependencyContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_globaldependency;
    return this;
}
GlobaldependencyContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
GlobaldependencyContext.prototype.constructor = GlobaldependencyContext;
GlobaldependencyContext.prototype.GLOBAL = function () {
    return this.getToken(LnParser.GLOBAL, 0);
};
GlobaldependencyContext.prototype.VARNAME = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.VARNAME);
    }
    else {
        return this.getToken(LnParser.VARNAME, i);
    }
};
GlobaldependencyContext.prototype.DIRSEP = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.DIRSEP);
    }
    else {
        return this.getToken(LnParser.DIRSEP, i);
    }
};
GlobaldependencyContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterGlobaldependency(this);
    }
};
GlobaldependencyContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitGlobaldependency(this);
    }
};
LnParser.GlobaldependencyContext = GlobaldependencyContext;
LnParser.prototype.globaldependency = function () {
    var localctx = new GlobaldependencyContext(this, this._ctx, this.state);
    this.enterRule(localctx, 14, LnParser.RULE_globaldependency);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 218;
        this.match(LnParser.GLOBAL);
        this.state = 220;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        do {
            this.state = 219;
            _la = this._input.LA(1);
            if (!(_la === LnParser.DIRSEP || _la === LnParser.VARNAME)) {
                this._errHandler.recoverInline(this);
            }
            else {
                this._errHandler.reportMatch(this);
                this.consume();
            }
            this.state = 222;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        } while (_la === LnParser.DIRSEP || _la === LnParser.VARNAME);
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function TypesContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_types;
    return this;
}
TypesContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
TypesContext.prototype.constructor = TypesContext;
TypesContext.prototype.TYPE = function () {
    return this.getToken(LnParser.TYPE, 0);
};
TypesContext.prototype.typename = function () {
    return this.getTypedRuleContext(TypenameContext, 0);
};
TypesContext.prototype.typebody = function () {
    return this.getTypedRuleContext(TypebodyContext, 0);
};
TypesContext.prototype.EQUALS = function () {
    return this.getToken(LnParser.EQUALS, 0);
};
TypesContext.prototype.fulltypename = function () {
    return this.getTypedRuleContext(FulltypenameContext, 0);
};
TypesContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
TypesContext.prototype.typegenerics = function () {
    return this.getTypedRuleContext(TypegenericsContext, 0);
};
TypesContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterTypes(this);
    }
};
TypesContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitTypes(this);
    }
};
LnParser.TypesContext = TypesContext;
LnParser.prototype.types = function () {
    var localctx = new TypesContext(this, this._ctx, this.state);
    this.enterRule(localctx, 16, LnParser.RULE_types);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 224;
        this.match(LnParser.TYPE);
        this.state = 226;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        do {
            this.state = 225;
            this.blank();
            this.state = 228;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        } while (_la === LnParser.NEWLINE || _la === LnParser.WS);
        this.state = 230;
        this.typename();
        this.state = 238;
        this._errHandler.sync(this);
        var la_ = this._interp.adaptivePredict(this._input, 17, this._ctx);
        if (la_ === 1) {
            this.state = 234;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                this.state = 231;
                this.blank();
                this.state = 236;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
            }
            this.state = 237;
            this.typegenerics();
        }
        this.state = 241;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        do {
            this.state = 240;
            this.blank();
            this.state = 243;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        } while (_la === LnParser.NEWLINE || _la === LnParser.WS);
        this.state = 254;
        this._errHandler.sync(this);
        switch (this._input.LA(1)) {
            case LnParser.OPENBODY:
                this.state = 245;
                this.typebody();
                break;
            case LnParser.EQUALS:
                this.state = 246;
                this.match(LnParser.EQUALS);
                this.state = 250;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                    this.state = 247;
                    this.blank();
                    this.state = 252;
                    this._errHandler.sync(this);
                    _la = this._input.LA(1);
                }
                this.state = 253;
                this.fulltypename();
                break;
            default:
                throw new antlr4.error.NoViableAltException(this);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function TypenameContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_typename;
    return this;
}
TypenameContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
TypenameContext.prototype.constructor = TypenameContext;
TypenameContext.prototype.VARNAME = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.VARNAME);
    }
    else {
        return this.getToken(LnParser.VARNAME, i);
    }
};
TypenameContext.prototype.METHODSEP = function () {
    return this.getToken(LnParser.METHODSEP, 0);
};
TypenameContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterTypename(this);
    }
};
TypenameContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitTypename(this);
    }
};
LnParser.TypenameContext = TypenameContext;
LnParser.prototype.typename = function () {
    var localctx = new TypenameContext(this, this._ctx, this.state);
    this.enterRule(localctx, 18, LnParser.RULE_typename);
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 256;
        this.match(LnParser.VARNAME);
        this.state = 259;
        this._errHandler.sync(this);
        var la_ = this._interp.adaptivePredict(this._input, 21, this._ctx);
        if (la_ === 1) {
            this.state = 257;
            this.match(LnParser.METHODSEP);
            this.state = 258;
            this.match(LnParser.VARNAME);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function TypegenericsContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_typegenerics;
    return this;
}
TypegenericsContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
TypegenericsContext.prototype.constructor = TypegenericsContext;
TypegenericsContext.prototype.OPENGENERIC = function () {
    return this.getToken(LnParser.OPENGENERIC, 0);
};
TypegenericsContext.prototype.fulltypename = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(FulltypenameContext);
    }
    else {
        return this.getTypedRuleContext(FulltypenameContext, i);
    }
};
TypegenericsContext.prototype.CLOSEGENERIC = function () {
    return this.getToken(LnParser.CLOSEGENERIC, 0);
};
TypegenericsContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
TypegenericsContext.prototype.SEP = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.SEP);
    }
    else {
        return this.getToken(LnParser.SEP, i);
    }
};
TypegenericsContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterTypegenerics(this);
    }
};
TypegenericsContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitTypegenerics(this);
    }
};
LnParser.TypegenericsContext = TypegenericsContext;
LnParser.prototype.typegenerics = function () {
    var localctx = new TypegenericsContext(this, this._ctx, this.state);
    this.enterRule(localctx, 20, LnParser.RULE_typegenerics);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 261;
        this.match(LnParser.OPENGENERIC);
        this.state = 265;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 262;
            this.blank();
            this.state = 267;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 268;
        this.fulltypename();
        this.state = 272;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 269;
            this.blank();
            this.state = 274;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 291;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.SEP) {
            this.state = 275;
            this.match(LnParser.SEP);
            this.state = 279;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                this.state = 276;
                this.blank();
                this.state = 281;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
            }
            this.state = 282;
            this.fulltypename();
            this.state = 286;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                this.state = 283;
                this.blank();
                this.state = 288;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
            }
            this.state = 293;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 294;
        this.match(LnParser.CLOSEGENERIC);
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function FulltypenameContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_fulltypename;
    return this;
}
FulltypenameContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
FulltypenameContext.prototype.constructor = FulltypenameContext;
FulltypenameContext.prototype.typename = function () {
    return this.getTypedRuleContext(TypenameContext, 0);
};
FulltypenameContext.prototype.typegenerics = function () {
    return this.getTypedRuleContext(TypegenericsContext, 0);
};
FulltypenameContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
FulltypenameContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterFulltypename(this);
    }
};
FulltypenameContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitFulltypename(this);
    }
};
LnParser.FulltypenameContext = FulltypenameContext;
LnParser.prototype.fulltypename = function () {
    var localctx = new FulltypenameContext(this, this._ctx, this.state);
    this.enterRule(localctx, 22, LnParser.RULE_fulltypename);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 296;
        this.typename();
        this.state = 304;
        this._errHandler.sync(this);
        var la_ = this._interp.adaptivePredict(this._input, 28, this._ctx);
        if (la_ === 1) {
            this.state = 300;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                this.state = 297;
                this.blank();
                this.state = 302;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
            }
            this.state = 303;
            this.typegenerics();
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function TypebodyContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_typebody;
    return this;
}
TypebodyContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
TypebodyContext.prototype.constructor = TypebodyContext;
TypebodyContext.prototype.OPENBODY = function () {
    return this.getToken(LnParser.OPENBODY, 0);
};
TypebodyContext.prototype.typelist = function () {
    return this.getTypedRuleContext(TypelistContext, 0);
};
TypebodyContext.prototype.CLOSEBODY = function () {
    return this.getToken(LnParser.CLOSEBODY, 0);
};
TypebodyContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
TypebodyContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterTypebody(this);
    }
};
TypebodyContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitTypebody(this);
    }
};
LnParser.TypebodyContext = TypebodyContext;
LnParser.prototype.typebody = function () {
    var localctx = new TypebodyContext(this, this._ctx, this.state);
    this.enterRule(localctx, 24, LnParser.RULE_typebody);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 306;
        this.match(LnParser.OPENBODY);
        this.state = 310;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 307;
            this.blank();
            this.state = 312;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 313;
        this.typelist();
        this.state = 317;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 314;
            this.blank();
            this.state = 319;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 320;
        this.match(LnParser.CLOSEBODY);
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function TypelineContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_typeline;
    return this;
}
TypelineContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
TypelineContext.prototype.constructor = TypelineContext;
TypelineContext.prototype.VARNAME = function () {
    return this.getToken(LnParser.VARNAME, 0);
};
TypelineContext.prototype.TYPESEP = function () {
    return this.getToken(LnParser.TYPESEP, 0);
};
TypelineContext.prototype.fulltypename = function () {
    return this.getTypedRuleContext(FulltypenameContext, 0);
};
TypelineContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
TypelineContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterTypeline(this);
    }
};
TypelineContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitTypeline(this);
    }
};
LnParser.TypelineContext = TypelineContext;
LnParser.prototype.typeline = function () {
    var localctx = new TypelineContext(this, this._ctx, this.state);
    this.enterRule(localctx, 26, LnParser.RULE_typeline);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 322;
        this.match(LnParser.VARNAME);
        this.state = 326;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 323;
            this.blank();
            this.state = 328;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 329;
        this.match(LnParser.TYPESEP);
        this.state = 333;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 330;
            this.blank();
            this.state = 335;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 336;
        this.fulltypename();
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function TypelistContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_typelist;
    return this;
}
TypelistContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
TypelistContext.prototype.constructor = TypelistContext;
TypelistContext.prototype.typeline = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(TypelineContext);
    }
    else {
        return this.getTypedRuleContext(TypelineContext, i);
    }
};
TypelistContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
TypelistContext.prototype.SEP = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.SEP);
    }
    else {
        return this.getToken(LnParser.SEP, i);
    }
};
TypelistContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterTypelist(this);
    }
};
TypelistContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitTypelist(this);
    }
};
LnParser.TypelistContext = TypelistContext;
LnParser.prototype.typelist = function () {
    var localctx = new TypelistContext(this, this._ctx, this.state);
    this.enterRule(localctx, 28, LnParser.RULE_typelist);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 338;
        this.typeline();
        this.state = 342;
        this._errHandler.sync(this);
        var _alt = this._interp.adaptivePredict(this._input, 33, this._ctx);
        while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
            if (_alt === 1) {
                this.state = 339;
                this.blank();
            }
            this.state = 344;
            this._errHandler.sync(this);
            _alt = this._interp.adaptivePredict(this._input, 33, this._ctx);
        }
        this.state = 361;
        this._errHandler.sync(this);
        var _alt = this._interp.adaptivePredict(this._input, 36, this._ctx);
        while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
            if (_alt === 1) {
                this.state = 345;
                this.match(LnParser.SEP);
                this.state = 349;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                    this.state = 346;
                    this.blank();
                    this.state = 351;
                    this._errHandler.sync(this);
                    _la = this._input.LA(1);
                }
                this.state = 352;
                this.typeline();
                this.state = 356;
                this._errHandler.sync(this);
                var _alt = this._interp.adaptivePredict(this._input, 35, this._ctx);
                while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
                    if (_alt === 1) {
                        this.state = 353;
                        this.blank();
                    }
                    this.state = 358;
                    this._errHandler.sync(this);
                    _alt = this._interp.adaptivePredict(this._input, 35, this._ctx);
                }
            }
            this.state = 363;
            this._errHandler.sync(this);
            _alt = this._interp.adaptivePredict(this._input, 36, this._ctx);
        }
        this.state = 365;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        if (_la === LnParser.SEP) {
            this.state = 364;
            this.match(LnParser.SEP);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function ArglistContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_arglist;
    return this;
}
ArglistContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
ArglistContext.prototype.constructor = ArglistContext;
ArglistContext.prototype.VARNAME = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.VARNAME);
    }
    else {
        return this.getToken(LnParser.VARNAME, i);
    }
};
ArglistContext.prototype.TYPESEP = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.TYPESEP);
    }
    else {
        return this.getToken(LnParser.TYPESEP, i);
    }
};
ArglistContext.prototype.fulltypename = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(FulltypenameContext);
    }
    else {
        return this.getTypedRuleContext(FulltypenameContext, i);
    }
};
ArglistContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
ArglistContext.prototype.SEP = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.SEP);
    }
    else {
        return this.getToken(LnParser.SEP, i);
    }
};
ArglistContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterArglist(this);
    }
};
ArglistContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitArglist(this);
    }
};
LnParser.ArglistContext = ArglistContext;
LnParser.prototype.arglist = function () {
    var localctx = new ArglistContext(this, this._ctx, this.state);
    this.enterRule(localctx, 30, LnParser.RULE_arglist);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 367;
        this.match(LnParser.VARNAME);
        this.state = 371;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 368;
            this.blank();
            this.state = 373;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 374;
        this.match(LnParser.TYPESEP);
        this.state = 378;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 375;
            this.blank();
            this.state = 380;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 381;
        this.fulltypename();
        this.state = 400;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.SEP) {
            this.state = 382;
            this.match(LnParser.SEP);
            this.state = 383;
            this.match(LnParser.VARNAME);
            this.state = 387;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                this.state = 384;
                this.blank();
                this.state = 389;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
            }
            this.state = 390;
            this.match(LnParser.TYPESEP);
            this.state = 394;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                this.state = 391;
                this.blank();
                this.state = 396;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
            }
            this.state = 397;
            this.fulltypename();
            this.state = 402;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function FunctionsContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_functions;
    return this;
}
FunctionsContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
FunctionsContext.prototype.constructor = FunctionsContext;
FunctionsContext.prototype.FN = function () {
    return this.getToken(LnParser.FN, 0);
};
FunctionsContext.prototype.fullfunctionbody = function () {
    return this.getTypedRuleContext(FullfunctionbodyContext, 0);
};
FunctionsContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
FunctionsContext.prototype.OPENARGS = function () {
    return this.getToken(LnParser.OPENARGS, 0);
};
FunctionsContext.prototype.CLOSEARGS = function () {
    return this.getToken(LnParser.CLOSEARGS, 0);
};
FunctionsContext.prototype.EOS = function () {
    return this.getToken(LnParser.EOS, 0);
};
FunctionsContext.prototype.VARNAME = function () {
    return this.getToken(LnParser.VARNAME, 0);
};
FunctionsContext.prototype.arglist = function () {
    return this.getTypedRuleContext(ArglistContext, 0);
};
FunctionsContext.prototype.TYPESEP = function () {
    return this.getToken(LnParser.TYPESEP, 0);
};
FunctionsContext.prototype.fulltypename = function () {
    return this.getTypedRuleContext(FulltypenameContext, 0);
};
FunctionsContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterFunctions(this);
    }
};
FunctionsContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitFunctions(this);
    }
};
LnParser.FunctionsContext = FunctionsContext;
LnParser.prototype.functions = function () {
    var localctx = new FunctionsContext(this, this._ctx, this.state);
    this.enterRule(localctx, 32, LnParser.RULE_functions);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 403;
        this.match(LnParser.FN);
        this.state = 405;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        do {
            this.state = 404;
            this.blank();
            this.state = 407;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        } while (_la === LnParser.NEWLINE || _la === LnParser.WS);
        this.state = 445;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        if (_la === LnParser.OPENARGS || _la === LnParser.VARNAME) {
            this.state = 416;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            if (_la === LnParser.VARNAME) {
                this.state = 409;
                this.match(LnParser.VARNAME);
                this.state = 413;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                    this.state = 410;
                    this.blank();
                    this.state = 415;
                    this._errHandler.sync(this);
                    _la = this._input.LA(1);
                }
            }
            this.state = 418;
            this.match(LnParser.OPENARGS);
            this.state = 420;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            if (_la === LnParser.VARNAME) {
                this.state = 419;
                this.arglist();
            }
            this.state = 422;
            this.match(LnParser.CLOSEARGS);
            this.state = 426;
            this._errHandler.sync(this);
            var _alt = this._interp.adaptivePredict(this._input, 47, this._ctx);
            while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
                if (_alt === 1) {
                    this.state = 423;
                    this.blank();
                }
                this.state = 428;
                this._errHandler.sync(this);
                _alt = this._interp.adaptivePredict(this._input, 47, this._ctx);
            }
            this.state = 443;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            if (((((_la - 36)) & ~0x1f) == 0 && ((1 << (_la - 36)) & ((1 << (LnParser.TYPESEP - 36)) | (1 << (LnParser.NEWLINE - 36)) | (1 << (LnParser.WS - 36)))) !== 0)) {
                this.state = 430;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                if (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                    this.state = 429;
                    this.blank();
                }
                this.state = 432;
                this.match(LnParser.TYPESEP);
                this.state = 434;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                if (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                    this.state = 433;
                    this.blank();
                }
                this.state = 436;
                this.fulltypename();
                this.state = 440;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                    this.state = 437;
                    this.blank();
                    this.state = 442;
                    this._errHandler.sync(this);
                    _la = this._input.LA(1);
                }
            }
        }
        this.state = 447;
        this.fullfunctionbody();
        this.state = 449;
        this._errHandler.sync(this);
        var la_ = this._interp.adaptivePredict(this._input, 53, this._ctx);
        if (la_ === 1) {
            this.state = 448;
            this.match(LnParser.EOS);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function FullfunctionbodyContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_fullfunctionbody;
    return this;
}
FullfunctionbodyContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
FullfunctionbodyContext.prototype.constructor = FullfunctionbodyContext;
FullfunctionbodyContext.prototype.functionbody = function () {
    return this.getTypedRuleContext(FunctionbodyContext, 0);
};
FullfunctionbodyContext.prototype.EQUALS = function () {
    return this.getToken(LnParser.EQUALS, 0);
};
FullfunctionbodyContext.prototype.assignables = function () {
    return this.getTypedRuleContext(AssignablesContext, 0);
};
FullfunctionbodyContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
FullfunctionbodyContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterFullfunctionbody(this);
    }
};
FullfunctionbodyContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitFullfunctionbody(this);
    }
};
LnParser.FullfunctionbodyContext = FullfunctionbodyContext;
LnParser.prototype.fullfunctionbody = function () {
    var localctx = new FullfunctionbodyContext(this, this._ctx, this.state);
    this.enterRule(localctx, 34, LnParser.RULE_fullfunctionbody);
    var _la = 0; // Token type
    try {
        this.state = 460;
        this._errHandler.sync(this);
        switch (this._input.LA(1)) {
            case LnParser.OPENBODY:
                this.enterOuterAlt(localctx, 1);
                this.state = 451;
                this.functionbody();
                break;
            case LnParser.EQUALS:
                this.enterOuterAlt(localctx, 2);
                this.state = 452;
                this.match(LnParser.EQUALS);
                this.state = 456;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                    this.state = 453;
                    this.blank();
                    this.state = 458;
                    this._errHandler.sync(this);
                    _la = this._input.LA(1);
                }
                this.state = 459;
                this.assignables();
                break;
            default:
                throw new antlr4.error.NoViableAltException(this);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function FunctionbodyContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_functionbody;
    return this;
}
FunctionbodyContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
FunctionbodyContext.prototype.constructor = FunctionbodyContext;
FunctionbodyContext.prototype.OPENBODY = function () {
    return this.getToken(LnParser.OPENBODY, 0);
};
FunctionbodyContext.prototype.CLOSEBODY = function () {
    return this.getToken(LnParser.CLOSEBODY, 0);
};
FunctionbodyContext.prototype.statements = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(StatementsContext);
    }
    else {
        return this.getTypedRuleContext(StatementsContext, i);
    }
};
FunctionbodyContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
FunctionbodyContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterFunctionbody(this);
    }
};
FunctionbodyContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitFunctionbody(this);
    }
};
LnParser.FunctionbodyContext = FunctionbodyContext;
LnParser.prototype.functionbody = function () {
    var localctx = new FunctionbodyContext(this, this._ctx, this.state);
    this.enterRule(localctx, 36, LnParser.RULE_functionbody);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 462;
        this.match(LnParser.OPENBODY);
        this.state = 464;
        this._errHandler.sync(this);
        var _alt = 1;
        do {
            switch (_alt) {
                case 1:
                    this.state = 463;
                    this.statements();
                    break;
                default:
                    throw new antlr4.error.NoViableAltException(this);
            }
            this.state = 466;
            this._errHandler.sync(this);
            _alt = this._interp.adaptivePredict(this._input, 56, this._ctx);
        } while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER);
        this.state = 471;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 468;
            this.blank();
            this.state = 473;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 474;
        this.match(LnParser.CLOSEBODY);
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function StatementsContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_statements;
    return this;
}
StatementsContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
StatementsContext.prototype.constructor = StatementsContext;
StatementsContext.prototype.declarations = function () {
    return this.getTypedRuleContext(DeclarationsContext, 0);
};
StatementsContext.prototype.exits = function () {
    return this.getTypedRuleContext(ExitsContext, 0);
};
StatementsContext.prototype.emits = function () {
    return this.getTypedRuleContext(EmitsContext, 0);
};
StatementsContext.prototype.conditionals = function () {
    return this.getTypedRuleContext(ConditionalsContext, 0);
};
StatementsContext.prototype.assignments = function () {
    return this.getTypedRuleContext(AssignmentsContext, 0);
};
StatementsContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
StatementsContext.prototype.assignables = function () {
    return this.getTypedRuleContext(AssignablesContext, 0);
};
StatementsContext.prototype.EOS = function () {
    return this.getToken(LnParser.EOS, 0);
};
StatementsContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterStatements(this);
    }
};
StatementsContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitStatements(this);
    }
};
LnParser.StatementsContext = StatementsContext;
LnParser.prototype.statements = function () {
    var localctx = new StatementsContext(this, this._ctx, this.state);
    this.enterRule(localctx, 38, LnParser.RULE_statements);
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 479;
        this._errHandler.sync(this);
        var _alt = this._interp.adaptivePredict(this._input, 58, this._ctx);
        while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
            if (_alt === 1) {
                this.state = 476;
                this.blank();
            }
            this.state = 481;
            this._errHandler.sync(this);
            _alt = this._interp.adaptivePredict(this._input, 58, this._ctx);
        }
        this.state = 490;
        this._errHandler.sync(this);
        var la_ = this._interp.adaptivePredict(this._input, 59, this._ctx);
        switch (la_) {
            case 1:
                this.state = 482;
                this.declarations();
                break;
            case 2:
                this.state = 483;
                this.exits();
                break;
            case 3:
                this.state = 484;
                this.emits();
                break;
            case 4:
                this.state = 485;
                this.conditionals();
                break;
            case 5:
                this.state = 486;
                this.assignments();
                break;
            case 6:
                this.state = 487;
                this.assignables();
                this.state = 488;
                this.match(LnParser.EOS);
                break;
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function DeclarationsContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_declarations;
    return this;
}
DeclarationsContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
DeclarationsContext.prototype.constructor = DeclarationsContext;
DeclarationsContext.prototype.EOS = function () {
    return this.getToken(LnParser.EOS, 0);
};
DeclarationsContext.prototype.constdeclaration = function () {
    return this.getTypedRuleContext(ConstdeclarationContext, 0);
};
DeclarationsContext.prototype.letdeclaration = function () {
    return this.getTypedRuleContext(LetdeclarationContext, 0);
};
DeclarationsContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterDeclarations(this);
    }
};
DeclarationsContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitDeclarations(this);
    }
};
LnParser.DeclarationsContext = DeclarationsContext;
LnParser.prototype.declarations = function () {
    var localctx = new DeclarationsContext(this, this._ctx, this.state);
    this.enterRule(localctx, 40, LnParser.RULE_declarations);
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 494;
        this._errHandler.sync(this);
        switch (this._input.LA(1)) {
            case LnParser.CONST:
                this.state = 492;
                this.constdeclaration();
                break;
            case LnParser.LET:
                this.state = 493;
                this.letdeclaration();
                break;
            default:
                throw new antlr4.error.NoViableAltException(this);
        }
        this.state = 496;
        this.match(LnParser.EOS);
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function ConstdeclarationContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_constdeclaration;
    return this;
}
ConstdeclarationContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
ConstdeclarationContext.prototype.constructor = ConstdeclarationContext;
ConstdeclarationContext.prototype.CONST = function () {
    return this.getToken(LnParser.CONST, 0);
};
ConstdeclarationContext.prototype.VARNAME = function () {
    return this.getToken(LnParser.VARNAME, 0);
};
ConstdeclarationContext.prototype.EQUALS = function () {
    return this.getToken(LnParser.EQUALS, 0);
};
ConstdeclarationContext.prototype.assignables = function () {
    return this.getTypedRuleContext(AssignablesContext, 0);
};
ConstdeclarationContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
ConstdeclarationContext.prototype.TYPESEP = function () {
    return this.getToken(LnParser.TYPESEP, 0);
};
ConstdeclarationContext.prototype.fulltypename = function () {
    return this.getTypedRuleContext(FulltypenameContext, 0);
};
ConstdeclarationContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterConstdeclaration(this);
    }
};
ConstdeclarationContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitConstdeclaration(this);
    }
};
LnParser.ConstdeclarationContext = ConstdeclarationContext;
LnParser.prototype.constdeclaration = function () {
    var localctx = new ConstdeclarationContext(this, this._ctx, this.state);
    this.enterRule(localctx, 42, LnParser.RULE_constdeclaration);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 498;
        this.match(LnParser.CONST);
        this.state = 502;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 499;
            this.blank();
            this.state = 504;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 505;
        this.match(LnParser.VARNAME);
        this.state = 509;
        this._errHandler.sync(this);
        var _alt = this._interp.adaptivePredict(this._input, 62, this._ctx);
        while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
            if (_alt === 1) {
                this.state = 506;
                this.blank();
            }
            this.state = 511;
            this._errHandler.sync(this);
            _alt = this._interp.adaptivePredict(this._input, 62, this._ctx);
        }
        this.state = 517;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        if (_la === LnParser.TYPESEP) {
            this.state = 512;
            this.match(LnParser.TYPESEP);
            this.state = 514;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            if (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                this.state = 513;
                this.blank();
            }
            this.state = 516;
            this.fulltypename();
        }
        this.state = 522;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 519;
            this.blank();
            this.state = 524;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 525;
        this.match(LnParser.EQUALS);
        this.state = 529;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 526;
            this.blank();
            this.state = 531;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 532;
        this.assignables();
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function LetdeclarationContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_letdeclaration;
    return this;
}
LetdeclarationContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
LetdeclarationContext.prototype.constructor = LetdeclarationContext;
LetdeclarationContext.prototype.LET = function () {
    return this.getToken(LnParser.LET, 0);
};
LetdeclarationContext.prototype.VARNAME = function () {
    return this.getToken(LnParser.VARNAME, 0);
};
LetdeclarationContext.prototype.EQUALS = function () {
    return this.getToken(LnParser.EQUALS, 0);
};
LetdeclarationContext.prototype.assignables = function () {
    return this.getTypedRuleContext(AssignablesContext, 0);
};
LetdeclarationContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
LetdeclarationContext.prototype.TYPESEP = function () {
    return this.getToken(LnParser.TYPESEP, 0);
};
LetdeclarationContext.prototype.fulltypename = function () {
    return this.getTypedRuleContext(FulltypenameContext, 0);
};
LetdeclarationContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterLetdeclaration(this);
    }
};
LetdeclarationContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitLetdeclaration(this);
    }
};
LnParser.LetdeclarationContext = LetdeclarationContext;
LnParser.prototype.letdeclaration = function () {
    var localctx = new LetdeclarationContext(this, this._ctx, this.state);
    this.enterRule(localctx, 44, LnParser.RULE_letdeclaration);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 534;
        this.match(LnParser.LET);
        this.state = 538;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 535;
            this.blank();
            this.state = 540;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 541;
        this.match(LnParser.VARNAME);
        this.state = 545;
        this._errHandler.sync(this);
        var _alt = this._interp.adaptivePredict(this._input, 68, this._ctx);
        while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
            if (_alt === 1) {
                this.state = 542;
                this.blank();
            }
            this.state = 547;
            this._errHandler.sync(this);
            _alt = this._interp.adaptivePredict(this._input, 68, this._ctx);
        }
        this.state = 553;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        if (_la === LnParser.TYPESEP) {
            this.state = 548;
            this.match(LnParser.TYPESEP);
            this.state = 550;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            if (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                this.state = 549;
                this.blank();
            }
            this.state = 552;
            this.fulltypename();
        }
        this.state = 558;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 555;
            this.blank();
            this.state = 560;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 561;
        this.match(LnParser.EQUALS);
        this.state = 565;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 562;
            this.blank();
            this.state = 567;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 568;
        this.assignables();
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function AssignmentsContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_assignments;
    return this;
}
AssignmentsContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
AssignmentsContext.prototype.constructor = AssignmentsContext;
AssignmentsContext.prototype.varn = function () {
    return this.getTypedRuleContext(VarnContext, 0);
};
AssignmentsContext.prototype.EQUALS = function () {
    return this.getToken(LnParser.EQUALS, 0);
};
AssignmentsContext.prototype.assignables = function () {
    return this.getTypedRuleContext(AssignablesContext, 0);
};
AssignmentsContext.prototype.EOS = function () {
    return this.getToken(LnParser.EOS, 0);
};
AssignmentsContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
AssignmentsContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterAssignments(this);
    }
};
AssignmentsContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitAssignments(this);
    }
};
LnParser.AssignmentsContext = AssignmentsContext;
LnParser.prototype.assignments = function () {
    var localctx = new AssignmentsContext(this, this._ctx, this.state);
    this.enterRule(localctx, 46, LnParser.RULE_assignments);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 570;
        this.varn();
        this.state = 574;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 571;
            this.blank();
            this.state = 576;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 577;
        this.match(LnParser.EQUALS);
        this.state = 581;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 578;
            this.blank();
            this.state = 583;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 584;
        this.assignables();
        this.state = 585;
        this.match(LnParser.EOS);
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function BaseassignableContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_baseassignable;
    return this;
}
BaseassignableContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
BaseassignableContext.prototype.constructor = BaseassignableContext;
BaseassignableContext.prototype.METHODSEP = function () {
    return this.getToken(LnParser.METHODSEP, 0);
};
BaseassignableContext.prototype.VARNAME = function () {
    return this.getToken(LnParser.VARNAME, 0);
};
BaseassignableContext.prototype.constants = function () {
    return this.getTypedRuleContext(ConstantsContext, 0);
};
BaseassignableContext.prototype.functions = function () {
    return this.getTypedRuleContext(FunctionsContext, 0);
};
BaseassignableContext.prototype.fncall = function () {
    return this.getTypedRuleContext(FncallContext, 0);
};
BaseassignableContext.prototype.objectliterals = function () {
    return this.getTypedRuleContext(ObjectliteralsContext, 0);
};
BaseassignableContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterBaseassignable(this);
    }
};
BaseassignableContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitBaseassignable(this);
    }
};
LnParser.BaseassignableContext = BaseassignableContext;
LnParser.prototype.baseassignable = function () {
    var localctx = new BaseassignableContext(this, this._ctx, this.state);
    this.enterRule(localctx, 48, LnParser.RULE_baseassignable);
    try {
        this.state = 593;
        this._errHandler.sync(this);
        switch (this._input.LA(1)) {
            case LnParser.METHODSEP:
                this.enterOuterAlt(localctx, 1);
                this.state = 587;
                this.match(LnParser.METHODSEP);
                break;
            case LnParser.VARNAME:
                this.enterOuterAlt(localctx, 2);
                this.state = 588;
                this.match(LnParser.VARNAME);
                break;
            case LnParser.BOOLCONSTANT:
            case LnParser.STRINGCONSTANT:
            case LnParser.NUMBERCONSTANT:
                this.enterOuterAlt(localctx, 3);
                this.state = 589;
                this.constants();
                break;
            case LnParser.FN:
                this.enterOuterAlt(localctx, 4);
                this.state = 590;
                this.functions();
                break;
            case LnParser.OPENARGS:
                this.enterOuterAlt(localctx, 5);
                this.state = 591;
                this.fncall();
                break;
            case LnParser.NEW:
            case LnParser.OPENARRAY:
                this.enterOuterAlt(localctx, 6);
                this.state = 592;
                this.objectliterals();
                break;
            default:
                throw new antlr4.error.NoViableAltException(this);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function WithoperatorsContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_withoperators;
    return this;
}
WithoperatorsContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
WithoperatorsContext.prototype.constructor = WithoperatorsContext;
WithoperatorsContext.prototype.baseassignable = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BaseassignableContext);
    }
    else {
        return this.getTypedRuleContext(BaseassignableContext, i);
    }
};
WithoperatorsContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
WithoperatorsContext.prototype.operators = function () {
    return this.getTypedRuleContext(OperatorsContext, 0);
};
WithoperatorsContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterWithoperators(this);
    }
};
WithoperatorsContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitWithoperators(this);
    }
};
LnParser.WithoperatorsContext = WithoperatorsContext;
LnParser.prototype.withoperators = function () {
    var localctx = new WithoperatorsContext(this, this._ctx, this.state);
    this.enterRule(localctx, 50, LnParser.RULE_withoperators);
    try {
        this.state = 607;
        this._errHandler.sync(this);
        switch (this._input.LA(1)) {
            case LnParser.FN:
            case LnParser.BOOLCONSTANT:
            case LnParser.NEW:
            case LnParser.OPENARGS:
            case LnParser.OPENARRAY:
            case LnParser.METHODSEP:
            case LnParser.STRINGCONSTANT:
            case LnParser.NUMBERCONSTANT:
            case LnParser.VARNAME:
                this.enterOuterAlt(localctx, 1);
                this.state = 602;
                this._errHandler.sync(this);
                var _alt = 1;
                do {
                    switch (_alt) {
                        case 1:
                            this.state = 595;
                            this.baseassignable();
                            this.state = 599;
                            this._errHandler.sync(this);
                            var _alt = this._interp.adaptivePredict(this._input, 76, this._ctx);
                            while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
                                if (_alt === 1) {
                                    this.state = 596;
                                    this.blank();
                                }
                                this.state = 601;
                                this._errHandler.sync(this);
                                _alt = this._interp.adaptivePredict(this._input, 76, this._ctx);
                            }
                            break;
                        default:
                            throw new antlr4.error.NoViableAltException(this);
                    }
                    this.state = 604;
                    this._errHandler.sync(this);
                    _alt = this._interp.adaptivePredict(this._input, 77, this._ctx);
                } while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER);
                break;
            case LnParser.OPENGENERIC:
            case LnParser.CLOSEGENERIC:
            case LnParser.GLOBAL:
            case LnParser.DIRSEP:
            case LnParser.TYPESEP:
            case LnParser.GENERALOPERATORS:
                this.enterOuterAlt(localctx, 2);
                this.state = 606;
                this.operators();
                break;
            default:
                throw new antlr4.error.NoViableAltException(this);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function AssignablesContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_assignables;
    return this;
}
AssignablesContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
AssignablesContext.prototype.constructor = AssignablesContext;
AssignablesContext.prototype.withoperators = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(WithoperatorsContext);
    }
    else {
        return this.getTypedRuleContext(WithoperatorsContext, i);
    }
};
AssignablesContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
AssignablesContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterAssignables(this);
    }
};
AssignablesContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitAssignables(this);
    }
};
LnParser.AssignablesContext = AssignablesContext;
LnParser.prototype.assignables = function () {
    var localctx = new AssignablesContext(this, this._ctx, this.state);
    this.enterRule(localctx, 52, LnParser.RULE_assignables);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 609;
        this.withoperators();
        this.state = 619;
        this._errHandler.sync(this);
        var _alt = this._interp.adaptivePredict(this._input, 80, this._ctx);
        while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
            if (_alt === 1) {
                this.state = 613;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                    this.state = 610;
                    this.blank();
                    this.state = 615;
                    this._errHandler.sync(this);
                    _la = this._input.LA(1);
                }
                this.state = 616;
                this.withoperators();
            }
            this.state = 621;
            this._errHandler.sync(this);
            _alt = this._interp.adaptivePredict(this._input, 80, this._ctx);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function ObjectliteralsContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_objectliterals;
    return this;
}
ObjectliteralsContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
ObjectliteralsContext.prototype.constructor = ObjectliteralsContext;
ObjectliteralsContext.prototype.arrayliteral = function () {
    return this.getTypedRuleContext(ArrayliteralContext, 0);
};
ObjectliteralsContext.prototype.typeliteral = function () {
    return this.getTypedRuleContext(TypeliteralContext, 0);
};
ObjectliteralsContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterObjectliterals(this);
    }
};
ObjectliteralsContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitObjectliterals(this);
    }
};
LnParser.ObjectliteralsContext = ObjectliteralsContext;
LnParser.prototype.objectliterals = function () {
    var localctx = new ObjectliteralsContext(this, this._ctx, this.state);
    this.enterRule(localctx, 54, LnParser.RULE_objectliterals);
    try {
        this.state = 624;
        this._errHandler.sync(this);
        var la_ = this._interp.adaptivePredict(this._input, 81, this._ctx);
        switch (la_) {
            case 1:
                this.enterOuterAlt(localctx, 1);
                this.state = 622;
                this.arrayliteral();
                break;
            case 2:
                this.enterOuterAlt(localctx, 2);
                this.state = 623;
                this.typeliteral();
                break;
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function AssignablelistContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_assignablelist;
    return this;
}
AssignablelistContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
AssignablelistContext.prototype.constructor = AssignablelistContext;
AssignablelistContext.prototype.assignables = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(AssignablesContext);
    }
    else {
        return this.getTypedRuleContext(AssignablesContext, i);
    }
};
AssignablelistContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
AssignablelistContext.prototype.SEP = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.SEP);
    }
    else {
        return this.getToken(LnParser.SEP, i);
    }
};
AssignablelistContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterAssignablelist(this);
    }
};
AssignablelistContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitAssignablelist(this);
    }
};
LnParser.AssignablelistContext = AssignablelistContext;
LnParser.prototype.assignablelist = function () {
    var localctx = new AssignablelistContext(this, this._ctx, this.state);
    this.enterRule(localctx, 56, LnParser.RULE_assignablelist);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 626;
        this.assignables();
        this.state = 630;
        this._errHandler.sync(this);
        var _alt = this._interp.adaptivePredict(this._input, 82, this._ctx);
        while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
            if (_alt === 1) {
                this.state = 627;
                this.blank();
            }
            this.state = 632;
            this._errHandler.sync(this);
            _alt = this._interp.adaptivePredict(this._input, 82, this._ctx);
        }
        this.state = 649;
        this._errHandler.sync(this);
        var _alt = this._interp.adaptivePredict(this._input, 85, this._ctx);
        while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
            if (_alt === 1) {
                this.state = 633;
                this.match(LnParser.SEP);
                this.state = 637;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                    this.state = 634;
                    this.blank();
                    this.state = 639;
                    this._errHandler.sync(this);
                    _la = this._input.LA(1);
                }
                this.state = 640;
                this.assignables();
                this.state = 644;
                this._errHandler.sync(this);
                var _alt = this._interp.adaptivePredict(this._input, 84, this._ctx);
                while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
                    if (_alt === 1) {
                        this.state = 641;
                        this.blank();
                    }
                    this.state = 646;
                    this._errHandler.sync(this);
                    _alt = this._interp.adaptivePredict(this._input, 84, this._ctx);
                }
            }
            this.state = 651;
            this._errHandler.sync(this);
            _alt = this._interp.adaptivePredict(this._input, 85, this._ctx);
        }
        this.state = 653;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        if (_la === LnParser.SEP) {
            this.state = 652;
            this.match(LnParser.SEP);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function TypeassignlistContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_typeassignlist;
    return this;
}
TypeassignlistContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
TypeassignlistContext.prototype.constructor = TypeassignlistContext;
TypeassignlistContext.prototype.VARNAME = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.VARNAME);
    }
    else {
        return this.getToken(LnParser.VARNAME, i);
    }
};
TypeassignlistContext.prototype.TYPESEP = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.TYPESEP);
    }
    else {
        return this.getToken(LnParser.TYPESEP, i);
    }
};
TypeassignlistContext.prototype.assignables = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(AssignablesContext);
    }
    else {
        return this.getTypedRuleContext(AssignablesContext, i);
    }
};
TypeassignlistContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
TypeassignlistContext.prototype.SEP = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.SEP);
    }
    else {
        return this.getToken(LnParser.SEP, i);
    }
};
TypeassignlistContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterTypeassignlist(this);
    }
};
TypeassignlistContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitTypeassignlist(this);
    }
};
LnParser.TypeassignlistContext = TypeassignlistContext;
LnParser.prototype.typeassignlist = function () {
    var localctx = new TypeassignlistContext(this, this._ctx, this.state);
    this.enterRule(localctx, 58, LnParser.RULE_typeassignlist);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 655;
        this.match(LnParser.VARNAME);
        this.state = 659;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 656;
            this.blank();
            this.state = 661;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 662;
        this.match(LnParser.TYPESEP);
        this.state = 666;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 663;
            this.blank();
            this.state = 668;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 669;
        this.assignables();
        this.state = 673;
        this._errHandler.sync(this);
        var _alt = this._interp.adaptivePredict(this._input, 89, this._ctx);
        while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
            if (_alt === 1) {
                this.state = 670;
                this.blank();
            }
            this.state = 675;
            this._errHandler.sync(this);
            _alt = this._interp.adaptivePredict(this._input, 89, this._ctx);
        }
        this.state = 706;
        this._errHandler.sync(this);
        var _alt = this._interp.adaptivePredict(this._input, 94, this._ctx);
        while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
            if (_alt === 1) {
                this.state = 676;
                this.match(LnParser.SEP);
                this.state = 680;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                    this.state = 677;
                    this.blank();
                    this.state = 682;
                    this._errHandler.sync(this);
                    _la = this._input.LA(1);
                }
                this.state = 683;
                this.match(LnParser.VARNAME);
                this.state = 687;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                    this.state = 684;
                    this.blank();
                    this.state = 689;
                    this._errHandler.sync(this);
                    _la = this._input.LA(1);
                }
                this.state = 690;
                this.match(LnParser.TYPESEP);
                this.state = 694;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                    this.state = 691;
                    this.blank();
                    this.state = 696;
                    this._errHandler.sync(this);
                    _la = this._input.LA(1);
                }
                this.state = 697;
                this.assignables();
                this.state = 701;
                this._errHandler.sync(this);
                var _alt = this._interp.adaptivePredict(this._input, 93, this._ctx);
                while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
                    if (_alt === 1) {
                        this.state = 698;
                        this.blank();
                    }
                    this.state = 703;
                    this._errHandler.sync(this);
                    _alt = this._interp.adaptivePredict(this._input, 93, this._ctx);
                }
            }
            this.state = 708;
            this._errHandler.sync(this);
            _alt = this._interp.adaptivePredict(this._input, 94, this._ctx);
        }
        this.state = 710;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        if (_la === LnParser.SEP) {
            this.state = 709;
            this.match(LnParser.SEP);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function LiteraldecContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_literaldec;
    return this;
}
LiteraldecContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
LiteraldecContext.prototype.constructor = LiteraldecContext;
LiteraldecContext.prototype.NEW = function () {
    return this.getToken(LnParser.NEW, 0);
};
LiteraldecContext.prototype.fulltypename = function () {
    return this.getTypedRuleContext(FulltypenameContext, 0);
};
LiteraldecContext.prototype.WS = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.WS);
    }
    else {
        return this.getToken(LnParser.WS, i);
    }
};
LiteraldecContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterLiteraldec(this);
    }
};
LiteraldecContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitLiteraldec(this);
    }
};
LnParser.LiteraldecContext = LiteraldecContext;
LnParser.prototype.literaldec = function () {
    var localctx = new LiteraldecContext(this, this._ctx, this.state);
    this.enterRule(localctx, 60, LnParser.RULE_literaldec);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 712;
        this.match(LnParser.NEW);
        this.state = 716;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.WS) {
            this.state = 713;
            this.match(LnParser.WS);
            this.state = 718;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 719;
        this.fulltypename();
        this.state = 723;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.WS) {
            this.state = 720;
            this.match(LnParser.WS);
            this.state = 725;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function ArraybaseContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_arraybase;
    return this;
}
ArraybaseContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
ArraybaseContext.prototype.constructor = ArraybaseContext;
ArraybaseContext.prototype.OPENARRAY = function () {
    return this.getToken(LnParser.OPENARRAY, 0);
};
ArraybaseContext.prototype.CLOSEARRAY = function () {
    return this.getToken(LnParser.CLOSEARRAY, 0);
};
ArraybaseContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
ArraybaseContext.prototype.assignablelist = function () {
    return this.getTypedRuleContext(AssignablelistContext, 0);
};
ArraybaseContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterArraybase(this);
    }
};
ArraybaseContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitArraybase(this);
    }
};
LnParser.ArraybaseContext = ArraybaseContext;
LnParser.prototype.arraybase = function () {
    var localctx = new ArraybaseContext(this, this._ctx, this.state);
    this.enterRule(localctx, 62, LnParser.RULE_arraybase);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 726;
        this.match(LnParser.OPENARRAY);
        this.state = 730;
        this._errHandler.sync(this);
        var _alt = this._interp.adaptivePredict(this._input, 98, this._ctx);
        while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
            if (_alt === 1) {
                this.state = 727;
                this.blank();
            }
            this.state = 732;
            this._errHandler.sync(this);
            _alt = this._interp.adaptivePredict(this._input, 98, this._ctx);
        }
        this.state = 734;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        if ((((_la) & ~0x1f) == 0 && ((1 << _la) & ((1 << LnParser.FN) | (1 << LnParser.BOOLCONSTANT) | (1 << LnParser.NEW) | (1 << LnParser.OPENARGS) | (1 << LnParser.OPENGENERIC) | (1 << LnParser.CLOSEGENERIC) | (1 << LnParser.OPENARRAY) | (1 << LnParser.METHODSEP))) !== 0) || ((((_la - 32)) & ~0x1f) == 0 && ((1 << (_la - 32)) & ((1 << (LnParser.GLOBAL - 32)) | (1 << (LnParser.DIRSEP - 32)) | (1 << (LnParser.TYPESEP - 32)) | (1 << (LnParser.STRINGCONSTANT - 32)) | (1 << (LnParser.NUMBERCONSTANT - 32)) | (1 << (LnParser.GENERALOPERATORS - 32)) | (1 << (LnParser.VARNAME - 32)))) !== 0)) {
            this.state = 733;
            this.assignablelist();
        }
        this.state = 739;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 736;
            this.blank();
            this.state = 741;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 742;
        this.match(LnParser.CLOSEARRAY);
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function ArrayliteralContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_arrayliteral;
    return this;
}
ArrayliteralContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
ArrayliteralContext.prototype.constructor = ArrayliteralContext;
ArrayliteralContext.prototype.arraybase = function () {
    return this.getTypedRuleContext(ArraybaseContext, 0);
};
ArrayliteralContext.prototype.literaldec = function () {
    return this.getTypedRuleContext(LiteraldecContext, 0);
};
ArrayliteralContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterArrayliteral(this);
    }
};
ArrayliteralContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitArrayliteral(this);
    }
};
LnParser.ArrayliteralContext = ArrayliteralContext;
LnParser.prototype.arrayliteral = function () {
    var localctx = new ArrayliteralContext(this, this._ctx, this.state);
    this.enterRule(localctx, 64, LnParser.RULE_arrayliteral);
    try {
        this.state = 748;
        this._errHandler.sync(this);
        switch (this._input.LA(1)) {
            case LnParser.OPENARRAY:
                this.enterOuterAlt(localctx, 1);
                this.state = 744;
                this.arraybase();
                break;
            case LnParser.NEW:
                this.enterOuterAlt(localctx, 2);
                this.state = 745;
                this.literaldec();
                this.state = 746;
                this.arraybase();
                break;
            default:
                throw new antlr4.error.NoViableAltException(this);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function TypebaseContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_typebase;
    return this;
}
TypebaseContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
TypebaseContext.prototype.constructor = TypebaseContext;
TypebaseContext.prototype.OPENBODY = function () {
    return this.getToken(LnParser.OPENBODY, 0);
};
TypebaseContext.prototype.typeassignlist = function () {
    return this.getTypedRuleContext(TypeassignlistContext, 0);
};
TypebaseContext.prototype.CLOSEBODY = function () {
    return this.getToken(LnParser.CLOSEBODY, 0);
};
TypebaseContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
TypebaseContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterTypebase(this);
    }
};
TypebaseContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitTypebase(this);
    }
};
LnParser.TypebaseContext = TypebaseContext;
LnParser.prototype.typebase = function () {
    var localctx = new TypebaseContext(this, this._ctx, this.state);
    this.enterRule(localctx, 66, LnParser.RULE_typebase);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 750;
        this.match(LnParser.OPENBODY);
        this.state = 754;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 751;
            this.blank();
            this.state = 756;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 757;
        this.typeassignlist();
        this.state = 761;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 758;
            this.blank();
            this.state = 763;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 764;
        this.match(LnParser.CLOSEBODY);
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function TypeliteralContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_typeliteral;
    return this;
}
TypeliteralContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
TypeliteralContext.prototype.constructor = TypeliteralContext;
TypeliteralContext.prototype.literaldec = function () {
    return this.getTypedRuleContext(LiteraldecContext, 0);
};
TypeliteralContext.prototype.typebase = function () {
    return this.getTypedRuleContext(TypebaseContext, 0);
};
TypeliteralContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterTypeliteral(this);
    }
};
TypeliteralContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitTypeliteral(this);
    }
};
LnParser.TypeliteralContext = TypeliteralContext;
LnParser.prototype.typeliteral = function () {
    var localctx = new TypeliteralContext(this, this._ctx, this.state);
    this.enterRule(localctx, 68, LnParser.RULE_typeliteral);
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 766;
        this.literaldec();
        this.state = 767;
        this.typebase();
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function FncallContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_fncall;
    return this;
}
FncallContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
FncallContext.prototype.constructor = FncallContext;
FncallContext.prototype.OPENARGS = function () {
    return this.getToken(LnParser.OPENARGS, 0);
};
FncallContext.prototype.CLOSEARGS = function () {
    return this.getToken(LnParser.CLOSEARGS, 0);
};
FncallContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
FncallContext.prototype.assignablelist = function () {
    return this.getTypedRuleContext(AssignablelistContext, 0);
};
FncallContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterFncall(this);
    }
};
FncallContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitFncall(this);
    }
};
LnParser.FncallContext = FncallContext;
LnParser.prototype.fncall = function () {
    var localctx = new FncallContext(this, this._ctx, this.state);
    this.enterRule(localctx, 70, LnParser.RULE_fncall);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 769;
        this.match(LnParser.OPENARGS);
        this.state = 773;
        this._errHandler.sync(this);
        var _alt = this._interp.adaptivePredict(this._input, 104, this._ctx);
        while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
            if (_alt === 1) {
                this.state = 770;
                this.blank();
            }
            this.state = 775;
            this._errHandler.sync(this);
            _alt = this._interp.adaptivePredict(this._input, 104, this._ctx);
        }
        this.state = 777;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        if ((((_la) & ~0x1f) == 0 && ((1 << _la) & ((1 << LnParser.FN) | (1 << LnParser.BOOLCONSTANT) | (1 << LnParser.NEW) | (1 << LnParser.OPENARGS) | (1 << LnParser.OPENGENERIC) | (1 << LnParser.CLOSEGENERIC) | (1 << LnParser.OPENARRAY) | (1 << LnParser.METHODSEP))) !== 0) || ((((_la - 32)) & ~0x1f) == 0 && ((1 << (_la - 32)) & ((1 << (LnParser.GLOBAL - 32)) | (1 << (LnParser.DIRSEP - 32)) | (1 << (LnParser.TYPESEP - 32)) | (1 << (LnParser.STRINGCONSTANT - 32)) | (1 << (LnParser.NUMBERCONSTANT - 32)) | (1 << (LnParser.GENERALOPERATORS - 32)) | (1 << (LnParser.VARNAME - 32)))) !== 0)) {
            this.state = 776;
            this.assignablelist();
        }
        this.state = 782;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 779;
            this.blank();
            this.state = 784;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 785;
        this.match(LnParser.CLOSEARGS);
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function ExitsContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_exits;
    return this;
}
ExitsContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
ExitsContext.prototype.constructor = ExitsContext;
ExitsContext.prototype.RETURN = function () {
    return this.getToken(LnParser.RETURN, 0);
};
ExitsContext.prototype.EOS = function () {
    return this.getToken(LnParser.EOS, 0);
};
ExitsContext.prototype.assignables = function () {
    return this.getTypedRuleContext(AssignablesContext, 0);
};
ExitsContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
ExitsContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterExits(this);
    }
};
ExitsContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitExits(this);
    }
};
LnParser.ExitsContext = ExitsContext;
LnParser.prototype.exits = function () {
    var localctx = new ExitsContext(this, this._ctx, this.state);
    this.enterRule(localctx, 72, LnParser.RULE_exits);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 787;
        this.match(LnParser.RETURN);
        this.state = 801;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        if ((((_la) & ~0x1f) == 0 && ((1 << _la) & ((1 << LnParser.FN) | (1 << LnParser.BOOLCONSTANT) | (1 << LnParser.NEW) | (1 << LnParser.OPENARGS) | (1 << LnParser.OPENGENERIC) | (1 << LnParser.CLOSEGENERIC) | (1 << LnParser.OPENARRAY) | (1 << LnParser.METHODSEP))) !== 0) || ((((_la - 32)) & ~0x1f) == 0 && ((1 << (_la - 32)) & ((1 << (LnParser.GLOBAL - 32)) | (1 << (LnParser.DIRSEP - 32)) | (1 << (LnParser.TYPESEP - 32)) | (1 << (LnParser.NEWLINE - 32)) | (1 << (LnParser.WS - 32)) | (1 << (LnParser.STRINGCONSTANT - 32)) | (1 << (LnParser.NUMBERCONSTANT - 32)) | (1 << (LnParser.GENERALOPERATORS - 32)) | (1 << (LnParser.VARNAME - 32)))) !== 0)) {
            this.state = 791;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                this.state = 788;
                this.blank();
                this.state = 793;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
            }
            this.state = 794;
            this.assignables();
            this.state = 798;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                this.state = 795;
                this.blank();
                this.state = 800;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
            }
        }
        this.state = 803;
        this.match(LnParser.EOS);
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function EmitsContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_emits;
    return this;
}
EmitsContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
EmitsContext.prototype.constructor = EmitsContext;
EmitsContext.prototype.EMIT = function () {
    return this.getToken(LnParser.EMIT, 0);
};
EmitsContext.prototype.eventref = function () {
    return this.getTypedRuleContext(EventrefContext, 0);
};
EmitsContext.prototype.EOS = function () {
    return this.getToken(LnParser.EOS, 0);
};
EmitsContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
EmitsContext.prototype.assignables = function () {
    return this.getTypedRuleContext(AssignablesContext, 0);
};
EmitsContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterEmits(this);
    }
};
EmitsContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitEmits(this);
    }
};
LnParser.EmitsContext = EmitsContext;
LnParser.prototype.emits = function () {
    var localctx = new EmitsContext(this, this._ctx, this.state);
    this.enterRule(localctx, 74, LnParser.RULE_emits);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 805;
        this.match(LnParser.EMIT);
        this.state = 809;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 806;
            this.blank();
            this.state = 811;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 812;
        this.eventref();
        this.state = 826;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        if ((((_la) & ~0x1f) == 0 && ((1 << _la) & ((1 << LnParser.FN) | (1 << LnParser.BOOLCONSTANT) | (1 << LnParser.NEW) | (1 << LnParser.OPENARGS) | (1 << LnParser.OPENGENERIC) | (1 << LnParser.CLOSEGENERIC) | (1 << LnParser.OPENARRAY) | (1 << LnParser.METHODSEP))) !== 0) || ((((_la - 32)) & ~0x1f) == 0 && ((1 << (_la - 32)) & ((1 << (LnParser.GLOBAL - 32)) | (1 << (LnParser.DIRSEP - 32)) | (1 << (LnParser.TYPESEP - 32)) | (1 << (LnParser.NEWLINE - 32)) | (1 << (LnParser.WS - 32)) | (1 << (LnParser.STRINGCONSTANT - 32)) | (1 << (LnParser.NUMBERCONSTANT - 32)) | (1 << (LnParser.GENERALOPERATORS - 32)) | (1 << (LnParser.VARNAME - 32)))) !== 0)) {
            this.state = 816;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                this.state = 813;
                this.blank();
                this.state = 818;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
            }
            this.state = 819;
            this.assignables();
            this.state = 823;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                this.state = 820;
                this.blank();
                this.state = 825;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
            }
        }
        this.state = 828;
        this.match(LnParser.EOS);
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function ConditionalsContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_conditionals;
    return this;
}
ConditionalsContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
ConditionalsContext.prototype.constructor = ConditionalsContext;
ConditionalsContext.prototype.IF = function () {
    return this.getToken(LnParser.IF, 0);
};
ConditionalsContext.prototype.assignables = function () {
    return this.getTypedRuleContext(AssignablesContext, 0);
};
ConditionalsContext.prototype.blocklikes = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlocklikesContext);
    }
    else {
        return this.getTypedRuleContext(BlocklikesContext, i);
    }
};
ConditionalsContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
ConditionalsContext.prototype.ELSE = function () {
    return this.getToken(LnParser.ELSE, 0);
};
ConditionalsContext.prototype.conditionals = function () {
    return this.getTypedRuleContext(ConditionalsContext, 0);
};
ConditionalsContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterConditionals(this);
    }
};
ConditionalsContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitConditionals(this);
    }
};
LnParser.ConditionalsContext = ConditionalsContext;
LnParser.prototype.conditionals = function () {
    var localctx = new ConditionalsContext(this, this._ctx, this.state);
    this.enterRule(localctx, 76, LnParser.RULE_conditionals);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 830;
        this.match(LnParser.IF);
        this.state = 834;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 831;
            this.blank();
            this.state = 836;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 837;
        this.assignables();
        this.state = 841;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 838;
            this.blank();
            this.state = 843;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 844;
        this.blocklikes();
        this.state = 862;
        this._errHandler.sync(this);
        var la_ = this._interp.adaptivePredict(this._input, 119, this._ctx);
        if (la_ === 1) {
            this.state = 848;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                this.state = 845;
                this.blank();
                this.state = 850;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
            }
            this.state = 851;
            this.match(LnParser.ELSE);
            this.state = 855;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                this.state = 852;
                this.blank();
                this.state = 857;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
            }
            this.state = 860;
            this._errHandler.sync(this);
            switch (this._input.LA(1)) {
                case LnParser.IF:
                    this.state = 858;
                    this.conditionals();
                    break;
                case LnParser.FN:
                case LnParser.OPENBODY:
                case LnParser.VARNAME:
                    this.state = 859;
                    this.blocklikes();
                    break;
                default:
                    throw new antlr4.error.NoViableAltException(this);
            }
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function BlocklikesContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_blocklikes;
    return this;
}
BlocklikesContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
BlocklikesContext.prototype.constructor = BlocklikesContext;
BlocklikesContext.prototype.functions = function () {
    return this.getTypedRuleContext(FunctionsContext, 0);
};
BlocklikesContext.prototype.functionbody = function () {
    return this.getTypedRuleContext(FunctionbodyContext, 0);
};
BlocklikesContext.prototype.eventref = function () {
    return this.getTypedRuleContext(EventrefContext, 0);
};
BlocklikesContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterBlocklikes(this);
    }
};
BlocklikesContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitBlocklikes(this);
    }
};
LnParser.BlocklikesContext = BlocklikesContext;
LnParser.prototype.blocklikes = function () {
    var localctx = new BlocklikesContext(this, this._ctx, this.state);
    this.enterRule(localctx, 78, LnParser.RULE_blocklikes);
    try {
        this.state = 867;
        this._errHandler.sync(this);
        switch (this._input.LA(1)) {
            case LnParser.FN:
                this.enterOuterAlt(localctx, 1);
                this.state = 864;
                this.functions();
                break;
            case LnParser.OPENBODY:
                this.enterOuterAlt(localctx, 2);
                this.state = 865;
                this.functionbody();
                break;
            case LnParser.VARNAME:
                this.enterOuterAlt(localctx, 3);
                this.state = 866;
                this.eventref();
                break;
            default:
                throw new antlr4.error.NoViableAltException(this);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function ConstantsContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_constants;
    return this;
}
ConstantsContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
ConstantsContext.prototype.constructor = ConstantsContext;
ConstantsContext.prototype.NUMBERCONSTANT = function () {
    return this.getToken(LnParser.NUMBERCONSTANT, 0);
};
ConstantsContext.prototype.STRINGCONSTANT = function () {
    return this.getToken(LnParser.STRINGCONSTANT, 0);
};
ConstantsContext.prototype.BOOLCONSTANT = function () {
    return this.getToken(LnParser.BOOLCONSTANT, 0);
};
ConstantsContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterConstants(this);
    }
};
ConstantsContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitConstants(this);
    }
};
LnParser.ConstantsContext = ConstantsContext;
LnParser.prototype.constants = function () {
    var localctx = new ConstantsContext(this, this._ctx, this.state);
    this.enterRule(localctx, 80, LnParser.RULE_constants);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 869;
        _la = this._input.LA(1);
        if (!(((((_la - 13)) & ~0x1f) == 0 && ((1 << (_la - 13)) & ((1 << (LnParser.BOOLCONSTANT - 13)) | (1 << (LnParser.STRINGCONSTANT - 13)) | (1 << (LnParser.NUMBERCONSTANT - 13)))) !== 0))) {
            this._errHandler.recoverInline(this);
        }
        else {
            this._errHandler.reportMatch(this);
            this.consume();
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function OperatorsContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_operators;
    return this;
}
OperatorsContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
OperatorsContext.prototype.constructor = OperatorsContext;
OperatorsContext.prototype.GENERALOPERATORS = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.GENERALOPERATORS);
    }
    else {
        return this.getToken(LnParser.GENERALOPERATORS, i);
    }
};
OperatorsContext.prototype.TYPESEP = function () {
    return this.getToken(LnParser.TYPESEP, 0);
};
OperatorsContext.prototype.OPENGENERIC = function () {
    return this.getToken(LnParser.OPENGENERIC, 0);
};
OperatorsContext.prototype.GLOBAL = function () {
    return this.getToken(LnParser.GLOBAL, 0);
};
OperatorsContext.prototype.DIRSEP = function () {
    return this.getToken(LnParser.DIRSEP, 0);
};
OperatorsContext.prototype.CLOSEGENERIC = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.CLOSEGENERIC);
    }
    else {
        return this.getToken(LnParser.CLOSEGENERIC, i);
    }
};
OperatorsContext.prototype.EQUALS = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.EQUALS);
    }
    else {
        return this.getToken(LnParser.EQUALS, i);
    }
};
OperatorsContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterOperators(this);
    }
};
OperatorsContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitOperators(this);
    }
};
LnParser.OperatorsContext = OperatorsContext;
LnParser.prototype.operators = function () {
    var localctx = new OperatorsContext(this, this._ctx, this.state);
    this.enterRule(localctx, 82, LnParser.RULE_operators);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 899;
        this._errHandler.sync(this);
        switch (this._input.LA(1)) {
            case LnParser.GENERALOPERATORS:
                this.state = 871;
                this.match(LnParser.GENERALOPERATORS);
                break;
            case LnParser.TYPESEP:
                this.state = 872;
                this.match(LnParser.TYPESEP);
                break;
            case LnParser.OPENGENERIC:
                this.state = 873;
                this.match(LnParser.OPENGENERIC);
                break;
            case LnParser.CLOSEGENERIC:
                this.state = 875;
                this._errHandler.sync(this);
                var _alt = 1;
                do {
                    switch (_alt) {
                        case 1:
                            this.state = 874;
                            this.match(LnParser.CLOSEGENERIC);
                            break;
                        default:
                            throw new antlr4.error.NoViableAltException(this);
                    }
                    this.state = 877;
                    this._errHandler.sync(this);
                    _alt = this._interp.adaptivePredict(this._input, 121, this._ctx);
                } while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER);
                this.state = 895;
                this._errHandler.sync(this);
                var la_ = this._interp.adaptivePredict(this._input, 125, this._ctx);
                if (la_ === 1) {
                    this.state = 880;
                    this._errHandler.sync(this);
                    _la = this._input.LA(1);
                    do {
                        this.state = 879;
                        this.match(LnParser.EQUALS);
                        this.state = 882;
                        this._errHandler.sync(this);
                        _la = this._input.LA(1);
                    } while (_la === LnParser.EQUALS);
                    this.state = 887;
                    this._errHandler.sync(this);
                    var _alt = this._interp.adaptivePredict(this._input, 123, this._ctx);
                    while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
                        if (_alt === 1) {
                            this.state = 884;
                            this.match(LnParser.GENERALOPERATORS);
                        }
                        this.state = 889;
                        this._errHandler.sync(this);
                        _alt = this._interp.adaptivePredict(this._input, 123, this._ctx);
                    }
                }
                else if (la_ === 2) {
                    this.state = 891;
                    this._errHandler.sync(this);
                    var _alt = 1;
                    do {
                        switch (_alt) {
                            case 1:
                                this.state = 890;
                                this.match(LnParser.GENERALOPERATORS);
                                break;
                            default:
                                throw new antlr4.error.NoViableAltException(this);
                        }
                        this.state = 893;
                        this._errHandler.sync(this);
                        _alt = this._interp.adaptivePredict(this._input, 124, this._ctx);
                    } while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER);
                }
                break;
            case LnParser.GLOBAL:
                this.state = 897;
                this.match(LnParser.GLOBAL);
                break;
            case LnParser.DIRSEP:
                this.state = 898;
                this.match(LnParser.DIRSEP);
                break;
            default:
                throw new antlr4.error.NoViableAltException(this);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function OperatormappingContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_operatormapping;
    return this;
}
OperatormappingContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
OperatormappingContext.prototype.constructor = OperatormappingContext;
OperatormappingContext.prototype.WS = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.WS);
    }
    else {
        return this.getToken(LnParser.WS, i);
    }
};
OperatormappingContext.prototype.PREFIX = function () {
    return this.getToken(LnParser.PREFIX, 0);
};
OperatormappingContext.prototype.INFIX = function () {
    return this.getToken(LnParser.INFIX, 0);
};
OperatormappingContext.prototype.fntoop = function () {
    return this.getTypedRuleContext(FntoopContext, 0);
};
OperatormappingContext.prototype.opprecedence = function () {
    return this.getTypedRuleContext(OpprecedenceContext, 0);
};
OperatormappingContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterOperatormapping(this);
    }
};
OperatormappingContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitOperatormapping(this);
    }
};
LnParser.OperatormappingContext = OperatormappingContext;
LnParser.prototype.operatormapping = function () {
    var localctx = new OperatormappingContext(this, this._ctx, this.state);
    this.enterRule(localctx, 84, LnParser.RULE_operatormapping);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 901;
        _la = this._input.LA(1);
        if (!(_la === LnParser.PREFIX || _la === LnParser.INFIX)) {
            this._errHandler.recoverInline(this);
        }
        else {
            this._errHandler.reportMatch(this);
            this.consume();
        }
        this.state = 902;
        this.match(LnParser.WS);
        this.state = 911;
        this._errHandler.sync(this);
        switch (this._input.LA(1)) {
            case LnParser.VARNAME:
                this.state = 903;
                this.fntoop();
                this.state = 904;
                this.match(LnParser.WS);
                this.state = 905;
                this.opprecedence();
                break;
            case LnParser.PRECEDENCE:
                this.state = 907;
                this.opprecedence();
                this.state = 908;
                this.match(LnParser.WS);
                this.state = 909;
                this.fntoop();
                break;
            default:
                throw new antlr4.error.NoViableAltException(this);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function FntoopContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_fntoop;
    return this;
}
FntoopContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
FntoopContext.prototype.constructor = FntoopContext;
FntoopContext.prototype.eventref = function () {
    return this.getTypedRuleContext(EventrefContext, 0);
};
FntoopContext.prototype.WS = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.WS);
    }
    else {
        return this.getToken(LnParser.WS, i);
    }
};
FntoopContext.prototype.AS = function () {
    return this.getToken(LnParser.AS, 0);
};
FntoopContext.prototype.operators = function () {
    return this.getTypedRuleContext(OperatorsContext, 0);
};
FntoopContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterFntoop(this);
    }
};
FntoopContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitFntoop(this);
    }
};
LnParser.FntoopContext = FntoopContext;
LnParser.prototype.fntoop = function () {
    var localctx = new FntoopContext(this, this._ctx, this.state);
    this.enterRule(localctx, 86, LnParser.RULE_fntoop);
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 913;
        this.eventref();
        this.state = 914;
        this.match(LnParser.WS);
        this.state = 915;
        this.match(LnParser.AS);
        this.state = 916;
        this.match(LnParser.WS);
        this.state = 917;
        this.operators();
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function OpprecedenceContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_opprecedence;
    return this;
}
OpprecedenceContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
OpprecedenceContext.prototype.constructor = OpprecedenceContext;
OpprecedenceContext.prototype.PRECEDENCE = function () {
    return this.getToken(LnParser.PRECEDENCE, 0);
};
OpprecedenceContext.prototype.WS = function () {
    return this.getToken(LnParser.WS, 0);
};
OpprecedenceContext.prototype.NUMBERCONSTANT = function () {
    return this.getToken(LnParser.NUMBERCONSTANT, 0);
};
OpprecedenceContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterOpprecedence(this);
    }
};
OpprecedenceContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitOpprecedence(this);
    }
};
LnParser.OpprecedenceContext = OpprecedenceContext;
LnParser.prototype.opprecedence = function () {
    var localctx = new OpprecedenceContext(this, this._ctx, this.state);
    this.enterRule(localctx, 88, LnParser.RULE_opprecedence);
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 919;
        this.match(LnParser.PRECEDENCE);
        this.state = 920;
        this.match(LnParser.WS);
        this.state = 921;
        this.match(LnParser.NUMBERCONSTANT);
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function EventsContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_events;
    return this;
}
EventsContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
EventsContext.prototype.constructor = EventsContext;
EventsContext.prototype.EVENT = function () {
    return this.getToken(LnParser.EVENT, 0);
};
EventsContext.prototype.VARNAME = function () {
    return this.getToken(LnParser.VARNAME, 0);
};
EventsContext.prototype.TYPESEP = function () {
    return this.getToken(LnParser.TYPESEP, 0);
};
EventsContext.prototype.fulltypename = function () {
    return this.getTypedRuleContext(FulltypenameContext, 0);
};
EventsContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
EventsContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterEvents(this);
    }
};
EventsContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitEvents(this);
    }
};
LnParser.EventsContext = EventsContext;
LnParser.prototype.events = function () {
    var localctx = new EventsContext(this, this._ctx, this.state);
    this.enterRule(localctx, 90, LnParser.RULE_events);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 923;
        this.match(LnParser.EVENT);
        this.state = 927;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 924;
            this.blank();
            this.state = 929;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 930;
        this.match(LnParser.VARNAME);
        this.state = 934;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 931;
            this.blank();
            this.state = 936;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 937;
        this.match(LnParser.TYPESEP);
        this.state = 941;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 938;
            this.blank();
            this.state = 943;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 944;
        this.fulltypename();
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function EventrefContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_eventref;
    return this;
}
EventrefContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
EventrefContext.prototype.constructor = EventrefContext;
EventrefContext.prototype.typename = function () {
    return this.getTypedRuleContext(TypenameContext, 0);
};
EventrefContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterEventref(this);
    }
};
EventrefContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitEventref(this);
    }
};
LnParser.EventrefContext = EventrefContext;
LnParser.prototype.eventref = function () {
    var localctx = new EventrefContext(this, this._ctx, this.state);
    this.enterRule(localctx, 92, LnParser.RULE_eventref);
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 946;
        this.typename();
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function HandlersContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_handlers;
    return this;
}
HandlersContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
HandlersContext.prototype.constructor = HandlersContext;
HandlersContext.prototype.ON = function () {
    return this.getToken(LnParser.ON, 0);
};
HandlersContext.prototype.eventref = function () {
    return this.getTypedRuleContext(EventrefContext, 0);
};
HandlersContext.prototype.functions = function () {
    return this.getTypedRuleContext(FunctionsContext, 0);
};
HandlersContext.prototype.typename = function () {
    return this.getTypedRuleContext(TypenameContext, 0);
};
HandlersContext.prototype.functionbody = function () {
    return this.getTypedRuleContext(FunctionbodyContext, 0);
};
HandlersContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
HandlersContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterHandlers(this);
    }
};
HandlersContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitHandlers(this);
    }
};
LnParser.HandlersContext = HandlersContext;
LnParser.prototype.handlers = function () {
    var localctx = new HandlersContext(this, this._ctx, this.state);
    this.enterRule(localctx, 94, LnParser.RULE_handlers);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 948;
        this.match(LnParser.ON);
        this.state = 950;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        do {
            this.state = 949;
            this.blank();
            this.state = 952;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        } while (_la === LnParser.NEWLINE || _la === LnParser.WS);
        this.state = 954;
        this.eventref();
        this.state = 956;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        do {
            this.state = 955;
            this.blank();
            this.state = 958;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        } while (_la === LnParser.NEWLINE || _la === LnParser.WS);
        this.state = 963;
        this._errHandler.sync(this);
        switch (this._input.LA(1)) {
            case LnParser.FN:
                this.state = 960;
                this.functions();
                break;
            case LnParser.VARNAME:
                this.state = 961;
                this.typename();
                break;
            case LnParser.OPENBODY:
                this.state = 962;
                this.functionbody();
                break;
            default:
                throw new antlr4.error.NoViableAltException(this);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function InterfacesContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_interfaces;
    return this;
}
InterfacesContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
InterfacesContext.prototype.constructor = InterfacesContext;
InterfacesContext.prototype.INTERFACE = function () {
    return this.getToken(LnParser.INTERFACE, 0);
};
InterfacesContext.prototype.VARNAME = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.VARNAME);
    }
    else {
        return this.getToken(LnParser.VARNAME, i);
    }
};
InterfacesContext.prototype.interfacebody = function () {
    return this.getTypedRuleContext(InterfacebodyContext, 0);
};
InterfacesContext.prototype.WS = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.WS);
    }
    else {
        return this.getToken(LnParser.WS, i);
    }
};
InterfacesContext.prototype.EQUALS = function () {
    return this.getToken(LnParser.EQUALS, 0);
};
InterfacesContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
InterfacesContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterInterfaces(this);
    }
};
InterfacesContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitInterfaces(this);
    }
};
LnParser.InterfacesContext = InterfacesContext;
LnParser.prototype.interfaces = function () {
    var localctx = new InterfacesContext(this, this._ctx, this.state);
    this.enterRule(localctx, 96, LnParser.RULE_interfaces);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 965;
        this.match(LnParser.INTERFACE);
        this.state = 969;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.WS) {
            this.state = 966;
            this.match(LnParser.WS);
            this.state = 971;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 972;
        this.match(LnParser.VARNAME);
        this.state = 976;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.WS) {
            this.state = 973;
            this.match(LnParser.WS);
            this.state = 978;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 988;
        this._errHandler.sync(this);
        switch (this._input.LA(1)) {
            case LnParser.OPENBODY:
                this.state = 979;
                this.interfacebody();
                break;
            case LnParser.EQUALS:
                this.state = 980;
                this.match(LnParser.EQUALS);
                this.state = 984;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                    this.state = 981;
                    this.blank();
                    this.state = 986;
                    this._errHandler.sync(this);
                    _la = this._input.LA(1);
                }
                this.state = 987;
                this.match(LnParser.VARNAME);
                break;
            default:
                throw new antlr4.error.NoViableAltException(this);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function InterfacebodyContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_interfacebody;
    return this;
}
InterfacebodyContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
InterfacebodyContext.prototype.constructor = InterfacebodyContext;
InterfacebodyContext.prototype.OPENBODY = function () {
    return this.getToken(LnParser.OPENBODY, 0);
};
InterfacebodyContext.prototype.CLOSEBODY = function () {
    return this.getToken(LnParser.CLOSEBODY, 0);
};
InterfacebodyContext.prototype.interfacelist = function () {
    return this.getTypedRuleContext(InterfacelistContext, 0);
};
InterfacebodyContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
InterfacebodyContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterInterfacebody(this);
    }
};
InterfacebodyContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitInterfacebody(this);
    }
};
LnParser.InterfacebodyContext = InterfacebodyContext;
LnParser.prototype.interfacebody = function () {
    var localctx = new InterfacebodyContext(this, this._ctx, this.state);
    this.enterRule(localctx, 98, LnParser.RULE_interfacebody);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 990;
        this.match(LnParser.OPENBODY);
        this.state = 992;
        this._errHandler.sync(this);
        var la_ = this._interp.adaptivePredict(this._input, 138, this._ctx);
        if (la_ === 1) {
            this.state = 991;
            this.interfacelist();
        }
        this.state = 997;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 994;
            this.blank();
            this.state = 999;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 1000;
        this.match(LnParser.CLOSEBODY);
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function InterfacelistContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_interfacelist;
    return this;
}
InterfacelistContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
InterfacelistContext.prototype.constructor = InterfacelistContext;
InterfacelistContext.prototype.interfaceline = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(InterfacelineContext);
    }
    else {
        return this.getTypedRuleContext(InterfacelineContext, i);
    }
};
InterfacelistContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
InterfacelistContext.prototype.SEP = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.SEP);
    }
    else {
        return this.getToken(LnParser.SEP, i);
    }
};
InterfacelistContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterInterfacelist(this);
    }
};
InterfacelistContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitInterfacelist(this);
    }
};
LnParser.InterfacelistContext = InterfacelistContext;
LnParser.prototype.interfacelist = function () {
    var localctx = new InterfacelistContext(this, this._ctx, this.state);
    this.enterRule(localctx, 100, LnParser.RULE_interfacelist);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 1005;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 1002;
            this.blank();
            this.state = 1007;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 1008;
        this.interfaceline();
        this.state = 1012;
        this._errHandler.sync(this);
        var _alt = this._interp.adaptivePredict(this._input, 141, this._ctx);
        while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
            if (_alt === 1) {
                this.state = 1009;
                this.blank();
            }
            this.state = 1014;
            this._errHandler.sync(this);
            _alt = this._interp.adaptivePredict(this._input, 141, this._ctx);
        }
        this.state = 1031;
        this._errHandler.sync(this);
        var _alt = this._interp.adaptivePredict(this._input, 144, this._ctx);
        while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
            if (_alt === 1) {
                this.state = 1015;
                this.match(LnParser.SEP);
                this.state = 1019;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                    this.state = 1016;
                    this.blank();
                    this.state = 1021;
                    this._errHandler.sync(this);
                    _la = this._input.LA(1);
                }
                this.state = 1022;
                this.interfaceline();
                this.state = 1026;
                this._errHandler.sync(this);
                var _alt = this._interp.adaptivePredict(this._input, 143, this._ctx);
                while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {
                    if (_alt === 1) {
                        this.state = 1023;
                        this.blank();
                    }
                    this.state = 1028;
                    this._errHandler.sync(this);
                    _alt = this._interp.adaptivePredict(this._input, 143, this._ctx);
                }
            }
            this.state = 1033;
            this._errHandler.sync(this);
            _alt = this._interp.adaptivePredict(this._input, 144, this._ctx);
        }
        this.state = 1035;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        if (_la === LnParser.SEP) {
            this.state = 1034;
            this.match(LnParser.SEP);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function InterfacelineContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_interfaceline;
    return this;
}
InterfacelineContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
InterfacelineContext.prototype.constructor = InterfacelineContext;
InterfacelineContext.prototype.functiontypeline = function () {
    return this.getTypedRuleContext(FunctiontypelineContext, 0);
};
InterfacelineContext.prototype.operatortypeline = function () {
    return this.getTypedRuleContext(OperatortypelineContext, 0);
};
InterfacelineContext.prototype.propertytypeline = function () {
    return this.getTypedRuleContext(PropertytypelineContext, 0);
};
InterfacelineContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterInterfaceline(this);
    }
};
InterfacelineContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitInterfaceline(this);
    }
};
LnParser.InterfacelineContext = InterfacelineContext;
LnParser.prototype.interfaceline = function () {
    var localctx = new InterfacelineContext(this, this._ctx, this.state);
    this.enterRule(localctx, 102, LnParser.RULE_interfaceline);
    try {
        this.state = 1040;
        this._errHandler.sync(this);
        var la_ = this._interp.adaptivePredict(this._input, 146, this._ctx);
        switch (la_) {
            case 1:
                this.enterOuterAlt(localctx, 1);
                this.state = 1037;
                this.functiontypeline();
                break;
            case 2:
                this.enterOuterAlt(localctx, 2);
                this.state = 1038;
                this.operatortypeline();
                break;
            case 3:
                this.enterOuterAlt(localctx, 3);
                this.state = 1039;
                this.propertytypeline();
                break;
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function FunctiontypelineContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_functiontypeline;
    return this;
}
FunctiontypelineContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
FunctiontypelineContext.prototype.constructor = FunctiontypelineContext;
FunctiontypelineContext.prototype.functiontype = function () {
    return this.getTypedRuleContext(FunctiontypeContext, 0);
};
FunctiontypelineContext.prototype.VARNAME = function () {
    return this.getToken(LnParser.VARNAME, 0);
};
FunctiontypelineContext.prototype.FN = function () {
    return this.getToken(LnParser.FN, 0);
};
FunctiontypelineContext.prototype.WS = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.WS);
    }
    else {
        return this.getToken(LnParser.WS, i);
    }
};
FunctiontypelineContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterFunctiontypeline(this);
    }
};
FunctiontypelineContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitFunctiontypeline(this);
    }
};
LnParser.FunctiontypelineContext = FunctiontypelineContext;
LnParser.prototype.functiontypeline = function () {
    var localctx = new FunctiontypelineContext(this, this._ctx, this.state);
    this.enterRule(localctx, 104, LnParser.RULE_functiontypeline);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 1042;
        _la = this._input.LA(1);
        if (!(_la === LnParser.FN || _la === LnParser.VARNAME)) {
            this._errHandler.recoverInline(this);
        }
        else {
            this._errHandler.reportMatch(this);
            this.consume();
        }
        this.state = 1046;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.WS) {
            this.state = 1043;
            this.match(LnParser.WS);
            this.state = 1048;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 1049;
        this.functiontype();
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function FunctiontypeContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_functiontype;
    return this;
}
FunctiontypeContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
FunctiontypeContext.prototype.constructor = FunctiontypeContext;
FunctiontypeContext.prototype.OPENARGS = function () {
    return this.getToken(LnParser.OPENARGS, 0);
};
FunctiontypeContext.prototype.fulltypename = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(FulltypenameContext);
    }
    else {
        return this.getTypedRuleContext(FulltypenameContext, i);
    }
};
FunctiontypeContext.prototype.CLOSEARGS = function () {
    return this.getToken(LnParser.CLOSEARGS, 0);
};
FunctiontypeContext.prototype.TYPESEP = function () {
    return this.getToken(LnParser.TYPESEP, 0);
};
FunctiontypeContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
FunctiontypeContext.prototype.SEP = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.SEP);
    }
    else {
        return this.getToken(LnParser.SEP, i);
    }
};
FunctiontypeContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterFunctiontype(this);
    }
};
FunctiontypeContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitFunctiontype(this);
    }
};
LnParser.FunctiontypeContext = FunctiontypeContext;
LnParser.prototype.functiontype = function () {
    var localctx = new FunctiontypeContext(this, this._ctx, this.state);
    this.enterRule(localctx, 106, LnParser.RULE_functiontype);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 1051;
        this.match(LnParser.OPENARGS);
        this.state = 1055;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 1052;
            this.blank();
            this.state = 1057;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 1058;
        this.fulltypename();
        this.state = 1062;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 1059;
            this.blank();
            this.state = 1064;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 1081;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.SEP) {
            this.state = 1065;
            this.match(LnParser.SEP);
            this.state = 1069;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                this.state = 1066;
                this.blank();
                this.state = 1071;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
            }
            this.state = 1072;
            this.fulltypename();
            this.state = 1076;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                this.state = 1073;
                this.blank();
                this.state = 1078;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
            }
            this.state = 1083;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 1084;
        this.match(LnParser.CLOSEARGS);
        this.state = 1086;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        if (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 1085;
            this.blank();
        }
        this.state = 1088;
        this.match(LnParser.TYPESEP);
        this.state = 1092;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 1089;
            this.blank();
            this.state = 1094;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 1095;
        this.fulltypename();
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function OperatortypelineContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_operatortypeline;
    return this;
}
OperatortypelineContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
OperatortypelineContext.prototype.constructor = OperatortypelineContext;
OperatortypelineContext.prototype.operators = function () {
    return this.getTypedRuleContext(OperatorsContext, 0);
};
OperatortypelineContext.prototype.rightarg = function () {
    return this.getTypedRuleContext(RightargContext, 0);
};
OperatortypelineContext.prototype.TYPESEP = function () {
    return this.getToken(LnParser.TYPESEP, 0);
};
OperatortypelineContext.prototype.fulltypename = function () {
    return this.getTypedRuleContext(FulltypenameContext, 0);
};
OperatortypelineContext.prototype.leftarg = function () {
    return this.getTypedRuleContext(LeftargContext, 0);
};
OperatortypelineContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
OperatortypelineContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterOperatortypeline(this);
    }
};
OperatortypelineContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitOperatortypeline(this);
    }
};
LnParser.OperatortypelineContext = OperatortypelineContext;
LnParser.prototype.operatortypeline = function () {
    var localctx = new OperatortypelineContext(this, this._ctx, this.state);
    this.enterRule(localctx, 108, LnParser.RULE_operatortypeline);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 1104;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        if (_la === LnParser.VARNAME) {
            this.state = 1097;
            this.leftarg();
            this.state = 1101;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                this.state = 1098;
                this.blank();
                this.state = 1103;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
            }
        }
        this.state = 1106;
        this.operators();
        this.state = 1110;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 1107;
            this.blank();
            this.state = 1112;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 1113;
        this.rightarg();
        this.state = 1117;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 1114;
            this.blank();
            this.state = 1119;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 1120;
        this.match(LnParser.TYPESEP);
        this.state = 1124;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
            this.state = 1121;
            this.blank();
            this.state = 1126;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 1127;
        this.fulltypename();
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function LeftargContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_leftarg;
    return this;
}
LeftargContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
LeftargContext.prototype.constructor = LeftargContext;
LeftargContext.prototype.fulltypename = function () {
    return this.getTypedRuleContext(FulltypenameContext, 0);
};
LeftargContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterLeftarg(this);
    }
};
LeftargContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitLeftarg(this);
    }
};
LnParser.LeftargContext = LeftargContext;
LnParser.prototype.leftarg = function () {
    var localctx = new LeftargContext(this, this._ctx, this.state);
    this.enterRule(localctx, 110, LnParser.RULE_leftarg);
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 1129;
        this.fulltypename();
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function RightargContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_rightarg;
    return this;
}
RightargContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
RightargContext.prototype.constructor = RightargContext;
RightargContext.prototype.fulltypename = function () {
    return this.getTypedRuleContext(FulltypenameContext, 0);
};
RightargContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterRightarg(this);
    }
};
RightargContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitRightarg(this);
    }
};
LnParser.RightargContext = RightargContext;
LnParser.prototype.rightarg = function () {
    var localctx = new RightargContext(this, this._ctx, this.state);
    this.enterRule(localctx, 112, LnParser.RULE_rightarg);
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 1131;
        this.fulltypename();
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function PropertytypelineContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_propertytypeline;
    return this;
}
PropertytypelineContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
PropertytypelineContext.prototype.constructor = PropertytypelineContext;
PropertytypelineContext.prototype.VARNAME = function () {
    return this.getToken(LnParser.VARNAME, 0);
};
PropertytypelineContext.prototype.TYPESEP = function () {
    return this.getToken(LnParser.TYPESEP, 0);
};
PropertytypelineContext.prototype.fulltypename = function () {
    return this.getTypedRuleContext(FulltypenameContext, 0);
};
PropertytypelineContext.prototype.WS = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.WS);
    }
    else {
        return this.getToken(LnParser.WS, i);
    }
};
PropertytypelineContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterPropertytypeline(this);
    }
};
PropertytypelineContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitPropertytypeline(this);
    }
};
LnParser.PropertytypelineContext = PropertytypelineContext;
LnParser.prototype.propertytypeline = function () {
    var localctx = new PropertytypelineContext(this, this._ctx, this.state);
    this.enterRule(localctx, 114, LnParser.RULE_propertytypeline);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 1133;
        this.match(LnParser.VARNAME);
        this.state = 1137;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.WS) {
            this.state = 1134;
            this.match(LnParser.WS);
            this.state = 1139;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 1140;
        this.match(LnParser.TYPESEP);
        this.state = 1144;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.WS) {
            this.state = 1141;
            this.match(LnParser.WS);
            this.state = 1146;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 1147;
        this.fulltypename();
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function ExportsContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_exports;
    return this;
}
ExportsContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
ExportsContext.prototype.constructor = ExportsContext;
ExportsContext.prototype.EXPORT = function () {
    return this.getToken(LnParser.EXPORT, 0);
};
ExportsContext.prototype.eventref = function () {
    return this.getTypedRuleContext(EventrefContext, 0);
};
ExportsContext.prototype.types = function () {
    return this.getTypedRuleContext(TypesContext, 0);
};
ExportsContext.prototype.functions = function () {
    return this.getTypedRuleContext(FunctionsContext, 0);
};
ExportsContext.prototype.operatormapping = function () {
    return this.getTypedRuleContext(OperatormappingContext, 0);
};
ExportsContext.prototype.events = function () {
    return this.getTypedRuleContext(EventsContext, 0);
};
ExportsContext.prototype.interfaces = function () {
    return this.getTypedRuleContext(InterfacesContext, 0);
};
ExportsContext.prototype.WS = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.WS);
    }
    else {
        return this.getToken(LnParser.WS, i);
    }
};
ExportsContext.prototype.NEWLINE = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.NEWLINE);
    }
    else {
        return this.getToken(LnParser.NEWLINE, i);
    }
};
ExportsContext.prototype.constdeclaration = function () {
    return this.getTypedRuleContext(ConstdeclarationContext, 0);
};
ExportsContext.prototype.EOS = function () {
    return this.getToken(LnParser.EOS, 0);
};
ExportsContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterExports(this);
    }
};
ExportsContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitExports(this);
    }
};
LnParser.ExportsContext = ExportsContext;
LnParser.prototype.exports = function () {
    var localctx = new ExportsContext(this, this._ctx, this.state);
    this.enterRule(localctx, 116, LnParser.RULE_exports);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 1149;
        this.match(LnParser.EXPORT);
        this.state = 1151;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        do {
            this.state = 1150;
            _la = this._input.LA(1);
            if (!(_la === LnParser.NEWLINE || _la === LnParser.WS)) {
                this._errHandler.recoverInline(this);
            }
            else {
                this._errHandler.reportMatch(this);
                this.consume();
            }
            this.state = 1153;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        } while (_la === LnParser.NEWLINE || _la === LnParser.WS);
        this.state = 1164;
        this._errHandler.sync(this);
        switch (this._input.LA(1)) {
            case LnParser.VARNAME:
                this.state = 1155;
                this.eventref();
                break;
            case LnParser.TYPE:
                this.state = 1156;
                this.types();
                break;
            case LnParser.CONST:
                this.state = 1157;
                this.constdeclaration();
                this.state = 1158;
                this.match(LnParser.EOS);
                break;
            case LnParser.FN:
                this.state = 1160;
                this.functions();
                break;
            case LnParser.PREFIX:
            case LnParser.INFIX:
                this.state = 1161;
                this.operatormapping();
                break;
            case LnParser.EVENT:
                this.state = 1162;
                this.events();
                break;
            case LnParser.INTERFACE:
                this.state = 1163;
                this.interfaces();
                break;
            default:
                throw new antlr4.error.NoViableAltException(this);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function VarlistContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_varlist;
    return this;
}
VarlistContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
VarlistContext.prototype.constructor = VarlistContext;
VarlistContext.prototype.renameablevar = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(RenameablevarContext);
    }
    else {
        return this.getTypedRuleContext(RenameablevarContext, i);
    }
};
VarlistContext.prototype.SEP = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.SEP);
    }
    else {
        return this.getToken(LnParser.SEP, i);
    }
};
VarlistContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterVarlist(this);
    }
};
VarlistContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitVarlist(this);
    }
};
LnParser.VarlistContext = VarlistContext;
LnParser.prototype.varlist = function () {
    var localctx = new VarlistContext(this, this._ctx, this.state);
    this.enterRule(localctx, 118, LnParser.RULE_varlist);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 1166;
        this.renameablevar();
        this.state = 1171;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.SEP) {
            this.state = 1167;
            this.match(LnParser.SEP);
            this.state = 1168;
            this.renameablevar();
            this.state = 1173;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function RenameablevarContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_renameablevar;
    return this;
}
RenameablevarContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
RenameablevarContext.prototype.constructor = RenameablevarContext;
RenameablevarContext.prototype.varop = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(VaropContext);
    }
    else {
        return this.getTypedRuleContext(VaropContext, i);
    }
};
RenameablevarContext.prototype.AS = function () {
    return this.getToken(LnParser.AS, 0);
};
RenameablevarContext.prototype.WS = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.WS);
    }
    else {
        return this.getToken(LnParser.WS, i);
    }
};
RenameablevarContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterRenameablevar(this);
    }
};
RenameablevarContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitRenameablevar(this);
    }
};
LnParser.RenameablevarContext = RenameablevarContext;
LnParser.prototype.renameablevar = function () {
    var localctx = new RenameablevarContext(this, this._ctx, this.state);
    this.enterRule(localctx, 120, LnParser.RULE_renameablevar);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 1174;
        this.varop();
        this.state = 1187;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        if (_la === LnParser.WS) {
            this.state = 1176;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            do {
                this.state = 1175;
                this.match(LnParser.WS);
                this.state = 1178;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
            } while (_la === LnParser.WS);
            this.state = 1180;
            this.match(LnParser.AS);
            this.state = 1182;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
            do {
                this.state = 1181;
                this.match(LnParser.WS);
                this.state = 1184;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
            } while (_la === LnParser.WS);
            this.state = 1186;
            this.varop();
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function VaropContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_varop;
    return this;
}
VaropContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
VaropContext.prototype.constructor = VaropContext;
VaropContext.prototype.VARNAME = function () {
    return this.getToken(LnParser.VARNAME, 0);
};
VaropContext.prototype.operators = function () {
    return this.getTypedRuleContext(OperatorsContext, 0);
};
VaropContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterVarop(this);
    }
};
VaropContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitVarop(this);
    }
};
LnParser.VaropContext = VaropContext;
LnParser.prototype.varop = function () {
    var localctx = new VaropContext(this, this._ctx, this.state);
    this.enterRule(localctx, 122, LnParser.RULE_varop);
    try {
        this.state = 1191;
        this._errHandler.sync(this);
        switch (this._input.LA(1)) {
            case LnParser.VARNAME:
                this.enterOuterAlt(localctx, 1);
                this.state = 1189;
                this.match(LnParser.VARNAME);
                break;
            case LnParser.OPENGENERIC:
            case LnParser.CLOSEGENERIC:
            case LnParser.GLOBAL:
            case LnParser.DIRSEP:
            case LnParser.TYPESEP:
            case LnParser.GENERALOPERATORS:
                this.enterOuterAlt(localctx, 2);
                this.state = 1190;
                this.operators();
                break;
            default:
                throw new antlr4.error.NoViableAltException(this);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function VarnContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_varn;
    return this;
}
VarnContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
VarnContext.prototype.constructor = VarnContext;
VarnContext.prototype.varsegment = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(VarsegmentContext);
    }
    else {
        return this.getTypedRuleContext(VarsegmentContext, i);
    }
};
VarnContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterVarn(this);
    }
};
VarnContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitVarn(this);
    }
};
LnParser.VarnContext = VarnContext;
LnParser.prototype.varn = function () {
    var localctx = new VarnContext(this, this._ctx, this.state);
    this.enterRule(localctx, 124, LnParser.RULE_varn);
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 1194;
        this._errHandler.sync(this);
        var _alt = 1;
        do {
            switch (_alt) {
                case 1:
                    this.state = 1193;
                    this.varsegment();
                    break;
                default:
                    throw new antlr4.error.NoViableAltException(this);
            }
            this.state = 1196;
            this._errHandler.sync(this);
            _alt = this._interp.adaptivePredict(this._input, 169, this._ctx);
        } while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER);
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function VarsegmentContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_varsegment;
    return this;
}
VarsegmentContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
VarsegmentContext.prototype.constructor = VarsegmentContext;
VarsegmentContext.prototype.VARNAME = function () {
    return this.getToken(LnParser.VARNAME, 0);
};
VarsegmentContext.prototype.METHODSEP = function () {
    return this.getToken(LnParser.METHODSEP, 0);
};
VarsegmentContext.prototype.blank = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTypedRuleContexts(BlankContext);
    }
    else {
        return this.getTypedRuleContext(BlankContext, i);
    }
};
VarsegmentContext.prototype.arrayaccess = function () {
    return this.getTypedRuleContext(ArrayaccessContext, 0);
};
VarsegmentContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterVarsegment(this);
    }
};
VarsegmentContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitVarsegment(this);
    }
};
LnParser.VarsegmentContext = VarsegmentContext;
LnParser.prototype.varsegment = function () {
    var localctx = new VarsegmentContext(this, this._ctx, this.state);
    this.enterRule(localctx, 126, LnParser.RULE_varsegment);
    var _la = 0; // Token type
    try {
        this.state = 1207;
        this._errHandler.sync(this);
        switch (this._input.LA(1)) {
            case LnParser.VARNAME:
                this.enterOuterAlt(localctx, 1);
                this.state = 1198;
                this.match(LnParser.VARNAME);
                break;
            case LnParser.METHODSEP:
            case LnParser.NEWLINE:
            case LnParser.WS:
                this.enterOuterAlt(localctx, 2);
                this.state = 1202;
                this._errHandler.sync(this);
                _la = this._input.LA(1);
                while (_la === LnParser.NEWLINE || _la === LnParser.WS) {
                    this.state = 1199;
                    this.blank();
                    this.state = 1204;
                    this._errHandler.sync(this);
                    _la = this._input.LA(1);
                }
                this.state = 1205;
                this.match(LnParser.METHODSEP);
                break;
            case LnParser.OPENARRAY:
                this.enterOuterAlt(localctx, 3);
                this.state = 1206;
                this.arrayaccess();
                break;
            default:
                throw new antlr4.error.NoViableAltException(this);
        }
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
function ArrayaccessContext(parser, parent, invokingState) {
    if (parent === undefined) {
        parent = null;
    }
    if (invokingState === undefined || invokingState === null) {
        invokingState = -1;
    }
    antlr4.ParserRuleContext.call(this, parent, invokingState);
    this.parser = parser;
    this.ruleIndex = LnParser.RULE_arrayaccess;
    return this;
}
ArrayaccessContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);
ArrayaccessContext.prototype.constructor = ArrayaccessContext;
ArrayaccessContext.prototype.OPENARRAY = function () {
    return this.getToken(LnParser.OPENARRAY, 0);
};
ArrayaccessContext.prototype.assignables = function () {
    return this.getTypedRuleContext(AssignablesContext, 0);
};
ArrayaccessContext.prototype.CLOSEARRAY = function () {
    return this.getToken(LnParser.CLOSEARRAY, 0);
};
ArrayaccessContext.prototype.WS = function (i) {
    if (i === undefined) {
        i = null;
    }
    if (i === null) {
        return this.getTokens(LnParser.WS);
    }
    else {
        return this.getToken(LnParser.WS, i);
    }
};
ArrayaccessContext.prototype.enterRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.enterArrayaccess(this);
    }
};
ArrayaccessContext.prototype.exitRule = function (listener) {
    if (listener instanceof LnListener) {
        listener.exitArrayaccess(this);
    }
};
LnParser.ArrayaccessContext = ArrayaccessContext;
LnParser.prototype.arrayaccess = function () {
    var localctx = new ArrayaccessContext(this, this._ctx, this.state);
    this.enterRule(localctx, 128, LnParser.RULE_arrayaccess);
    var _la = 0; // Token type
    try {
        this.enterOuterAlt(localctx, 1);
        this.state = 1209;
        this.match(LnParser.OPENARRAY);
        this.state = 1213;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.WS) {
            this.state = 1210;
            this.match(LnParser.WS);
            this.state = 1215;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 1216;
        this.assignables();
        this.state = 1220;
        this._errHandler.sync(this);
        _la = this._input.LA(1);
        while (_la === LnParser.WS) {
            this.state = 1217;
            this.match(LnParser.WS);
            this.state = 1222;
            this._errHandler.sync(this);
            _la = this._input.LA(1);
        }
        this.state = 1223;
        this.match(LnParser.CLOSEARRAY);
    }
    catch (re) {
        if (re instanceof antlr4.error.RecognitionException) {
            localctx.exception = re;
            this._errHandler.reportError(this, re);
            this._errHandler.recover(this, re);
        }
        else {
            throw re;
        }
    }
    finally {
        this.exitRule();
    }
    return localctx;
};
exports.LnParser = LnParser;

},{"./LnListener":7,"antlr4/index":66}],9:[function(require,module,exports){
module.exports = {
    LnLexer: require('./LnLexer').LnLexer,
    LnParser: require('./LnParser').LnParser,
};

},{"./LnLexer":6,"./LnParser":8}],10:[function(require,module,exports){
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.assignablesAstFromString = exports.fulltypenameAstFromString = exports.statementAstFromString = exports.functionAstFromString = exports.resolveImports = exports.resolveDependency = exports.fromFile = exports.fromString = void 0;
const fs = require("fs");
const path = require("path");
const antlr4_1 = require("antlr4");
const ln_1 = require("../ln");
const resolve = (path) => {
    try {
        return fs.realpathSync(path);
    }
    catch (e) {
        return null;
    }
};
exports.fromString = (str) => {
    const inputStream = new antlr4_1.InputStream(str);
    const langLexer = new ln_1.LnLexer(inputStream);
    const commonTokenStream = new antlr4_1.CommonTokenStream(langLexer);
    const langParser = new ln_1.LnParser(commonTokenStream);
    return langParser.module();
};
exports.fromFile = (filename) => {
    return exports.fromString(fs.readFileSync(filename, { encoding: 'utf8', }));
};
exports.resolveDependency = (modulePath, dependency) => {
    // Special case path for the standard library importing itself
    if (modulePath.substring(0, 4) === '@std')
        return dependency.getText().trim();
    // For everything else...
    let importPath = null;
    // If the dependency is a local dependency, there's little logic in determining
    // what is being imported. It's either the relative path to a file with the language
    // extension, or the relative path to a directory containing an "index.ln" file
    if (dependency.localdependency() != null) {
        const dirPath = resolve(path.join(path.dirname(modulePath), dependency.localdependency().getText().toString(), "index.ln"));
        const filePath = resolve(path.join(path.dirname(modulePath), dependency.localdependency().getText().toString() + ".ln"));
        // It's possible for both to exist. Prefer the directory-based one, but warn the user
        if (typeof dirPath === "string" && typeof filePath === "string") {
            console.error(dirPath + " and " + filePath + " both exist. Using " + dirPath);
        }
        if (typeof filePath === "string") {
            importPath = filePath;
        }
        if (typeof dirPath === "string") {
            importPath = dirPath;
        }
        if (importPath === null) {
            // Should I do anything else here?
            throw new Error("The dependency " +
                dependency.localdependency().getText().toString() +
                " could not be found.");
        }
    }
    // If the dependency is a global dependency, there's a more complicated resolution to find it.
    // This is inspired by the Ruby and Node resolution mechanisms, but with some changes that
    // should hopefully make some improvements so dependency-injection is effectively first-class
    // and micro-libraries are discouraged (the latter will require a multi-pronged effort)
    //
    // Essentially, there are two recursively-found directories that global modules can be found,
    // the `modules` directory and the `dependencies` directory (TBD: are these the final names?)
    // The `modules` directory is recursively checked first (with a special check to make sure it
    // ignores self-resolutions) and the first one found in that check, if any, is used. If not,
    // there's a special check if the dependency is an `@std/...` dependency, and if so to return
    // that string as-is so the built-in dependency is used. Next the same recursive check is
    // performed on the `dependencies` directories until the dependency is found. If that also
    // fails, then there will be a complaint and the process will exit.
    //
    // The idea is that the package manager will install dependencies into the `dependencies`
    // directory at the root of the project (or maybe PWD, but that seems a bit too unwieldy).
    // Meanwhile the `modules` directory will only exist if the developer wants it, but it can be
    // useful for cross-cutting code in the same project that doesn't really need to be open-
    // sourced but is annoying to always reference slightly differently in each file, eg
    // `../../../util`. Instead the project can have a project-root-level `modules` directory and
    // then `modules/util.ln` can be referenced simply with `import @util` anywhere in the project.
    //
    // Since this is also recursive, it's should make dependency injection a first-class citizen
    // of the language. For instance you can put all of your models in `modules/models/`, and then
    // your unit test suite can have its model mocks in `tests/modules/models/` and the dependency
    // you intend to inject into can be symlinked in the `tests/` directory to cause that version
    // to pull the injected code, instead. And of course, if different tests need different
    // dependency injections, you can turn the test file into a directory of the same name and
    // rename the file to `index.ln` within it, and then have the specific mocks that test needs
    // stored in a `modules/` directory in parallel with it, which will not impact other mocks.
    //
    // Because these mocks also have a special exception to not import themselves, this can also
    // be used for instrumentation purposes, where they override the actual module but then also
    // import the real thing and add extra behavior to it.
    //
    // While there are certainly uses for splitting some logical piece of code into a tree of
    // files and directories, it is my hope that the standard application organization path is a
    // project with a root `index.ln` file and `modules` and `dependencies` directories, and little
    // else. At least things like `modules/logger`, `modules/config`, etc should belong there.
    if (dependency.globaldependency() != null) {
        // Get the two potential dependency types, file and directory-style.
        const fileModule = dependency.globaldependency().getText().toString().substring(1) + ".ln";
        const dirModule = dependency.globaldependency().getText().toString().substring(1) + "/index.ln";
        // Get the initial root to check
        let pathRoot = path.dirname(modulePath);
        // Search the recursively up the directory structure in the `modules` directories for the
        // specified dependency, and if found, return it.
        while (pathRoot != null) {
            const dirPath = resolve(path.join(pathRoot, "modules", dirModule));
            const filePath = resolve(path.join(pathRoot, "modules", fileModule));
            // It's possible for a module to accidentally resolve to itself when the module wraps the
            // actual dependency it is named for.
            if (dirPath === modulePath || filePath === modulePath) {
                pathRoot = path.dirname(pathRoot);
                continue;
            }
            // It's possible for both to exist. Prefer the directory-based one, but warn the user
            if (typeof dirPath === "string" && typeof filePath === "string") {
                console.error(dirPath + " and " + filePath + " both exist. Using " + dirPath);
            }
            if (typeof filePath === "string") {
                importPath = filePath;
                break;
            }
            if (typeof dirPath === "string") {
                importPath = dirPath;
                break;
            }
            if (pathRoot === "/" || /[A-Z]:\\/.test(pathRoot)) {
                pathRoot = null;
            }
            else {
                pathRoot = path.dirname(pathRoot);
            }
        }
        if (importPath == null) {
            // If we can't find it defined in a `modules` directory, check if it's an `@std/...`
            // module and abort here so the built-in standard library is used.
            if (dependency.globaldependency().getText().toString().substring(0, 5) === "@std/") {
                // Not a valid path (starting with '@') to be used as signal to use built-in library)
                importPath = dependency.globaldependency().getText().toString();
            }
            else {
                // Go back to the original point and search up the tree for `dependencies` directories
                pathRoot = path.dirname(modulePath);
                while (pathRoot != null) {
                    const dirPath = resolve(path.join(pathRoot, "dependencies", dirModule));
                    const filePath = resolve(path.join(pathRoot, "dependencies", fileModule));
                    // It's possible for both to exist. Prefer the directory-based one, but warn the user
                    if (typeof dirPath === "string" && typeof filePath === "string") {
                        console.error(dirPath + " and " + filePath + " both exist. Using " + dirPath);
                    }
                    if (typeof filePath === "string") {
                        importPath = filePath;
                        break;
                    }
                    if (typeof dirPath === "string") {
                        importPath = dirPath;
                        break;
                    }
                    if (pathRoot === "/" || /[A-Z]:\\/.test(pathRoot)) {
                        pathRoot = null;
                    }
                    else {
                        pathRoot = path.dirname(pathRoot);
                    }
                }
            }
            if (importPath == null) {
                // Should I do anything else here?
                throw new Error("The dependency " +
                    dependency.globaldependency().getText().toString() +
                    " could not be found.");
            }
        }
    }
    return importPath;
};
exports.resolveImports = (modulePath, ast) => {
    let resolvedImports = [];
    let imports = ast.imports();
    for (let i = 0; i < imports.length; i++) {
        const standardImport = imports[i].standardImport();
        const fromImport = imports[i].fromImport();
        let dependency = null;
        if (standardImport != null) {
            dependency = standardImport.dependency();
        }
        if (fromImport != null) {
            dependency = fromImport.dependency();
        }
        if (dependency == null) {
            // Should I do anything else here?
            throw new Error("Things are horribly broken!");
        }
        const importPath = exports.resolveDependency(modulePath, dependency);
        resolvedImports.push(importPath);
    }
    return resolvedImports;
};
exports.functionAstFromString = (fn) => {
    const inputStream = new antlr4_1.InputStream(fn);
    const langLexer = new ln_1.LnLexer(inputStream);
    const commonTokenStream = new antlr4_1.CommonTokenStream(langLexer);
    const langParser = new ln_1.LnParser(commonTokenStream);
    return langParser.functions();
};
exports.statementAstFromString = (s) => {
    const inputStream = new antlr4_1.InputStream(s);
    const langLexer = new ln_1.LnLexer(inputStream);
    const commonTokenStream = new antlr4_1.CommonTokenStream(langLexer);
    const langParser = new ln_1.LnParser(commonTokenStream);
    return langParser.statements();
};
exports.fulltypenameAstFromString = (s) => {
    const inputStream = new antlr4_1.InputStream(s);
    const langLexer = new ln_1.LnLexer(inputStream);
    const commonTokenStream = new antlr4_1.CommonTokenStream(langLexer);
    const langParser = new ln_1.LnParser(commonTokenStream);
    return langParser.fulltypename();
};
exports.assignablesAstFromString = (s) => {
    const inputStream = new antlr4_1.InputStream(s);
    const langLexer = new ln_1.LnLexer(inputStream);
    const commonTokenStream = new antlr4_1.CommonTokenStream(langLexer);
    const langParser = new ln_1.LnParser(commonTokenStream);
    return langParser.assignables();
};

},{"../ln":9,"antlr4":66,"fs":74,"path":85}],11:[function(require,module,exports){
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
class Constant {
    constructor(name, assignablesAst, scope) {
        this.name = name;
        this.assignablesAst = assignablesAst;
        this.scope = scope;
    }
    static fromAst(constdeclaration, scope) {
        const name = constdeclaration.VARNAME().getText();
        const outConst = new Constant(name, constdeclaration.assignables(), scope);
        scope.put(name, outConst);
        return outConst;
    }
}
exports.default = Constant;

},{}],12:[function(require,module,exports){
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const Type_1 = require("./Type");
let Event = /** @class */ (() => {
    class Event {
        constructor(name, type, builtIn) {
            this.name = name,
                this.type = type;
            this.builtIn = builtIn;
            this.handlers = [];
            Event.allEvents.push(this);
        }
        toString() {
            return `event ${this.name}: ${this.type.typename}`;
        }
        static fromAst(eventAst, scope) {
            const name = eventAst.VARNAME().getText();
            const type = scope.deepGet(eventAst.fulltypename().getText());
            if (!type) {
                throw new Error("Could not find specified type: " + eventAst.fulltypename().getText());
            }
            else if (!(type instanceof Type_1.default)) {
                throw new Error(eventAst.fulltypename().getText() + " is not a type");
            }
            return new Event(name, type, false);
        }
    }
    Event.allEvents = [];
    return Event;
})();
exports.default = Event;

},{"./Type":19}],13:[function(require,module,exports){
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const uuid_1 = require("uuid");
const Ast = require("./Ast");
const Event_1 = require("./Event");
const Operator_1 = require("./Operator");
const Constant_1 = require("./Constant");
const Scope_1 = require("./Scope");
const Statement_1 = require("./Statement");
const StatementType_1 = require("./StatementType");
const Type_1 = require("./Type");
const UserFunction_1 = require("./UserFunction");
const FIXED_TYPES = ['int64', 'int32', 'int16', 'int8', 'float64', 'float32', 'bool', 'void'];
class Microstatement {
    constructor(statementType, scope, pure, outputName, outputType = Type_1.default.builtinTypes.void, inputNames = [], fns = [], alias = '', closurePure = true, closureStatements = [], closureArgs = {}, closureOutputType = Type_1.default.builtinTypes.void) {
        this.statementType = statementType;
        this.scope = scope;
        this.pure = pure;
        this.outputName = outputName;
        this.outputType = outputType;
        this.inputNames = inputNames;
        this.fns = fns;
        this.alias = alias;
        this.closurePure = closurePure;
        this.closureStatements = closureStatements;
        this.closureArgs = closureArgs;
        this.closureOutputType = closureOutputType;
    }
    toString() {
        let outString = "";
        switch (this.statementType) {
            case StatementType_1.default.CONSTDEC:
                outString = "const " + this.outputName + ": " + this.outputType.typename;
                if (this.fns.length > 0) {
                    outString += " = " + this.fns[0].getName() + "(" + this.inputNames.join(", ") + ")";
                }
                else if (this.inputNames.length > 0) {
                    outString += " = " + this.inputNames[0]; // Doesn't appear the list is ever used here
                }
                break;
            case StatementType_1.default.LETDEC:
                outString = "let " + this.outputName + ": " + this.outputType.typename;
                if (this.fns.length > 0) {
                    outString += " = " + this.fns[0].getName() + "(" + this.inputNames.join(", ") + ")";
                }
                else if (this.inputNames.length > 0) {
                    outString += " = " + this.inputNames[0]; // Doesn't appear the list is ever used here
                }
                break;
            case StatementType_1.default.ASSIGNMENT:
                outString = this.outputName;
                if (this.fns.length > 0) {
                    outString += " = " + this.fns[0].getName() + "(" + this.inputNames.join(", ") + ")";
                }
                else if (this.inputNames.length > 0) {
                    outString += " = " + this.inputNames[0]; // Doesn't appear the list is ever used here
                }
                else {
                    outString += "NO!";
                }
                break;
            case StatementType_1.default.CALL:
                if (this.fns.length > 0) {
                    outString += this.fns[0].getName() + "(" + this.inputNames.join(", ") + ")";
                }
                break;
            case StatementType_1.default.EMIT:
                outString = "emit " + this.outputName + " ";
                if (this.fns.length > 0) {
                    outString += this.fns[0].getName() + "(" + this.inputNames.join(", ") + ")";
                }
                else if (this.inputNames.length > 0) {
                    outString += this.inputNames[0]; // Doesn't appear the list is ever used here
                }
                break;
            case StatementType_1.default.EXIT:
                outString = "return " + this.outputName;
                break;
            case StatementType_1.default.CLOSURE:
                outString = "const " + this.outputName + ": function = fn (";
                let args = [];
                for (const [name, type] of Object.entries(this.closureArgs)) {
                    if (name !== "" && type.typename != "") {
                        args.push(name + ": " + type.typename);
                    }
                }
                outString += args.join(",");
                outString += "): " + this.closureOutputType.typename + " {\n";
                for (const m of this.closureStatements) {
                    const s = m.toString();
                    if (s !== "") {
                        outString += "    " + m.toString() + "\n";
                    }
                }
                outString += "  }";
                break;
            case StatementType_1.default.REREF:
            case StatementType_1.default.ARG:
            case StatementType_1.default.CLOSUREDEF:
                // Intentionally never output anything, this is metadata for the transpiler algo only
                break;
        }
        return outString;
    }
    static fromVarName(varName, scope, microstatements) {
        let original = null;
        for (let i = microstatements.length - 1; i > -1; i--) {
            const microstatement = microstatements[i];
            // TODO: var resolution is complex. Need to revisit this.
            if (microstatement.outputName === varName) {
                original = microstatement;
                if (microstatement.statementType !== StatementType_1.default.REREF) {
                    break;
                }
            }
            if (microstatement.alias === varName) {
                original = microstatement;
                for (let j = i - 1; j >= 0; j--) {
                    if (microstatements[j].outputName === original.outputName &&
                        microstatements[j].statementType !== StatementType_1.default.REREF) {
                        original = microstatements[j];
                        break;
                    }
                }
                break;
            }
        }
        // Check if this is a module constant that should be un-hoisted
        if (original === null &&
            !!scope.deepGet(varName) &&
            scope.deepGet(varName) instanceof Constant_1.default) {
            const globalConst = scope.deepGet(varName);
            Microstatement.fromAssignablesAst(globalConst.assignablesAst, globalConst.scope, // Eval this in its original scope in case it was an exported const
            microstatements // that was dependent on unexported internal functions or constants
            );
            const last = microstatements[microstatements.length - 1];
            microstatements.push(new Microstatement(StatementType_1.default.REREF, scope, true, last.outputName, last.outputType, [], [], globalConst.name));
        }
        return original;
    }
    // TODO: Eliminate ANTLR
    static fromVarAst(varAst, scope, microstatements) {
        // Short-circuit if this exact var was already loaded
        let original = Microstatement.fromVarName(varAst.getText(), scope, microstatements);
        if (!original) {
            // Otherwise, we're digging in piece by piece to find the relevant microstatement.
            const segments = varAst.varsegment();
            let name = '';
            for (const segment of segments) {
                // A 'normal' segment. Either append it to the name and attempt to get the underlying
                // sub-name or rewrite it into an array access if it's a user-defined type field name
                if (segment.VARNAME()) {
                    // Decide if this is an access on a user-defined type that should be rewritten as an array
                    // access instead
                    name += segment.VARNAME().getText();
                    if (!original || !original.outputType || original.outputType.builtIn) {
                        original = Microstatement.fromVarName(name, scope, microstatements);
                    }
                    else {
                        // Next, figure out which field number this is
                        const fieldName = segment.VARNAME().getText();
                        const fields = Object.keys(original.outputType.properties);
                        const fieldNum = fields.indexOf(fieldName);
                        if (fieldNum < 0) {
                            // Invalid object access
                            throw new Error(`${name} does not have a field named ${fieldName}
${varAst.getText()} on line ${varAst.start.line}:${varAst.start.column}`);
                        }
                        // Create a new variable to hold the address within the array literal
                        const addrName = "_" + uuid_1.v4().replace(/-/g, "_");
                        microstatements.push(new Microstatement(StatementType_1.default.CONSTDEC, scope, true, addrName, Type_1.default.builtinTypes['int64'], [`${fieldNum}`], []));
                        // Insert a `register` opcode.
                        const opcodes = require('./opcodes').default;
                        opcodes.exportScope.get('register')[0].microstatementInlining([original.outputName, addrName], scope, microstatements);
                        // We'll need a reference to this for later
                        const typeRecord = original;
                        // Set the original to this newly-generated microstatement
                        original = microstatements[microstatements.length - 1];
                        // Now we do something odd, but correct here; we need to replace the `outputType` from
                        // `any` to the type that was actually copied so function resolution continues to work
                        original.outputType = typeRecord.outputType.properties[fieldName];
                    }
                }
                // A separator, just append it and do nothing else
                if (segment.METHODSEP()) {
                    name += segment.METHODSEP().getText();
                }
                // An array access. This requires resolving the contents of the array access variable and
                // then using that value to find the correct index to read from. For now, that will be
                // emitting a `resfrom` opcode call. Also for now it is an error if the resolved type is
                // anything but `int64` for the array access path. Maps use the same syntax with the type
                // being the Map's Key type.
                if (segment.arrayaccess()) {
                    if (original == null || !(original instanceof Microstatement)) {
                        // This is all moot if we didn't resolve a variable to dig into
                        throw new Error(`${name} cannot be found
${varAst.getText()} on line ${varAst.start.line}:${varAst.start.column}`);
                    }
                    // We're still ID'ing it with the raw text to make the short-circuit work
                    name += segment.arrayaccess().getText();
                    const assignables = segment.arrayaccess().assignables();
                    Microstatement.fromAssignablesAst(assignables, scope, microstatements);
                    const lookup = microstatements[microstatements.length - 1];
                    // TODO: Map support, which requires figuring out if the outer memory object is an array
                    // or a map.
                    if (lookup.outputType.typename !== 'int64') {
                        throw new Error(`${segment.getText()} cannot be used in an array lookup as it is not an int64
${varAst.getText()} on line ${varAst.start.line}:${varAst.start.column}`);
                    }
                    // Insert a `resfrom` opcode.
                    const opcodes = require('./opcodes').default;
                    opcodes.exportScope.get('resfrom')[0].microstatementInlining([original.outputName, lookup.outputName], scope, microstatements);
                    // We'll need a reference to this for later
                    const arrayRecord = original;
                    // Set the original to this newly-generated microstatement
                    original = microstatements[microstatements.length - 1];
                    // Now we do something odd, but correct here; we need to replace the `outputType` from
                    // `any` to the type that was actually copied so function resolution continues to work
                    original.outputType = Type_1.default.builtinTypes.Result.solidify([Object.values(arrayRecord.outputType.properties)[0].typename], scope);
                }
            }
        }
        if (original == null || !(original instanceof Microstatement)) {
            throw new Error(`${varAst.getText()} cannot be found
${varAst.getText()} on line ${varAst.start.line}:${varAst.start.column}`);
        }
        // When a variable is reassigned (or was referenced in a function call or operator statement,
        // instead of duplicating its data, add a microstatement to rereference that data (all of the
        // function and operator calls expect their arguments to be the N statements preceding them).
        microstatements.push(new Microstatement(StatementType_1.default.REREF, scope, true, original.outputName, original.outputType, [], []));
    }
    // TODO: Eliminate ANTLR
    static fromConstantsAst(constantsAst, scope, microstatements) {
        const constName = "_" + uuid_1.v4().replace(/-/g, "_");
        let constType = 'void';
        if (constantsAst.BOOLCONSTANT() != null) {
            constType = 'bool';
        }
        if (constantsAst.STRINGCONSTANT() != null) {
            constType = 'string';
        }
        if (constantsAst.NUMBERCONSTANT() != null) {
            // TODO: Add support for hex, octal, scientific, etc
            const numberConst = constantsAst.NUMBERCONSTANT().getText();
            if (numberConst.indexOf('.') > -1) { // It's a float
                constType = 'float64';
            }
            else { // It's an integer
                constType = 'int64';
            }
        }
        let constVal;
        try {
            JSON.parse(constantsAst.getText()); // Will fail on strings with escape chars
            constVal = constantsAst.getText();
        }
        catch (e) {
            // It may be a zero-padded number
            if (['int8', 'int16', 'int32', 'int64'].includes(constType) &&
                constantsAst.getText()[0] === '0') {
                constVal = parseInt(constantsAst.getText(), 10).toString();
            }
            else if (['float32', 'float64'].includes(constType) &&
                constantsAst.getText()[0] === '0') {
                constVal = parseFloat(constantsAst.getText()).toString();
            }
            else {
                // Hackery to get these strings to work
                constVal = JSON.stringify(constantsAst.getText()
                    .replace(/^["']/, '').replace(/["']$/, ''));
            }
        }
        microstatements.push(new Microstatement(StatementType_1.default.CONSTDEC, scope, true, constName, scope.deepGet(constType), [constVal], []));
    }
    static fromObjectLiteralsAst(objectLiteralsAst, // TODO: Eliminate ANTLR
    scope, microstatements) {
        if (objectLiteralsAst.arrayliteral()) {
            // Array literals first need all of the microstatements of the array contents defined, then
            // a `newarr` opcode call is inserted for the object literal itself, then `pusharr` opcode
            // calls are emitted to insert the relevant data into the array, and finally the array itself
            // is REREFed for the outer microstatement generation call.
            const arrayLiteralContents = [];
            const assignablelist = objectLiteralsAst.arrayliteral().arraybase().assignablelist();
            const assignableLen = assignablelist ? assignablelist.assignables().length : 0;
            for (let i = 0; i < assignableLen; i++) {
                Microstatement.fromAssignablesAst(assignablelist.assignables(i), scope, microstatements);
                arrayLiteralContents.push(microstatements[microstatements.length - 1]);
            }
            let typeBox = null;
            if (objectLiteralsAst.arrayliteral().literaldec()) {
                typeBox = scope.deepGet(objectLiteralsAst.arrayliteral().literaldec().fulltypename().getText().trim());
                if (!typeBox) {
                    // Try to define it if it's a generic type
                    if (objectLiteralsAst.arrayliteral().literaldec().fulltypename().typegenerics()) {
                        const outerTypeBox = scope.deepGet(objectLiteralsAst.arrayliteral().literaldec().fulltypename().typename().getText().trim());
                        if (!outerTypeBox) {
                            throw new Error(`${objectLiteralsAst.arrayliteral().literaldec().fulltypename().getText()}  is not defined
${objectLiteralsAst.getText()} on line ${objectLiteralsAst.start.line}:${objectLiteralsAst.start.column}`);
                        }
                        outerTypeBox.solidify(objectLiteralsAst.arrayliteral().literaldec().fulltypename().typegenerics().fulltypename().map((t) => t.getText() // TODO: Eliminate ANTLR
                        ), scope);
                        typeBox = scope.deepGet(objectLiteralsAst.arrayliteral().literaldec().fulltypename().getText().trim());
                    }
                }
                if (!(typeBox instanceof Type_1.default)) {
                    throw new Error(`${objectLiteralsAst.arrayliteral().literaldec().fulltypename().getText().trim()} is not a type
${objectLiteralsAst.getText()} on line ${objectLiteralsAst.start.line}:${objectLiteralsAst.start.column}`);
                }
            }
            else if (arrayLiteralContents.length > 0) {
                const innerType = arrayLiteralContents[0].outputType.typename;
                Type_1.default.builtinTypes['Array'].solidify([innerType], scope);
                typeBox = scope.deepGet(`Array<${innerType}>`);
            }
            else {
                throw new Error(`Ambiguous array type, please specify the type for an empty array with the syntax \`new Array<MyType> []\`
${objectLiteralsAst.getText()} on line ${objectLiteralsAst.start.line}:${objectLiteralsAst.start.column}`);
            }
            // Create a new variable to hold the size of the array literal
            const lenName = "_" + uuid_1.v4().replace(/-/g, "_");
            microstatements.push(new Microstatement(StatementType_1.default.CONSTDEC, scope, true, lenName, Type_1.default.builtinTypes['int64'], [`${arrayLiteralContents.length}`], []));
            // Add the opcode to create a new array with the specified size
            const opcodes = require('./opcodes').default;
            opcodes.exportScope.get('newarr')[0].microstatementInlining([lenName], scope, microstatements);
            // Get the array microstatement and extract the name and insert the correct type
            const array = microstatements[microstatements.length - 1];
            array.outputType = typeBox;
            // Try to use the "real" type if knowable
            if (arrayLiteralContents.length > 0) {
                array.outputType = Type_1.default.builtinTypes['Array'].solidify([arrayLiteralContents[0].outputType.typename], scope);
            }
            const arrayName = array.outputName;
            // Push the values into the array
            for (let i = 0; i < arrayLiteralContents.length; i++) {
                // Create a new variable to hold the size of the array value
                const size = FIXED_TYPES.includes(arrayLiteralContents[i].outputType.typename) ? "8" : "0";
                const sizeName = "_" + uuid_1.v4().replace(/-/g, "_");
                microstatements.push(new Microstatement(StatementType_1.default.CONSTDEC, scope, true, sizeName, Type_1.default.builtinTypes['int64'], [size], []));
                // Push the value into the array
                const opcodes = require('./opcodes').default;
                opcodes.exportScope.get('pusharr')[0].microstatementInlining([arrayName, arrayLiteralContents[i].outputName, sizeName], scope, microstatements);
            }
            // REREF the array
            microstatements.push(new Microstatement(StatementType_1.default.REREF, scope, true, arrayName, array.outputType, [], []));
        }
        else if (!!objectLiteralsAst.typeliteral()) {
            // User types are represented in AMM and lower as `Array<any>`. This reduces the number of
            // concepts that have to be maintained in the execution layer (and is really what C structs
            // are, anyways). The order of the properties on the specified type directly map to the
            // order that they are inserted into the Array, not the order they're defined in the object
            // literal notation, so reads and updates later on can occur predictably by mapping the name
            // of the property to its array index.
            //
            // If the type literal is missing any fields, that's a hard compile error to make sure
            // accessing undefined data is impossible. If a value might not be needed, they should use
            // the `Option` type and provide a `None` value there.
            let typeBox = scope.deepGet(objectLiteralsAst.typeliteral().literaldec().fulltypename().getText().trim());
            if (typeBox === null) {
                // Try to define it if it's a generic type
                if (objectLiteralsAst.typeliteral().literaldec().fulltypename().typegenerics()) {
                    const outerTypeBox = scope.deepGet(objectLiteralsAst.typeliteral().literaldec().fulltypename().typename().getText().trim());
                    if (outerTypeBox === null) {
                        throw new Error(`${objectLiteralsAst.typeliteral().literaldec().fulltypename().getText()}  is not defined
${objectLiteralsAst.getText()} on line ${objectLiteralsAst.start.line}:${objectLiteralsAst.start.column}`);
                    }
                    outerTypeBox.solidify(objectLiteralsAst.typeliteral().literaldec().fulltypename().typegenerics().fulltypename().map((t) => t.getText() // TODO: Eliminate ANTLR
                    ), scope);
                    typeBox = scope.deepGet(objectLiteralsAst.typeliteral().literaldec().fulltypename().getText().trim());
                }
            }
            if (!(typeBox instanceof Type_1.default)) {
                throw new Error(`${objectLiteralsAst.typeliteral().literaldec().fulltypename().getText().trim()} is not a type
${objectLiteralsAst.getText()} on line ${objectLiteralsAst.start.line}:${objectLiteralsAst.start.column}`);
            }
            const assignlist = objectLiteralsAst.typeliteral().typebase().typeassignlist();
            const assignfields = assignlist.VARNAME().map((f) => f.getText());
            const assignvals = assignlist.assignables();
            const fields = Object.keys(typeBox.properties);
            let missingFields = [];
            let foundFields = [];
            let extraFields = [];
            let astLookup = {};
            for (let i = 0; i < assignfields.length; i++) {
                const assignfield = assignfields[i];
                const assignval = assignvals[i];
                astLookup[assignfield] = assignval;
                if (!fields.includes(assignfield)) {
                    extraFields.push(assignfield);
                }
                if (foundFields.includes(assignfield)) {
                    extraFields.push(assignfield);
                }
                foundFields.push(assignfield);
            }
            for (const field of fields) {
                if (!foundFields.includes(field)) {
                    missingFields.push(field);
                }
            }
            if (missingFields.length > 0 || extraFields.length > 0) {
                let errMsg = `${objectLiteralsAst.typeliteral().literaldec().fulltypename().getText().trim()} object literal improperly defined`;
                if (missingFields.length > 0) {
                    errMsg += '\n' + `Missing fields: ${missingFields.join(', ')}`;
                }
                if (extraFields.length > 0) {
                    errMsg += '\n' + `Extra fields: ${extraFields.join(', ')}`;
                }
                errMsg += '\n' +
                    objectLiteralsAst.getText() +
                    " on line " +
                    objectLiteralsAst.start.line +
                    ":" +
                    objectLiteralsAst.start.column;
                throw new Error(errMsg);
            }
            // The assignment looks good, now we'll mimic the array literal logic mostly
            const arrayLiteralContents = [];
            for (let i = 0; i < fields.length; i++) {
                Microstatement.fromAssignablesAst(astLookup[fields[i]], scope, microstatements);
                arrayLiteralContents.push(microstatements[microstatements.length - 1]);
            }
            // Create a new variable to hold the size of the array literal
            const lenName = "_" + uuid_1.v4().replace(/-/g, "_");
            microstatements.push(new Microstatement(StatementType_1.default.CONSTDEC, scope, true, lenName, Type_1.default.builtinTypes['int64'], [`${fields.length}`], []));
            // Add the opcode to create a new array with the specified size
            const opcodes = require('./opcodes').default;
            opcodes.exportScope.get('newarr')[0].microstatementInlining([lenName], scope, microstatements);
            // Get the array microstatement and extract the name and insert the correct type
            const array = microstatements[microstatements.length - 1];
            array.outputType = typeBox;
            const arrayName = array.outputName;
            // Push the values into the array
            for (let i = 0; i < arrayLiteralContents.length; i++) {
                // Create a new variable to hold the size of the array value
                const size = FIXED_TYPES.includes(arrayLiteralContents[i].outputType.typename) ? "8" : "0";
                const sizeName = "_" + uuid_1.v4().replace(/-/g, "_");
                microstatements.push(new Microstatement(StatementType_1.default.CONSTDEC, scope, true, sizeName, Type_1.default.builtinTypes['int64'], [size], []));
                // Push the value into the array
                const opcodes = require('./opcodes').default;
                opcodes.exportScope.get('pusharr')[0].microstatementInlining([arrayName, arrayLiteralContents[i].outputName, sizeName], scope, microstatements);
            }
            // REREF the array
            microstatements.push(new Microstatement(StatementType_1.default.REREF, scope, true, arrayName, array.outputType, [], []));
        }
    }
    static closureDef(fns, scope, microstatements) {
        const closuredefName = "_" + uuid_1.v4().replace(/-/g, "_");
        // Keep any rerefs around as closure references
        const rerefs = microstatements.filter(m => m.statementType === StatementType_1.default.REREF);
        microstatements.push(new Microstatement(StatementType_1.default.CLOSUREDEF, scope, true, // TODO: What should this be?
        closuredefName, Type_1.default.builtinTypes['function'], [], fns, '', true, rerefs));
    }
    static closureFromUserFunction(userFunction, scope, microstatements, interfaceMap) {
        const fn = userFunction.maybeTransform(interfaceMap);
        const idx = microstatements.length;
        const args = Object.entries(fn.args);
        for (const [name, type] of args) {
            if (name !== "" && type.typename != "") {
                microstatements.push(new Microstatement(StatementType_1.default.CONSTDEC, scope, true, name, type));
            }
        }
        const len = microstatements.length - args.length;
        for (const s of fn.statements) {
            Microstatement.fromStatementsAst(s.statementAst, scope, microstatements);
        }
        microstatements.splice(idx, args.length);
        const newlen = microstatements.length;
        // There might be off-by-one bugs in the conversion here
        const innerMicrostatements = microstatements.slice(len, newlen);
        microstatements.splice(len, newlen - len);
        const constName = "_" + uuid_1.v4().replace(/-/g, "_");
        // if closure is not void return the last inner statement
        // TODO: Revisit this, if the closure doesn't have a type defined, sometimes it can only be
        // determined in the calling context and shouldn't be assumed to be `void`
        if (innerMicrostatements.length > 0 && fn.getReturnType() !== Type_1.default.builtinTypes.void) {
            const last = innerMicrostatements[innerMicrostatements.length - 1];
            innerMicrostatements.push(new Microstatement(StatementType_1.default.EXIT, scope, true, last.outputName, last.outputType));
        }
        microstatements.push(new Microstatement(StatementType_1.default.CLOSURE, scope, true, // TODO: Figure out if this is true or not
        constName, Type_1.default.builtinTypes['function'], [], [], '', fn.pure, innerMicrostatements, fn.args, fn.getReturnType()));
    }
    static fromEmitsAst(emitsAst, // TODO: Eliminate ANTLR
    scope, microstatements) {
        if (emitsAst.assignables() != null) {
            // If there's an assignable value here, add it to the list of microstatements first, then
            // rewrite the final const assignment as the emit statement.
            Microstatement.fromAssignablesAst(emitsAst.assignables(), scope, microstatements);
            const eventBox = scope.deepGet(emitsAst.eventref().getText()); // TODO: Port to fromVarAst when Box is removed
            if (!(eventBox instanceof Event_1.default)) {
                throw new Error(`${emitsAst.eventref().getText()} is not an event!
${emitsAst.getText()} on line ${emitsAst.start.line}:${emitsAst.start.column}`);
            }
            const last = microstatements[microstatements.length - 1];
            if (last.outputType != eventBox.type &&
                !eventBox.type.castable(last.outputType)) {
                throw new Error(`Attempting to assign a value of type ${last.outputType.typename} to an event of type ${eventBox.type.typename}
${emitsAst.getText()} on line ${emitsAst.start.line}:${emitsAst.start.column}`);
            }
            microstatements.push(new Microstatement(StatementType_1.default.EMIT, scope, true, eventBox.name, eventBox.type, [last.outputName], []));
        }
        else {
            // Otherwise, create an emit statement with no value
            const eventBox = scope.deepGet(emitsAst.eventref().getText()); // TODO: Port to fromVarAst
            if (!(eventBox instanceof Event_1.default)) {
                throw new Error(`${emitsAst.eventref().getText()} is not an event!
${emitsAst.getText()} on line ${emitsAst.start.line}:${emitsAst.start.column}`);
            }
            if (eventBox.type != Type_1.default.builtinTypes.void) {
                throw new Error(`${emitsAst.eventref().getText()} must have a value emitted to it!
${emitsAst.getText()} on line ${emitsAst.start.line}:${emitsAst.start.column}`);
            }
            microstatements.push(new Microstatement(StatementType_1.default.EMIT, scope, true, eventBox.name, Type_1.default.builtinTypes.void, [], []));
        }
    }
    static fromExitsAst(exitsAst, // TODO: Eliminate ANTLR
    scope, microstatements) {
        // `alan--` handlers don't have the concept of a `return` statement, the functions are all inlined
        // and the last assigned value for the function *is* the return statement
        if (exitsAst.assignables() != null) {
            // If there's an assignable value here, add it to the list of microstatements
            Microstatement.fromAssignablesAst(exitsAst.assignables(), scope, microstatements);
        }
        else {
            // Otherwise, create a microstatement with no value
            const constName = "_" + uuid_1.v4().replace(/-/g, "_");
            microstatements.push(new Microstatement(StatementType_1.default.CONSTDEC, scope, true, constName, Type_1.default.builtinTypes.void, ["void"], null));
        }
    }
    static fromAssignmentsAst(assignmentsAst, // TODO: Eliminate ANTLR
    scope, microstatements) {
        // For reassigning to a variable, we need to determine that the root variable is a
        // `let`-defined mutable variable and then tease out if any array or property accesses are done,
        // and if so we need to `register` a mutable reference to the array memory space and then update
        // the value with a `register` call from the assignables result address to the relevant inner
        // address of the last access argument. The format of a `varn` can only be the following:
        // `{moduleScope}.varName[arrayAccess].userProperty` where the array accesses and userProperties
        // can come in any order after the preamble. *Fortunately,* for this scenario, any situation
        // where `moduleScope` is included is invalid since only constants can be exported out of a
        // module, not mutable values, so we only need to read the *first* segment to immediately
        // determine if it is relevant or not -- if it comes back as a `Scope` object we abort with an
        // error. If not, then we find the relevant `Microstatement` and determine if it is a `const`
        // or a `let` declaration and abort if it is a `const`. After that, if there are no segments
        // beyond the first one, we simply take the `assignable` microstatement output and turn it into
        // an `ASSIGNMENT` StatementType, otherwise we need to go through a more complicated procedure
        // to `register` the `n-1` remaining inner array segments to new variables as references and
        // finally `register` the `assignable` into the location the last segment indicates.
        const segments = assignmentsAst.varn().varsegment();
        // Now, find the original variable and confirm that it actually is a let declaration
        const letName = segments[0].getText();
        let actualLetName;
        let original;
        for (let i = microstatements.length - 1; i >= 0; i--) {
            const microstatement = microstatements[i];
            if (microstatement.alias === letName) {
                actualLetName = microstatement.outputName;
                continue;
            }
            if (microstatement.outputName === actualLetName) {
                if (microstatement.statementType === StatementType_1.default.LETDEC) {
                    original = microstatement;
                    break;
                }
                else if (microstatement.statementType === StatementType_1.default.REREF) {
                    original = Microstatement.fromVarName(microstatement.outputName, scope, microstatements);
                    break;
                }
                else if (microstatement.statementType === StatementType_1.default.ASSIGNMENT) {
                    // We could treat this as evidence that it's cool, but let's just skip it.
                    continue;
                }
                else {
                    throw new Error(`Attempting to reassign a non-let variable.
${letName} on line ${assignmentsAst.start.line}:${assignmentsAst.start.column}`);
                }
            }
        }
        if (!original) {
            throw new Error(`Attempting to reassign to an undeclared variable
${letName} on line ${assignmentsAst.line}:${assignmentsAst.start.column}`);
        }
        if (segments.length === 1) { // Could be a simple let variable
            const letName = segments[0].getText();
            let actualLetName;
            for (let i = microstatements.length - 1; i >= 0; i--) {
                const microstatement = microstatements[i];
                if (microstatement.alias === letName) {
                    actualLetName = microstatement.outputName;
                    continue;
                }
                if (microstatement.outputName === actualLetName) {
                    if (microstatement.statementType === StatementType_1.default.LETDEC) {
                        break;
                    }
                    else if (microstatement.statementType === StatementType_1.default.REREF) {
                        original = Microstatement.fromVarName(microstatement.outputName, scope, microstatements);
                        break;
                    }
                    else if (microstatement.statementType === StatementType_1.default.ASSIGNMENT) {
                        // Could treat this as evidence that it's okay, but let's be sure about that
                        continue;
                    }
                    else {
                        throw new Error(`Attempting to reassign a non-let variable.
${letName} on line ${assignmentsAst.line}:${assignmentsAst.start.column}`);
                    }
                }
            }
            Microstatement.fromAssignablesAst(assignmentsAst.assignables(), scope, microstatements);
            // By definition the last microstatement is the const assignment we care about, so we can
            // just mutate its object to rename the output variable name to the name we need instead.
            let last = microstatements[microstatements.length - 1];
            if (last.statementType === StatementType_1.default.REREF) {
                // Find what it's rereferencing and adjust that, instead
                for (let i = microstatements.length - 2; i >= 0; i--) {
                    let m = microstatements[i];
                    if (m.outputName === last.outputName && m.statementType !== StatementType_1.default.REREF) {
                        last = m;
                        break;
                    }
                }
            }
            if (last.statementType === StatementType_1.default.LETDEC) {
                // Insert a ref call for this instead of mutating the original assignment
                Microstatement.fromAssignablesAst(Ast.assignablesAstFromString(`ref(${last.outputName})`), scope, microstatements);
                last = microstatements[microstatements.length - 1];
                if (last.statementType === StatementType_1.default.REREF) {
                    // Find what it's rereferencing and adjust that, instead
                    for (let i = microstatements.length - 2; i >= 0; i--) {
                        let m = microstatements[i];
                        if (m.outputName === last.outputName && m.statementType !== StatementType_1.default.REREF) {
                            last = m;
                            break;
                        }
                    }
                }
            }
            last.outputName = actualLetName;
            last.statementType = StatementType_1.default.ASSIGNMENT;
            // Attempt to "merge" the output types, useful for multiple branches assigning into the same
            // variable but only part of the type information is known in each branch (like in `Result`
            // or `Either` with the result value only in one branch or one type in each of the branches
            // for `Either`).
            if (original.outputType.typename !== last.outputType.typename) {
                if (!!original.outputType.iface) {
                    // Just overwrite if it's an interface type
                    original.outputType = last.outputType;
                }
                else if (!!original.outputType.originalType &&
                    !!last.outputType.originalType &&
                    original.outputType.originalType.typename === last.outputType.originalType.typename) {
                    // The tricky path, let's try to merge the two types together
                    const baseType = original.outputType.originalType;
                    const originalTypeAst = Ast.fulltypenameAstFromString(original.outputType.typename);
                    const lastTypeAst = Ast.fulltypenameAstFromString(last.outputType.typename);
                    const originalTypeGenerics = originalTypeAst.typegenerics();
                    const lastTypeGenerics = lastTypeAst.typegenerics();
                    const originalSubtypes = originalTypeGenerics ? originalTypeGenerics.fulltypename().map((t) => t.getText()) : [];
                    const lastSubtypes = lastTypeGenerics ? lastTypeGenerics.fulltypename().map((t) => t.getText()) : [];
                    const newSubtypes = [];
                    for (let i = 0; i < originalSubtypes.length; i++) {
                        if (originalSubtypes[i] === lastSubtypes[i]) {
                            newSubtypes.push(originalSubtypes[i]);
                        }
                        else {
                            let originalSubtype = scope.deepGet(originalSubtypes[i]);
                            if (!!originalSubtype.iface) {
                                newSubtypes.push(lastSubtypes[i]);
                            }
                            else if (!!originalSubtype.originalType) {
                                // TODO: Support nesting
                                newSubtypes.push(originalSubtypes[i]);
                            }
                            else {
                                newSubtypes.push(originalSubtypes[i]);
                            }
                        }
                    }
                    const newType = baseType.solidify(newSubtypes, scope);
                    original.outputType = newType;
                }
                else {
                    // Hmm... what to do here?
                    original.outputType = last.outputType;
                }
            }
            return;
        }
        // The more complicated path. First, rule out that the first segment is not a `scope`.
        const testBox = scope.deepGet(segments[0].getText());
        if (!!testBox && testBox instanceof Scope_1.default) {
            throw new Error(`Atempting to reassign to variable from another module
${assignmentsAst.varn().getText()} on line ${assignmentsAst.start.line}:${assignmentsAst.start.column}`);
        }
        let nestedLetType = original.outputType;
        for (let i = 1; i < segments.length - 1; i++) {
            const segment = segments[i];
            // A separator, just do nothing else this loop
            if (segment.METHODSEP())
                continue;
            // An array access. Until the grammar definition is reworked, this will parse correctly, but
            // it is banned in alan (due to being unable to catch and report assignment errors to arrays)
            if (segment.arrayaccess()) {
                throw new Error(`${segments.join('')} cannot be written to. Please use 'set' to mutate arrays and hash tables`);
            }
            // If it's a varname here, then we're accessing an inner property type. We need to figure out
            // which index it is in the underlying array structure and then `register` that piece (since
            // this is an intermediate access and not the final access point)
            if (segment.VARNAME()) {
                const fieldName = segment.VARNAME().getText();
                const fields = Object.keys(nestedLetType.properties);
                const fieldNum = fields.indexOf(fieldName);
                if (fieldNum < 0) {
                    // Invalid object access
                    throw new Error(`${letName} does not have a field named ${fieldName}
${assignmentsAst.varn().getText()} on line ${assignmentsAst.varn().start.line}:${assignmentsAst.varn().start.column}`);
                }
                // Create a new variable to hold the address within the array literal
                const addrName = "_" + uuid_1.v4().replace(/-/g, "_");
                microstatements.push(new Microstatement(StatementType_1.default.CONSTDEC, scope, true, addrName, Type_1.default.builtinTypes['int64'], [`${fieldNum}`], []));
                // Insert a `register` opcode.
                const opcodes = require('./opcodes').default;
                opcodes.exportScope.get('register')[0].microstatementInlining([original.outputName, addrName], scope, microstatements);
                // Now, we need to update the type we're working with.
                nestedLetType = Object.values(nestedLetType.properties)[fieldNum];
                // Now update the `original` record to the new `register` result
                original = microstatements[microstatements.length - 1];
            }
        }
        Microstatement.fromAssignablesAst(assignmentsAst.assignables(), scope, microstatements);
        // Grab a reference to the final assignment variable.
        const assign = microstatements[microstatements.length - 1];
        // Next, determine which kind of final segment this is and perform the appropriate action to
        // insert into with a `copytof` or `copytov` opcode.
        const copytoop = [
            'int8', 'int16', 'int32', 'int64', 'float32', 'float64', 'bool'
        ].includes(assign.outputType.typename) ? 'copytof' : 'copytov';
        const finalSegment = segments[segments.length - 1];
        if (finalSegment.arrayaccess()) {
            const assignables = finalSegment.arrayaccess().assignables();
            Microstatement.fromAssignablesAst(assignables, scope, microstatements);
            const lookup = microstatements[microstatements.length - 1];
            // TODO: Map support, which requires figuring out if the outer memory object is an array
            // or a map.
            if (lookup.outputType.typename !== 'int64') {
                throw new Error(`${finalSegment.getText()} cannot be used in an array lookup as it is not an int64
${letName} on line ${assignmentsAst.start.line}:${assignmentsAst.start.column}`);
            }
            // Insert a `copytof` or `copytov` opcode.
            const opcodes = require('./opcodes').default;
            opcodes.exportScope.get(copytoop)[0].microstatementInlining([original.outputName, lookup.outputName, assign.outputName], scope, microstatements);
        }
        else if (finalSegment.VARNAME()) {
            const fieldName = finalSegment.VARNAME().getText();
            const fields = Object.keys(nestedLetType.properties);
            const fieldNum = fields.indexOf(fieldName);
            if (fieldNum < 0) {
                // Invalid object access
                throw new Error(`${letName} does not have a field named ${fieldName}
${letName} on line ${assignmentsAst.start.line}:${assignmentsAst.start.column}`);
            }
            // Check if the new variable is allowed to be assigned to this object
            const originalType = nestedLetType.properties[fieldName];
            if (!originalType.typeApplies(assign.outputType, scope)) {
                throw new Error(`${letName}.${fieldName} is of type ${originalType.typename} but assigned a value of type ${assign.outputType.typename}`);
            }
            // Create a new variable to hold the address within the array literal
            const addrName = "_" + uuid_1.v4().replace(/-/g, "_");
            microstatements.push(new Microstatement(StatementType_1.default.CONSTDEC, scope, true, addrName, Type_1.default.builtinTypes['int64'], [`${fieldNum}`], []));
            // Insert a `copytof` or `copytov` opcode.
            const opcodes = require('./opcodes').default;
            opcodes.exportScope.get(copytoop)[0].microstatementInlining([original.outputName, addrName, assign.outputName], scope, microstatements);
        }
        else {
            throw new Error(`${finalSegment.getText()} cannot be the final piece in a reassignment statement
${letName} on line ${assignmentsAst.start.line}:${assignmentsAst.start.column}`);
        }
    }
    static fromLetdeclarationAst(letdeclarationAst, // TODO: Eliminate ANTLR
    scope, microstatements) {
        const letAlias = letdeclarationAst.VARNAME().getText();
        const letTypeHint = letdeclarationAst.fulltypename() ? letdeclarationAst.fulltypename().getText() : '';
        const typeBox = scope.deepGet(letTypeHint);
        if (typeBox === null && letTypeHint !== '') {
            // Try to define it if it's a generic type
            if (letdeclarationAst.fulltypename().typegenerics()) {
                const outerTypeBox = scope.deepGet(letdeclarationAst.fulltypename().typename().getText());
                if (outerTypeBox === null) {
                    throw new Error(`${letdeclarationAst.fulltypename().typename().getText()}  is not defined
${letdeclarationAst.getText()} on line ${letdeclarationAst.start.line}:${letdeclarationAst.start.column}`);
                }
                outerTypeBox.solidify(letdeclarationAst.fulltypename().typegenerics().fulltypename().map((t) => t.getText() // TODO: Eliminate ANTLR
                ), scope);
            }
        }
        Microstatement.fromAssignablesAst(letdeclarationAst.assignables(), scope, microstatements);
        // By definition the last microstatement is the const assignment we care about, so we can just
        // mutate its object to rename the output variable name to the name we need instead.
        // EXCEPT with Arrays and User Types. The last is a REREF, so follow it back to the original
        // and mutate that, instead
        let val = microstatements[microstatements.length - 1];
        if (val.statementType === StatementType_1.default.REREF) {
            val = Microstatement.fromVarName(val.alias, scope, microstatements);
        }
        val.statementType = StatementType_1.default.LETDEC;
        microstatements.push(new Microstatement(StatementType_1.default.REREF, scope, true, val.outputName, val.outputType, [], [], letAlias));
    }
    static fromConstdeclarationAst(constdeclarationAst, // TODO: Eliminate ANTLR
    scope, microstatements) {
        const constName = "_" + uuid_1.v4().replace(/-/g, "_");
        const constAlias = constdeclarationAst.VARNAME().getText();
        const constTypeHint = constdeclarationAst.fulltypename() ?
            constdeclarationAst.fulltypename().getText() :
            '';
        const typeBox = scope.deepGet(constTypeHint);
        if (typeBox === null && constTypeHint !== '') {
            // Try to define it if it's a generic type
            if (constdeclarationAst.fulltypename().typegenerics()) {
                const outerTypeBox = scope.deepGet(constdeclarationAst.fulltypename().typename().getText());
                if (outerTypeBox === null) {
                    throw new Error(`${constdeclarationAst.fulltypename().typename().getText()}  is not defined
${constdeclarationAst.getText()} on line ${constdeclarationAst.start.line}:${constdeclarationAst.start.column}`);
                }
                outerTypeBox.solidify(constdeclarationAst.fulltypename().typegenerics().fulltypename().map((t) => t.getText() // TODO: Eliminate ANTLR
                ), scope);
            }
        }
        Microstatement.fromAssignablesAst(constdeclarationAst.assignables(), scope, microstatements);
        // By definition the last microstatement is the const assignment we care about, so we can just
        // mutate its object to rename the output variable name to the name we need instead.
        microstatements.push(new Microstatement(StatementType_1.default.REREF, scope, true, microstatements[microstatements.length - 1].outputName, microstatements[microstatements.length - 1].outputType, [], [], constAlias));
    }
    // DFS recursive algo to get the microstatements in a valid ordering
    static fromStatementsAst(statementAst, // TODO: Eliminate ANTLR
    scope, microstatements) {
        if (statementAst.declarations() != null) {
            if (statementAst.declarations().constdeclaration() != null) {
                Microstatement.fromConstdeclarationAst(statementAst.declarations().constdeclaration(), scope, microstatements);
            }
            else {
                Microstatement.fromLetdeclarationAst(statementAst.declarations().letdeclaration(), scope, microstatements);
            }
        }
        if (statementAst.assignments() != null) {
            Microstatement.fromAssignmentsAst(statementAst.assignments(), scope, microstatements);
        }
        if (statementAst.assignables() != null) {
            Microstatement.fromAssignablesAst(statementAst.assignables(), scope, microstatements);
        }
        if (statementAst.exits() != null) {
            Microstatement.fromExitsAst(statementAst.exits(), scope, microstatements);
        }
        if (statementAst.emits() != null) {
            Microstatement.fromEmitsAst(statementAst.emits(), scope, microstatements);
        }
        return microstatements;
    }
    static fromBaseAssignableAst(baseAssignableAsts, // TODO: Eliminate ANTLR
    scope, microstatements) {
        // The base assignables array are a lightly annotated set of primitives that can be combined
        // together to produce an assignable value. Certain combinations of these primitives are invalid
        // and TODO provide good error messaging when these are encountered. A state machine of valid
        // transitions is defined below:
        //
        // null -> { var, obj, fn, const, group }
        // var -> { dot, arraccess, call, eos }
        // obj -> { dot, arraccess, eos }
        // fn -> { call, eos }
        // const -> { dot, eos }
        // group -> { dot, arraccess, eos }
        // call -> { call, arraccess, dot, eos }
        // arraccess -> { arraccess, dot, call, eos }
        //
        // Where `null` is the initial state and `eos` is end-of-statement terminating state. `var` is
        // some variable-name-like value (could be a scope, variable, property, or function name). `obj`
        // is object literal syntax, `fn` is function literal syntax, `const` is a constant literal.
        // `group)` is re-using the function call syntax to handle operator grouping (eg `2 * (3 + 4)`).
        // Because of how operators are mixed in with the assignables, the only time this syntax is used
        // as an operator grouping syntax is if it is the first element in the array. Otherwise it is
        // being used as a function call for a given function (either defined by a variable, an
        // inline-defined function, or a returned function from another call or array access) as `call`.
        // Finally `arraccess` is when an array (and ideally later a HashMap) is accessed. This mode is
        // also abusing the `obj` syntax, but only when it's an array literal with only one value and no
        // `new Array<foo>` type definition *and* when there are prior elements in the list. This means
        // `[0][0]` is unambiguous and would return a Result-wrapped zero value, for instance.
        //
        // The exact meaning of `var.var...` chains varies based on the elements of the array both
        // before and after such a chain. If the start of such a list, and if a `call` is at the end, it
        // could be something like `scope.variable.property.functionName(args)` where `.property` can
        // repeat multiple times over. Basically, to properly parse any `.var` requires both the prior
        // state *and* look-ahead to the next element in the list.
        //
        // All of this to re-iterate that for the sake of compile time, some of the complexities of the
        // grammar have been moved from the ANTLR definition into the compiler itself for performance
        // reasons, explaining the complicated iterative logic that follows.
        let currVal = null;
        for (let i = 0; i < baseAssignableAsts.length; i++) {
            const baseassignable = baseAssignableAsts[i];
            if (!!baseassignable.METHODSEP()) {
                if (i === 0) {
                    throw new Error(`Invalid start of assignable statement. Cannot begin with a dot (.)
${baseassignable.getText()} on line ${baseassignable.start.line}:${baseassignable.start.column}`);
                }
                const prevassignable = baseAssignableAsts[i - 1];
                if (!!prevassignable.METHODSEP()) {
                    throw new Error(`Invalid property access. You accidentally typed a dot twice in a row.
${baseassignable.getText()} on line ${baseassignable.start.line}:${baseassignable.start.column}`);
                }
                else if (!!prevassignable.functions()) {
                    throw new Error(`Invalid property access. Functions do not have properties.
${baseassignable.getText()} on line ${baseassignable.start.line}:${baseassignable.start.column}`);
                }
                // TODO: Do we even do anything else in this branch?
            }
            else if (!!baseassignable.VARNAME()) {
                const nextassignable = baseAssignableAsts[i + 1];
                if (!!nextassignable && !!nextassignable.fncall()) {
                    // This is a function call path
                    const fncall = nextassignable.fncall();
                    const argAsts = fncall.assignablelist() ? fncall.assignablelist().assignables() : [];
                    const argMicrostatements = argAsts.map(arg => {
                        Microstatement.fromAssignablesAst(arg, scope, microstatements);
                        return microstatements[microstatements.length - 1];
                    });
                    if (currVal === null) {
                        // This is a basic function call
                        const realArgNames = argMicrostatements.map(arg => arg.outputName);
                        const realArgTypes = argMicrostatements.map(arg => arg.outputType);
                        // Do a scan of the microstatements for an inner defined closure that might exist.
                        const fn = scope.deepGet(baseassignable.VARNAME().getText());
                        if (!fn ||
                            !(fn instanceof Array && fn[0].microstatementInlining instanceof Function)) {
                            const fnName = baseassignable.VARNAME().getText();
                            let actualFnName;
                            let inlinedClosure = false;
                            for (let i = microstatements.length - 1; i >= 0; i--) {
                                if (microstatements[i].alias === fnName) {
                                    actualFnName = microstatements[i].outputName;
                                    continue;
                                }
                                if (microstatements[i].outputName === actualFnName &&
                                    microstatements[i].statementType === StatementType_1.default.CLOSUREDEF) {
                                    const m = [...microstatements, ...microstatements[i].closureStatements];
                                    const fn = UserFunction_1.default.dispatchFn(microstatements[i].fns, realArgTypes, scope);
                                    const interfaceMap = new Map();
                                    Object.values(fn.getArguments()).forEach((t, i) => t.typeApplies(realArgTypes[i], scope, interfaceMap));
                                    Microstatement.closureFromUserFunction(fn, fn.scope || scope, m, interfaceMap);
                                    const closure = m.pop();
                                    microstatements.push(...closure.closureStatements.filter(s => s.statementType !== StatementType_1.default.EXIT));
                                    currVal = microstatements[microstatements.length - 1];
                                    inlinedClosure = true;
                                    break;
                                }
                            }
                            if (!inlinedClosure) {
                                throw new Error(`${baseassignable.VARNAME().getText()} is not a function but used as one.
${baseassignable.getText()} on line ${baseassignable.start.line}:${baseassignable.start.column}`);
                            }
                        }
                        else {
                            // Generate the relevant microstatements for this function. UserFunctions get inlined
                            // with the return statement turned into a const assignment as the last statement,
                            // while built-in functions are kept as function calls with the correct renaming.
                            UserFunction_1.default
                                .dispatchFn(fn, realArgTypes, scope)
                                .microstatementInlining(realArgNames, scope, microstatements);
                            currVal = microstatements[microstatements.length - 1];
                        }
                    }
                    else if (currVal instanceof Scope_1.default) {
                        // This is calling a function by its parent scope
                        const realArgNames = argMicrostatements.map(arg => arg.outputName);
                        const realArgTypes = argMicrostatements.map(arg => arg.outputType);
                        const fn = currVal.deepGet(baseassignable.VARNAME().getText());
                        if (!fn ||
                            !(fn instanceof Array && fn[0].microstatementInlining instanceof Function)) {
                            throw new Error(`${baseassignable.VARNAME().getText()} is not a function but used as one.
${baseassignable.getText()} on line ${baseassignable.start.line}:${baseassignable.start.column}`);
                        }
                        // Generate the relevant microstatements for this function. UserFunctions get inlined
                        // with the return statement turned into a const assignment as the last statement,
                        // while built-in functions are kept as function calls with the correct renaming.
                        UserFunction_1.default
                            .dispatchFn(fn, realArgTypes, scope)
                            .microstatementInlining(realArgNames, scope, microstatements);
                        currVal = microstatements[microstatements.length - 1];
                    }
                    else { // It's a method-style function call
                        const realArgNames = [
                            currVal.outputName,
                            ...argMicrostatements.map(arg => arg.outputName)
                        ];
                        const realArgTypes = [
                            currVal.outputType,
                            ...argMicrostatements.map(arg => arg.outputType)
                        ];
                        const fn = scope.deepGet(baseassignable.VARNAME().getText());
                        if (!fn ||
                            !(fn instanceof Array && fn[0].microstatementInlining instanceof Function)) {
                            throw new Error(`${baseassignable.VARNAME().getText()} is not a function but used as one.
${baseassignable.getText()} on line ${baseassignable.start.line}:${baseassignable.start.column}`);
                        }
                        // Generate the relevant microstatements for this function. UserFunctions get inlined
                        // with the return statement turned into a const assignment as the last statement,
                        // while built-in functions are kept as function calls with the correct renaming.
                        UserFunction_1.default
                            .dispatchFn(fn, realArgTypes, scope)
                            .microstatementInlining(realArgNames, scope, microstatements);
                        currVal = microstatements[microstatements.length - 1];
                    }
                    // Intentionally skip over the `fncall` block on the next iteration
                    i++;
                }
                else {
                    if (currVal === null) {
                        let thing = Microstatement.fromVarName(baseassignable.VARNAME().getText(), scope, microstatements);
                        if (!thing) {
                            thing = scope.deepGet(baseassignable.VARNAME().getText());
                        }
                        if (!thing) {
                            throw new Error(`${baseassignable.VARNAME().getText()} not found.
  ${baseassignable.getText()} on line ${baseassignable.start.line}:${baseassignable.start.column}`);
                        }
                        currVal = thing;
                    }
                    else if (currVal instanceof Scope_1.default) {
                        const thing = currVal.deepGet(baseassignable.VARNAME().getText());
                        if (!thing) {
                            throw new Error(`${baseassignable.VARNAME().getText()} not found in other scope.
  ${baseassignable.getText()} on line ${baseassignable.start.line}:${baseassignable.start.column}`);
                        }
                        currVal = thing;
                    }
                    else if (currVal instanceof Microstatement) {
                        const fieldName = baseassignable.VARNAME().getText();
                        const fields = Object.keys(currVal.outputType.properties);
                        const fieldNum = fields.indexOf(fieldName);
                        if (fieldNum < 0) {
                            // Invalid object access
                            throw new Error(`${fieldName} property not found.
  ${baseassignable.getText()} on line ${baseassignable.start.line}:${baseassignable.start.column}`);
                        }
                        // Create a new variable to hold the address within the array literal
                        const addrName = "_" + uuid_1.v4().replace(/-/g, "_");
                        microstatements.push(new Microstatement(StatementType_1.default.CONSTDEC, scope, true, addrName, Type_1.default.builtinTypes['int64'], [`${fieldNum}`], []));
                        // Insert a `register` opcode.
                        const opcodes = require('./opcodes').default;
                        opcodes.exportScope.get('register')[0].microstatementInlining([currVal.outputName, addrName], scope, microstatements);
                        // We'll need a reference to this for later
                        const typeRecord = currVal;
                        // Set the original to this newly-generated microstatement
                        currVal = microstatements[microstatements.length - 1];
                        // Now we do something odd, but correct here; we need to replace the `outputType` from
                        // `any` to the type that was actually copied so function resolution continues to work
                        currVal.outputType = typeRecord.outputType.properties[fieldName];
                    }
                    else {
                        // What is this?
                        throw new Error(`Impossible path found. Bug in compiler, please report!
Previous value type: ${typeof currVal}
${baseassignable.getText()} on line ${baseassignable.start.line}:${baseassignable.start.column}`);
                    }
                }
            }
            else if (!!baseassignable.constants()) {
                if (currVal !== null) {
                    throw new Error(`Unexpected constant value detected.
Previous value type: ${typeof currVal}
${baseassignable.getText()} on line ${baseassignable.start.line}:${baseassignable.start.column}`);
                }
                Microstatement.fromConstantsAst(baseassignable.constants(), scope, microstatements);
                currVal = microstatements[microstatements.length - 1];
            }
            else if (!!baseassignable.functions()) {
                if (currVal !== null) {
                    throw new Error(`Unexpected function definition detected.
Previous value type: ${typeof currVal}
${baseassignable.getText()} on line ${baseassignable.start.line}:${baseassignable.start.column}`);
                }
                // So the closures eval correctly, we add the alias microstatements to the scope
                // TODO: Is this the right approach?
                microstatements.filter(m => !!m.alias).forEach(m => scope.put(m.alias, m));
                const fn = UserFunction_1.default.fromFunctionsAst(baseassignable.functions(), scope);
                currVal = fn; // TODO: Is this the right choice here?
            }
            else if (!!baseassignable.objectliterals()) {
                if (currVal === null) {
                    // Has to be a "normal" object literal in this case
                    Microstatement.fromObjectLiteralsAst(baseassignable.objectliterals(), scope, microstatements);
                    currVal = microstatements[microstatements.length - 1];
                }
                else {
                    // Can only be an array accessor syntax
                    const objlit = baseassignable.objectliterals();
                    if (!!objlit.typeliteral() || !!objlit.arrayliteral().literaldec()) {
                        throw new Error(`Unexpected object literal definition detected.
Previous value type: ${typeof currVal}
${baseassignable.getText()} on line ${baseassignable.start.line}:${baseassignable.start.column}`);
                    }
                    const arrbase = objlit.arrayliteral().arraybase();
                    if (!arrbase.assignablelist() || arrbase.assignablelist().assignables().length !== 1) {
                        throw new Error(`Array access must provide only one index value to query the array with
${baseassignable.getText()} on line ${baseassignable.start.line}:${baseassignable.start.column}`);
                    }
                    const assignableAst = arrbase.assignablelist().assignables(0);
                    Microstatement.fromAssignablesAst(assignableAst, scope, microstatements);
                    const arrIndex = microstatements[microstatements.length - 1];
                    if (arrIndex.outputType.typename !== 'int64') {
                        throw new Error(`Array access must be done with an int64 value
${baseassignable.getText()} on line ${baseassignable.start.line}:${baseassignable.start.column}`);
                    }
                    if (!(currVal instanceof Microstatement) ||
                        currVal.outputType.originalType.typename !== 'Array') {
                        throw new Error(`Array access may only be performed on arrays.
Previous value type: ${currVal.outputType.typename}
${baseassignable.getText()} on line ${baseassignable.start.line}:${baseassignable.start.column}`);
                    }
                    // All of those safeguards out of the way, time to extract the desired value
                    // Insert a `resfrom` opcode.
                    const opcodes = require('./opcodes').default;
                    opcodes.exportScope.get('resfrom')[0].microstatementInlining([currVal.outputName, arrIndex.outputName], scope, microstatements);
                    // We'll need a reference to this for later
                    const arrayRecord = currVal;
                    // Update to this newly-generated microstatement
                    currVal = microstatements[microstatements.length - 1];
                    // Now we do something odd, but correct here; we need to replace the `outputType` from
                    // `any` to the type that was actually copied so function resolution continues to work
                    currVal.outputType = Type_1.default.builtinTypes.Result.solidify([Object.values(arrayRecord.outputType.properties)[0].typename], scope);
                }
            }
            else if (!!baseassignable.fncall()) {
                // It's a `fncall` syntax block but it wasn't caught in a function call before, so it's
                // either a function call on a returned function type, or it's an assignable group
                if (!currVal) {
                    // It's probably an assignable group
                    if (!baseassignable.fncall().assignablelist() ||
                        baseassignable.fncall().assignablelist().assignables().length !== 1) {
                        throw new Error(`Expected a group of assignable values, but got a function call signature.
${baseassignable.getText()} on line ${baseassignable.start.line}:${baseassignable.start.column}`);
                    }
                    // It *is* an assignable group!
                    Microstatement.fromAssignablesAst(baseassignable.fncall().assignablelist().assignables(0), scope, microstatements);
                    currVal = microstatements[microstatements.length - 1];
                }
                else {
                    // TODO: handle functions/closures being called from access out of other function returns
                    // and the like
                }
            }
            else {
                throw new Error(`Compiler error! Completely unhandled input.
${baseassignable.getText()} on line ${baseassignable.start.line}:${baseassignable.start.column}`);
            }
        }
        if (!(currVal instanceof Microstatement)) {
            if (currVal instanceof UserFunction_1.default) {
                Microstatement.closureDef([currVal], currVal.scope || scope, microstatements);
            }
            else if (currVal instanceof Array && currVal[0] instanceof UserFunction_1.default) {
                Microstatement.closureDef(currVal, currVal[0].scope || scope, microstatements);
            }
        }
        else if (currVal.statementType !== StatementType_1.default.EMIT) {
            microstatements.push(new Microstatement(StatementType_1.default.REREF, scope, true, currVal.outputName, currVal.outputType, [], [], currVal.alias));
        }
    }
    static fromAssignablesAst(assignablesAst, // TODO: Eliminate ANTLR
    scope, microstatements) {
        const withoperators = assignablesAst.withoperators();
        let withOperatorsList = [];
        for (const operatorOrAssignable of withoperators) {
            if (!!operatorOrAssignable.operators()) {
                const operator = operatorOrAssignable.operators();
                const op = scope.deepGet(operator.getText());
                if (op == null || !(op instanceof Array && op[0] instanceof Operator_1.default)) {
                    throw new Error("Operator " + operator.getText() + " is not defined");
                }
                withOperatorsList.push(op);
            }
            else if (!!operatorOrAssignable.baseassignable() &&
                operatorOrAssignable.baseassignable().length > 0) {
                Microstatement.fromBaseAssignableAst(operatorOrAssignable.baseassignable(), scope, microstatements);
                const last = microstatements[microstatements.length - 1];
                withOperatorsList.push(last);
            }
        }
        // Now to combine these operators and values in the correct order. A compiled language could
        // never do something so inefficient, but I don't care about performance right now, so here's
        // the algorithm: while the list length is greater than 1, perform the two steps:
        // 1. Find the operator with the greatest precedence
        // 2. Apply the underlying function to the values on either side of the operator (or just the
        //    right side if the operator is a prefix operator), then replace the operator with the
        //    returned value in the list and delete the impacted values.
        while (withOperatorsList.length > 1) {
            let maxPrecedence = -1;
            let maxOperatorLoc = -1;
            let maxOperatorListLoc = -1;
            for (let i = 0; i < withOperatorsList.length; i++) {
                if (withOperatorsList[i] instanceof Array && withOperatorsList[i][0] instanceof Operator_1.default) {
                    const ops = withOperatorsList[i];
                    let op = null;
                    let operatorListLoc = -1;
                    let operatorPrecedence = -127;
                    if (ops.length == 1) {
                        op = ops[0];
                        operatorListLoc = 0;
                    }
                    else {
                        // TODO: We need to identify which particular operator applies in this case.
                        // We're just going to short-circuit this process on the first operator that matches
                        // but we need to come up with a "best match" behavior (ie, if one argument is an int8
                        // it may choose the int64-based operator because it was first and it can cast int8 to
                        // int64 and then miss the specialized int8 version of the function).
                        let left = null;
                        if (i != 0)
                            left = withOperatorsList[i - 1];
                        let right = null;
                        if (i != withOperatorsList.length - 1)
                            right = withOperatorsList[i + 1];
                        // Skip over any operator that is followed by another operator as it must be a prefix
                        // operator (or a syntax error, but we'll catch that later)
                        if (right === null || right instanceof Microstatement) {
                            for (let j = 0; j < ops.length; j++) {
                                if (ops[j].precedence > operatorPrecedence &&
                                    ops[j].applicableFunction(!left ? // Left is special, if two operators are in a row, this one
                                        null : // needs to be a prefix operator for this to work at all
                                        left instanceof Microstatement ?
                                            left.outputType :
                                            null, right === null ? null : right.outputType, scope) != null) {
                                    op = ops[j];
                                    operatorListLoc = j;
                                    operatorPrecedence = op.precedence;
                                }
                            }
                        }
                        // During the process of determining the operator ordering, there may be tests that
                        // will not match because operator precedence will convert the neighboring types into
                        // types that will match. This is complicated and doing this statically will be more
                        // difficult, but for now, just skip over these.
                        if (op == null)
                            continue;
                    }
                    if (op.precedence > maxPrecedence) {
                        maxPrecedence = op.precedence;
                        maxOperatorLoc = i;
                        maxOperatorListLoc = operatorListLoc;
                    }
                }
            }
            if (maxPrecedence == -1 || maxOperatorLoc == -1) {
                let errMsg = `Cannot resolve operators with remaining statement
${assignablesAst.getText()}`;
                let withOperatorsTranslation = [];
                for (let i = 0; i < withOperatorsList.length; i++) {
                    const node = withOperatorsList[i];
                    if (node instanceof Array && node[0] instanceof Operator_1.default) {
                        withOperatorsTranslation.push(node[0].name);
                    }
                    else {
                        withOperatorsTranslation.push("<" + node.outputType.typename + ">");
                    }
                }
                errMsg += '\n' + withOperatorsTranslation.join(' ');
                throw new Error(errMsg);
            }
            const op = withOperatorsList[maxOperatorLoc][maxOperatorListLoc];
            let realArgNames = [];
            let realArgTypes = [];
            if (!op.isPrefix) {
                const left = withOperatorsList[maxOperatorLoc - 1];
                realArgNames.push(left.outputName);
                realArgTypes.push(left.outputType);
            }
            const right = withOperatorsList[maxOperatorLoc + 1];
            realArgNames.push(right.outputName);
            realArgTypes.push(right.outputType);
            UserFunction_1.default
                .dispatchFn(op.potentialFunctions, realArgTypes, scope)
                .microstatementInlining(realArgNames, scope, microstatements);
            const last = microstatements[microstatements.length - 1];
            withOperatorsList[maxOperatorLoc] = last;
            withOperatorsList.splice(maxOperatorLoc + 1, 1);
            if (!op.isPrefix) {
                withOperatorsList.splice(maxOperatorLoc - 1, 1);
            }
        }
    }
    static fromStatement(statement, microstatements, secondaryScope = null) {
        let actualStatement = statement;
        if (secondaryScope !== null) {
            const newScope = new Scope_1.default(statement.scope);
            newScope.secondaryPar = secondaryScope;
            actualStatement = new Statement_1.default(statement.statementAst, newScope, statement.pure);
        }
        Microstatement.fromStatementsAst(actualStatement.statementAst, actualStatement.scope, microstatements);
    }
}
exports.default = Microstatement;

},{"./Ast":10,"./Constant":11,"./Event":12,"./Operator":15,"./Scope":16,"./Statement":17,"./StatementType":18,"./Type":19,"./UserFunction":20,"./opcodes":22,"uuid":118}],14:[function(require,module,exports){
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const Ast = require("./Ast");
const Constant_1 = require("./Constant");
const Event_1 = require("./Event");
const Operator_1 = require("./Operator");
const Scope_1 = require("./Scope");
const UserFunction_1 = require("./UserFunction");
const Type_1 = require("./Type");
const modules = {};
class Module {
    constructor(rootScope) {
        // Thoughts on how to handle this right now:
        // 1. The outermost module scope is read-only always.
        // 2. Therefore anything in the export scope can simply be duplicated in both scopes
        // 3. Therefore export scope needs access to the module scope so the functions function, but
        //    the module scope can just use its local copy
        this.moduleScope = new Scope_1.default(rootScope);
        this.exportScope = new Scope_1.default(this.moduleScope);
    }
    static getAllModules() {
        return modules;
    }
    static populateModule(path, ast, // ModuleContext
    rootScope, isStd = false) {
        // First, take the export scope of the root scope and put references to it in this module. If
        // it is a built-in std module, it inherits from the root scope, otherwise it attaches all
        // exported references. This way std modules get access to the opcode scope via inheritance and
        // 'normal' modules do not.
        let module = new Module(isStd ? rootScope : undefined);
        if (!isStd) {
            for (const rootModuleName of Object.keys(rootScope.vals)) {
                module.moduleScope.put(rootModuleName, rootScope.vals[rootModuleName]);
            }
        }
        // Now, populate all of the imports
        const imports = ast.imports();
        for (const importAst of imports) {
            // Figure out which kind of import format we're dealing with
            const standardImport = importAst.standardImport();
            const fromImport = importAst.fromImport();
            // If it's a "standard" import, figure out what name to call it (if the user overrode it)
            // and then attach the entire module with that name to the local scope.
            if (!!standardImport) {
                let importName;
                if (standardImport.AS() != null) {
                    importName = standardImport.VARNAME().getText();
                }
                else if (standardImport.dependency().localdependency() != null) {
                    let nameParts = standardImport.dependency().localdependency().getText().split("/");
                    importName = nameParts[nameParts.length - 1];
                }
                else if (standardImport.dependency().globaldependency() != null) {
                    let nameParts = standardImport.dependency().globaldependency().getText().split("/");
                    importName = nameParts[nameParts.length - 1];
                }
                else {
                    // What?
                    throw new Error("This path should be impossible");
                }
                const importedModule = modules[Ast.resolveDependency(path, standardImport.dependency())];
                module.moduleScope.put(importName, importedModule.exportScope);
            }
            // If it's a "from" import, we're picking off pieces of the exported scope and inserting them
            // also potentially renaming them if requested by the user
            if (!!fromImport) {
                const importedModule = modules[Ast.resolveDependency(path, fromImport.dependency())];
                const vars = fromImport.varlist().renameablevar();
                for (const moduleVar of vars) {
                    let importName;
                    const exportName = moduleVar.varop(0).getText();
                    if (moduleVar.AS() != null) {
                        importName = moduleVar.varop(1).getText();
                    }
                    else {
                        importName = moduleVar.varop(0).getText();
                    }
                    const thing = importedModule.exportScope.shallowGet(exportName);
                    if (thing instanceof Array && thing[0].microstatementInlining instanceof Function) {
                        const otherthing = module.moduleScope.deepGet(importName);
                        if (!!otherthing &&
                            otherthing instanceof Array &&
                            otherthing[0].microstatementInlining instanceof Function) {
                            module.moduleScope.put(importName, [...thing, ...otherthing]);
                        }
                        else {
                            module.moduleScope.put(importName, thing);
                        }
                    }
                    else if (thing instanceof Array && thing[0] instanceof Operator_1.default) {
                        const otherthing = module.moduleScope.deepGet(importName);
                        if (!!otherthing && otherthing instanceof Array && otherthing instanceof Operator_1.default) {
                            module.moduleScope.put(importName, [...thing, ...otherthing]);
                        }
                        else {
                            module.moduleScope.put(importName, thing);
                        }
                    }
                    else {
                        module.moduleScope.put(importName, thing);
                    }
                    // Special behavior for interfaces. If there are any functions or operators that match
                    // the interface, pull them in. Similarly any types that match the entire interface. This
                    // allows concise importing of a related suite of tools without having to explicitly call
                    // out each one.
                    if (thing instanceof Type_1.Type && thing.iface) {
                        const iface = thing.iface;
                        const typesToCheck = Object.keys(importedModule.exportScope.vals)
                            .map(n => importedModule.exportScope.vals[n])
                            .filter(v => v instanceof Type_1.Type);
                        const fnsToCheck = Object.keys(importedModule.exportScope.vals)
                            .map(n => importedModule.exportScope.vals[n])
                            .filter(v => v instanceof Array && v[0].microstatementInlining instanceof Function);
                        const opsToCheck = Object.keys(importedModule.exportScope.vals)
                            .map(n => importedModule.exportScope.vals[n])
                            .filter(v => v instanceof Array && v[0] instanceof Operator_1.default);
                        typesToCheck
                            .filter(t => iface.typeApplies(t, importedModule.exportScope))
                            .forEach(t => {
                            module.moduleScope.put(t.typename, t);
                        });
                        fnsToCheck
                            .filter(fn => {
                            // TODO: Make this better and move it to the Interface file in the future
                            return iface.functionTypes.some((ft) => ft.functionname === fn[0].getName());
                        })
                            .forEach(fn => {
                            module.moduleScope.put(fn[0].getName(), fn);
                        });
                        opsToCheck
                            .filter(op => {
                            return iface.operatorTypes.some((ot) => ot.operatorname === op[0].name);
                        })
                            .forEach(op => {
                            module.moduleScope.put(op[0].name, op);
                        });
                    }
                }
            }
        }
        // Next, types
        const types = ast.types();
        for (const typeAst of types) {
            const newType = Type_1.Type.fromAst(typeAst, module.moduleScope);
            module.moduleScope.put(newType.typename, newType.alias ? newType.alias : newType);
        }
        // Next, interfaces
        const interfaces = ast.interfaces();
        for (const interfaceAst of interfaces) {
            Type_1.Interface.fromAst(interfaceAst, module.moduleScope);
            // Automatically inserts the interface into the module scope, we're done.
        }
        // Next, constants
        const constdeclarations = ast.constdeclaration();
        for (const constdeclaration of constdeclarations) {
            Constant_1.default.fromAst(constdeclaration, module.moduleScope);
        }
        // Next, events
        const events = ast.events();
        for (const eventAst of events) {
            const newEvent = Event_1.default.fromAst(eventAst, module.moduleScope);
            module.moduleScope.put(newEvent.name, newEvent);
        }
        // Next, functions
        const functions = ast.functions();
        for (const functionAst of functions) {
            const newFunc = UserFunction_1.default.fromAst(functionAst, module.moduleScope);
            if (newFunc.getName() == null) {
                throw new Error("Module-level functions must have a name");
            }
            let fns = module.moduleScope.get(newFunc.getName());
            if (fns == null) {
                module.moduleScope.put(newFunc.getName(), [newFunc]);
            }
            else {
                fns.push(newFunc);
            }
        }
        // Next, operators
        const operatorMapping = ast.operatormapping();
        for (const operatorAst of operatorMapping) {
            const isPrefix = operatorAst.INFIX() === null;
            const name = operatorAst.fntoop().operators().getText().trim();
            const precedence = parseInt(operatorAst.opprecedence().NUMBERCONSTANT().getText(), 10);
            const fns = module.moduleScope.deepGet(operatorAst.fntoop().eventref().getText());
            if (fns == null) {
                throw new Error("Operator " + name + " declared for unknown function " + operatorAst.varn().getText());
            }
            const op = new Operator_1.default(name, precedence, isPrefix, fns);
            const opsBox = module.moduleScope.deepGet(name);
            if (!opsBox) {
                module.moduleScope.put(name, [op]);
            }
            else {
                // To make sure we don't accidentally mutate other scopes, we're cloning this operator list
                let ops = [...opsBox];
                ops.push(op);
                module.moduleScope.put(name, ops);
            }
        }
        // Next, exports, which can be most of the above
        const exports = ast.exports();
        for (const exportAst of exports) {
            if (exportAst.eventref() != null) {
                const exportVar = module.moduleScope.deepGet(exportAst.eventref().getText());
                const splitName = exportAst.eventref().getText().split(".");
                module.moduleScope.put(splitName[splitName.length - 1], exportVar);
                module.exportScope.put(splitName[splitName.length - 1], exportVar);
            }
            else if (exportAst.types() != null) {
                const newType = Type_1.Type.fromAst(exportAst.types(), module.moduleScope);
                const typeBox = !newType.alias ? newType : newType.alias;
                module.moduleScope.put(newType.typename, typeBox);
                module.exportScope.put(newType.typename, typeBox);
            }
            else if (exportAst.interfaces() != null) {
                const interfaceBox = Type_1.Interface.fromAst(exportAst.interfaces(), module.moduleScope);
                // Automatically inserts the interface into the module scope
                module.exportScope.put(interfaceBox.typename, interfaceBox);
            }
            else if (exportAst.constdeclaration() != null) {
                const constVal = Constant_1.default.fromAst(exportAst.constdeclaration(), module.moduleScope);
                module.exportScope.put(constVal.name, constVal);
            }
            else if (exportAst.functions() != null) {
                const newFunc = UserFunction_1.default.fromAst(exportAst.functions(), module.moduleScope);
                if (newFunc.getName() == null) {
                    throw new Error("Module-level functions must have a name");
                }
                // Exported scope must be checked first because it will fall through to the not-exported
                // scope by default.
                let expFns = module.exportScope.shallowGet(newFunc.getName());
                if (!expFns) {
                    module.exportScope.put(newFunc.getName(), [newFunc]);
                }
                else {
                    expFns.push(newFunc);
                }
                let modFns = module.moduleScope.get(newFunc.getName());
                if (!modFns) {
                    module.moduleScope.put(newFunc.getName(), [newFunc]);
                }
                else {
                    modFns.push(newFunc);
                }
            }
            else if (exportAst.operatormapping() != null) {
                const operatorAst = exportAst.operatormapping();
                const isPrefix = operatorAst.INFIX() == null;
                const name = operatorAst.fntoop().operators().getText().trim();
                const precedence = parseInt(operatorAst.opprecedence().NUMBERCONSTANT().getText(), 10);
                let fns = module.exportScope.deepGet(operatorAst.fntoop().eventref().getText());
                if (!fns) {
                    fns = module.moduleScope.deepGet(operatorAst.fntoop().eventref().getText());
                    if (!!fns) {
                        throw new Error("Exported operator " +
                            name +
                            " wrapping unexported function " +
                            operatorAst.varn().getText() +
                            " which is not allowed, please export the function, as well.");
                    }
                    throw new Error("Operator " + name + " declared for unknown function " + operatorAst.varn().getText());
                }
                const op = new Operator_1.default(name, precedence, isPrefix, fns);
                let modOpsBox = module.moduleScope.deepGet(name);
                if (!modOpsBox) {
                    module.moduleScope.put(name, [op]);
                }
                else {
                    let ops = [...modOpsBox];
                    ops.push(op);
                    module.moduleScope.put(name, ops);
                }
                let expOpsBox = module.exportScope.deepGet(name);
                if (!expOpsBox) {
                    module.exportScope.put(name, [op]);
                }
                else {
                    let ops = [...expOpsBox];
                    ops.push(op);
                    module.exportScope.put(name, ops);
                }
            }
            else if (exportAst.events() != null) {
                const newEvent = Event_1.default.fromAst(exportAst.events(), module.moduleScope);
                module.moduleScope.put(newEvent.name, newEvent);
                module.exportScope.put(newEvent.name, newEvent);
            }
            else {
                // What?
                throw new Error("What should be an impossible export state has been reached.");
            }
        }
        // Finally, event handlers, so they can depend on events that are exported from the same module
        const handlers = ast.handlers();
        for (const handlerAst of handlers) {
            let evt = null;
            if (handlerAst.eventref() != null) {
                evt = module.moduleScope.deepGet(handlerAst.eventref().getText());
            }
            if (!evt) {
                throw new Error("Could not find specified event: " + handlerAst.eventref().getText());
            }
            if (!(evt instanceof Event_1.default)) {
                throw new Error(handlerAst.eventref().getText() + " is not an event");
            }
            let fn = null;
            if (handlerAst.typename() != null) {
                const fnName = handlerAst.typename().getText();
                const fns = module.moduleScope.deepGet(handlerAst.typename().getText());
                if (!fns) {
                    throw new Error("Could not find specified function: " + fnName);
                }
                if (!(fns instanceof Array && fns[0].microstatementInlining instanceof Function)) {
                    throw new Error(fnName + " is not a function");
                }
                for (let i = 0; i < fns.length; i++) {
                    if (evt.type.typename === "void" && Object.values(fns[i].getArguments()).length === 0) {
                        fn = fns[i];
                        break;
                    }
                    const argTypes = Object.values(fns[i].getArguments());
                    if (argTypes.length !== 1)
                        continue;
                    if (argTypes[0] == evt.type) {
                        fn = fns[i];
                        break;
                    }
                }
                if (fn == null) {
                    throw new Error("Could not find function named " + fnName + " with matching function signature");
                }
            }
            if (handlerAst.functions() != null) {
                fn = UserFunction_1.default.fromAst(handlerAst.functions(), module.moduleScope);
            }
            if (handlerAst.functionbody() != null) {
                fn = UserFunction_1.default.fromAst(handlerAst.functionbody(), module.moduleScope);
            }
            if (fn == null) {
                // Shouldn't be possible
                throw new Error("Impossible state reached processing event handler");
            }
            if (Object.keys(fn.getArguments()).length > 1 ||
                (evt.type === Type_1.Type.builtinTypes["void"] && Object.keys(fn.getArguments()).length !== 0)) {
                throw new Error("Function provided for " + handlerAst.eventref().getText() + " has invalid argument signature");
            }
            evt.handlers.push(fn);
        }
        return module;
    }
    static modulesFromAsts(astMap, // string to ModuleContext
    rootScope) {
        let modulePaths = Object.keys(astMap);
        while (modulePaths.length > 0) {
            for (let i = 0; i < modulePaths.length; i++) {
                const path = modulePaths[i];
                const moduleAst = astMap[path];
                const imports = Ast.resolveImports(path, moduleAst);
                let loadable = true;
                for (const importPath of imports) {
                    if (importPath[0] === '@')
                        continue;
                    if (modules.hasOwnProperty(importPath))
                        continue;
                    loadable = false;
                }
                if (!loadable)
                    continue;
                modulePaths.splice(i, 1);
                i--;
                const module = Module.populateModule(path, moduleAst, rootScope);
                modules[path] = module;
            }
        }
        return modules;
    }
}
exports.default = Module;

},{"./Ast":10,"./Constant":11,"./Event":12,"./Operator":15,"./Scope":16,"./Type":19,"./UserFunction":20}],15:[function(require,module,exports){
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const Ast = require("./Ast");
const Type_1 = require("./Type");
class Operator {
    constructor(name, precedence, isPrefix, potentialFunctions) {
        this.name = name;
        this.precedence = precedence;
        this.isPrefix = isPrefix;
        this.potentialFunctions = potentialFunctions;
    }
    applicableFunction(left, right, scope) {
        let argumentTypeList = [];
        if (!this.isPrefix) {
            if (left == null)
                return null;
            argumentTypeList.push(left);
        }
        argumentTypeList.push(right);
        const fns = this.potentialFunctions;
        for (let i = 0; i < fns.length; i++) {
            const args = fns[i].getArguments();
            const argList = Object.values(args);
            if (argList.length != argumentTypeList.length)
                continue;
            let skip = false;
            for (let j = 0; j < argList.length; j++) {
                if (argList[j].typename === argumentTypeList[j].typename)
                    continue;
                if (argList[j].iface &&
                    argList[j].iface.typeApplies(argumentTypeList[j], scope))
                    continue;
                if (argList[j].generics.length > 0 && argumentTypeList[j].originalType == argList[j]) {
                    continue;
                }
                if (argList[j].originalType != null &&
                    argumentTypeList[j].originalType == argList[j].originalType) {
                    const argListAst = Ast.fulltypenameAstFromString(argList[j].typename);
                    const argumentTypeListAst = Ast.fulltypenameAstFromString(argumentTypeList[j].typename);
                    const len = argListAst.typegenerics() ?
                        argListAst.typegenerics().fulltypename().length : 0;
                    let innerSkip = false;
                    for (let i = 0; i < len; i++) {
                        const argListTypeProp = argListAst.typegenerics().fulltypename(i).getText();
                        const argumentTypeListTypeProp = argumentTypeListAst.typegenerics().fulltypename(i).getText();
                        if (argListTypeProp === argumentTypeListTypeProp)
                            continue;
                        const argListProp = scope.deepGet(argListTypeProp);
                        const argumentTypeListProp = scope.deepGet(argumentTypeListTypeProp);
                        if (!argListProp || !(argListProp instanceof Type_1.default)) {
                            innerSkip = true;
                            break;
                        }
                        if (!argumentTypeListProp || !(argumentTypeListProp instanceof Type_1.default)) {
                            innerSkip = true;
                            break;
                        }
                        if (argListProp.iface != null &&
                            argListProp.iface.typeApplies(argumentTypeListProp, scope))
                            continue;
                        innerSkip = true;
                    }
                    if (innerSkip)
                        skip = true;
                    continue;
                }
                skip = true;
            }
            if (skip)
                continue;
            return fns[i];
        }
        return null;
    }
}
exports.default = Operator;

},{"./Ast":10,"./Type":19}],16:[function(require,module,exports){
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
class Scope {
    constructor(par) {
        this.vals = {};
        this.par = par ? par : null;
        this.secondaryPar = null;
    }
    get(name) {
        if (this.vals.hasOwnProperty(name)) {
            return this.vals[name];
        }
        if (!!this.par) {
            const val = this.par.get(name);
            if (!val && !!this.secondaryPar) {
                return this.secondaryPar.get(name);
            }
            else {
                return val;
            }
        }
        return null;
    }
    shallowGet(name) {
        if (this.vals.hasOwnProperty(name)) {
            return this.vals[name];
        }
        return null;
    }
    deepGet(fullName) {
        const fullVar = fullName.trim().split(".");
        let boxedVar;
        for (let i = 0; i < fullVar.length; i++) {
            if (i === 0) {
                boxedVar = this.get(fullVar[i]);
            }
            else if (!boxedVar) {
                return null;
            }
            else {
                if (boxedVar instanceof Scope) {
                    boxedVar = boxedVar.get(fullVar[i]);
                }
                else {
                    return null;
                }
            }
        }
        return boxedVar;
    }
    has(name) {
        if (this.vals.hasOwnProperty(name)) {
            return true;
        }
        if (!!this.par) {
            return this.par.has(name);
        }
        return false;
    }
    put(name, val) {
        this.vals[name.trim()] = val;
    }
}
exports.default = Scope;

},{}],17:[function(require,module,exports){
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
// Only implements the pieces necessary for the first stage compiler
class Statement {
    constructor(statementAst, scope, pure) {
        this.statementAst = statementAst,
            this.scope = scope;
        this.pure = pure;
    }
    isConditionalStatement() {
        return this.statementAst.conditionals() !== null;
    }
    isReturnStatement() {
        return this.statementAst.exits() !== null;
    }
    static baseAssignableHasObjectLiteral(baseAssignableAst) {
        return !!baseAssignableAst.objectliterals();
    }
    static assignablesHasObjectLiteral(assignablesAst) {
        for (const wo of assignablesAst.withoperators()) {
            if (!!wo.operators())
                continue;
            for (const ba of wo.baseassignable()) {
                if (Statement.baseAssignableHasObjectLiteral(ba))
                    return true;
                if (!!ba.fncall() && !!ba.fncall().assignablelist()) {
                    const innerAssignables = ba.fncall().assignablelist().assignables();
                    for (const ia of innerAssignables) {
                        if (Statement.assignablesHasObjectLiteral(ia))
                            return true;
                    }
                }
            }
        }
        return false;
    }
    static assignmentsHasObjectLiteral(assignmentsAst) {
        return Statement.assignablesHasObjectLiteral(assignmentsAst.assignables());
    }
    hasObjectLiteral() {
        const s = this.statementAst;
        if (s.declarations()) {
            const d = s.declarations().constdeclaration() || s.declarations().letdeclaration();
            return Statement.assignablesHasObjectLiteral(d.assignables());
        }
        if (s.assignments())
            return Statement.assignmentsHasObjectLiteral(s.assignments());
        if (s.assignables())
            return Statement.assignablesHasObjectLiteral(s.assignables());
        if (s.exits() && s.exits().assignables())
            return Statement.assignablesHasObjectLiteral(s.exits().assignables());
        if (s.emits() && s.emits().assignables())
            return Statement.assignablesHasObjectLiteral(s.emits().assignables());
        // TODO: Cover conditionals
        return false;
    }
    static isCallPure(callAst, scope) {
        // TODO: Add purity checking for chained method-style calls
        const fn = scope.deepGet(callAst.callbase(0).varn(0).getText());
        if (!fn) {
            // TODO: This function may be defined in the execution scope, we won't know until runtime
            // right now, but it should be determinable at "compile time". Need to fix this to check
            // if prior statements defined it, for now, just assume it exists and is not pure
            return false;
        }
        if (!(fn instanceof Array && fn[0].microstatementInlining instanceof Function)) {
            throw new Error(callAst.callbase(0).varn(0).getText() + " is not a function");
        }
        // TODO: Add all of the logic to determine which function to use in here, too. For now,
        // let's just assume they all have the same purity state, which is a terrible assumption, but
        // easier.
        if (!fn[0].isPure())
            return false;
        const assignableListAst = callAst.callbase(0).fncall(0).assignablelist();
        if (assignableListAst == null) { // No arguments to this function call
            return true;
        }
        for (const assignable of assignableListAst.assignables()) {
            if (Statement.isAssignablePure(assignable, scope) === false)
                return false;
        }
        return true;
    }
    static isAssignablePure(assignableAst, scope) {
        // TODO: Redo this
        return true;
    }
    static create(statementAst, scope) {
        if (!!statementAst.exception) {
            throw statementAst.exception;
        }
        let pure = true;
        if (statementAst.declarations() != null) {
            if (statementAst.declarations().constdeclaration() != null) {
                pure = Statement.isAssignablePure(statementAst.declarations().constdeclaration().assignables(), scope);
            }
            else if (statementAst.declarations().letdeclaration() != null) {
                if (statementAst.declarations().letdeclaration().assignables() == null) {
                    pure = true;
                }
                else {
                    pure = Statement.isAssignablePure(statementAst.declarations().letdeclaration().assignables(), scope);
                }
            }
            else {
                throw new Error("Bad assignment somehow reached");
            }
        }
        if (statementAst.assignments() != null) {
            if (statementAst.assignments().assignables() != null) {
                pure = Statement.isAssignablePure(statementAst.assignments().assignables(), scope);
            }
        }
        if (statementAst.assignables() != null) {
            pure = Statement.isAssignablePure(statementAst.assignables(), scope);
        }
        if (statementAst.exits() != null) {
            if (statementAst.exits().assignables() != null) {
                pure = Statement.isAssignablePure(statementAst.exits().assignables(), scope);
            }
        }
        if (statementAst.emits() != null) {
            if (statementAst.emits().assignables() != null) {
                pure = Statement.isAssignablePure(statementAst.emits().assignables(), scope);
            }
        }
        return new Statement(statementAst, scope, pure);
    }
    toString() {
        return this.statementAst.getText();
    }
}
exports.default = Statement;

},{}],18:[function(require,module,exports){
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
var StatementType;
(function (StatementType) {
    StatementType["CONSTDEC"] = "CONSTDEC";
    StatementType["LETDEC"] = "LETDEC";
    StatementType["ASSIGNMENT"] = "ASSIGNMENT";
    StatementType["CALL"] = "CALL";
    StatementType["EMIT"] = "EMIT";
    StatementType["REREF"] = "REREF";
    StatementType["CLOSURE"] = "CLOSURE";
    StatementType["ARG"] = "ARG";
    StatementType["ENTERFN"] = "ENTERFN";
    StatementType["EXIT"] = "EXIT";
    StatementType["CLOSUREDEF"] = "CLOSUREDEF";
})(StatementType || (StatementType = {}));
exports.default = StatementType;

},{}],19:[function(require,module,exports){
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.Type = exports.Interface = exports.OperatorType = exports.FunctionType = void 0;
const Scope_1 = require("./Scope");
const Operator_1 = require("./Operator");
const Ast_1 = require("./Ast");
class FunctionType {
    constructor(functionname = null, args = [], returnType) {
        this.functionname = functionname;
        this.args = args;
        this.returnType = returnType;
    }
}
exports.FunctionType = FunctionType;
class OperatorType {
    constructor(operatorname, isPrefix = false, args, returnType) {
        this.operatorname = operatorname;
        this.isPrefix = isPrefix;
        this.args = args;
        this.returnType = returnType;
    }
}
exports.OperatorType = OperatorType;
class Interface {
    constructor(interfacename, functionTypes = [], operatorTypes = [], requiredProperties = {}) {
        this.interfacename = interfacename;
        this.functionTypes = functionTypes;
        this.operatorTypes = operatorTypes;
        this.requiredProperties = requiredProperties;
    }
    typeApplies(typeToCheck, scope) {
        // Solve circular dependency issue
        for (const requiredProperty of Object.keys(this.requiredProperties)) {
            if (!typeToCheck.properties.hasOwnProperty(requiredProperty))
                return false;
        }
        for (const functionType of this.functionTypes) {
            if (!functionType.functionname)
                continue; // Anonymous functions checked at callsite
            const potentialFunctions = scope.deepGet(functionType.functionname);
            if (!potentialFunctions ||
                !(potentialFunctions instanceof Array &&
                    potentialFunctions[0].microstatementInlining instanceof Function)) {
                throw new Error(functionType.functionname + " is not the name of a function");
            }
            let functionFound = false;
            for (const potentialFunction of potentialFunctions) {
                const argTypes = potentialFunction.getArguments();
                let argsMatch = true;
                let typeNames = Object.keys(argTypes);
                for (let i = 0; i < typeNames.length; i++) {
                    const functionTypeArgType = functionType.args[i];
                    if (argTypes[typeNames[i]] === functionTypeArgType)
                        continue;
                    if (argTypes[typeNames[i]].originalType === functionTypeArgType)
                        continue;
                    if (argTypes[typeNames[i]].originalType === functionTypeArgType.originalType &&
                        Object.values(functionTypeArgType.properties).every((prop, j) => {
                            const comparable = Object.values(argTypes[typeNames[i]].properties)[j];
                            if (prop === comparable)
                                return true;
                            if (prop.iface && prop.iface.typeApplies(comparable, scope))
                                return true;
                            return false;
                        }))
                        continue;
                    if (argTypes[typeNames[i]] === typeToCheck)
                        continue;
                    if (!!argTypes[typeNames[i]].iface &&
                        !!functionTypeArgType.iface &&
                        argTypes[typeNames[i]].iface === functionTypeArgType.iface)
                        continue;
                    argsMatch = false;
                    break;
                }
                if (!argsMatch)
                    continue;
                functionFound = true;
                break;
            }
            if (!functionFound)
                return false;
        }
        for (const operatorType of this.operatorTypes) {
            const potentialOperators = scope.deepGet(operatorType.operatorname);
            if (!potentialOperators ||
                !(potentialOperators instanceof Array &&
                    potentialOperators[0] instanceof Operator_1.default)) {
                throw new Error(`${operatorType.operatorname} is not an operator`);
            }
            let operatorFound = false;
            for (const potentialOperator of potentialOperators) {
                for (const potentialFunction of potentialOperator.potentialFunctions) {
                    const argTypes = potentialFunction.getArguments();
                    let argsMatch = true;
                    let typeNames = Object.keys(argTypes);
                    for (let i = 0; i < typeNames.length; i++) {
                        const operatorTypeArgType = operatorType.args[i];
                        if (argTypes[typeNames[i]] === operatorTypeArgType)
                            continue;
                        if (argTypes[typeNames[i]].originalType === operatorTypeArgType)
                            continue;
                        if (argTypes[typeNames[i]] === typeToCheck)
                            continue;
                        if (!!argTypes[typeNames[i]].iface &&
                            !!operatorTypeArgType.iface &&
                            argTypes[typeNames[i]].iface === operatorTypeArgType.iface)
                            continue;
                        argsMatch = false;
                        break;
                    }
                    if (!argsMatch)
                        continue;
                    operatorFound = true;
                    break;
                }
            }
            if (!operatorFound)
                return false;
        }
        return true;
    }
    static fromAst(interfaceAst, scope) {
        // Construct the basic interface, the wrapper type, and insert it into the scope
        // This is all necessary so the interface can self-reference when constructing the function and
        // operator types.
        const interfacename = interfaceAst.VARNAME(0).getText();
        let iface = new Interface(interfacename);
        const ifaceType = new Type(interfacename, false, false, {}, {}, null, iface);
        scope.put(interfacename, ifaceType);
        // Now, insert the actual declarations of the interface, if there are any (if there are none,
        // it will provide only as much as a type generic -- you can set it to a variable and return it
        // but nothing else, unlike Go's ridiculous interpretation of a bare interface).
        if (!!interfaceAst.interfacebody() && !!interfaceAst.interfacebody().interfacelist()) {
            for (const interfaceline of interfaceAst.interfacebody().interfacelist().interfaceline()) {
                if (!!interfaceline.functiontypeline()) {
                    const functiontypeline = interfaceline.functiontypeline();
                    let functionname = null;
                    if (!!functiontypeline.VARNAME()) {
                        functionname = functiontypeline.VARNAME().getText();
                    }
                    const typenames = functiontypeline.functiontype().fulltypename();
                    const returnType = scope.deepGet(typenames[typenames.length - 1].getText());
                    if (!returnType || !(returnType instanceof Type)) {
                        throw new Error(typenames.get(typenames.size() - 1).getText() + " is not a type");
                    }
                    let args = [];
                    for (let i = 0; i < typenames.length - 1; i++) {
                        const argument = scope.deepGet(typenames[i].getText());
                        if (!argument || !(argument instanceof Type)) {
                            throw new Error(typenames.get(i).getText() + " is not a type");
                        }
                        args.push(argument);
                    }
                    const functionType = new FunctionType(functionname, args, returnType);
                    iface.functionTypes.push(functionType);
                }
                if (!!interfaceline.operatortypeline()) {
                    const operatorname = interfaceline.operatortypeline().operators().getText();
                    const isPrefix = !interfaceline.operatortypeline().leftarg();
                    const argTypenames = [];
                    if (!isPrefix) {
                        argTypenames.push(interfaceline.operatortypeline().leftarg().getText());
                    }
                    argTypenames.push(interfaceline.operatortypeline().rightarg().getText());
                    const returnTypename = interfaceline.operatortypeline().fulltypename().getText();
                    const args = argTypenames.map(n => {
                        const box = scope.deepGet(n);
                        if (!box || !(box instanceof Type)) {
                            throw new Error(`${n} is not a type`);
                        }
                        return box;
                    });
                    const returnType = scope.deepGet(returnTypename);
                    if (!returnType || !(returnType instanceof Type)) {
                        throw new Error(`${returnTypename} is not a type`);
                    }
                    const operatorType = new OperatorType(operatorname, isPrefix, args, returnType);
                    iface.operatorTypes.push(operatorType);
                }
                if (!!interfaceline.propertytypeline()) {
                    const propertyType = scope.deepGet(interfaceline.propertytypeline().varn().getText());
                    if (!propertyType || !(propertyType instanceof Type)) {
                        throw new Error(interfaceline.propertytypeline().varn().getText() + " is not a type");
                    }
                    iface.requiredProperties[interfaceline.propertytypeline().VARNAME().getText()] = propertyType;
                }
            }
        }
        else if (!!interfaceAst.VARNAME(1)) {
            // It's an alias, so grab it and give it the new name
            const otherInterface = scope.deepGet(interfaceAst.VARNAME(1).getText());
            if (!(otherInterface instanceof Type) || !otherInterface.iface) {
                throw new Error(`${interfaceAst.varn().getText()} is not an interface`);
            }
            // Replace the interface with the other one
            ifaceType.iface = otherInterface.iface;
        }
        return ifaceType;
    }
}
exports.Interface = Interface;
let Type = /** @class */ (() => {
    class Type {
        constructor(typename, builtIn = false, isGenericStandin = false, properties = {}, generics = {}, originalType = null, iface = null, alias = null) {
            this.typename = typename;
            this.builtIn = builtIn;
            this.isGenericStandin = isGenericStandin;
            this.properties = properties;
            this.generics = generics;
            this.originalType = originalType;
            this.iface = iface;
            this.alias = alias;
        }
        toString() {
            if (this.iface != null)
                return "// Interfaces TBD";
            let outString = "type " + this.typename;
            if (this.alias != null) {
                outString += " = " + this.alias.typename;
                return outString;
            }
            if (this.generics.length > 0) {
                outString += "<" + Object.keys(this.generics).join(", ") + ">";
            }
            outString += "{\n";
            for (const propName of Object.keys(this.properties)) {
                outString += "  " + propName + ": " + this.properties[propName].typename + "\n";
            }
            outString += "}\n";
            return outString;
        }
        static fromAst(typeAst, scope) {
            let type = new Type(typeAst.typename().getText());
            const genScope = new Scope_1.default();
            const typeScope = new Scope_1.default(scope);
            typeScope.secondaryPar = genScope;
            if (typeAst.typegenerics() != null) {
                const generics = typeAst.typegenerics().fulltypename();
                for (let i = 0; i < generics.length; i++) {
                    type.generics[generics[i].getText()] = i;
                    genScope.put(generics[i].getText(), new Type(generics[i].getText(), true, true));
                }
            }
            if (typeAst.typebody() != null) {
                const lines = typeAst.typebody().typelist().typeline();
                for (const lineAst of lines) {
                    const propertyName = lineAst.VARNAME().getText();
                    const typeName = lineAst.fulltypename().getText().trim();
                    const property = typeScope.deepGet(typeName);
                    if (!property || !(property instanceof Type)) {
                        // Potentially a type that depends on the type generics of this type
                        const baseTypeName = lineAst.fulltypename().typename().getText();
                        const innerGenerics = lineAst.fulltypename().typegenerics().fulltypename();
                        const genericsList = [];
                        const genericsQueue = [];
                        for (const generic of innerGenerics) {
                            genericsList.push(generic);
                        }
                        while (genericsList.length > 0) {
                            const generic = genericsList.shift();
                            genericsQueue.push(generic);
                            if (generic.typegenerics()) {
                                genericsList.push(...generic.typegenerics().fulltypename());
                            }
                        }
                        while (genericsQueue.length > 0) {
                            const generic = genericsQueue.pop();
                            const innerType = typeScope.deepGet(generic.getText());
                            if (!innerType) {
                                const innerBaseTypeName = generic.typename().getText();
                                const innerBaseType = typeScope.deepGet(innerBaseTypeName);
                                if (!innerBaseType) {
                                    throw new Error('wut');
                                }
                                innerBaseType.solidify(generic.typegenerics().fulltypename().map((t) => t.getText()), typeScope);
                            }
                        }
                        const baseType = scope.deepGet(baseTypeName);
                        if (!baseType || !(baseType instanceof Type)) {
                            throw new Error(lineAst.fulltypename().getText() + " is not a type");
                        }
                        type.properties[propertyName] = baseType.solidify(innerGenerics.map((t) => t.getText()), typeScope);
                    }
                    else {
                        type.properties[propertyName] = property;
                    }
                }
            }
            if (typeAst.fulltypename() != null) {
                const otherTypebox = scope.deepGet(typeAst.fulltypename().typename().getText());
                if (!otherTypebox) {
                    throw new Error("Type " + typeAst.fulltypename().getText() + " not defined");
                }
                if (!(otherTypebox instanceof Type)) {
                    throw new Error(typeAst.fulltypename().getText() + " is not a valid type");
                }
                let fulltypename = otherTypebox;
                if (Object.keys(fulltypename.generics).length > 0 && !!typeAst.fulltypename().typegenerics()) {
                    let solidTypes = [];
                    for (const fulltypenameAst of typeAst.fulltypename().typegenerics().fulltypename()) {
                        solidTypes.push(fulltypenameAst.getText());
                    }
                    fulltypename = fulltypename.solidify(solidTypes, scope);
                }
                // For simplification of the type aliasing functionality, the other type is attached as
                // an alias. The module construction will, if present, perfer the alias over the actual
                // type, to make sure built-in types that are aliased continue to work. This means that
                // `type varA == type varB` will work if `varA` is assigned to an alias and `varB` to the
                // orignal type. I can see the argument either way on this, but the simplicity of this
                // approach is why I will go with this for now.
                type.alias = fulltypename;
            }
            scope.put(type.typename, type);
            return type;
        }
        solidify(genericReplacements, scope) {
            let genericTypes = Object.keys(this.generics).map(t => new Type(t, true, true));
            let replacementTypes = [];
            for (const typename of genericReplacements) {
                const typebox = scope.deepGet(typename);
                if (!typebox || !(typebox instanceof Type)) {
                    const fulltypename = Ast_1.fulltypenameAstFromString(typename);
                    if (fulltypename.typegenerics()) {
                        const basename = fulltypename.typename().getText();
                        const generics = fulltypename.typegenerics().fulltypename().map((t) => t.getText());
                        const baseType = scope.deepGet(basename);
                        if (!baseType || !(baseType instanceof Type)) {
                            throw new Error(basename + " type not found");
                        }
                        else {
                            const newtype = baseType.solidify(generics, scope);
                            replacementTypes.push(newtype);
                        }
                    }
                    else {
                        throw new Error(typename + " type not found");
                    }
                }
                else {
                    replacementTypes.push(typebox);
                }
            }
            const genericMap = new Map();
            genericTypes.forEach((g, i) => genericMap.set(g, replacementTypes[i]));
            const solidifiedName = this.typename + "<" + genericReplacements.join(", ") + ">";
            let solidified = new Type(solidifiedName, this.builtIn);
            solidified.originalType = this;
            for (const propKey of Object.keys(this.properties)) {
                const propValue = this.properties[propKey];
                const newPropValue = propValue.realize(genericMap, scope);
                solidified.properties[propKey] = newPropValue;
            }
            scope.put(solidifiedName, solidified);
            return solidified;
        }
        typeApplies(otherType, scope, interfaceMap = new Map()) {
            if (this.typename === otherType.typename)
                return true;
            if (!!this.iface) {
                const applies = this.iface.typeApplies(otherType, scope);
                if (applies) {
                    interfaceMap.set(this, otherType);
                }
                return applies;
            }
            if (!this.originalType ||
                !otherType.originalType ||
                this.originalType.typename !== otherType.originalType.typename)
                return false;
            const typeAst = Ast_1.fulltypenameAstFromString(this.typename);
            const otherTypeAst = Ast_1.fulltypenameAstFromString(otherType.typename);
            const generics = typeAst.typegenerics().fulltypename().map((g) => (scope.deepGet(g.getText()) ||
                Type.fromStringWithMap(g.getText(), interfaceMap, scope)));
            const otherGenerics = otherTypeAst.typegenerics().fulltypename().map((g) => (scope.deepGet(g.getText()) ||
                Type.fromStringWithMap(g.getText(), interfaceMap, scope)));
            return generics.every((t, i) => t.typeApplies(otherGenerics[i], scope, interfaceMap));
        }
        // There has to be a more elegant way to tackle this
        static fromStringWithMap(typestr, interfaceMap, scope) {
            const typeAst = Ast_1.fulltypenameAstFromString(typestr);
            const baseName = typeAst.typename().getText();
            const baseType = scope.deepGet(baseName);
            if (typeAst.typegenerics()) {
                const genericNames = typeAst.typegenerics().fulltypename().map((t) => t.getText());
                const generics = genericNames.map((t) => {
                    const interfaceMapping = [
                        ...interfaceMap.entries()
                    ].find(e => e[0].typename === t.trim());
                    if (interfaceMapping)
                        return interfaceMapping[1];
                    const innerType = Type.fromStringWithMap(t, interfaceMap, scope);
                    return innerType;
                });
                return baseType.solidify(generics.map((g) => interfaceMap.get(g) || g).map((t) => t.typename), scope);
            }
            else {
                return interfaceMap.get(baseType) || baseType;
            }
        }
        realize(interfaceMap, scope) {
            if (!!this.isGenericStandin)
                return [
                    ...interfaceMap.entries()
                ].find(e => e[0].typename === this.typename)[1];
            if (!this.iface && !this.originalType)
                return this;
            if (!!this.iface)
                return interfaceMap.get(this) || this;
            const self = new Type(this.typename, this.builtIn, this.isGenericStandin, { ...this.properties, }, { ...this.generics, }, this.originalType, this.iface, this.alias);
            const newProps = Object.values(self.properties).map(t => t.realize(interfaceMap, scope));
            Object.keys(self.properties).forEach((k, i) => {
                self.properties[k] = newProps[i];
            });
            const newType = Type.fromStringWithMap(self.typename, interfaceMap, scope);
            return newType;
        }
        // This is only necessary for the numeric types. TODO: Can we eliminate it?
        castable(otherType) {
            const intTypes = ["int8", "int16", "int32", "int64"];
            const floatTypes = ["float32", "float64"];
            if (intTypes.includes(this.typename) && intTypes.includes(otherType.typename))
                return true;
            if (floatTypes.includes(this.typename) && floatTypes.includes(otherType.typename))
                return true;
            if (floatTypes.includes(this.typename) && intTypes.includes(otherType.typename))
                return true;
            return false;
        }
    }
    Type.builtinTypes = {
        void: new Type("void", true),
        int8: new Type("int8", true),
        int16: new Type("int16", true),
        int32: new Type("int32", true),
        int64: new Type("int64", true),
        float32: new Type("float32", true),
        float64: new Type("float64", true),
        bool: new Type("bool", true),
        string: new Type("string", true),
        "Error": new Type("Error", true, false, {
            msg: new Type("string", true, true),
        }),
        "Maybe": new Type("Maybe", true, false, {
            value: new Type("T", true, true),
        }, {
            T: 0,
        }),
        "Result": new Type("Result", true, false, {
            value: new Type("T", true, true),
            error: new Type("Error", true, false, {
                msg: new Type("string", true, true),
            }),
        }, {
            T: 0,
        }),
        "Either": new Type("Either", true, false, {
            main: new Type("T", true, true),
            alt: new Type("U", true, true),
        }, {
            T: 0,
            U: 1,
        }),
        "Array": new Type("Array", true, false, {
            records: new Type("V", true, true),
        }, {
            V: 0,
        }),
        ExecRes: new Type("ExecRes", false, false, {
            exitCode: new Type("int64", true),
            stdout: new Type("string", true),
            stderr: new Type("string", true),
        }),
        InitialReduce: new Type("InitialReduce", false, false, {
            arr: new Type("Array<T>", true, false, {
                records: new Type("T", true, true),
            }, {
                T: 0,
            }),
            initial: new Type("U", true, true),
        }, {
            T: 0,
            U: 1,
        }),
        // HTTP server opcode-related builtin Types, also defined in std/http.ln
        InternalRequest: new Type("InternalRequest", true, false, {
            url: new Type("string", true),
            headers: new Type("Array<KeyVal<string, string>>", true, false, {
                records: new Type('KeyVal<string, string>>', true, false, {
                    key: new Type("string", true),
                    val: new Type("string", true),
                }),
            }),
            body: new Type('string', true),
            connId: new Type('int64', true),
        }),
        InternalResponse: new Type("InternalResponse", true, false, {
            status: new Type("int64", true),
            headers: new Type("Array<KeyVal<string, string>>", true, false, {
                records: new Type('KeyVal<string, string>>', true, false, {
                    key: new Type("string", true),
                    val: new Type("string", true),
                }),
            }),
            body: new Type('string', true),
            connId: new Type('int64', true),
        }),
        Seq: new Type("Seq", true, false, {
            counter: new Type("int64", true, true),
            limit: new Type("int64", true, true),
        }),
        Self: new Type("Self", true, false, {
            seq: new Type("Seq", true, false, {
                counter: new Type("int64", true, true),
                limit: new Type("int64", true, true),
            }),
            recurseFn: new Type("function", true),
        }),
        "function": new Type("function", true),
        operator: new Type("operator", true),
        Event: new Type("Event", true, false, {
            type: new Type("E", true, true),
        }, {
            E: 0,
        }),
        type: new Type("type", true),
        scope: new Type("scope", true),
        microstatement: new Type("microstatement", true),
    };
    return Type;
})();
exports.Type = Type;
exports.default = Type;

},{"./Ast":10,"./Operator":15,"./Scope":16}],20:[function(require,module,exports){
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const uuid_1 = require("uuid");
const Ast = require("./Ast");
const Microstatement_1 = require("./Microstatement");
const Scope_1 = require("./Scope");
const Statement_1 = require("./Statement");
const StatementType_1 = require("./StatementType");
const Type_1 = require("./Type");
const ln_1 = require("../ln");
class UserFunction {
    constructor(name, args, returnType, scope, statements, pure) {
        this.name = name;
        this.args = args;
        this.returnType = returnType;
        this.scope = scope;
        for (let i = 0; i < statements.length - 1; i++) {
            if (statements[i].isReturnStatement()) {
                // There are unreachable statements after this line, abort
                throw new Error(`Unreachable code in function '${name}' after:
${statements[i].statementAst.getText().trim()} on line ${statements[i].statementAst.start.line}:${statements[i].statementAst.start.column}`);
            }
        }
        this.statements = statements;
        this.pure = pure;
    }
    static fromAst(functionishAst, scope) {
        if (functionishAst instanceof ln_1.LnParser.BlocklikesContext) {
            if (functionishAst.functions() != null) {
                return UserFunction.fromFunctionsAst(functionishAst.functions(), scope);
            }
            if (functionishAst.functionbody() != null) {
                return UserFunction.fromFunctionbodyAst(functionishAst.functionbody(), scope);
            }
        }
        if (functionishAst instanceof ln_1.LnParser.FunctionsContext) {
            return UserFunction.fromFunctionsAst(functionishAst, scope);
        }
        if (functionishAst instanceof ln_1.LnParser.FunctionbodyContext) {
            return UserFunction.fromFunctionbodyAst(functionishAst, scope);
        }
        return null;
    }
    static fromFunctionbodyAst(functionbodyAst, scope) {
        let args = {};
        const returnType = Type_1.default.builtinTypes.void;
        let pure = true; // Assume purity and then downgrade if needed
        let statements = [];
        const statementsAst = functionbodyAst.statements();
        for (const statementAst of statementsAst) {
            const statement = Statement_1.default.create(statementAst, scope);
            if (!statement.pure)
                pure = false;
            statements.push(statement);
        }
        return new UserFunction(null, args, returnType, scope, statements, pure);
    }
    static fromFunctionsAst(functionAst, scope) {
        const name = functionAst.VARNAME() == null ? null : functionAst.VARNAME().getText();
        let args = {};
        const argsAst = functionAst.arglist();
        if (argsAst !== null) {
            const arglen = argsAst.VARNAME().length;
            for (let i = 0; i < arglen; i++) {
                const argName = argsAst.VARNAME(i).getText();
                let getArgType = scope.deepGet(argsAst.fulltypename(i).getText());
                if (!getArgType) {
                    if (argsAst.fulltypename(i).typegenerics() !== null) {
                        getArgType =
                            scope.deepGet(argsAst.fulltypename(i).typename().getText());
                        if (!getArgType) {
                            throw new Error("Could not find type " + argsAst.fulltypename(i).getText() + " for argument " + argName);
                        }
                        if (!(getArgType instanceof Type_1.default)) {
                            throw new Error("Function argument is not a valid type: " + argsAst.fulltypename(i).getText());
                        }
                        let genericTypes = [];
                        for (const fulltypename of argsAst.fulltypename(i).typegenerics().fulltypename()) {
                            genericTypes.push(fulltypename.getText());
                        }
                        getArgType = getArgType.solidify(genericTypes, scope);
                    }
                    else {
                        throw new Error("Could not find type " + argsAst.fulltypename(i).getText() + " for argument " + argName);
                    }
                }
                if (!(getArgType instanceof Type_1.default)) {
                    throw new Error("Function argument is not a valid type: " + argsAst.fulltypename(i).getText());
                }
                args[argName] = getArgType;
            }
        }
        let returnType = null;
        if (functionAst.fulltypename() !== null) {
            let getReturnType = scope.deepGet(functionAst.fulltypename().getText());
            if (getReturnType == null || !(getReturnType instanceof Type_1.default)) {
                if (functionAst.fulltypename().typegenerics() != null) {
                    getReturnType = scope.deepGet(functionAst.fulltypename().typename().getText());
                    if (getReturnType == null) {
                        throw new Error("Could not find type " + functionAst.fulltypename().getText() + " for function " + functionAst.VARNAME().getText());
                    }
                    if (!(getReturnType instanceof Type_1.default)) {
                        throw new Error("Function return is not a valid type: " + functionAst.fulltypename().getText());
                    }
                    let genericTypes = [];
                    for (const fulltypename of functionAst.fulltypename().typegenerics().fulltypename()) {
                        genericTypes.push(fulltypename.getText());
                    }
                    getReturnType = getReturnType.solidify(genericTypes, scope);
                }
                else {
                    throw new Error("Could not find type " + functionAst.fulltypename().getText() + " for function " + functionAst.VARNAME().getText());
                }
            }
            returnType = getReturnType;
        }
        let pure = true;
        let statements = [];
        const functionbody = functionAst.fullfunctionbody().functionbody();
        if (functionbody !== null) {
            const statementsAst = functionbody.statements();
            for (const statementAst of statementsAst) {
                let statement = Statement_1.default.create(statementAst, scope);
                if (!statement.pure)
                    pure = false;
                statements.push(statement);
            }
            if (returnType === null)
                returnType = Type_1.default.builtinTypes['void'];
        }
        else {
            const assignablesAst = functionAst.fullfunctionbody().assignables();
            const statementAst = Ast.statementAstFromString(`return ${assignablesAst.getText()};\n`);
            const statement = Statement_1.default.create(statementAst, scope);
            if (!statement.pure)
                pure = false;
            statements.push(statement);
            if (!returnType && Object.keys(args).every(arg => args[arg].typename !== 'function')) {
                // We're going to use the Microstatement logic here
                const microstatements = [];
                // First lets add all microstatements from the provided scope into the list
                // TODO: If this pattern is ever used more than once, add a new method to the Scope type
                Object.keys(scope.vals).forEach(val => {
                    if (scope.vals[val] instanceof Microstatement_1.default) {
                        microstatements.push(scope.vals[val]);
                    }
                });
                Object.keys(args).forEach(arg => {
                    microstatements.push(new Microstatement_1.default(StatementType_1.default.REREF, scope, true, arg, args[arg], [], [], arg));
                });
                Microstatement_1.default.fromAssignablesAst(assignablesAst, scope, microstatements);
                const last = microstatements[microstatements.length - 1];
                if (last.statementType !== StatementType_1.default.EMIT) {
                    // TODO: Come up with a better solution than this hackery for void function calls as the
                    // only value for a one-liner function
                    returnType = last.outputType;
                }
                else {
                    returnType = Type_1.default.builtinTypes.void;
                }
            }
            else if (!returnType) {
                // TODO: Generalize this hackery for opcodes that take closure functions
                const opcodeName = assignablesAst.getText().split('(')[0];
                const opcode = scope.deepGet(opcodeName);
                returnType = opcode ? opcode[0].getReturnType() : Type_1.default.builtinTypes['void'];
            }
        }
        return new UserFunction(name, args, returnType, scope, statements, pure);
    }
    getName() {
        return this.name;
    }
    getArguments() {
        return this.args;
    }
    getReturnType() {
        return this.returnType;
    }
    isPure() {
        return this.pure;
    }
    toFnStr() {
        return `
      fn ${this.name || ''} (${Object.keys(this.args).map(argName => `${argName}: ${this.args[argName].typename}`).join(', ')}): ${this.getReturnType().typename} {
        ${this.statements.map(s => s.statementAst.getText()).join('\n')}
      }
    `.trim();
    }
    static conditionalToCond(cond, scope) {
        let newStatements = [];
        let hasConditionalReturn = false; // Flag for potential second pass
        const condName = "_" + uuid_1.v4().replace(/-/g, "_");
        const condStatement = Ast.statementAstFromString(`
      const ${condName}: bool = ${cond.assignables().getText()}
    `.trim() + ';\n');
        const condBlockFn = (cond.blocklikes(0).functionbody() ?
            UserFunction.fromFunctionbodyAst(cond.blocklikes(0).functionbody(), scope) :
            cond.blocklikes(0).eventref() ?
                scope.deepGet(cond.blocklikes(0).eventref().getText())[0] :
                UserFunction.fromFunctionsAst(cond.blocklikes(0).functions(), scope)).maybeTransform(new Map());
        if (condBlockFn.statements[condBlockFn.statements.length - 1].isReturnStatement()) {
            hasConditionalReturn = true;
        }
        const condBlock = condBlockFn.toFnStr();
        const condCall = Ast.statementAstFromString(`
      cond(${condName}, ${condBlock})
    `.trim() + ';\n'); // TODO: If the blocklike is a reference, grab it and inline it
        newStatements.push(condStatement, condCall);
        if (!!cond.ELSE()) {
            if (!!cond.blocklikes(1)) {
                const elseBlockFn = (cond.blocklikes(1).functionbody() ?
                    UserFunction.fromFunctionbodyAst(cond.blocklikes(1).functionbody(), scope) :
                    cond.blocklikes(1).eventref() ?
                        scope.deepGet(cond.blocklikes(1).eventref().getText())[0] :
                        UserFunction.fromFunctionsAst(cond.blocklikes(1).functions(), scope)).maybeTransform(new Map());
                if (elseBlockFn.statements[elseBlockFn.statements.length - 1].isReturnStatement()) {
                    hasConditionalReturn = true;
                }
                const elseBlock = elseBlockFn.toFnStr();
                const elseStatement = Ast.statementAstFromString(`
          cond(not(${condName}), ${elseBlock})
        `.trim() + ';\n');
                newStatements.push(elseStatement);
            }
            else {
                const res = UserFunction.conditionalToCond(cond.conditionals(), scope);
                const innerCondStatements = res[0];
                if (res[1])
                    hasConditionalReturn = true;
                const elseStatement = Ast.statementAstFromString(`
          cond(!${condName}, fn {
            ${innerCondStatements.map(s => s.getText()).join('\n')}
          })
        `.trim() + ';\n');
                newStatements.push(elseStatement);
            }
        }
        return [newStatements, hasConditionalReturn];
    }
    static earlyReturnRewrite(retVal, retNotSet, statements, // TODO: Eliminate ANTLR
    scope) {
        let replacementStatements = [];
        while (statements.length > 0) {
            const s = statements.shift();
            // TODO: This doesn't work for actual direct-usage of `cond` in some sort of method chaining
            // if that's even possible. Probably lots of other weirdness to deal with here.
            if (s.assignables() &&
                s.assignables().withoperators(0).baseassignable().length >= 2 &&
                s.assignables().withoperators(0).baseassignable(0).getText().trim() === 'cond' &&
                s.assignables().withoperators(0).baseassignable(1).fncall()) {
                // Potentially need to rewrite
                const args = s.assignables().withoperators(0).baseassignable(1).fncall().assignablelist();
                if (args && args.assignables().length == 2) {
                    const block = args.assignables(1).withoperators(0).baseassignable() ?
                        args.assignables(1).withoperators(0).baseassignable(0).functions() :
                        null;
                    if (block) {
                        const blockFn = UserFunction.fromAst(block, scope);
                        if (blockFn.statements[blockFn.statements.length - 1].isReturnStatement()) {
                            const innerStatements = blockFn.statements.map(s => s.statementAst);
                            const newBlockStatements = UserFunction.earlyReturnRewrite(retVal, retNotSet, innerStatements, scope);
                            const cond = args.assignables(0).getText().trim();
                            const newBlock = Ast.statementAstFromString(`
                cond(${cond}, fn {
                  ${newBlockStatements.map(s => s.getText()).join('\n')}
                })
              `.trim() + ';\n');
                            replacementStatements.push(newBlock);
                            if (statements.length > 0) {
                                const remainingStatements = UserFunction.earlyReturnRewrite(retVal, retNotSet, statements, scope);
                                const remainingBlock = Ast.statementAstFromString(`
                  cond(${retNotSet}, fn {
                    ${remainingStatements.map(s => s.getText()).join('\n')}
                  })
                `.trim() + ';\n');
                                replacementStatements.push(remainingBlock);
                            }
                        }
                        else {
                            replacementStatements.push(s);
                        }
                    }
                    else {
                        replacementStatements.push(s);
                    }
                }
                else {
                    replacementStatements.push(s);
                }
            }
            else {
                replacementStatements.push(s);
            }
        }
        // If no inner conditional was found in this branch, check if there's a final return
        if (replacementStatements[replacementStatements.length - 1].exits()) {
            const retStatement = replacementStatements.pop();
            if (retStatement.exits().assignables()) {
                const newAssign = Ast.statementAstFromString(`
          ${retVal} = ref(${retStatement.exits().assignables().getText()})
        `.trim() + ';\n');
                replacementStatements.push(newAssign);
            }
            replacementStatements.push(Ast.statementAstFromString(`
        ${retNotSet} = clone(false)
      `.trim() + ';\n'));
        }
        return replacementStatements;
    }
    maybeTransform(interfaceMap, scope) {
        if (this.statements.some(s => s.isConditionalStatement()) ||
            this.statements.some(s => s.hasObjectLiteral())) {
            // First pass, convert conditionals to `cond` fn calls and wrap assignment statements
            let statementAsts = [];
            let hasConditionalReturn = false; // Flag for potential second pass
            for (let i = 0; i < this.statements.length; i++) {
                let s = new Statement_1.default(this.statements[i].statementAst, this.statements[i].scope, this.statements[i].pure);
                // Potentially rewrite the type for the object literal to match the interface type used by
                // a specific call
                const str = s.statementAst.getText();
                const corrected = str.replace(/new ([^<]+)<([^{\[]+)> *([{\[])/g, (_, basetypestr, genericstr, openstr) => {
                    const originaltypestr = `${basetypestr.trim()}<${genericstr.trim()}>`;
                    let originalType = this.scope.deepGet(originaltypestr);
                    if (!originalType || !(originalType instanceof Type_1.default)) {
                        // It may be the first time this particular type has shown up, let's build it
                        const typeAst = Ast.fulltypenameAstFromString(originaltypestr);
                        const baseTypeName = typeAst.typename().getText();
                        const generics = typeAst.typegenerics().fulltypename().map((g) => g.getText());
                        const baseType = this.scope.deepGet(baseTypeName);
                        if (!baseType || !(baseType instanceof Type_1.default)) { // Now we panic
                            throw new Error('This should be impossible');
                        }
                        originalType = baseType.solidify(generics, this.scope);
                    }
                    let newScope = this.scope;
                    if (scope !== undefined) {
                        newScope = new Scope_1.default(scope);
                        newScope.secondaryPar = this.scope;
                    }
                    const replacementType = originalType.realize(interfaceMap, newScope);
                    return `new ${replacementType.typename} ${openstr}`;
                });
                // TODO: Get rid of these regex-based type corrections
                const secondCorrection = corrected.replace(/: (?!new )([^:<,]+)<([^{\)]+)>( *[,{\)])/g, (_, basetypestr, genericstr, openstr) => {
                    const originaltypestr = `${basetypestr.trim()}<${genericstr.trim()}>`;
                    let originalType = this.scope.deepGet(originaltypestr);
                    if (!originalType || !(originalType instanceof Type_1.default)) {
                        // It may be the first time this particular type has shown up, let's build it
                        const typeAst = Ast.fulltypenameAstFromString(originaltypestr);
                        const baseTypeName = typeAst.typename().getText();
                        const generics = typeAst.typegenerics().fulltypename().map((g) => g.getText());
                        const baseType = this.scope.deepGet(baseTypeName);
                        if (!baseType || !(baseType instanceof Type_1.default)) { // Now we panic
                            throw new Error('This should be impossible');
                        }
                        originalType = baseType.solidify(generics, this.scope);
                    }
                    const replacementType = originalType.realize(interfaceMap, this.scope);
                    return `: ${replacementType.typename}${openstr}`;
                });
                const correctedAst = Ast.statementAstFromString(secondCorrection);
                s.statementAst = correctedAst;
                // statementAsts.push(correctedAst)
                if (s.isConditionalStatement()) {
                    const cond = s.statementAst.conditionals();
                    const res = UserFunction.conditionalToCond(cond, this.scope);
                    const newStatements = res[0];
                    if (res[1])
                        hasConditionalReturn = true;
                    statementAsts.push(...newStatements);
                }
                else if (s.statementAst instanceof ln_1.LnParser.AssignmentsContext) {
                    const a = s.statementAst;
                    const wrappedAst = Ast.statementAstFromString(`
            ${a.varn().getText()} = ref(${a.assignables().getText()})
          `.trim() + ';\n');
                    statementAsts.push(wrappedAst);
                }
                else if (s.statementAst instanceof ln_1.LnParser.LetdeclarationContext) {
                    const l = s.statementAst;
                    const name = l.VARNAME().getText();
                    const type = l.fulltypename() ? l.fulltypename().getText() : undefined;
                    const v = l.assignables().getText();
                    const wrappedAst = Ast.statementAstFromString(`
            let ${name}${type ? `: ${type}` : ''} = ref(${v})
          `.trim() + ';\n');
                    statementAsts.push(wrappedAst);
                }
                else {
                    statementAsts.push(s.statementAst);
                }
            }
            // Second pass, there was a conditional return, mutate everything *again* so the return is
            // instead hoisted into writing a closure variable
            if (hasConditionalReturn) {
                // Need the UUID to make sure this is unique if there's multiple layers of nested returns
                const retNamePostfix = "_" + uuid_1.v4().replace(/-/g, "_");
                const retVal = "retVal" + retNamePostfix;
                const retNotSet = "retNotSet" + retNamePostfix;
                const retValStatement = Ast.statementAstFromString(`
          let ${retVal}: ${this.getReturnType().typename} = clone()
        `.trim() + ';\n');
                const retNotSetStatement = Ast.statementAstFromString(`
          let ${retNotSet}: bool = clone(true)
        `.trim() + ';\n');
                let replacementStatements = [retValStatement, retNotSetStatement];
                replacementStatements.push(...UserFunction.earlyReturnRewrite(retVal, retNotSet, statementAsts, this.scope));
                replacementStatements.push(Ast.statementAstFromString(`
          return ${retVal}
        `.trim() + ';\n'));
                statementAsts = replacementStatements;
            }
            // TODO: Should these be attached to the scope or should callers provide a merged scope?
            const newArgs = {};
            for (const argName in this.args) {
                const a = this.args[argName];
                newArgs[argName] = interfaceMap.has(a) ? interfaceMap.get(a) : a;
                this.scope.put(newArgs[argName].typename, newArgs[argName]);
            }
            const newRet = interfaceMap.has(this.getReturnType()) ?
                interfaceMap.get(this.getReturnType()) : this.getReturnType();
            this.scope.put(newRet.typename, newRet);
            const fnStr = `
        fn ${this.name || ''} (${Object.keys(newArgs).map(argName => `${argName}: ${newArgs[argName].typename}`).join(', ')}): ${newRet.typename} {
          ${statementAsts.map(s => s.getText()).join('\n')}
        }
      `.trim();
            const fn = UserFunction.fromAst(Ast.functionAstFromString(fnStr), this.scope);
            return fn;
        }
        else {
            let hasNewType = false;
            const newArgs = {};
            for (const argName in this.args) {
                const a = this.args[argName];
                newArgs[argName] = interfaceMap.has(a) ? interfaceMap.get(a) : a;
                if (newArgs[argName] !== this.args[argName]) {
                    this.scope.put(newArgs[argName].typename, newArgs[argName]);
                    hasNewType = true;
                }
            }
            const newRet = interfaceMap.has(this.getReturnType()) ?
                interfaceMap.get(this.getReturnType()) : this.getReturnType();
            if (newRet !== this.getReturnType()) {
                this.scope.put(newRet.typename, newRet);
                hasNewType = true;
            }
            if (hasNewType) {
                const statementAsts = this.statements.map(s => s.statementAst);
                const fnStr = `
          fn ${this.name || ''} (${Object.keys(newArgs).map(argName => `${argName}: ${newArgs[argName].typename}`).join(', ')}): ${newRet.typename} {
            ${statementAsts.map(s => s.getText()).join('\n')}
          }
        `.trim();
                const fn = UserFunction.fromAst(Ast.functionAstFromString(fnStr), this.scope);
                return fn;
            }
            else {
                return this;
            }
        }
    }
    microstatementInlining(realArgNames, scope, microstatements) {
        // Get the current statement length for usage in multiple cleanup routines
        const originalStatementLength = microstatements.length;
        // First, check if there are any ENTERFN microstatements indicating a nested inlining, then
        // check that list for self-containment, which would cause an infinite loop in compilation and
        // abort with a useful error message.
        const enterfns = microstatements.filter(m => m.statementType === StatementType_1.default.ENTERFN);
        const isRecursive = enterfns.some(m => m.fns[0] === this);
        if (isRecursive) {
            let path = enterfns
                .slice(enterfns.findIndex(m => m.fns[0] === this))
                .map(m => m.fns[0].getName());
            path.push(this.getName());
            let pathstr = path.join(' -> ');
            throw new Error(`Recursive callstack detected: ${pathstr}. Aborting.`);
        }
        else {
            // Otherwise, add a marker for this
            microstatements.push(new Microstatement_1.default(StatementType_1.default.ENTERFN, scope, true, '', Type_1.default.builtinTypes.void, [], [this]));
        }
        // Perform a transform, if necessary, before generating the microstatements
        // Resolve circular dependency issue
        const internalNames = Object.keys(this.args);
        const inputs = realArgNames.map(n => Microstatement_1.default.fromVarName(n, scope, microstatements));
        const inputTypes = inputs.map(i => i.outputType);
        const originalTypes = Object.values(this.getArguments());
        const interfaceMap = new Map();
        originalTypes.forEach((t, i) => t.typeApplies(inputTypes[i], scope, interfaceMap));
        for (let i = 0; i < internalNames.length; i++) {
            const realArgName = realArgNames[i];
            // Instead of copying the relevant data, define a reference to where the data is located with
            // an alias for the function's expected variable name so statements referencing the argument
            // can be rewritten to use the new variable name.
            microstatements.push(new Microstatement_1.default(StatementType_1.default.REREF, scope, true, realArgName, inputTypes[i], [], [], internalNames[i]));
        }
        const fn = this.maybeTransform(interfaceMap, scope);
        for (const s of fn.statements) {
            Microstatement_1.default.fromStatement(s, microstatements, scope);
        }
        // Delete `REREF`s except a `return` statement's `REREF` to make sure it doesn't interfere with
        // the outer scope (if it has the same variable name defined, for instance)
        for (let i = originalStatementLength; i < microstatements.length - 1; i++) {
            if (microstatements[i].statementType == StatementType_1.default.REREF) {
                microstatements.splice(i, 1);
                i--;
            }
        }
        // If the output return type is an interface or is a realized generic with an inner interface
        // type, figure out what its actual type is. This is assuming that any input type of the same
        // interface's real type is the same as the output type, which is a valid assumption as long as
        // all inputs of that particular interface are the same type. TODO: If this is not true, it must
        // be a compile-time error earlier on.
        const last = microstatements[microstatements.length - 1];
        if (!this.getReturnType().typeApplies(last.outputType, scope, new Map())) {
            const returnTypeAst = Ast.fulltypenameAstFromString(this.getReturnType().typename);
            const returnTypeGenerics = returnTypeAst.typegenerics();
            const returnSubtypes = returnTypeGenerics ? returnTypeGenerics.fulltypename().map((t) => scope.deepGet(t.getText())) : [];
            if (this.getReturnType().iface) {
                const originalArgTypes = Object.values(this.args);
                for (let i = 0; i < inputTypes.length; i++) {
                    if (this.getReturnType() === originalArgTypes[i]) {
                        microstatements[microstatements.length - 1].outputType = inputTypes[i];
                    }
                }
            }
            else if (returnSubtypes.some((t) => !!t.iface)) {
                const oldReturnType = this.getReturnType();
                const originalArgTypes = Object.values(this.args);
                for (let i = 0; i < inputTypes.length; i++) {
                    for (let j = 0; j < returnSubtypes.length; j++) {
                        if (returnSubtypes[j] === originalArgTypes[i]) {
                            returnSubtypes[j] = inputTypes[i];
                        }
                    }
                }
                let newReturnType = oldReturnType.originalType.solidify(returnSubtypes.map((t) => t.typename), scope);
                last.outputType = newReturnType;
            }
            else {
                const lastTypeAst = Ast.fulltypenameAstFromString(last.outputType.typename);
                const lastTypeGenerics = lastTypeAst.typegenerics();
                const lastSubtypes = lastTypeGenerics ? lastTypeGenerics.fulltypename().map((t) => scope.deepGet(t.getText()) || scope.deepGet(t.typename().getText()).solidify(t.typegenerics().fulltypename().map((t) => t.getText()), scope)) : [];
                if (lastSubtypes.some((t) => !!t.iface)) {
                    const oldLastType = last.outputType;
                    const originalArgTypes = Object.values(this.args);
                    for (let i = 0; i < inputTypes.length; i++) {
                        for (let j = 0; j < lastSubtypes.length; j++) {
                            if (lastSubtypes[j] === originalArgTypes[i]) {
                                lastSubtypes[j] = inputTypes[i];
                            }
                        }
                    }
                    let newLastType = oldLastType.originalType.solidify(lastSubtypes.map((t) => t.typename), scope);
                    last.outputType = newLastType;
                }
            }
        }
        // Now that we're done with this, we need to pop out all of the ENTERFN microstatements created
        // after this one so we don't mark non-recursive calls to a function multiple times as recursive
        // TODO: This is not the most efficient way to do things, come up with a better metadata
        // mechanism to pass around.
        for (let i = originalStatementLength; i < microstatements.length; i++) {
            if (microstatements[i].statementType === StatementType_1.default.ENTERFN) {
                microstatements.splice(i, 1);
                i--;
            }
        }
    }
    static dispatchFn(fns, argumentTypeList, scope) {
        let fn = null;
        for (let i = 0; i < fns.length; i++) {
            const args = fns[i].getArguments();
            const argList = Object.values(args);
            if (argList.length !== argumentTypeList.length)
                continue;
            let skip = false;
            for (let j = 0; j < argList.length; j++) {
                if (argList[j].typeApplies(argumentTypeList[j], scope))
                    continue;
                skip = true;
            }
            if (skip)
                continue;
            fn = fns[i];
        }
        if (fn == null) {
            let errMsg = "Unable to find matching function for name and argument type set";
            let argTypes = [];
            for (let i = 0; i < argumentTypeList.length; i++) {
                argTypes.push("<" + argumentTypeList[i].typename + ">");
            }
            errMsg += '\n' + fns[0].getName() + "(" + argTypes.join(", ") + ")\n";
            errMsg += 'Candidate functions considered:\n';
            for (let i = 0; i < fns.length; i++) {
                const fn = fns[i];
                if (fn instanceof UserFunction) {
                    const fnStr = fn.toFnStr().split('{')[0];
                    errMsg += `${fnStr}\n`;
                }
                else {
                    // TODO: Add this to the opcode definition, too?
                    errMsg += `fn ${fn.getName()}(${Object.entries(fn.getArguments()).map(kv => `${kv[0]}: ${kv[1].typename}`)}): ${fn.getReturnType().typename}\n`;
                }
            }
            throw new Error(errMsg);
        }
        return fn;
    }
}
exports.default = UserFunction;

},{"../ln":9,"./Ast":10,"./Microstatement":13,"./Scope":16,"./Statement":17,"./StatementType":18,"./Type":19,"uuid":118}],21:[function(require,module,exports){
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.fromString = exports.fromFile = void 0;
const fs = require("fs");
const uuid_1 = require("uuid");
const Ast = require("./Ast");
const Std = require("./Std");
const Event_1 = require("./Event");
const Microstatement_1 = require("./Microstatement");
const Module_1 = require("./Module");
const StatementType_1 = require("./StatementType");
const UserFunction_1 = require("./UserFunction");
const hoistConst = (microstatements, constantDedupeLookup, constantDuplicateLookup, constants, eventTypes) => {
    let i = 0;
    while (i < microstatements.length) {
        const m = microstatements[i];
        if (m.statementType === StatementType_1.default.CONSTDEC &&
            m.fns.length === 0) {
            const original = constantDedupeLookup[m.inputNames[0]];
            if (!original) {
                constants.add(m);
                if (!m.outputType.builtIn) {
                    eventTypes.add(m.outputType);
                }
                microstatements.splice(i, 1);
                constantDedupeLookup[m.inputNames[0]] = m;
            }
            else {
                constantDuplicateLookup[m.outputName] = original.outputName;
                // Rewrite with the replaced name
                for (let j = i + 1; j < microstatements.length; j++) {
                    const n = microstatements[j];
                    for (let k = 0; k < n.inputNames.length; k++) {
                        if (n.inputNames[k] === m.outputName) {
                            n.inputNames[k] = original.outputName;
                        }
                    }
                }
                microstatements.splice(i, 1);
            }
        }
        else if (m.statementType === StatementType_1.default.CLOSURE) {
            hoistConst(m.closureStatements, constantDedupeLookup, constantDuplicateLookup, constants, eventTypes);
            i++;
        }
        else {
            i++;
        }
    }
};
const finalDedupe = (microstatements, constantDuplicateLookup) => {
    for (let i = 0; i < microstatements.length; i++) {
        const m = microstatements[i];
        if (m.statementType !== StatementType_1.default.LETDEC && m.statementType !== StatementType_1.default.CLOSURE) {
            for (let j = 0; j < m.inputNames.length; j++) {
                if (!!constantDuplicateLookup[m.inputNames[j]]) {
                    m.inputNames[j] = constantDuplicateLookup[m.inputNames[j]];
                }
            }
        }
        else if (m.statementType === StatementType_1.default.CLOSURE) {
            finalDedupe(m.closureStatements, constantDuplicateLookup);
        }
    }
};
const moduleAstsFromFile = (filename) => {
    let moduleAsts = {};
    let paths = [];
    const rootPath = fs.realpathSync(filename);
    paths.push(rootPath);
    while (paths.length > 0) {
        const modulePath = paths.shift();
        let module = null;
        try {
            module = Ast.fromFile(modulePath);
        }
        catch (e) {
            console.error("Could not load " + modulePath);
            console.error(e);
            throw e;
        }
        moduleAsts[modulePath] = module;
        const imports = Ast.resolveImports(modulePath, module);
        for (let i = 0; i < imports.length; i++) {
            if (!moduleAsts[imports[i]] && !(imports[i].substring(0, 5) === "@std/")) {
                paths.push(imports[i]);
            }
        }
    }
    return moduleAsts;
};
const moduleAstsFromString = (str) => {
    // If loading from a string, it's in the browser and some internal state needs cleaning. Some of
    // this doesn't appear to affect things, but better to compile from a known state
    Event_1.default.allEvents = [Event_1.default.allEvents[0]]; // Keep the `start` event
    Event_1.default.allEvents[0].handlers = []; // Reset the registered handlers on the `start` event
    let moduleAsts = {};
    const fakeRoot = '/fake/root/test.ln';
    let module = null;
    try {
        module = Ast.fromString(str);
    }
    catch (e) {
        console.error("Could not load test.ln");
        console.error(e);
        throw e;
    }
    moduleAsts[fakeRoot] = module;
    const imports = Ast.resolveImports(fakeRoot, module);
    for (let i = 0; i < imports.length; i++) {
        if (moduleAsts[imports[i]] === null && !(imports[i].substring(0, 5) === "@std/")) {
            console.error('Only @std imports allowed in the playground');
            throw new Error('Import declaration error');
        }
    }
    return moduleAsts;
};
const ammFromModuleAsts = (moduleAsts) => {
    // Load the standard library
    let stdFiles = new Set();
    for (const [modulePath, module] of Object.entries(moduleAsts)) {
        for (const importt of Ast.resolveImports(modulePath, module)) {
            if (importt.substring(0, 5) === "@std/") {
                stdFiles.add(importt.substring(5, importt.length) + '.ln');
            }
        }
    }
    Std.loadStdModules(stdFiles);
    const rootScope = Module_1.default.getAllModules()['<root>'].exportScope;
    // Load all modules
    Module_1.default.modulesFromAsts(moduleAsts, rootScope);
    // This implicitly populates the `allEvents` static property on the `Event` type, which we can
    // use to serialize out the definitions, skipping the built-in events. In the process we're need
    // to check a hashset for duplicate event names and rename as necessary. We also need to get the
    // list of user-defined types that we need to emit.
    let eventNames = new Set();
    let eventTypeNames = new Set();
    let eventTypes = new Set();
    let constantDedupeLookup = {}; // String to Microstatement object
    let constantDuplicateLookup = {}; // String to String object
    let constants = new Set(); // Microstatment objects
    for (const evt of Event_1.default.allEvents) {
        // Skip built-in events
        if (evt.builtIn)
            continue;
        // Check if there's a collision
        if (eventNames.has(evt.name)) {
            // We modify the event name by attaching a UUIDv4 to it
            evt.name = evt.name + "_" + uuid_1.v4().replace(/-/g, "_");
        }
        // Add the event to the list
        eventNames.add(evt.name);
        // Now on to event type processing
        const type = evt.type;
        // Skip built-in types, too
        if (type.builtIn)
            continue;
        // Check if there's a collision
        if (eventTypeNames.has(type.typename)) {
            // An event type may be seen multiple times, make sure this is an actual collision
            if (eventTypes.has(type))
                continue; // This event was already processed, so we're done
            // Modify the type name by attaching a UUIDv4 to it
            type.typename = type.typename + "_" + uuid_1.v4().replace(/-/g, "_");
        }
        // Add the type to the list
        eventTypeNames.add(type.typename);
        eventTypes.add(type);
        // Determine if any of the properties of the type should be added to the list
        for (const propType of Object.values(type.properties)) {
            // Skip built-in types, too
            if (propType.builtIn)
                continue;
            // Check if there's a collision
            if (eventTypeNames.has(propType.typename)) {
                // A type may be seen multiple times, make sure this is an actual collision
                if (eventTypes.has(propType))
                    continue; // This event was already processed, so we're done
                // Modify the type name by attaching a UUIDv4 to it
                propType.typename = propType.typename + "_" + uuid_1.v4().replace(/-/g, "_");
            }
            // Add the type to the list
            eventTypeNames.add(propType.typename);
            eventTypes.add(propType);
        }
    }
    // Extract the handler definitions and constant data
    let handlers = {}; // String to array of Microstatement objects
    for (let evt of Event_1.default.allEvents) {
        for (let handler of evt.handlers) {
            if (handler instanceof UserFunction_1.default) {
                // Define the handler preamble
                let handlerDec = "on " + evt.name + " fn (";
                let argList = [];
                let microstatements = [];
                for (const arg of Object.keys(handler.getArguments())) {
                    argList.push(arg + ": " + handler.getArguments()[arg].typename);
                    microstatements.push(new Microstatement_1.default(StatementType_1.default.ARG, handler.scope, true, arg, handler.getArguments()[arg], [], []));
                }
                handlerDec += argList.join(", ");
                handlerDec += "): " + handler.getReturnType().typename + " {";
                // Extract the handler statements and compile into microstatements
                const statements = handler.maybeTransform(new Map()).statements;
                for (const s of statements) {
                    Microstatement_1.default.fromStatement(s, microstatements);
                }
                // Pull the constants out of the microstatements into the constants set.
                hoistConst(microstatements, constantDedupeLookup, constantDuplicateLookup, constants, eventTypes);
                // Register the handler and remaining statements
                handlers.hasOwnProperty(handlerDec) ? handlers[handlerDec].push(microstatements) : handlers[handlerDec] = [microstatements];
            }
        }
    }
    // Second pass to fully-deduplicate constants
    for (let handler of Object.keys(handlers)) {
        const functions = handlers[handler];
        for (let microstatements of functions) {
            finalDedupe(microstatements, constantDuplicateLookup);
        }
    }
    let outStr = "";
    // Print the event types
    /* for (const eventType of eventTypes) {
      outStr += eventType.toString() + "\n"
    } */ // TODO: It doesn't appear to be required in the rest of the stack
    // Print the constants
    for (const constant of constants) {
        outStr += constant.toString() + "\n";
    }
    // Print the user-defined event declarations
    for (const evt of Event_1.default.allEvents) {
        if (evt.builtIn)
            continue; // Skip built-in events
        outStr += evt.toString() + "\n";
    }
    // Print the user-defined event handlers
    for (const [handlerDec, handlersList] of Object.entries(handlers)) {
        for (const microstatements of handlersList) {
            outStr += handlerDec + "\n";
            for (const m of microstatements) {
                const mString = m.toString();
                if (mString === "")
                    continue;
                outStr += "  " + mString + "\n";
            }
            outStr += "}\n";
        }
    }
    return outStr;
};
exports.fromFile = (filename) => ammFromModuleAsts(moduleAstsFromFile(filename));
exports.fromString = (str) => ammFromModuleAsts(moduleAstsFromString(str));

},{"./Ast":10,"./Event":12,"./Microstatement":13,"./Module":14,"./StatementType":18,"./Std":1,"./UserFunction":20,"fs":74,"uuid":118}],22:[function(require,module,exports){
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const uuid_1 = require("uuid");
const Event_1 = require("./Event");
const Microstatement_1 = require("./Microstatement");
const Module_1 = require("./Module");
const Scope_1 = require("./Scope");
const StatementType_1 = require("./StatementType");
const Type_1 = require("./Type");
const UserFunction_1 = require("./UserFunction");
const opcodeScope = new Scope_1.default();
const opcodeModule = new Module_1.default(opcodeScope);
// Base types
const addBuiltIn = (name) => {
    opcodeScope.put(name, Type_1.Type.builtinTypes[name]);
};
([
    'void', 'int8', 'int16', 'int32', 'int64', 'float32', 'float64', 'bool', 'string', 'function',
    'operator', 'Error', 'Maybe', 'Result', 'Either', 'Array', 'ExecRes', 'InitialReduce',
    'InternalResponse', 'Seq', 'Self',
].map(addBuiltIn));
Type_1.Type.builtinTypes['Array'].solidify(['string'], opcodeScope);
opcodeScope.put('any', new Type_1.Type('any', true, false, {}, {}, null, new Type_1.Interface('any')));
opcodeScope.put('anythingElse', new Type_1.Type('anythingElse', true, false, {}, {}, null, new Type_1.Interface('anythingElse')));
Type_1.Type.builtinTypes['Array'].solidify(['any'], opcodeScope);
Type_1.Type.builtinTypes['Array'].solidify(['anythingElse'], opcodeScope);
Type_1.Type.builtinTypes.Maybe.solidify(['any'], opcodeScope);
Type_1.Type.builtinTypes.Result.solidify(['any'], opcodeScope);
Type_1.Type.builtinTypes.Result.solidify(['anythingElse'], opcodeScope);
Type_1.Type.builtinTypes.Result.solidify(['int64'], opcodeScope);
Type_1.Type.builtinTypes.Result.solidify(['string'], opcodeScope);
Type_1.Type.builtinTypes.Either.solidify(['any', 'anythingElse'], opcodeScope);
Type_1.Type.builtinTypes.InitialReduce.solidify(['any', 'anythingElse'], opcodeScope);
opcodeScope.put("start", new Event_1.default("_start", Type_1.Type.builtinTypes.void, true));
opcodeScope.put("__conn", new Event_1.default("__conn", Type_1.Type.builtinTypes.InternalRequest, true));
const t = (str) => opcodeScope.get(str);
// opcode declarations
const addopcodes = (opcodes) => {
    const opcodeNames = Object.keys(opcodes);
    opcodeNames.forEach((opcodeName) => {
        const opcodeDef = opcodes[opcodeName];
        const [args, returnType] = opcodeDef;
        if (!returnType) { // This is a three-arg, 0-return opcode
            const opcodeObj = {
                getName: () => opcodeName,
                getArguments: () => args,
                getReturnType: () => Type_1.Type.builtinTypes.void,
                isPure: () => true,
                microstatementInlining: (realArgNames, scope, microstatements) => {
                    if (['seqwhile'].includes(opcodeName)) {
                        const inputs = realArgNames.map(n => Microstatement_1.default.fromVarName(n, scope, microstatements));
                        const condfn = UserFunction_1.default.dispatchFn(inputs[1].fns, [], scope);
                        const condidx = microstatements.indexOf(inputs[1]);
                        const condm = microstatements.slice(0, condidx);
                        Microstatement_1.default.closureFromUserFunction(condfn, condfn.scope || scope, condm, new Map());
                        const condclosure = condm[condm.length - 1];
                        microstatements.splice(condidx, 0, condclosure);
                        realArgNames[1] = condclosure.outputName;
                        const bodyfn = UserFunction_1.default.dispatchFn(inputs[2].fns, [], scope);
                        const bodyidx = microstatements.indexOf(inputs[2]);
                        const bodym = microstatements.slice(0, bodyidx);
                        Microstatement_1.default.closureFromUserFunction(bodyfn, bodyfn.scope || scope, bodym, new Map());
                        const bodyclosure = bodym[bodym.length - 1];
                        microstatements.splice(bodyidx, 0, bodyclosure);
                        realArgNames[2] = bodyclosure.outputName;
                    }
                    microstatements.push(new Microstatement_1.default(StatementType_1.default.CALL, scope, true, null, opcodeObj.getReturnType(), realArgNames, [opcodeObj]));
                },
            };
            // Add each opcode
            opcodeScope.put(opcodeName, [opcodeObj]);
        }
        else {
            const opcodeObj = {
                getName: () => opcodeName,
                getArguments: () => args,
                getReturnType: () => returnType,
                isPure: () => true,
                microstatementInlining: (realArgNames, scope, microstatements) => {
                    const inputs = realArgNames.map(n => Microstatement_1.default.fromVarName(n, scope, microstatements));
                    const inputTypes = inputs.map(i => i.outputType);
                    const interfaceMap = new Map();
                    Object.values(args).forEach((t, i) => t.typeApplies(inputTypes[i], scope, interfaceMap));
                    microstatements.push(new Microstatement_1.default(StatementType_1.default.CONSTDEC, scope, true, "_" + uuid_1.v4().replace(/-/g, "_"), ((inputTypes, scope) => {
                        if (!!returnType.iface) {
                            // Path 1: the opcode returns an interface based on the interface type of an input
                            let replacementType;
                            Object.values(args).forEach((a, i) => {
                                if (inputs[i].statementType === StatementType_1.default.CLOSUREDEF) {
                                    const idx = microstatements.indexOf(inputs[i]);
                                    const m = microstatements.slice(0, idx);
                                    let fn;
                                    // TODO: Remove this hackery after function types are more than just 'function'
                                    if ([
                                        'map', 'mapl', 'each', 'eachl', 'every', 'everyl', 'some', 'somel', 'filter',
                                        'filterl', 'seqeach',
                                    ].includes(opcodeName)) {
                                        // TODO: Try to re-unify these blocks from above
                                        const arrayInnerType = scope.deepGet(inputTypes[0].typename.replace(/^Array<(.*)>$/, "$1"));
                                        const innerType = inputTypes[0].originalType ?
                                            arrayInnerType :
                                            Type_1.Type.builtinTypes.int64; // Hackery for seqeach
                                        try {
                                            fn = UserFunction_1.default.dispatchFn(inputs[i].fns, [innerType], scope)(Object.values(fn.getArguments())[0])
                                                .typeApplies(innerType, scope, interfaceMap);
                                        }
                                        catch {
                                            try {
                                                fn = UserFunction_1.default.dispatchFn(inputs[i].fns, [], scope);
                                            }
                                            catch {
                                                fn = UserFunction_1.default.dispatchFn(inputs[i].fns, [arrayInnerType, Type_1.Type.builtinTypes.int64], scope);
                                                const closureArgs = Object.values(fn.getArguments());
                                                closureArgs[0].typeApplies(arrayInnerType, scope, interfaceMap);
                                                closureArgs[1].typeApplies(Type_1.Type.builtinTypes.int64, scope, interfaceMap);
                                            }
                                        }
                                    }
                                    else if (['reducel', 'reducep'].includes(opcodeName)) {
                                        const arrayInnerType = scope.deepGet(inputTypes[0].typename.replace(/^Array<(.*)>$/, "$1"));
                                        fn = UserFunction_1.default.dispatchFn(inputs[i].fns, [arrayInnerType, arrayInnerType], scope);
                                        const closureArgs = Object.values(fn.getArguments());
                                        closureArgs[0].typeApplies(arrayInnerType, scope, interfaceMap);
                                        closureArgs[1].typeApplies(arrayInnerType, scope, interfaceMap);
                                    }
                                    else if (['foldl'].includes(opcodeName)) {
                                        const reducerTypes = Object.values(inputTypes[0].properties);
                                        const inType = scope.deepGet(reducerTypes[0].typename.replace(/^Array<(.*)>$/, "$1"));
                                        const fnArgTypes = [
                                            reducerTypes[1],
                                            inType,
                                        ];
                                        fn = UserFunction_1.default.dispatchFn(inputs[i].fns, fnArgTypes, scope);
                                        const closureArgs = Object.values(fn.getArguments());
                                        closureArgs[0].typeApplies(reducerTypes[1], scope, interfaceMap);
                                        closureArgs[1].typeApplies(inType, scope, interfaceMap);
                                    }
                                    else if (['foldp'].includes(opcodeName)) {
                                        const reducerTypes = Object.values(inputTypes[0].properties);
                                        const inType = scope.deepGet(reducerTypes[0].typename.replace(/^Array<(.*)>$/, "$1"));
                                        const fnArgTypes = [
                                            reducerTypes[1],
                                            inType,
                                        ];
                                        fn = UserFunction_1.default.dispatchFn(inputs[i].fns, fnArgTypes, scope);
                                        const closureArgs = Object.values(fn.getArguments());
                                        closureArgs[0].typeApplies(reducerTypes[1], scope, interfaceMap);
                                        closureArgs[1].typeApplies(inType, scope, interfaceMap);
                                    }
                                    else if (['seqrec'].includes(opcodeName)) {
                                        // TODO: Is this even reachable?
                                        // TODO: How would multiple dispatch even work here?
                                        fn = inputs[1].fns[0];
                                    }
                                    else if (['selfrec'].includes(opcodeName)) {
                                        // TODO: Is this even reachable?
                                        fn = inputs[0].fns[0];
                                    }
                                    else {
                                        fn = UserFunction_1.default.dispatchFn(inputs[i].fns, [], scope);
                                    }
                                    Microstatement_1.default.closureFromUserFunction(fn, fn.scope || scope, m, interfaceMap);
                                    const closure = m[m.length - 1];
                                    microstatements.splice(idx, 0, closure);
                                    realArgNames[i] = closure.outputName;
                                }
                                if (!!a.iface && a.iface.interfacename === returnType.iface.interfacename) {
                                    replacementType = inputTypes[i];
                                }
                                if (Object.values(a.properties).some(p => !!p.iface && p.iface.interfacename === returnType.iface.interfacename)) {
                                    Object.values(a.properties).forEach((p, j) => {
                                        if (!!p.iface && p.iface.interfacename === returnType.iface.interfacename) {
                                            replacementType = Object.values(inputTypes[i].properties)[j];
                                        }
                                    });
                                }
                            });
                            if (!replacementType)
                                return returnType;
                            return replacementType;
                        }
                        else if (returnType.originalType &&
                            Object.values(returnType.properties).some((p) => !!p.iface)) {
                            // TODO: Remove this hackery after function types are more than just 'function'
                            if ([
                                'map', 'mapl', 'each', 'eachl', 'every', 'everyl', 'some', 'somel', 'filter',
                                'filterl', 'seqeach',
                            ].includes(opcodeName)) {
                                // The ideal `map` opcode type declaration is something like:
                                // `map(Array<any>, fn (any): anythingElse): Array<anythingElse>` and then the
                                // interface matching logic figures out what the return type of the opcode is
                                // based on the return type of the function given to it.
                                // For now, we just do that "by hand."
                                const arrayInnerType = scope.deepGet(inputTypes[0].typename.replace(/^Array<(.*)>$/, "$1"));
                                const innerType = inputTypes[0].originalType ?
                                    arrayInnerType :
                                    Type_1.Type.builtinTypes.int64; // Hackery for seqeach
                                let fn;
                                try {
                                    fn = UserFunction_1.default.dispatchFn(inputs[1].fns, [innerType], scope);
                                }
                                catch {
                                    try {
                                        fn = UserFunction_1.default.dispatchFn(inputs[1].fns, [], scope);
                                    }
                                    catch {
                                        fn = UserFunction_1.default.dispatchFn(inputs[1].fns, [arrayInnerType, Type_1.Type.builtinTypes.int64], scope);
                                    }
                                }
                                const closureArgs = Object.values(fn.getArguments());
                                if (closureArgs[0]) {
                                    closureArgs[0].typeApplies(innerType, scope, interfaceMap);
                                }
                                if (closureArgs[1]) {
                                    closureArgs[1].typeApplies(Type_1.Type.builtinTypes.int64, scope, interfaceMap);
                                }
                                const idx = microstatements.indexOf(inputs[1]);
                                const m = microstatements.slice(0, idx);
                                Microstatement_1.default.closureFromUserFunction(fn, fn.scope || scope, m, interfaceMap);
                                const closure = m[m.length - 1];
                                microstatements.splice(idx, 0, closure);
                                realArgNames[1] = closure.outputName;
                                if (['filter', 'filterl'].includes(opcodeName)) {
                                    return inputs[0].outputType;
                                }
                                else {
                                    const innerType = closure.closureOutputType;
                                    const newInnerType = innerType.realize(interfaceMap, scope); // Necessary?
                                    const baseType = returnType.originalType;
                                    const newReturnType = baseType ?
                                        baseType.solidify([newInnerType.typename], scope) :
                                        returnType;
                                    return newReturnType;
                                }
                            }
                            else if (['find', 'findl'].includes(opcodeName)) {
                                const arrayInnerType = scope.deepGet(inputTypes[0].typename.replace(/^Array<(.*)>$/, "$1"));
                                const innerType = inputTypes[0].originalType ?
                                    arrayInnerType :
                                    Type_1.Type.builtinTypes.int64; // Hackery for seqeach
                                let fn = UserFunction_1.default.dispatchFn(inputs[1].fns, [arrayInnerType], scope);
                                const closureArgs = Object.values(fn.getArguments());
                                if (closureArgs[0]) {
                                    closureArgs[0].typeApplies(innerType, scope, interfaceMap);
                                }
                                const idx = microstatements.indexOf(inputs[1]);
                                const m = microstatements.slice(0, idx);
                                Microstatement_1.default.closureFromUserFunction(fn, fn.scope || scope, m, interfaceMap);
                                const closure = m[m.length - 1];
                                microstatements.splice(idx, 0, closure);
                                realArgNames[1] = closure.outputName;
                                return Type_1.Type.builtinTypes.Result.solidify([innerType.typename], scope);
                            }
                            else if (['reducel', 'reducep'].includes(opcodeName)) {
                                const arrayInnerType = scope.deepGet(inputTypes[0].typename.replace(/^Array<(.*)>$/, "$1"));
                                let fn = UserFunction_1.default.dispatchFn(inputs[1].fns, [arrayInnerType, arrayInnerType], scope);
                                const closureArgs = Object.values(fn.getArguments());
                                closureArgs[0].typeApplies(arrayInnerType, scope, interfaceMap);
                                closureArgs[1].typeApplies(arrayInnerType, scope, interfaceMap);
                                const idx = microstatements.indexOf(inputs[1]);
                                const m = microstatements.slice(0, idx);
                                Microstatement_1.default.closureFromUserFunction(fn, fn.scope || scope, m, interfaceMap);
                                const closure = m[m.length - 1];
                                microstatements.splice(idx, 0, closure);
                                realArgNames[1] = closure.outputName;
                                return arrayInnerType;
                            }
                            else if (['foldl'].includes(opcodeName)) {
                                const reducerTypes = Object.values(inputTypes[0].properties);
                                const inType = scope.deepGet(reducerTypes[0].typename.replace(/^Array<(.*)>$/, "$1"));
                                const fnArgTypes = [
                                    reducerTypes[1],
                                    inType,
                                ];
                                let fn = UserFunction_1.default.dispatchFn(inputs[1].fns, fnArgTypes, scope);
                                const closureArgs = Object.values(fn.getArguments());
                                closureArgs[0].typeApplies(reducerTypes[1], scope, interfaceMap);
                                closureArgs[1].typeApplies(inType, scope, interfaceMap);
                                const idx = microstatements.indexOf(inputs[1]);
                                const m = microstatements.slice(0, idx);
                                Microstatement_1.default.closureFromUserFunction(fn, fn.scope || scope, m, interfaceMap);
                                const closure = m[m.length - 1];
                                microstatements.splice(idx, 0, closure);
                                realArgNames[1] = closure.outputName;
                                return closure.closureOutputType;
                            }
                            else if (['foldp'].includes(opcodeName)) {
                                const reducerTypes = Object.values(inputTypes[0].properties);
                                const inType = scope.deepGet(reducerTypes[0].typename.replace(/^Array<(.*)>$/, "$1"));
                                const fnArgTypes = [
                                    reducerTypes[1],
                                    inType,
                                ];
                                const fn = UserFunction_1.default.dispatchFn(inputs[1].fns, fnArgTypes, scope);
                                const closureArgs = Object.values(fn.getArguments());
                                closureArgs[0].typeApplies(reducerTypes[1], scope, interfaceMap);
                                closureArgs[1].typeApplies(inType, scope, interfaceMap);
                                const idx = microstatements.indexOf(inputs[1]);
                                const m = microstatements.slice(0, idx);
                                Microstatement_1.default.closureFromUserFunction(fn, fn.scope || scope, m, interfaceMap);
                                const closure = m[m.length - 1];
                                microstatements.splice(idx, 0, closure);
                                realArgNames[1] = closure.outputName;
                                return Type_1.Type.builtinTypes['Array'].solidify([closure.closureOutputType.typename], scope);
                            }
                            else if (['seqrec'].includes(opcodeName)) {
                                // TODO: How would multiple dispatch even work here?
                                const fn = inputs[1].inputNames[1].fns[0];
                                const idx = microstatements.indexOf(inputs[1]);
                                const m = microstatements.slice(0, idx);
                                Microstatement_1.default.closureFromUserFunction(fn, fn.scope || scope, m, interfaceMap);
                                const closure = m[m.length - 1];
                                microstatements.splice(idx, 0, closure);
                                realArgNames[1] = closure.outputName;
                                // TODO: How do interface types work here?
                                return closure.closureOutputType.typename;
                            }
                            else if (['selfrec'].includes(opcodeName)) {
                                // TODO: This is absolute crap. How to fix?
                                return inputs[0].inputNames[1] ? Microstatement_1.default.fromVarName(inputs[0].inputNames[1], scope, microstatements).closureOutputType : returnType;
                            }
                            else {
                                // Path 2: the opcode returns solidified generic type with an interface generic
                                // that mathces the interface type of an input
                                const returnIfaces = Object.values(returnType.properties)
                                    .filter((p) => !!p.iface).map((p) => p.iface);
                                if (returnIfaces.length > 0) {
                                    const newReturnType = returnType.realize(interfaceMap, scope);
                                    return newReturnType;
                                }
                                else {
                                    return returnType;
                                }
                            }
                        }
                        else {
                            // No need to adjust the return type, but may still need to lazy eval a closure
                            Object.values(args).forEach((_a, i) => {
                                if (inputs[i].statementType === StatementType_1.default.CLOSUREDEF) {
                                    const idx = microstatements.indexOf(inputs[i]);
                                    const m = microstatements.slice(0, idx);
                                    let fn;
                                    // TODO: Remove this hackery after function types are more than just 'function'
                                    if ([
                                        'map', 'mapl', 'each', 'eachl', 'every', 'everyl', 'some', 'somel', 'filter',
                                        'filterl', 'seqeach',
                                    ].includes(opcodeName)) {
                                        // TODO: Try to re-unify these blocks from above
                                        const arrayInnerType = scope.deepGet(inputTypes[0].typename.replace(/^Array<(.*)>$/, "$1"));
                                        const innerType = inputTypes[0].originalType ?
                                            arrayInnerType :
                                            Type_1.Type.builtinTypes.int64; // Hackery for seqeach
                                        try {
                                            fn = UserFunction_1.default.dispatchFn(inputs[i].fns, [innerType], scope);
                                        }
                                        catch {
                                            try {
                                                fn = UserFunction_1.default.dispatchFn(inputs[i].fns, [], scope);
                                            }
                                            catch {
                                                fn = UserFunction_1.default.dispatchFn(inputs[i].fns, [arrayInnerType, Type_1.Type.builtinTypes.int64], scope);
                                            }
                                        }
                                        const closureArgs = Object.values(fn.getArguments());
                                        if (closureArgs[0]) {
                                            closureArgs[0].typeApplies(innerType, scope, interfaceMap);
                                        }
                                        if (closureArgs[1]) {
                                            closureArgs[1].typeApplies(Type_1.Type.builtinTypes.int64, scope, interfaceMap);
                                        }
                                    }
                                    else if (['reducel', 'reducep'].includes(opcodeName)) {
                                        const arrayInnerType = scope.deepGet(inputTypes[0].typename.replace(/^Array<(.*)>$/, "$1"));
                                        fn = UserFunction_1.default.dispatchFn(inputs[1].fns, [arrayInnerType, arrayInnerType], scope);
                                        const closureArgs = Object.values(fn.getArguments());
                                        closureArgs[0].typeApplies(arrayInnerType, scope, interfaceMap);
                                        closureArgs[1].typeApplies(arrayInnerType, scope, interfaceMap);
                                    }
                                    else if (['foldl'].includes(opcodeName)) {
                                        const reducerTypes = Object.values(inputTypes[0].properties);
                                        const inType = scope.deepGet(reducerTypes[0].typename.replace(/^Array<(.*)>$/, "$1"));
                                        const fnArgTypes = [
                                            reducerTypes[1],
                                            inType,
                                        ];
                                        let fn = UserFunction_1.default.dispatchFn(inputs[1].fns, fnArgTypes, scope);
                                        const closureArgs = Object.values(fn.getArguments());
                                        closureArgs[0].typeApplies(reducerTypes[1], scope, interfaceMap);
                                        closureArgs[1].typeApplies(inType, scope, interfaceMap);
                                    }
                                    else if (['seqrec'].includes(opcodeName)) {
                                        // TODO: How would multiple dispatch even work here?
                                        fn = inputs[1].fns[0];
                                    }
                                    else if (['selfrec'].includes(opcodeName)) {
                                        // TODO: Is this even reachable?
                                        fn = inputs[0].inputNames[1].fns[0];
                                    }
                                    else {
                                        fn = UserFunction_1.default.dispatchFn(inputs[i].fns, [], scope);
                                    }
                                    Microstatement_1.default.closureFromUserFunction(fn, fn.scope || scope, m, interfaceMap);
                                    const closure = m[m.length - 1];
                                    microstatements.splice(idx, 0, closure);
                                    realArgNames[i] = closure.outputName;
                                }
                            });
                        }
                        return returnType;
                    })(inputTypes, scope), realArgNames, [opcodeObj]));
                },
            };
            // Add each opcode
            opcodeScope.put(opcodeName, [opcodeObj]);
        }
    });
};
addopcodes({
    i8f64: [{ number: t('int8'), }, t('float64')],
    i16f64: [{ number: t('int16'), }, t('float64')],
    i32f64: [{ number: t('int32'), }, t('float64')],
    i64f64: [{ number: t('int64'), }, t('float64')],
    f32f64: [{ number: t('float32'), }, t('float64')],
    strf64: [{ str: t('string'), }, t('float64')],
    boolf64: [{ boo: t('bool'), }, t('float64')],
    i8f32: [{ number: t('int8'), }, t('float32')],
    i16f32: [{ number: t('int16'), }, t('float32')],
    i32f32: [{ number: t('int32'), }, t('float32')],
    i64f32: [{ number: t('int64'), }, t('float32')],
    f64f32: [{ number: t('float64'), }, t('float32')],
    strf32: [{ str: t('string'), }, t('float32')],
    boolf32: [{ boo: t('bool'), }, t('float32')],
    i8i64: [{ number: t('int8'), }, t('int64')],
    i16i64: [{ number: t('int16'), }, t('int64')],
    i32i64: [{ number: t('int32'), }, t('int64')],
    f32i64: [{ number: t('float32'), }, t('int64')],
    f64i64: [{ number: t('float64'), }, t('int64')],
    stri64: [{ str: t('string'), }, t('int64')],
    booli64: [{ boo: t('bool'), }, t('int64')],
    i8i32: [{ number: t('int8'), }, t('int32')],
    i16i32: [{ number: t('int16'), }, t('int32')],
    i64i32: [{ number: t('int64'), }, t('int32')],
    f32i32: [{ number: t('float32'), }, t('int32')],
    f64i32: [{ number: t('float64'), }, t('int32')],
    stri32: [{ str: t('string'), }, t('int32')],
    booli32: [{ boo: t('bool'), }, t('int32')],
    i8i16: [{ number: t('int8'), }, t('int16')],
    i32i16: [{ number: t('int32'), }, t('int16')],
    i64i16: [{ number: t('int64'), }, t('int16')],
    f32i16: [{ number: t('float32'), }, t('int16')],
    f64i16: [{ number: t('float64'), }, t('int16')],
    stri16: [{ str: t('string'), }, t('int16')],
    booli16: [{ boo: t('bool'), }, t('int16')],
    i16i8: [{ number: t('int16'), }, t('int8')],
    i32i8: [{ number: t('int32'), }, t('int8')],
    i64i8: [{ number: t('int64'), }, t('int8')],
    f32i8: [{ number: t('float32'), }, t('int8')],
    f64i8: [{ number: t('float64'), }, t('int8')],
    stri8: [{ str: t('string'), }, t('int8')],
    booli8: [{ boo: t('bool'), }, t('int8')],
    i8bool: [{ number: t('int8'), }, t('bool')],
    i16bool: [{ number: t('int16'), }, t('bool')],
    i32bool: [{ number: t('int32'), }, t('bool')],
    i64bool: [{ number: t('int64'), }, t('bool')],
    f32bool: [{ number: t('float32'), }, t('bool')],
    f64bool: [{ number: t('float64'), }, t('bool')],
    strbool: [{ str: t('string'), }, t('bool')],
    i8str: [{ number: t('int8'), }, t('string')],
    i16str: [{ number: t('int16'), }, t('string')],
    i32str: [{ number: t('int32'), }, t('string')],
    i64str: [{ number: t('int64'), }, t('string')],
    f32str: [{ number: t('float32'), }, t('string')],
    f64str: [{ number: t('float64'), }, t('string')],
    boolstr: [{ boo: t('bool'), }, t('string')],
    addi8: [{ a: t('int8'), b: t('int8'), }, t('int8')],
    addi16: [{ a: t('int16'), b: t('int16'), }, t('int16')],
    addi32: [{ a: t('int32'), b: t('int32'), }, t('int32')],
    addi64: [{ a: t('int64'), b: t('int64'), }, t('int64')],
    addf32: [{ a: t('float32'), b: t('float32'), }, t('float32')],
    addf64: [{ a: t('float64'), b: t('float64'), }, t('float64')],
    subi8: [{ a: t('int8'), b: t('int8'), }, t('int8')],
    subi16: [{ a: t('int16'), b: t('int16'), }, t('int16')],
    subi32: [{ a: t('int32'), b: t('int32'), }, t('int32')],
    subi64: [{ a: t('int64'), b: t('int64'), }, t('int64')],
    subf32: [{ a: t('float32'), b: t('float32'), }, t('float32')],
    subf64: [{ a: t('float64'), b: t('float64'), }, t('float64')],
    negi8: [{ a: t('int8'), }, t('int8')],
    negi16: [{ a: t('int16'), }, t('int16')],
    negi32: [{ a: t('int32'), }, t('int32')],
    negi64: [{ a: t('int64'), }, t('int64')],
    negf32: [{ a: t('float32'), }, t('float32')],
    negf64: [{ a: t('float64'), }, t('float64')],
    absi8: [{ a: t('int8'), }, t('int8')],
    absi16: [{ a: t('int16'), }, t('int16')],
    absi32: [{ a: t('int32'), }, t('int32')],
    absi64: [{ a: t('int64'), }, t('int64')],
    absf32: [{ a: t('float32'), }, t('float32')],
    absf64: [{ a: t('float64'), }, t('float64')],
    muli8: [{ a: t('int8'), b: t('int8'), }, t('int8')],
    muli16: [{ a: t('int16'), b: t('int16'), }, t('int16')],
    muli32: [{ a: t('int32'), b: t('int32'), }, t('int32')],
    muli64: [{ a: t('int64'), b: t('int64'), }, t('int64')],
    mulf32: [{ a: t('float32'), b: t('float32'), }, t('float32')],
    mulf64: [{ a: t('float64'), b: t('float64'), }, t('float64')],
    divi8: [{ a: t('int8'), b: t('int8'), }, t('int8')],
    divi16: [{ a: t('int16'), b: t('int16'), }, t('int16')],
    divi32: [{ a: t('int32'), b: t('int32'), }, t('int32')],
    divi64: [{ a: t('int64'), b: t('int64'), }, t('int64')],
    divf32: [{ a: t('float32'), b: t('float32'), }, t('float32')],
    divf64: [{ a: t('float64'), b: t('float64'), }, t('float64')],
    modi8: [{ a: t('int8'), b: t('int8'), }, t('int8')],
    modi16: [{ a: t('int16'), b: t('int16'), }, t('int16')],
    modi32: [{ a: t('int32'), b: t('int32'), }, t('int32')],
    modi64: [{ a: t('int64'), b: t('int64'), }, t('int64')],
    powi8: [{ a: t('int8'), b: t('int8'), }, t('int8')],
    powi16: [{ a: t('int16'), b: t('int16'), }, t('int16')],
    powi32: [{ a: t('int32'), b: t('int32'), }, t('int32')],
    powi64: [{ a: t('int64'), b: t('int64'), }, t('int64')],
    powf32: [{ a: t('float32'), b: t('float32'), }, t('float32')],
    powf64: [{ a: t('float64'), b: t('float64'), }, t('float64')],
    sqrtf32: [{ a: t('float32'), }, t('float32')],
    sqrtf64: [{ a: t('float64'), }, t('float64')],
    andi8: [{ a: t('int8'), b: t('int8'), }, t('int8')],
    andi16: [{ a: t('int16'), b: t('int16'), }, t('int16')],
    andi32: [{ a: t('int32'), b: t('int32'), }, t('int32')],
    andi64: [{ a: t('int64'), b: t('int64'), }, t('int64')],
    andbool: [{ a: t('bool'), b: t('bool'), }, t('bool')],
    ori8: [{ a: t('int8'), b: t('int8'), }, t('int8')],
    ori16: [{ a: t('int16'), b: t('int16'), }, t('int16')],
    ori32: [{ a: t('int32'), b: t('int32'), }, t('int32')],
    ori64: [{ a: t('int64'), b: t('int64'), }, t('int64')],
    orbool: [{ a: t('bool'), b: t('bool'), }, t('bool')],
    xori8: [{ a: t('int8'), b: t('int8'), }, t('int8')],
    xori16: [{ a: t('int16'), b: t('int16'), }, t('int16')],
    xori32: [{ a: t('int32'), b: t('int32'), }, t('int32')],
    xori64: [{ a: t('int64'), b: t('int64'), }, t('int64')],
    xorbool: [{ a: t('bool'), b: t('bool'), }, t('bool')],
    noti8: [{ a: t('int8'), }, t('int8')],
    noti16: [{ a: t('int16'), }, t('int16')],
    noti32: [{ a: t('int32'), }, t('int32')],
    noti64: [{ a: t('int64'), }, t('int64')],
    notbool: [{ a: t('bool'), }, t('bool')],
    nandi8: [{ a: t('int8'), b: t('int8'), }, t('int8')],
    nandi16: [{ a: t('int16'), b: t('int16'), }, t('int16')],
    nandi32: [{ a: t('int32'), b: t('int32'), }, t('int32')],
    nandi64: [{ a: t('int64'), b: t('int64'), }, t('int64')],
    nandboo: [{ a: t('bool'), b: t('bool'), }, t('bool')],
    nori8: [{ a: t('int8'), b: t('int8'), }, t('int8')],
    nori16: [{ a: t('int16'), b: t('int16'), }, t('int16')],
    nori32: [{ a: t('int32'), b: t('int32'), }, t('int32')],
    nori64: [{ a: t('int64'), b: t('int64'), }, t('int64')],
    norbool: [{ a: t('bool'), b: t('bool'), }, t('bool')],
    xnori8: [{ a: t('int8'), b: t('int8'), }, t('int8')],
    xnori16: [{ a: t('int16'), b: t('int16'), }, t('int16')],
    xnori32: [{ a: t('int32'), b: t('int32'), }, t('int32')],
    xnori64: [{ a: t('int64'), b: t('int64'), }, t('int64')],
    xnorboo: [{ a: t('bool'), b: t('bool'), }, t('bool')],
    eqi8: [{ a: t('int8'), b: t('int8'), }, t('bool')],
    eqi16: [{ a: t('int16'), b: t('int16'), }, t('bool')],
    eqi32: [{ a: t('int32'), b: t('int32'), }, t('bool')],
    eqi64: [{ a: t('int64'), b: t('int64'), }, t('bool')],
    eqf32: [{ a: t('float32'), b: t('float32'), }, t('bool')],
    eqf64: [{ a: t('float64'), b: t('float64'), }, t('bool')],
    eqbool: [{ a: t('bool'), b: t('bool'), }, t('bool')],
    eqstr: [{ a: t('string'), b: t('string'), }, t('bool')],
    neqi8: [{ a: t('int8'), b: t('int8'), }, t('bool')],
    neqi16: [{ a: t('int16'), b: t('int16'), }, t('bool')],
    neqi32: [{ a: t('int32'), b: t('int32'), }, t('bool')],
    neqi64: [{ a: t('int64'), b: t('int64'), }, t('bool')],
    neqf32: [{ a: t('float32'), b: t('float32'), }, t('bool')],
    neqf64: [{ a: t('float64'), b: t('float64'), }, t('bool')],
    neqbool: [{ a: t('bool'), b: t('bool'), }, t('bool')],
    neqstr: [{ a: t('string'), b: t('string'), }, t('bool')],
    lti8: [{ a: t('int8'), b: t('int8'), }, t('bool')],
    lti16: [{ a: t('int16'), b: t('int16'), }, t('bool')],
    lti32: [{ a: t('int32'), b: t('int32'), }, t('bool')],
    lti64: [{ a: t('int64'), b: t('int64'), }, t('bool')],
    ltf32: [{ a: t('float32'), b: t('float32'), }, t('bool')],
    ltf64: [{ a: t('float64'), b: t('float64'), }, t('bool')],
    ltstr: [{ a: t('string'), b: t('string'), }, t('bool')],
    ltei8: [{ a: t('int8'), b: t('int8'), }, t('bool')],
    ltei16: [{ a: t('int16'), b: t('int16'), }, t('bool')],
    ltei32: [{ a: t('int32'), b: t('int32'), }, t('bool')],
    ltei64: [{ a: t('int64'), b: t('int64'), }, t('bool')],
    ltef32: [{ a: t('float32'), b: t('float32'), }, t('bool')],
    ltef64: [{ a: t('float64'), b: t('float64'), }, t('bool')],
    ltestr: [{ a: t('string'), b: t('string'), }, t('bool')],
    gti8: [{ a: t('int8'), b: t('int8'), }, t('bool')],
    gti16: [{ a: t('int16'), b: t('int16'), }, t('bool')],
    gti32: [{ a: t('int32'), b: t('int32'), }, t('bool')],
    gti64: [{ a: t('int64'), b: t('int64'), }, t('bool')],
    gtf32: [{ a: t('float32'), b: t('float32'), }, t('bool')],
    gtf64: [{ a: t('float64'), b: t('float64'), }, t('bool')],
    gtstr: [{ a: t('string'), b: t('string'), }, t('bool')],
    gtei8: [{ a: t('int8'), b: t('int8'), }, t('bool')],
    gtei16: [{ a: t('int16'), b: t('int16'), }, t('bool')],
    gtei32: [{ a: t('int32'), b: t('int32'), }, t('bool')],
    gtei64: [{ a: t('int64'), b: t('int64'), }, t('bool')],
    gtef32: [{ a: t('float32'), b: t('float32'), }, t('bool')],
    gtef64: [{ a: t('float64'), b: t('float64'), }, t('bool')],
    gtestr: [{ a: t('string'), b: t('string'), }, t('bool')],
    httpget: [{ a: t('string') }, t('Result<string>')],
    httppost: [{ a: t('string'), b: t('string') }, t('Result<string>')],
    httplsn: [{ a: t('int64'), }, t('Result<string>')],
    httpsend: [{ a: t('InternalResponse'), }, t('Result<string>')],
    execop: [{ a: t('string') }, t('ExecRes')],
    waitop: [{ a: t('int64') }, t('void')],
    catstr: [{ a: t('string'), b: t('string'), }, t('string')],
    catarr: [{ a: t('Array<any>'), b: t('Array<any>') }, t('Array<any>')],
    split: [{ str: t('string'), spl: t('string'), }, t('Array<string>')],
    repstr: [{ s: t('string'), n: t('int64'), }, t('string')],
    reparr: [{ arr: t('Array<any>'), n: t('int64'), }, t('Array<any>')],
    matches: [{ s: t('string'), t: t('string'), }, t('bool')],
    indstr: [{ s: t('string'), t: t('string'), }, t('Result<int64>')],
    indarrf: [{ arr: t('Array<any>'), val: t('any'), }, t('Result<int64>')],
    indarrv: [{ arr: t('Array<any>'), val: t('any'), }, t('Result<int64>')],
    lenstr: [{ s: t('string'), }, t('int64')],
    lenarr: [{ arr: t('Array<any>'), }, t('int64')],
    trim: [{ s: t('string'), }, t('string')],
    condfn: [{ cond: t('bool'), optional: t('function'), }, t('any')],
    pusharr: [{ arr: t('Array<any>'), val: t('any'), size: t('int64') }],
    poparr: [{ arr: t('Array<any>') }, t('Result<any>')],
    delindx: [{ arr: t('Array<any>'), idx: t('int64') }, t('Result<any>')],
    each: [{ arr: t('Array<any>'), cb: t('function'), }, t('void')],
    eachl: [{ arr: t('Array<any>'), cb: t('function'), }, t('void')],
    map: [{ arr: t('Array<any>'), cb: t('function'), }, t('Array<any>')],
    mapl: [{ arr: t('Array<any>'), cb: t('function'), }, t('Array<any>')],
    reducel: [{ arr: t('Array<any>'), cb: t('function'), }, t('any')],
    reducep: [{ arr: t('Array<any>'), cb: t('function'), }, t('any')],
    foldl: [{ arr: t('InitialReduce<any, anythingElse>'), cb: t('function'), }, t('anythingElse')],
    foldp: [{ arr: t('InitialReduce<any, anythingElse>'), cb: t('function'), }, t('Array<anythingElse>')],
    filter: [{ arr: t('Array<any>'), cb: t('function'), }, t('Array<any>')],
    filterl: [{ arr: t('Array<any>'), cb: t('function'), }, t('Array<any>')],
    find: [{ arr: t('Array<any>'), cb: t('function'), }, t('Result<any>')],
    findl: [{ arr: t('Array<any>'), cb: t('function'), }, t('Result<any>')],
    every: [{ arr: t('Array<any>'), cb: t('function'), }, t('bool')],
    everyl: [{ arr: t('Array<any>'), cb: t('function'), }, t('bool')],
    some: [{ arr: t('Array<any>'), cb: t('function'), }, t('bool')],
    somel: [{ arr: t('Array<any>'), cb: t('function'), }, t('bool')],
    join: [{ arr: t('Array<string>'), sep: t('string'), }, t('string')],
    newarr: [{ size: t('int64'), }, t('Array<any>')],
    stdoutp: [{ out: t('string'), }, t('void')],
    stderrp: [{ err: t('string'), }, t('void')],
    exitop: [{ code: t('int8'), }, t('void')],
    copyfrom: [{ arr: t('Array<any>'), addr: t('int64') }, t('any')],
    copytof: [{ arr: t('Array<any>'), addr: t('int64'), val: t('any') }],
    copytov: [{ arr: t('Array<any>'), addr: t('int64'), val: t('any') }],
    register: [{ arr: t('Array<any>'), addr: t('int64') }, t('Array<any>')],
    copyi8: [{ a: t('int8'), }, t('int8')],
    copyi16: [{ a: t('int16'), }, t('int16')],
    copyi32: [{ a: t('int32'), }, t('int32')],
    copyi64: [{ a: t('int64'), }, t('int64')],
    copyvoid: [{ a: t('void'), }, t('void')],
    copyf32: [{ a: t('float32'), }, t('float32')],
    copyf64: [{ a: t('float64'), }, t('float64')],
    copybool: [{ a: t('bool'), }, t('bool')],
    copystr: [{ a: t('string'), }, t('string')],
    copyarr: [{ a: t('any'), }, t('any')],
    zeroed: [{}, t('any')],
    lnf64: [{ a: t('float64'), }, t('float64')],
    logf64: [{ a: t('float64'), }, t('float64')],
    sinf64: [{ a: t('float64'), }, t('float64')],
    cosf64: [{ a: t('float64'), }, t('float64')],
    tanf64: [{ a: t('float64'), }, t('float64')],
    asinf64: [{ a: t('float64'), }, t('float64')],
    acosf64: [{ a: t('float64'), }, t('float64')],
    atanf64: [{ a: t('float64'), }, t('float64')],
    sinhf64: [{ a: t('float64'), }, t('float64')],
    coshf64: [{ a: t('float64'), }, t('float64')],
    tanhf64: [{ a: t('float64'), }, t('float64')],
    error: [{ a: t('string'), }, t('Error')],
    reff: [{ a: t('any'), }, t('any')],
    refv: [{ a: t('any'), }, t('any')],
    noerr: [{}, t('Error')],
    errorstr: [{ a: t('Error'), }, t('string')],
    someM: [{ a: t('any'), size: t('int64'), }, t('Maybe<any>')],
    noneM: [{}, t('Maybe<any>')],
    isSome: [{ a: t('Maybe<any>'), }, t('bool')],
    isNone: [{ a: t('Maybe<any>'), }, t('bool')],
    getOrM: [{ a: t('Maybe<any>'), b: t('any'), }, t('any')],
    okR: [{ a: t('any'), size: t('int64'), }, t('Result<any>')],
    err: [{ a: t('string'), }, t('Result<any>')],
    isOk: [{ a: t('Result<any>'), }, t('bool')],
    isErr: [{ a: t('Result<any>'), }, t('bool')],
    getOrR: [{ a: t('Result<any>'), b: t('any'), }, t('any')],
    getOrRS: [{ a: t('Result<any>'), b: t('string'), }, t('string')],
    getR: [{ a: t('Result<any>'), }, t('any')],
    getErr: [{ a: t('Result<any>'), b: t('Error'), }, t('Error')],
    resfrom: [{ arr: t('Array<any>'), addr: t('int64') }, t('Result<any>')],
    mainE: [{ a: t('any'), size: t('int64'), }, t('Either<any, anythingElse>')],
    altE: [{ a: t('anythingElse'), size: t('int64'), }, t('Either<any, anythingElse>')],
    isMain: [{ a: t('Either<any, anythingElse>'), }, t('bool')],
    isAlt: [{ a: t('Either<any, anythingElse>'), }, t('bool')],
    mainOr: [{ a: t('Either<any, anythingElse>'), b: t('any'), }, t('any')],
    altOr: [{ a: t('Either<any, anythingElse>'), b: t('anythingElse'), }, t('anythingElse')],
    hashf: [{ a: t('any'), }, t('int64')],
    hashv: [{ a: t('any'), }, t('int64')],
    dssetf: [{ ns: t('string'), key: t('string'), val: t('any'), }],
    dssetv: [{ ns: t('string'), key: t('string'), val: t('any'), }],
    dshas: [{ ns: t('string'), key: t('string'), }, t('bool')],
    dsdel: [{ ns: t('string'), key: t('string'), }, t('bool')],
    dsgetf: [{ ns: t('string'), key: t('string'), }, t('Result<any>')],
    dsgetv: [{ ns: t('string'), key: t('string'), }, t('Result<any>')],
    newseq: [{ limit: t('int64'), }, t('Seq')],
    seqnext: [{ seq: t('Seq'), }, t('Result<int64>')],
    seqeach: [{ seq: t('Seq'), func: t('function'), }, t('void')],
    seqwhile: [{ seq: t('Seq'), condFn: t('function'), bodyFn: t('function'), }],
    seqdo: [{ seq: t('Seq'), bodyFn: t('function'), }, t('void')],
    selfrec: [{ self: t('Self'), arg: t('any'), }, t('Result<anythingElse>')],
    seqrec: [{ seq: t('Seq'), recurseFn: t('function'), }, t('Self')],
});
exports.default = opcodeModule;

},{"./Event":12,"./Microstatement":13,"./Module":14,"./Scope":16,"./StatementType":18,"./Type":19,"./UserFunction":20,"uuid":118}],23:[function(require,module,exports){
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.RangeSet = exports.CharSet = exports.NamedOr = exports.NamedAnd = exports.Or = exports.And = exports.OneOrMore = exports.ZeroOrMore = exports.ZeroOrOne = exports.Not = exports.Token = exports.NulLP = exports.lpError = exports.LP = void 0;
const fs = require("fs"); // This syntax is so dumb
// An LP record and methods, used for keeping track of advancements through the text to parse
class LP {
    constructor(filename, loadData = true) {
        this.filename = filename;
        this.data = loadData ? fs.readFileSync(filename, 'utf8') : '';
        this.line = 1;
        this.char = 1;
        this.i = 0;
    }
    advance(n) {
        for (let i = 0; i < n; i++) {
            this.i += 1;
            if (this.data[this.i] === '\n') {
                this.line += 1;
                this.char = 1;
            }
            else {
                this.char += 1;
            }
        }
    }
    clone() {
        const clone = new LP(this.filename, false);
        clone.data = this.data;
        clone.line = this.line;
        clone.char = this.char;
        clone.i = this.i;
        return clone;
    }
    static fromText(data) {
        const lp = new LP('fakeFile', false);
        lp.data = data;
        return lp;
    }
    snapshot() {
        return {
            line: this.line,
            char: this.char,
            i: this.i
        };
    }
    restore(snap) {
        this.line = snap.line;
        this.char = snap.char;
        this.i = snap.i;
    }
}
exports.LP = LP;
exports.lpError = (message, obj) => new Error(`${message} in file ${obj.filename} line ${obj.line}:${obj.char}`);
// A special AST node that indicates that you successfully matched nothing, useful for optional ASTs
class NulLP {
    constructor() {
        this.t = '';
    }
    get() {
        return this;
    }
    getAll() {
        return [this];
    }
    has() {
        return false;
    }
    apply() {
        return new Error('nullish');
    }
    toString() {
        return this.t;
    }
}
exports.NulLP = NulLP;
// One of the 'leaf' AST nodes. It declares a fixed set of characters in a row to match
class Token {
    constructor(t, filename, line, char) {
        this.t = t;
        this.filename = filename;
        this.line = line;
        this.char = char;
    }
    static build(t) {
        return new Token(t, '', -1, -1);
    }
    toString() {
        return this.t;
    }
    get() {
        return this;
    }
    getAll() {
        return [this];
    }
    has() {
        return this.line > -1;
    }
    check(lp) {
        let matches = true;
        const t = this.t;
        const len = t.length;
        const data = lp.data;
        const j = lp.i;
        for (let i = 0; i < len; i++) {
            if (t[i] !== data[i + j]) {
                matches = false;
                break;
            }
        }
        return matches;
    }
    apply(lp) {
        if (this.check(lp)) {
            lp.advance(this.t.length);
            return new Token(this.t, lp.filename, lp.line, lp.char);
        }
        return exports.lpError(`Token mismatch, ${this.t} not found`, lp);
    }
}
exports.Token = Token;
// Another 'leaf' AST node. It matches any characters that DO NOT match the string provided
class Not {
    constructor(t, filename, line, char) {
        this.t = t;
        this.filename = filename;
        this.line = line;
        this.char = char;
    }
    static build(t) {
        return new Not(t, '', -1, -1);
    }
    toString() {
        return this.t;
    }
    check(lp) {
        let matches = true;
        const t = this.t;
        const len = t.length;
        const data = lp.data;
        const j = lp.i;
        for (let i = 0; i < len; i++) {
            if (t[i] !== data[i + j]) {
                matches = false;
                break;
            }
        }
        return !matches;
    }
    get() {
        return this;
    }
    getAll() {
        return [this];
    }
    has() {
        return this.line > -1;
    }
    apply(lp) {
        if (this.check(lp)) {
            const newT = lp.data[lp.i];
            lp.advance(this.t.length);
            return new Not(newT, lp.filename, lp.line, lp.char);
        }
        return exports.lpError(`Not mismatch, ${this.t} found`, lp);
    }
}
exports.Not = Not;
// An AST node that optionally matches the AST node below it
class ZeroOrOne {
    constructor(t, zeroOrOne, filename, line, char) {
        this.t = t;
        this.zeroOrOne = zeroOrOne;
        this.filename = filename;
        this.line = line;
        this.char = char;
    }
    static build(zeroOrOne) {
        return new ZeroOrOne('', zeroOrOne, '', -1, -1);
    }
    toString() {
        return this.t;
    }
    get() {
        return this.zeroOrOne;
    }
    getAll() {
        return [this.zeroOrOne];
    }
    has() {
        return this.line > -1;
    }
    apply(lp) {
        const s = lp.snapshot();
        const zeroOrOne = this.zeroOrOne.apply(lp);
        if (zeroOrOne instanceof Error) {
            lp.restore(s);
            return new NulLP();
        }
        return zeroOrOne;
    }
}
exports.ZeroOrOne = ZeroOrOne;
// An AST node that optionally matches the AST node below it as many times as possible
class ZeroOrMore {
    constructor(t, zeroOrMore, filename, line, char) {
        this.t = t;
        this.zeroOrMore = zeroOrMore;
        this.filename = filename;
        this.line = line;
        this.char = char;
    }
    static build(zeroOrMore) {
        return new ZeroOrMore('', [zeroOrMore], '', -1, -1);
    }
    toString() {
        return this.t;
    }
    get(i) {
        if (this.zeroOrMore[i])
            return this.zeroOrMore[i];
        return new NulLP();
    }
    getAll() {
        return this.zeroOrMore;
    }
    has(id) {
        if (typeof id === 'number') {
            if (this.zeroOrMore[id]) {
                return this.zeroOrMore[id].has();
            }
            return false;
        }
        return this.line > -1;
    }
    apply(lp) {
        const filename = lp.filename;
        const line = lp.line;
        const char = lp.char;
        let t = '';
        let zeroOrMore = [];
        do {
            const s = lp.snapshot();
            const z = this.zeroOrMore[0].apply(lp);
            if (z instanceof Error) {
                lp.restore(s);
                return new ZeroOrMore(t, zeroOrMore, filename, line, char);
            }
            const t2 = z.toString();
            if (t2.length === 0) {
                return exports.lpError('ZeroOrMore made no forward progress, will infinite loop', lp);
            }
            t += t2;
            zeroOrMore.push(z);
        } while (true);
    }
}
exports.ZeroOrMore = ZeroOrMore;
// An AST node that matches the node below it multiple times and fails if it finds no match
class OneOrMore {
    constructor(t, oneOrMore, filename, line, char) {
        this.t = t;
        this.oneOrMore = oneOrMore;
        this.filename = filename;
        this.line = line;
        this.char = char;
    }
    static build(oneOrMore) {
        return new OneOrMore('', [oneOrMore], '', -1, -1);
    }
    toString() {
        return this.t;
    }
    get(i) {
        if (this.oneOrMore[i])
            return this.oneOrMore[i];
        return new NulLP();
    }
    getAll() {
        return this.oneOrMore;
    }
    has(id) {
        if (typeof id === 'number') {
            if (this.oneOrMore[id]) {
                return this.oneOrMore[id].has();
            }
            return false;
        }
        return this.line > -1;
    }
    apply(lp) {
        const filename = lp.filename;
        const line = lp.line;
        const char = lp.char;
        let t = '';
        let oneOrMore = [];
        do {
            const s = lp.snapshot();
            const o = this.oneOrMore[0].apply(lp);
            if (o instanceof Error) {
                lp.restore(s);
                if (oneOrMore.length === 0) {
                    return exports.lpError('No match for OneOrMore', lp);
                }
                return new OneOrMore(t, oneOrMore, filename, line, char);
            }
            const t2 = o.toString();
            if (t2.length === 0) {
                return exports.lpError('OneOrMore made no forward progress, will infinite loop', lp);
            }
            t += t2;
            oneOrMore.push(o);
        } while (true);
    }
}
exports.OneOrMore = OneOrMore;
// An AST node that matches a sequence of child nodes in a row or fails
class And {
    constructor(t, and, filename, line, char) {
        this.t = t;
        this.and = and;
        this.filename = filename;
        this.line = line;
        this.char = char;
    }
    static build(and) {
        return new And('', and, '', -1, -1);
    }
    toString() {
        return this.t;
    }
    get(i) {
        if (this.and[i])
            return this.and[i];
        return new NulLP();
    }
    getAll() {
        return this.and;
    }
    has(id) {
        if (typeof id === 'number') {
            if (this.and[id]) {
                return this.and[id].has();
            }
            return false;
        }
        return this.line > -1;
    }
    apply(lp) {
        const filename = lp.filename;
        const line = lp.line;
        const char = lp.char;
        let t = '';
        let and = [];
        const s = lp.snapshot();
        // This can fail, allow the underlying error to bubble up
        for (let i = 0; i < this.and.length; i++) {
            const a = this.and[i].apply(lp);
            if (a instanceof Error) {
                lp.restore(s);
                return a;
            }
            t += a.toString();
            and.push(a);
        }
        return new And(t, and, filename, line, char);
    }
}
exports.And = And;
// An AST node that matches any of its child nodes or fails. Only returns the first match.
class Or {
    constructor(t, or, filename, line, char) {
        this.t = t;
        this.or = or;
        this.filename = filename;
        this.line = line;
        this.char = char;
    }
    static build(or) {
        return new Or('', or, '', -1, -1);
    }
    toString() {
        return this.t;
    }
    get() {
        if (this.or[0])
            return this.or[0];
        return new NulLP();
    }
    getAll() {
        return this.or;
    }
    has(id) {
        if (typeof id === 'number') {
            if (this.or[id]) {
                return this.or[id].has();
            }
            return false;
        }
        return this.line > -1;
    }
    apply(lp) {
        const filename = lp.filename;
        const line = lp.line;
        const char = lp.char;
        let t = '';
        let or = [];
        // Return the first match (if there are multiple matches, it is the first one)
        for (let i = 0; i < this.or.length; i++) {
            const s = lp.snapshot();
            const o = this.or[i].apply(lp);
            if (o instanceof Error) {
                lp.restore(s);
                continue;
            }
            // We have a match!
            t = o.toString();
            or.push(o);
            break;
        }
        if (or.length === 0)
            return exports.lpError('No matching tokens found', lp);
        return new Or(t, or, filename, line, char);
    }
}
exports.Or = Or;
// An AST node that matches all of the child nodes or fails. Also provides easier access to the
// matched child nodes.
class NamedAnd {
    constructor(t, and, filename, line, char) {
        this.t = t;
        this.and = and;
        this.filename = filename;
        this.line = line;
        this.char = char;
    }
    static build(and) {
        return new NamedAnd(Object.keys(and).join(' '), and, '', -1, -1);
    }
    toString() {
        return this.t;
    }
    get(name) {
        if (this.and[name])
            return this.and[name];
        return new NulLP();
    }
    getAll() {
        return Object.values(this.and);
    }
    has(id) {
        if (typeof id === 'string') {
            if (this.and[id]) {
                return this.and[id].has();
            }
            return false;
        }
        return this.line > -1;
    }
    apply(lp) {
        const filename = lp.filename;
        const line = lp.line;
        const char = lp.char;
        let t = '';
        let and = {};
        const andNames = Object.keys(this.and);
        const s = lp.snapshot();
        // This can fail, allow the underlying error to bubble up
        for (let i = 0; i < andNames.length; i++) {
            const a = this.and[andNames[i]].apply(lp);
            if (a instanceof Error) {
                lp.restore(s);
                return a;
            }
            t += a.toString();
            and[andNames[i]] = a;
        }
        return new NamedAnd(t, and, filename, line, char);
    }
}
exports.NamedAnd = NamedAnd;
// An AST node that matches one of the child nodes or fails. The first match is returned. Also
// provides easier access to the child node by name.
class NamedOr {
    constructor(t, or, filename, line, char) {
        this.t = t;
        this.or = or;
        this.filename = filename;
        this.line = line;
        this.char = char;
    }
    static build(or) {
        return new NamedOr(Object.keys(or).join(' '), or, '', -1, -1);
    }
    toString() {
        return this.t;
    }
    get(name) {
        if (this.or[name])
            return this.or[name];
        return new NulLP();
    }
    getAll() {
        return Object.values(this.or);
    }
    has(id) {
        if (typeof id === 'string') {
            if (this.or[id]) {
                return this.or[id].has();
            }
            return false;
        }
        return this.line > -1;
    }
    apply(lp) {
        const filename = lp.filename;
        const line = lp.line;
        const char = lp.char;
        let t = '';
        let or = {};
        const orNames = Object.keys(this.or);
        // Return the first match (if there are multiple matches, it is the first one)
        for (let i = 0; i < orNames.length; i++) {
            const s = lp.snapshot();
            const o = this.or[orNames[i]].apply(lp);
            if (o instanceof Error) {
                lp.restore(s);
                continue;
            }
            // We have a match!
            t = o.toString();
            or[orNames[i]] = o;
            break;
        }
        if (Object.keys(or).length === 0)
            return exports.lpError('No matching or tokens found', lp);
        return new NamedOr(t, or, filename, line, char);
    }
}
exports.NamedOr = NamedOr;
// A 'leaf' AST node that matches a character within the specified range of characters. Useful for
// building regex-like matchers.
class CharSet {
    constructor(t, lowerChar, upperChar, filename, line, char) {
        this.t = t;
        this.lowerCharCode = lowerChar.charCodeAt(0);
        this.upperCharCode = upperChar.charCodeAt(0);
        this.filename = filename;
        this.line = line;
        this.char = char;
    }
    static build(lowerChar, upperChar) {
        return new CharSet(`[${lowerChar}-${upperChar}]`, lowerChar, upperChar, '', -1, -1);
    }
    toString() {
        return this.t;
    }
    check(lp) {
        let lpCharCode = lp.data.charCodeAt(lp.i);
        return this.lowerCharCode <= lpCharCode && this.upperCharCode >= lpCharCode;
    }
    get() {
        return this;
    }
    getAll() {
        return [this];
    }
    has() {
        return this.line > -1;
    }
    apply(lp) {
        if (this.check(lp)) {
            const outCharSet = new CharSet(lp.data[lp.i], String.fromCharCode(this.lowerCharCode), String.fromCharCode(this.upperCharCode), lp.filename, lp.line, lp.char);
            lp.advance(1);
            return outCharSet;
        }
        return exports.lpError(`Token mismatch, expected character in range of ${String.fromCharCode(this.lowerCharCode)}-${String.fromCharCode(this.upperCharCode)}`, lp);
    }
}
exports.CharSet = CharSet;
// A composite AST 'node' that matches the child node between the minimum and maximum repetitions or
// fails.
exports.RangeSet = (toRepeat, min, max) => {
    let sets = [];
    for (let i = min; i <= max; i++) {
        if (i === 0) {
            sets.push(Token.build(''));
            continue;
        }
        else {
            let set = [];
            for (let j = 0; j < i; j++) {
                set.push(toRepeat);
            }
            sets.push(And.build(set));
        }
    }
    return Or.build(sets);
};

},{"fs":74}],24:[function(require,module,exports){
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const buildPipeline = (converters) => {
    // Get a unique set of inputs and outputs, and index the converters by their input and output
    const inputs = new Set();
    const outputs = new Set();
    const both = new Set();
    const byInput = new Map();
    const byOutput = new Map();
    const byBoth = new Map();
    converters.forEach(converter => {
        inputs.add(converter[0]);
        outputs.add(converter[1]);
        both.add(converter[0]);
        both.add(converter[1]);
        if (!byInput.has(converter[0])) {
            byInput.set(converter[0], []);
        }
        byInput.get(converter[0]).push(converter);
        if (!byOutput.has(converter[1])) {
            byOutput.set(converter[1], []);
        }
        byOutput.get(converter[1]).push(converter);
        byBoth.set(converter[0] + converter[1], converter[2]);
    });
    // Compute the shortest path from every input to every output, or drop it if not possible
    const paths = {};
    inputs.forEach((input) => {
        outputs.forEach((output) => {
            // Skip identical inputs and outputs
            if (input === output)
                return;
            // Short-circuit if a direct conversion is possible
            if (byBoth.has(input + output)) {
                if (!paths[input])
                    paths[input] = {};
                paths[input][output] = [input, output];
                return;
            }
            // Otherwise, scan through the graph using Djikstra's Algorithm
            const nodes = new Set();
            const dist = new Map();
            const prev = new Map();
            both.forEach(n => {
                nodes.add(n);
                dist.set(n, Infinity);
                prev.set(n, undefined);
            });
            dist.set(input, 0);
            let minDist = 0;
            let minNode = input;
            while (nodes.size > 0) {
                const n = minNode;
                if (n === output)
                    break;
                nodes.delete(n);
                minNode = undefined;
                minDist = Infinity;
                // Find the smallest remaining distance node to continue the search
                nodes.forEach((node) => {
                    if (dist.get(node) < minDist || minDist === Infinity) {
                        minDist = dist.get(node);
                        minNode = node;
                    }
                });
                if (byInput.has(n)) {
                    byInput.get(n).map((r) => r[1]).forEach((neighbor) => {
                        const newDist = dist.get(n) + 1;
                        if (newDist < dist.get(neighbor)) {
                            dist.set(neighbor, newDist);
                            prev.set(neighbor, n);
                        }
                        if (newDist < minDist) {
                            minDist = newDist;
                            minNode = neighbor;
                        }
                    });
                }
            }
            const path = [];
            let node = output;
            while (node) {
                path.unshift(node);
                node = prev.get(node);
            }
            if (path.length < 2)
                return; // Invalid/impossible path, skip it
            if (!paths[input])
                paths[input] = {};
            paths[input][output] = path;
        });
    });
    const lookup = {};
    Object.keys(paths).forEach(i => {
        Object.keys(paths[i]).forEach(o => {
            if (!lookup[i])
                lookup[i] = {};
            const c = paths[i][o].reduce((cumu, curr) => {
                if (!cumu.prev)
                    return {
                        prev: curr,
                        fromFile: undefined,
                        fromString: undefined,
                    };
                const converter = byBoth.get(cumu.prev + curr);
                if (!cumu.fromFile) {
                    return {
                        prev: curr,
                        fromFile: converter.fromFile,
                        fromString: converter.fromString,
                    };
                }
                return {
                    prev: curr,
                    fromFile: (filename) => converter.fromString(cumu.fromFile(filename)),
                    fromString: (str) => converter.fromString(cumu.fromString(str)),
                };
            }, { prev: undefined, fromFile: undefined, fromString: undefined, });
            lookup[i][o] = {
                fromFile: c.fromFile,
                fromString: c.fromString,
            };
        });
    });
    return lookup;
};
exports.default = buildPipeline;

},{}],25:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

// This implementation of {@link TokenStream} loads tokens from a
// {@link TokenSource} on-demand, and places the tokens in a buffer to provide
// access to any previous token by index.
//
// <p>
// This token stream ignores the value of {@link Token//getChannel}. If your
// parser requires the token stream filter tokens to only those on a particular
// channel, such as {@link Token//DEFAULT_CHANNEL} or
// {@link Token//HIDDEN_CHANNEL}, use a filtering token stream such a
// {@link CommonTokenStream}.</p>

var Token = require('./Token').Token;
var Lexer = require('./Lexer').Lexer;
var Interval = require('./IntervalSet').Interval;

// this is just to keep meaningful parameter types to Parser
function TokenStream() {
	return this;
}

function BufferedTokenStream(tokenSource) {

	TokenStream.call(this);
	// The {@link TokenSource} from which tokens for this stream are fetched.
	this.tokenSource = tokenSource;

	// A collection of all tokens fetched from the token source. The list is
	// considered a complete view of the input once {@link //fetchedEOF} is set
	// to {@code true}.
	this.tokens = [];

	// The index into {@link //tokens} of the current token (next token to
	// {@link //consume}). {@link //tokens}{@code [}{@link //p}{@code ]} should
	// be
	// {@link //LT LT(1)}.
	//
	// <p>This field is set to -1 when the stream is first constructed or when
	// {@link //setTokenSource} is called, indicating that the first token has
	// not yet been fetched from the token source. For additional information,
	// see the documentation of {@link IntStream} for a description of
	// Initializing Methods.</p>
	this.index = -1;

	// Indicates whether the {@link Token//EOF} token has been fetched from
	// {@link //tokenSource} and added to {@link //tokens}. This field improves
	// performance for the following cases:
	//
	// <ul>
	// <li>{@link //consume}: The lookahead check in {@link //consume} to
	// prevent
	// consuming the EOF symbol is optimized by checking the values of
	// {@link //fetchedEOF} and {@link //p} instead of calling {@link
	// //LA}.</li>
	// <li>{@link //fetch}: The check to prevent adding multiple EOF symbols
	// into
	// {@link //tokens} is trivial with this field.</li>
	// <ul>
	this.fetchedEOF = false;
	return this;
}

BufferedTokenStream.prototype = Object.create(TokenStream.prototype);
BufferedTokenStream.prototype.constructor = BufferedTokenStream;

BufferedTokenStream.prototype.mark = function() {
	return 0;
};

BufferedTokenStream.prototype.release = function(marker) {
	// no resources to release
};

BufferedTokenStream.prototype.reset = function() {
	this.seek(0);
};

BufferedTokenStream.prototype.seek = function(index) {
	this.lazyInit();
	this.index = this.adjustSeekIndex(index);
};

BufferedTokenStream.prototype.get = function(index) {
	this.lazyInit();
	return this.tokens[index];
};

BufferedTokenStream.prototype.consume = function() {
	var skipEofCheck = false;
	if (this.index >= 0) {
		if (this.fetchedEOF) {
			// the last token in tokens is EOF. skip check if p indexes any
			// fetched token except the last.
			skipEofCheck = this.index < this.tokens.length - 1;
		} else {
			// no EOF token in tokens. skip check if p indexes a fetched token.
			skipEofCheck = this.index < this.tokens.length;
		}
	} else {
		// not yet initialized
		skipEofCheck = false;
	}
	if (!skipEofCheck && this.LA(1) === Token.EOF) {
		throw "cannot consume EOF";
	}
	if (this.sync(this.index + 1)) {
		this.index = this.adjustSeekIndex(this.index + 1);
	}
};

// Make sure index {@code i} in tokens has a token.
//
// @return {@code true} if a token is located at index {@code i}, otherwise
// {@code false}.
// @see //get(int i)
// /
BufferedTokenStream.prototype.sync = function(i) {
	var n = i - this.tokens.length + 1; // how many more elements we need?
	if (n > 0) {
		var fetched = this.fetch(n);
		return fetched >= n;
	}
	return true;
};

// Add {@code n} elements to buffer.
//
// @return The actual number of elements added to the buffer.
// /
BufferedTokenStream.prototype.fetch = function(n) {
	if (this.fetchedEOF) {
		return 0;
	}
	for (var i = 0; i < n; i++) {
		var t = this.tokenSource.nextToken();
		t.tokenIndex = this.tokens.length;
		this.tokens.push(t);
		if (t.type === Token.EOF) {
			this.fetchedEOF = true;
			return i + 1;
		}
	}
	return n;
};

// Get all tokens from start..stop inclusively///
BufferedTokenStream.prototype.getTokens = function(start, stop, types) {
	if (types === undefined) {
		types = null;
	}
	if (start < 0 || stop < 0) {
		return null;
	}
	this.lazyInit();
	var subset = [];
	if (stop >= this.tokens.length) {
		stop = this.tokens.length - 1;
	}
	for (var i = start; i < stop; i++) {
		var t = this.tokens[i];
		if (t.type === Token.EOF) {
			break;
		}
		if (types === null || types.contains(t.type)) {
			subset.push(t);
		}
	}
	return subset;
};

BufferedTokenStream.prototype.LA = function(i) {
	return this.LT(i).type;
};

BufferedTokenStream.prototype.LB = function(k) {
	if (this.index - k < 0) {
		return null;
	}
	return this.tokens[this.index - k];
};

BufferedTokenStream.prototype.LT = function(k) {
	this.lazyInit();
	if (k === 0) {
		return null;
	}
	if (k < 0) {
		return this.LB(-k);
	}
	var i = this.index + k - 1;
	this.sync(i);
	if (i >= this.tokens.length) { // return EOF token
		// EOF must be last token
		return this.tokens[this.tokens.length - 1];
	}
	return this.tokens[i];
};

// Allowed derived classes to modify the behavior of operations which change
// the current stream position by adjusting the target token index of a seek
// operation. The default implementation simply returns {@code i}. If an
// exception is thrown in this method, the current stream index should not be
// changed.
//
// <p>For example, {@link CommonTokenStream} overrides this method to ensure
// that
// the seek target is always an on-channel token.</p>
//
// @param i The target token index.
// @return The adjusted target token index.

BufferedTokenStream.prototype.adjustSeekIndex = function(i) {
	return i;
};

BufferedTokenStream.prototype.lazyInit = function() {
	if (this.index === -1) {
		this.setup();
	}
};

BufferedTokenStream.prototype.setup = function() {
	this.sync(0);
	this.index = this.adjustSeekIndex(0);
};

// Reset this token stream by setting its token source.///
BufferedTokenStream.prototype.setTokenSource = function(tokenSource) {
	this.tokenSource = tokenSource;
	this.tokens = [];
	this.index = -1;
	this.fetchedEOF = false;
};


// Given a starting index, return the index of the next token on channel.
// Return i if tokens[i] is on channel. Return -1 if there are no tokens
// on channel between i and EOF.
// /
BufferedTokenStream.prototype.nextTokenOnChannel = function(i, channel) {
	this.sync(i);
	if (i >= this.tokens.length) {
		return -1;
	}
	var token = this.tokens[i];
	while (token.channel !== this.channel) {
		if (token.type === Token.EOF) {
			return -1;
		}
		i += 1;
		this.sync(i);
		token = this.tokens[i];
	}
	return i;
};

// Given a starting index, return the index of the previous token on channel.
// Return i if tokens[i] is on channel. Return -1 if there are no tokens
// on channel between i and 0.
BufferedTokenStream.prototype.previousTokenOnChannel = function(i, channel) {
	while (i >= 0 && this.tokens[i].channel !== channel) {
		i -= 1;
	}
	return i;
};

// Collect all tokens on specified channel to the right of
// the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or
// EOF. If channel is -1, find any non default channel token.
BufferedTokenStream.prototype.getHiddenTokensToRight = function(tokenIndex,
		channel) {
	if (channel === undefined) {
		channel = -1;
	}
	this.lazyInit();
	if (tokenIndex < 0 || tokenIndex >= this.tokens.length) {
		throw "" + tokenIndex + " not in 0.." + this.tokens.length - 1;
	}
	var nextOnChannel = this.nextTokenOnChannel(tokenIndex + 1, Lexer.DEFAULT_TOKEN_CHANNEL);
	var from_ = tokenIndex + 1;
	// if none onchannel to right, nextOnChannel=-1 so set to = last token
	var to = nextOnChannel === -1 ? this.tokens.length - 1 : nextOnChannel;
	return this.filterForChannel(from_, to, channel);
};

// Collect all tokens on specified channel to the left of
// the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.
// If channel is -1, find any non default channel token.
BufferedTokenStream.prototype.getHiddenTokensToLeft = function(tokenIndex,
		channel) {
	if (channel === undefined) {
		channel = -1;
	}
	this.lazyInit();
	if (tokenIndex < 0 || tokenIndex >= this.tokens.length) {
		throw "" + tokenIndex + " not in 0.." + this.tokens.length - 1;
	}
	var prevOnChannel = this.previousTokenOnChannel(tokenIndex - 1, Lexer.DEFAULT_TOKEN_CHANNEL);
	if (prevOnChannel === tokenIndex - 1) {
		return null;
	}
	// if none on channel to left, prevOnChannel=-1 then from=0
	var from_ = prevOnChannel + 1;
	var to = tokenIndex - 1;
	return this.filterForChannel(from_, to, channel);
};

BufferedTokenStream.prototype.filterForChannel = function(left, right, channel) {
	var hidden = [];
	for (var i = left; i < right + 1; i++) {
		var t = this.tokens[i];
		if (channel === -1) {
			if (t.channel !== Lexer.DEFAULT_TOKEN_CHANNEL) {
				hidden.push(t);
			}
		} else if (t.channel === channel) {
			hidden.push(t);
		}
	}
	if (hidden.length === 0) {
		return null;
	}
	return hidden;
};

BufferedTokenStream.prototype.getSourceName = function() {
	return this.tokenSource.getSourceName();
};

// Get the text of all tokens in this buffer.///
BufferedTokenStream.prototype.getText = function(interval) {
	this.lazyInit();
	this.fill();
	if (interval === undefined || interval === null) {
		interval = new Interval(0, this.tokens.length - 1);
	}
	var start = interval.start;
	if (start instanceof Token) {
		start = start.tokenIndex;
	}
	var stop = interval.stop;
	if (stop instanceof Token) {
		stop = stop.tokenIndex;
	}
	if (start === null || stop === null || start < 0 || stop < 0) {
		return "";
	}
	if (stop >= this.tokens.length) {
		stop = this.tokens.length - 1;
	}
	var s = "";
	for (var i = start; i < stop + 1; i++) {
		var t = this.tokens[i];
		if (t.type === Token.EOF) {
			break;
		}
		s = s + t.text;
	}
	return s;
};

// Get all tokens from lexer until EOF///
BufferedTokenStream.prototype.fill = function() {
	this.lazyInit();
	while (this.fetch(1000) === 1000) {
		continue;
	}
};

exports.BufferedTokenStream = BufferedTokenStream;

},{"./IntervalSet":31,"./Lexer":33,"./Token":39}],26:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
//

var InputStream = require('./InputStream').InputStream;

var isNodeJs = typeof window === 'undefined' && typeof importScripts === 'undefined';
var fs = isNodeJs ? require("fs") : null;

// Utility functions to create InputStreams from various sources.
//
// All returned InputStreams support the full range of Unicode
// up to U+10FFFF (the default behavior of InputStream only supports
// code points up to U+FFFF).
var CharStreams = {
  // Creates an InputStream from a string.
  fromString: function(str) {
    return new InputStream(str, true);
  },

  // Asynchronously creates an InputStream from a blob given the
  // encoding of the bytes in that blob (defaults to 'utf8' if
  // encoding is null).
  //
  // Invokes onLoad(result) on success, onError(error) on
  // failure.
  fromBlob: function(blob, encoding, onLoad, onError) {
    var reader = FileReader();
    reader.onload = function(e) {
      var is = new InputStream(e.target.result, true);
      onLoad(is);
    };
    reader.onerror = onError;
    reader.readAsText(blob, encoding);
  },

  // Creates an InputStream from a Buffer given the
  // encoding of the bytes in that buffer (defaults to 'utf8' if
  // encoding is null).
  fromBuffer: function(buffer, encoding) {
    return new InputStream(buffer.toString(encoding), true);
  },

  // Asynchronously creates an InputStream from a file on disk given
  // the encoding of the bytes in that file (defaults to 'utf8' if
  // encoding is null).
  //
  // Invokes callback(error, result) on completion.
  fromPath: function(path, encoding, callback) {
    fs.readFile(path, encoding, function(err, data) {
      var is = null;
      if (data !== null) {
        is = new InputStream(data, true);
      }
      callback(err, is);
    });
  },

  // Synchronously creates an InputStream given a path to a file
  // on disk and the encoding of the bytes in that file (defaults to
  // 'utf8' if encoding is null).
  fromPathSync: function(path, encoding) {
    var data = fs.readFileSync(path, encoding);
    return new InputStream(data, true);
  }
};

exports.CharStreams = CharStreams;

},{"./InputStream":30,"fs":74}],27:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
//

//
// This default implementation of {@link TokenFactory} creates
// {@link CommonToken} objects.
//

var CommonToken = require('./Token').CommonToken;

function TokenFactory() {
	return this;
}

function CommonTokenFactory(copyText) {
	TokenFactory.call(this);
    // Indicates whether {@link CommonToken//setText} should be called after
    // constructing tokens to explicitly set the text. This is useful for cases
    // where the input stream might not be able to provide arbitrary substrings
    // of text from the input after the lexer creates a token (e.g. the
    // implementation of {@link CharStream//getText} in
    // {@link UnbufferedCharStream} throws an
    // {@link UnsupportedOperationException}). Explicitly setting the token text
    // allows {@link Token//getText} to be called at any time regardless of the
    // input stream implementation.
    //
    // <p>
    // The default value is {@code false} to avoid the performance and memory
    // overhead of copying text for every token unless explicitly requested.</p>
    //
    this.copyText = copyText===undefined ? false : copyText;
	return this;
}

CommonTokenFactory.prototype = Object.create(TokenFactory.prototype);
CommonTokenFactory.prototype.constructor = CommonTokenFactory;

//
// The default {@link CommonTokenFactory} instance.
//
// <p>
// This token factory does not explicitly copy token text when constructing
// tokens.</p>
//
CommonTokenFactory.DEFAULT = new CommonTokenFactory();

CommonTokenFactory.prototype.create = function(source, type, text, channel, start, stop, line, column) {
    var t = new CommonToken(source, type, channel, start, stop);
    t.line = line;
    t.column = column;
    if (text !==null) {
        t.text = text;
    } else if (this.copyText && source[1] !==null) {
        t.text = source[1].getText(start,stop);
    }
    return t;
};

CommonTokenFactory.prototype.createThin = function(type, text) {
    var t = new CommonToken(null, type);
    t.text = text;
    return t;
};

exports.CommonTokenFactory = CommonTokenFactory;

},{"./Token":39}],28:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
///

//
// This class extends {@link BufferedTokenStream} with functionality to filter
// token streams to tokens on a particular channel (tokens where
// {@link Token//getChannel} returns a particular value).
//
// <p>
// This token stream provides access to all tokens by index or when calling
// methods like {@link //getText}. The channel filtering is only used for code
// accessing tokens via the lookahead methods {@link //LA}, {@link //LT}, and
// {@link //LB}.</p>
//
// <p>
// By default, tokens are placed on the default channel
// ({@link Token//DEFAULT_CHANNEL}), but may be reassigned by using the
// {@code ->channel(HIDDEN)} lexer command, or by using an embedded action to
// call {@link Lexer//setChannel}.
// </p>
//
// <p>
// Note: lexer rules which use the {@code ->skip} lexer command or call
// {@link Lexer//skip} do not produce tokens at all, so input text matched by
// such a rule will not be available as part of the token stream, regardless of
// channel.</p>
///

var Token = require('./Token').Token;
var BufferedTokenStream = require('./BufferedTokenStream').BufferedTokenStream;

function CommonTokenStream(lexer, channel) {
	BufferedTokenStream.call(this, lexer);
    this.channel = channel===undefined ? Token.DEFAULT_CHANNEL : channel;
    return this;
}

CommonTokenStream.prototype = Object.create(BufferedTokenStream.prototype);
CommonTokenStream.prototype.constructor = CommonTokenStream;

CommonTokenStream.prototype.adjustSeekIndex = function(i) {
    return this.nextTokenOnChannel(i, this.channel);
};

CommonTokenStream.prototype.LB = function(k) {
    if (k===0 || this.index-k<0) {
        return null;
    }
    var i = this.index;
    var n = 1;
    // find k good tokens looking backwards
    while (n <= k) {
        // skip off-channel tokens
        i = this.previousTokenOnChannel(i - 1, this.channel);
        n += 1;
    }
    if (i < 0) {
        return null;
    }
    return this.tokens[i];
};

CommonTokenStream.prototype.LT = function(k) {
    this.lazyInit();
    if (k === 0) {
        return null;
    }
    if (k < 0) {
        return this.LB(-k);
    }
    var i = this.index;
    var n = 1; // we know tokens[pos] is a good one
    // find k good tokens
    while (n < k) {
        // skip off-channel tokens, but make sure to not look past EOF
        if (this.sync(i + 1)) {
            i = this.nextTokenOnChannel(i + 1, this.channel);
        }
        n += 1;
    }
    return this.tokens[i];
};

// Count EOF just once.///
CommonTokenStream.prototype.getNumberOfOnChannelTokens = function() {
    var n = 0;
    this.fill();
    for (var i =0; i< this.tokens.length;i++) {
        var t = this.tokens[i];
        if( t.channel===this.channel) {
            n += 1;
        }
        if( t.type===Token.EOF) {
            break;
        }
    }
    return n;
};

exports.CommonTokenStream = CommonTokenStream;
},{"./BufferedTokenStream":25,"./Token":39}],29:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
//

//
//  This is an InputStream that is loaded from a file all at once
//  when you construct the object.
//
var InputStream = require('./InputStream').InputStream;
var isNodeJs = typeof window === 'undefined' && typeof importScripts === 'undefined';
var fs = isNodeJs ? require("fs") : null;

function FileStream(fileName, decodeToUnicodeCodePoints) {
	var data = fs.readFileSync(fileName, "utf8");
	InputStream.call(this, data, decodeToUnicodeCodePoints);
	this.fileName = fileName;
	return this;
}

FileStream.prototype = Object.create(InputStream.prototype);
FileStream.prototype.constructor = FileStream;

exports.FileStream = FileStream;

},{"./InputStream":30,"fs":74}],30:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
//

var Token = require('./Token').Token;
require('./polyfills/codepointat');
require('./polyfills/fromcodepoint');

// Vacuum all input from a string and then treat it like a buffer.

function _loadString(stream) {
	stream._index = 0;
	stream.data = [];
	if (stream.decodeToUnicodeCodePoints) {
		for (var i = 0; i < stream.strdata.length; ) {
			var codePoint = stream.strdata.codePointAt(i);
			stream.data.push(codePoint);
			i += codePoint <= 0xFFFF ? 1 : 2;
		}
	} else {
		for (var i = 0; i < stream.strdata.length; i++) {
			var codeUnit = stream.strdata.charCodeAt(i);
			stream.data.push(codeUnit);
		}
	}
	stream._size = stream.data.length;
}

// If decodeToUnicodeCodePoints is true, the input is treated
// as a series of Unicode code points.
//
// Otherwise, the input is treated as a series of 16-bit UTF-16 code
// units.
function InputStream(data, decodeToUnicodeCodePoints) {
	this.name = "<empty>";
	this.strdata = data;
	this.decodeToUnicodeCodePoints = decodeToUnicodeCodePoints || false;
	_loadString(this);
	return this;
}

Object.defineProperty(InputStream.prototype, "index", {
	get : function() {
		return this._index;
	}
});

Object.defineProperty(InputStream.prototype, "size", {
	get : function() {
		return this._size;
	}
});

// Reset the stream so that it's in the same state it was
// when the object was created *except* the data array is not
// touched.
//
InputStream.prototype.reset = function() {
	this._index = 0;
};

InputStream.prototype.consume = function() {
	if (this._index >= this._size) {
		// assert this.LA(1) == Token.EOF
		throw ("cannot consume EOF");
	}
	this._index += 1;
};

InputStream.prototype.LA = function(offset) {
	if (offset === 0) {
		return 0; // undefined
	}
	if (offset < 0) {
		offset += 1; // e.g., translate LA(-1) to use offset=0
	}
	var pos = this._index + offset - 1;
	if (pos < 0 || pos >= this._size) { // invalid
		return Token.EOF;
	}
	return this.data[pos];
};

InputStream.prototype.LT = function(offset) {
	return this.LA(offset);
};

// mark/release do nothing; we have entire buffer
InputStream.prototype.mark = function() {
	return -1;
};

InputStream.prototype.release = function(marker) {
};

// consume() ahead until p==_index; can't just set p=_index as we must
// update line and column. If we seek backwards, just set p
//
InputStream.prototype.seek = function(_index) {
	if (_index <= this._index) {
		this._index = _index; // just jump; don't update stream state (line,
								// ...)
		return;
	}
	// seek forward
	this._index = Math.min(_index, this._size);
};

InputStream.prototype.getText = function(start, stop) {
	if (stop >= this._size) {
		stop = this._size - 1;
	}
	if (start >= this._size) {
		return "";
	} else {
		if (this.decodeToUnicodeCodePoints) {
			var result = "";
			for (var i = start; i <= stop; i++) {
				result += String.fromCodePoint(this.data[i]);
			}
			return result;
		} else {
			return this.strdata.slice(start, stop + 1);
		}
	}
};

InputStream.prototype.toString = function() {
	return this.strdata;
};

exports.InputStream = InputStream;

},{"./Token":39,"./polyfills/codepointat":67,"./polyfills/fromcodepoint":68}],31:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

/*jslint smarttabs:true */

var Token = require('./Token').Token;

/* stop is not included! */
function Interval(start, stop) {
	this.start = start;
	this.stop = stop;
	return this;
}

Interval.prototype.contains = function(item) {
	return item >= this.start && item < this.stop;
};

Interval.prototype.toString = function() {
	if(this.start===this.stop-1) {
		return this.start.toString();
	} else {
		return this.start.toString() + ".." + (this.stop-1).toString();
	}
};


Object.defineProperty(Interval.prototype, "length", {
	get : function() {
		return this.stop - this.start;
	}
});

function IntervalSet() {
	this.intervals = null;
	this.readOnly = false;
}

IntervalSet.prototype.first = function(v) {
	if (this.intervals === null || this.intervals.length===0) {
		return Token.INVALID_TYPE;
	} else {
		return this.intervals[0].start;
	}
};

IntervalSet.prototype.addOne = function(v) {
	this.addInterval(new Interval(v, v + 1));
};

IntervalSet.prototype.addRange = function(l, h) {
	this.addInterval(new Interval(l, h + 1));
};

IntervalSet.prototype.addInterval = function(v) {
	if (this.intervals === null) {
		this.intervals = [];
		this.intervals.push(v);
	} else {
		// find insert pos
		for (var k = 0; k < this.intervals.length; k++) {
			var i = this.intervals[k];
			// distinct range -> insert
			if (v.stop < i.start) {
				this.intervals.splice(k, 0, v);
				return;
			}
			// contiguous range -> adjust
			else if (v.stop === i.start) {
				this.intervals[k].start = v.start;
				return;
			}
			// overlapping range -> adjust and reduce
			else if (v.start <= i.stop) {
				this.intervals[k] = new Interval(Math.min(i.start, v.start), Math.max(i.stop, v.stop));
				this.reduce(k);
				return;
			}
		}
		// greater than any existing
		this.intervals.push(v);
	}
};

IntervalSet.prototype.addSet = function(other) {
	if (other.intervals !== null) {
		for (var k = 0; k < other.intervals.length; k++) {
			var i = other.intervals[k];
			this.addInterval(new Interval(i.start, i.stop));
		}
	}
	return this;
};

IntervalSet.prototype.reduce = function(k) {
	// only need to reduce if k is not the last
	if (k < this.intervalslength - 1) {
		var l = this.intervals[k];
		var r = this.intervals[k + 1];
		// if r contained in l
		if (l.stop >= r.stop) {
			this.intervals.pop(k + 1);
			this.reduce(k);
		} else if (l.stop >= r.start) {
			this.intervals[k] = new Interval(l.start, r.stop);
			this.intervals.pop(k + 1);
		}
	}
};

IntervalSet.prototype.complement = function(start, stop) {
    var result = new IntervalSet();
    result.addInterval(new Interval(start,stop+1));
    for(var i=0; i<this.intervals.length; i++) {
        result.removeRange(this.intervals[i]);
    }
    return result;
};

IntervalSet.prototype.contains = function(item) {
	if (this.intervals === null) {
		return false;
	} else {
		for (var k = 0; k < this.intervals.length; k++) {
			if(this.intervals[k].contains(item)) {
				return true;
			}
		}
		return false;
	}
};

Object.defineProperty(IntervalSet.prototype, "length", {
	get : function() {
		var len = 0;
		this.intervals.map(function(i) {len += i.length;});
		return len;
	}
});

IntervalSet.prototype.removeRange = function(v) {
    if(v.start===v.stop-1) {
        this.removeOne(v.start);
    } else if (this.intervals!==null) {
        var k = 0;
        for(var n=0; n<this.intervals.length; n++) {
            var i = this.intervals[k];
            // intervals are ordered
            if (v.stop<=i.start) {
                return;
            }
            // check for including range, split it
            else if(v.start>i.start && v.stop<i.stop) {
                this.intervals[k] = new Interval(i.start, v.start);
                var x = new Interval(v.stop, i.stop);
                this.intervals.splice(k, 0, x);
                return;
            }
            // check for included range, remove it
            else if(v.start<=i.start && v.stop>=i.stop) {
                this.intervals.splice(k, 1);
                k = k - 1; // need another pass
            }
            // check for lower boundary
            else if(v.start<i.stop) {
                this.intervals[k] = new Interval(i.start, v.start);
            }
            // check for upper boundary
            else if(v.stop<i.stop) {
                this.intervals[k] = new Interval(v.stop, i.stop);
            }
            k += 1;
        }
    }
};

IntervalSet.prototype.removeOne = function(v) {
	if (this.intervals !== null) {
		for (var k = 0; k < this.intervals.length; k++) {
			var i = this.intervals[k];
			// intervals is ordered
			if (v < i.start) {
				return;
			}
			// check for single value range
			else if (v === i.start && v === i.stop - 1) {
				this.intervals.splice(k, 1);
				return;
			}
			// check for lower boundary
			else if (v === i.start) {
				this.intervals[k] = new Interval(i.start + 1, i.stop);
				return;
			}
			// check for upper boundary
			else if (v === i.stop - 1) {
				this.intervals[k] = new Interval(i.start, i.stop - 1);
				return;
			}
			// split existing range
			else if (v < i.stop - 1) {
				var x = new Interval(i.start, v);
				i.start = v + 1;
				this.intervals.splice(k, 0, x);
				return;
			}
		}
	}
};

IntervalSet.prototype.toString = function(literalNames, symbolicNames, elemsAreChar) {
	literalNames = literalNames || null;
	symbolicNames = symbolicNames || null;
	elemsAreChar = elemsAreChar || false;
	if (this.intervals === null) {
		return "{}";
	} else if(literalNames!==null || symbolicNames!==null) {
		return this.toTokenString(literalNames, symbolicNames);
	} else if(elemsAreChar) {
		return this.toCharString();
	} else {
		return this.toIndexString();
	}
};

IntervalSet.prototype.toCharString = function() {
	var names = [];
	for (var i = 0; i < this.intervals.length; i++) {
		var v = this.intervals[i];
		if(v.stop===v.start+1) {
			if ( v.start===Token.EOF ) {
				names.push("<EOF>");
			} else {
				names.push("'" + String.fromCharCode(v.start) + "'");
			}
		} else {
			names.push("'" + String.fromCharCode(v.start) + "'..'" + String.fromCharCode(v.stop-1) + "'");
		}
	}
	if (names.length > 1) {
		return "{" + names.join(", ") + "}";
	} else {
		return names[0];
	}
};


IntervalSet.prototype.toIndexString = function() {
	var names = [];
	for (var i = 0; i < this.intervals.length; i++) {
		var v = this.intervals[i];
		if(v.stop===v.start+1) {
			if ( v.start===Token.EOF ) {
				names.push("<EOF>");
			} else {
				names.push(v.start.toString());
			}
		} else {
			names.push(v.start.toString() + ".." + (v.stop-1).toString());
		}
	}
	if (names.length > 1) {
		return "{" + names.join(", ") + "}";
	} else {
		return names[0];
	}
};


IntervalSet.prototype.toTokenString = function(literalNames, symbolicNames) {
	var names = [];
	for (var i = 0; i < this.intervals.length; i++) {
		var v = this.intervals[i];
		for (var j = v.start; j < v.stop; j++) {
			names.push(this.elementName(literalNames, symbolicNames, j));
		}
	}
	if (names.length > 1) {
		return "{" + names.join(", ") + "}";
	} else {
		return names[0];
	}
};

IntervalSet.prototype.elementName = function(literalNames, symbolicNames, a) {
	if (a === Token.EOF) {
		return "<EOF>";
	} else if (a === Token.EPSILON) {
		return "<EPSILON>";
	} else {
		return literalNames[a] || symbolicNames[a];
	}
};

exports.Interval = Interval;
exports.IntervalSet = IntervalSet;

},{"./Token":39}],32:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
///

var Set = require('./Utils').Set;
var BitSet = require('./Utils').BitSet;
var Token = require('./Token').Token;
var ATNConfig = require('./atn/ATNConfig').ATNConfig;
var Interval = require('./IntervalSet').Interval;
var IntervalSet = require('./IntervalSet').IntervalSet;
var RuleStopState = require('./atn/ATNState').RuleStopState;
var RuleTransition = require('./atn/Transition').RuleTransition;
var NotSetTransition = require('./atn/Transition').NotSetTransition;
var WildcardTransition = require('./atn/Transition').WildcardTransition;
var AbstractPredicateTransition = require('./atn/Transition').AbstractPredicateTransition;

var pc = require('./PredictionContext');
var predictionContextFromRuleContext = pc.predictionContextFromRuleContext;
var PredictionContext = pc.PredictionContext;
var SingletonPredictionContext = pc.SingletonPredictionContext;

function LL1Analyzer (atn) {
    this.atn = atn;
}

//* Special value added to the lookahead sets to indicate that we hit
//  a predicate during analysis if {@code seeThruPreds==false}.
///
LL1Analyzer.HIT_PRED = Token.INVALID_TYPE;


//*
// Calculates the SLL(1) expected lookahead set for each outgoing transition
// of an {@link ATNState}. The returned array has one element for each
// outgoing transition in {@code s}. If the closure from transition
// <em>i</em> leads to a semantic predicate before matching a symbol, the
// element at index <em>i</em> of the result will be {@code null}.
//
// @param s the ATN state
// @return the expected symbols for each outgoing transition of {@code s}.
///
LL1Analyzer.prototype.getDecisionLookahead = function(s) {
    if (s === null) {
        return null;
    }
    var count = s.transitions.length;
    var look = [];
    for(var alt=0; alt< count; alt++) {
        look[alt] = new IntervalSet();
        var lookBusy = new Set();
        var seeThruPreds = false; // fail to get lookahead upon pred
        this._LOOK(s.transition(alt).target, null, PredictionContext.EMPTY,
              look[alt], lookBusy, new BitSet(), seeThruPreds, false);
        // Wipe out lookahead for this alternative if we found nothing
        // or we had a predicate when we !seeThruPreds
        if (look[alt].length===0 || look[alt].contains(LL1Analyzer.HIT_PRED)) {
            look[alt] = null;
        }
    }
    return look;
};

//*
// Compute set of tokens that can follow {@code s} in the ATN in the
// specified {@code ctx}.
//
// <p>If {@code ctx} is {@code null} and the end of the rule containing
// {@code s} is reached, {@link Token//EPSILON} is added to the result set.
// If {@code ctx} is not {@code null} and the end of the outermost rule is
// reached, {@link Token//EOF} is added to the result set.</p>
//
// @param s the ATN state
// @param stopState the ATN state to stop at. This can be a
// {@link BlockEndState} to detect epsilon paths through a closure.
// @param ctx the complete parser context, or {@code null} if the context
// should be ignored
//
// @return The set of tokens that can follow {@code s} in the ATN in the
// specified {@code ctx}.
///
LL1Analyzer.prototype.LOOK = function(s, stopState, ctx) {
    var r = new IntervalSet();
    var seeThruPreds = true; // ignore preds; get all lookahead
	ctx = ctx || null;
    var lookContext = ctx!==null ? predictionContextFromRuleContext(s.atn, ctx) : null;
    this._LOOK(s, stopState, lookContext, r, new Set(), new BitSet(), seeThruPreds, true);
    return r;
};

//*
// Compute set of tokens that can follow {@code s} in the ATN in the
// specified {@code ctx}.
//
// <p>If {@code ctx} is {@code null} and {@code stopState} or the end of the
// rule containing {@code s} is reached, {@link Token//EPSILON} is added to
// the result set. If {@code ctx} is not {@code null} and {@code addEOF} is
// {@code true} and {@code stopState} or the end of the outermost rule is
// reached, {@link Token//EOF} is added to the result set.</p>
//
// @param s the ATN state.
// @param stopState the ATN state to stop at. This can be a
// {@link BlockEndState} to detect epsilon paths through a closure.
// @param ctx The outer context, or {@code null} if the outer context should
// not be used.
// @param look The result lookahead set.
// @param lookBusy A set used for preventing epsilon closures in the ATN
// from causing a stack overflow. Outside code should pass
// {@code new Set<ATNConfig>} for this argument.
// @param calledRuleStack A set used for preventing left recursion in the
// ATN from causing a stack overflow. Outside code should pass
// {@code new BitSet()} for this argument.
// @param seeThruPreds {@code true} to true semantic predicates as
// implicitly {@code true} and "see through them", otherwise {@code false}
// to treat semantic predicates as opaque and add {@link //HIT_PRED} to the
// result if one is encountered.
// @param addEOF Add {@link Token//EOF} to the result if the end of the
// outermost context is reached. This parameter has no effect if {@code ctx}
// is {@code null}.
///
LL1Analyzer.prototype._LOOK = function(s, stopState , ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF) {
    var c = new ATNConfig({state:s, alt:0, context: ctx}, null);
    if (lookBusy.contains(c)) {
        return;
    }
    lookBusy.add(c);
    if (s === stopState) {
        if (ctx ===null) {
            look.addOne(Token.EPSILON);
            return;
        } else if (ctx.isEmpty() && addEOF) {
            look.addOne(Token.EOF);
            return;
        }
    }
    if (s instanceof RuleStopState ) {
        if (ctx ===null) {
            look.addOne(Token.EPSILON);
            return;
        } else if (ctx.isEmpty() && addEOF) {
            look.addOne(Token.EOF);
            return;
        }
        if (ctx !== PredictionContext.EMPTY) {
            // run thru all possible stack tops in ctx
            for(var i=0; i<ctx.length; i++) {
                var returnState = this.atn.states[ctx.getReturnState(i)];
                var removed = calledRuleStack.contains(returnState.ruleIndex);
                try {
                    calledRuleStack.remove(returnState.ruleIndex);
                    this._LOOK(returnState, stopState, ctx.getParent(i), look, lookBusy, calledRuleStack, seeThruPreds, addEOF);
                } finally {
                    if (removed) {
                        calledRuleStack.add(returnState.ruleIndex);
                    }
                }
            }
            return;
        }
    }
    for(var j=0; j<s.transitions.length; j++) {
        var t = s.transitions[j];
        if (t.constructor === RuleTransition) {
            if (calledRuleStack.contains(t.target.ruleIndex)) {
                continue;
            }
            var newContext = SingletonPredictionContext.create(ctx, t.followState.stateNumber);
            try {
                calledRuleStack.add(t.target.ruleIndex);
                this._LOOK(t.target, stopState, newContext, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);
            } finally {
                calledRuleStack.remove(t.target.ruleIndex);
            }
        } else if (t instanceof AbstractPredicateTransition ) {
            if (seeThruPreds) {
                this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);
            } else {
                look.addOne(LL1Analyzer.HIT_PRED);
            }
        } else if( t.isEpsilon) {
            this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);
        } else if (t.constructor === WildcardTransition) {
            look.addRange( Token.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType );
        } else {
            var set = t.label;
            if (set !== null) {
                if (t instanceof NotSetTransition) {
                    set = set.complement(Token.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType);
                }
                look.addSet(set);
            }
        }
    }
};

exports.LL1Analyzer = LL1Analyzer;


},{"./IntervalSet":31,"./PredictionContext":36,"./Token":39,"./Utils":40,"./atn/ATNConfig":42,"./atn/ATNState":47,"./atn/Transition":55}],33:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
///

// A lexer is recognizer that draws input symbols from a character stream.
//  lexer grammars result in a subclass of this object. A Lexer object
//  uses simplified match() and error recovery mechanisms in the interest of speed.

var Token = require('./Token').Token;
var Recognizer = require('./Recognizer').Recognizer;
var CommonTokenFactory = require('./CommonTokenFactory').CommonTokenFactory;
var RecognitionException  = require('./error/Errors').RecognitionException;
var LexerNoViableAltException = require('./error/Errors').LexerNoViableAltException;

function TokenSource() {
	return this;
}

function Lexer(input) {
	Recognizer.call(this);
	this._input = input;
	this._factory = CommonTokenFactory.DEFAULT;
	this._tokenFactorySourcePair = [ this, input ];

	this._interp = null; // child classes must populate this

	// The goal of all lexer rules/methods is to create a token object.
	// this is an instance variable as multiple rules may collaborate to
	// create a single token. nextToken will return this object after
	// matching lexer rule(s). If you subclass to allow multiple token
	// emissions, then set this to the last token to be matched or
	// something nonnull so that the auto token emit mechanism will not
	// emit another token.
	this._token = null;

	// What character index in the stream did the current token start at?
	// Needed, for example, to get the text for current token. Set at
	// the start of nextToken.
	this._tokenStartCharIndex = -1;

	// The line on which the first character of the token resides///
	this._tokenStartLine = -1;

	// The character position of first character within the line///
	this._tokenStartColumn = -1;

	// Once we see EOF on char stream, next token will be EOF.
	// If you have DONE : EOF ; then you see DONE EOF.
	this._hitEOF = false;

	// The channel number for the current token///
	this._channel = Token.DEFAULT_CHANNEL;

	// The token type for the current token///
	this._type = Token.INVALID_TYPE;

	this._modeStack = [];
	this._mode = Lexer.DEFAULT_MODE;

	// You can set the text for the current token to override what is in
	// the input char buffer. Use setText() or can set this instance var.
	// /
	this._text = null;

	return this;
}

Lexer.prototype = Object.create(Recognizer.prototype);
Lexer.prototype.constructor = Lexer;

Lexer.DEFAULT_MODE = 0;
Lexer.MORE = -2;
Lexer.SKIP = -3;

Lexer.DEFAULT_TOKEN_CHANNEL = Token.DEFAULT_CHANNEL;
Lexer.HIDDEN = Token.HIDDEN_CHANNEL;
Lexer.MIN_CHAR_VALUE = 0x0000;
Lexer.MAX_CHAR_VALUE = 0x10FFFF;

Lexer.prototype.reset = function() {
	// wack Lexer state variables
	if (this._input !== null) {
		this._input.seek(0); // rewind the input
	}
	this._token = null;
	this._type = Token.INVALID_TYPE;
	this._channel = Token.DEFAULT_CHANNEL;
	this._tokenStartCharIndex = -1;
	this._tokenStartColumn = -1;
	this._tokenStartLine = -1;
	this._text = null;

	this._hitEOF = false;
	this._mode = Lexer.DEFAULT_MODE;
	this._modeStack = [];

	this._interp.reset();
};

// Return a token from this source; i.e., match a token on the char stream.
Lexer.prototype.nextToken = function() {
	if (this._input === null) {
		throw "nextToken requires a non-null input stream.";
	}

	// Mark start location in char stream so unbuffered streams are
	// guaranteed at least have text of current token
	var tokenStartMarker = this._input.mark();
	try {
		while (true) {
			if (this._hitEOF) {
				this.emitEOF();
				return this._token;
			}
			this._token = null;
			this._channel = Token.DEFAULT_CHANNEL;
			this._tokenStartCharIndex = this._input.index;
			this._tokenStartColumn = this._interp.column;
			this._tokenStartLine = this._interp.line;
			this._text = null;
			var continueOuter = false;
			while (true) {
				this._type = Token.INVALID_TYPE;
				var ttype = Lexer.SKIP;
				try {
					ttype = this._interp.match(this._input, this._mode);
				} catch (e) {
				    if(e instanceof RecognitionException) {
                        this.notifyListeners(e); // report error
                        this.recover(e);
                    } else {
                        console.log(e.stack);
                        throw e;
                    }
				}
				if (this._input.LA(1) === Token.EOF) {
					this._hitEOF = true;
				}
				if (this._type === Token.INVALID_TYPE) {
					this._type = ttype;
				}
				if (this._type === Lexer.SKIP) {
					continueOuter = true;
					break;
				}
				if (this._type !== Lexer.MORE) {
					break;
				}
			}
			if (continueOuter) {
				continue;
			}
			if (this._token === null) {
				this.emit();
			}
			return this._token;
		}
	} finally {
		// make sure we release marker after match or
		// unbuffered char stream will keep buffering
		this._input.release(tokenStartMarker);
	}
};

// Instruct the lexer to skip creating a token for current lexer rule
// and look for another token. nextToken() knows to keep looking when
// a lexer rule finishes with token set to SKIP_TOKEN. Recall that
// if token==null at end of any token rule, it creates one for you
// and emits it.
// /
Lexer.prototype.skip = function() {
	this._type = Lexer.SKIP;
};

Lexer.prototype.more = function() {
	this._type = Lexer.MORE;
};

Lexer.prototype.mode = function(m) {
	this._mode = m;
};

Lexer.prototype.pushMode = function(m) {
	if (this._interp.debug) {
		console.log("pushMode " + m);
	}
	this._modeStack.push(this._mode);
	this.mode(m);
};

Lexer.prototype.popMode = function() {
	if (this._modeStack.length === 0) {
		throw "Empty Stack";
	}
	if (this._interp.debug) {
		console.log("popMode back to " + this._modeStack.slice(0, -1));
	}
	this.mode(this._modeStack.pop());
	return this._mode;
};

// Set the char stream and reset the lexer
Object.defineProperty(Lexer.prototype, "inputStream", {
	get : function() {
		return this._input;
	},
	set : function(input) {
		this._input = null;
		this._tokenFactorySourcePair = [ this, this._input ];
		this.reset();
		this._input = input;
		this._tokenFactorySourcePair = [ this, this._input ];
	}
});

Object.defineProperty(Lexer.prototype, "sourceName", {
	get : function sourceName() {
		return this._input.sourceName;
	}
});

// By default does not support multiple emits per nextToken invocation
// for efficiency reasons. Subclass and override this method, nextToken,
// and getToken (to push tokens into a list and pull from that list
// rather than a single variable as this implementation does).
// /
Lexer.prototype.emitToken = function(token) {
	this._token = token;
};

// The standard method called to automatically emit a token at the
// outermost lexical rule. The token object should point into the
// char buffer start..stop. If there is a text override in 'text',
// use that to set the token's text. Override this method to emit
// custom Token objects or provide a new factory.
// /
Lexer.prototype.emit = function() {
	var t = this._factory.create(this._tokenFactorySourcePair, this._type,
			this._text, this._channel, this._tokenStartCharIndex, this
					.getCharIndex() - 1, this._tokenStartLine,
			this._tokenStartColumn);
	this.emitToken(t);
	return t;
};

Lexer.prototype.emitEOF = function() {
	var cpos = this.column;
	var lpos = this.line;
	var eof = this._factory.create(this._tokenFactorySourcePair, Token.EOF,
			null, Token.DEFAULT_CHANNEL, this._input.index,
			this._input.index - 1, lpos, cpos);
	this.emitToken(eof);
	return eof;
};

Object.defineProperty(Lexer.prototype, "type", {
	get : function() {
		return this.type;
	},
	set : function(type) {
		this._type = type;
	}
});

Object.defineProperty(Lexer.prototype, "line", {
	get : function() {
		return this._interp.line;
	},
	set : function(line) {
		this._interp.line = line;
	}
});

Object.defineProperty(Lexer.prototype, "column", {
	get : function() {
		return this._interp.column;
	},
	set : function(column) {
		this._interp.column = column;
	}
});


// What is the index of the current character of lookahead?///
Lexer.prototype.getCharIndex = function() {
	return this._input.index;
};

// Return the text matched so far for the current token or any text override.
//Set the complete text of this token; it wipes any previous changes to the text.
Object.defineProperty(Lexer.prototype, "text", {
	get : function() {
		if (this._text !== null) {
			return this._text;
		} else {
			return this._interp.getText(this._input);
		}
	},
	set : function(text) {
		this._text = text;
	}
});
// Return a list of all Token objects in input char stream.
// Forces load of all tokens. Does not include EOF token.
// /
Lexer.prototype.getAllTokens = function() {
	var tokens = [];
	var t = this.nextToken();
	while (t.type !== Token.EOF) {
		tokens.push(t);
		t = this.nextToken();
	}
	return tokens;
};

Lexer.prototype.notifyListeners = function(e) {
	var start = this._tokenStartCharIndex;
	var stop = this._input.index;
	var text = this._input.getText(start, stop);
	var msg = "token recognition error at: '" + this.getErrorDisplay(text) + "'";
	var listener = this.getErrorListenerDispatch();
	listener.syntaxError(this, null, this._tokenStartLine,
			this._tokenStartColumn, msg, e);
};

Lexer.prototype.getErrorDisplay = function(s) {
	var d = [];
	for (var i = 0; i < s.length; i++) {
		d.push(s[i]);
	}
	return d.join('');
};

Lexer.prototype.getErrorDisplayForChar = function(c) {
	if (c.charCodeAt(0) === Token.EOF) {
		return "<EOF>";
	} else if (c === '\n') {
		return "\\n";
	} else if (c === '\t') {
		return "\\t";
	} else if (c === '\r') {
		return "\\r";
	} else {
		return c;
	}
};

Lexer.prototype.getCharErrorDisplay = function(c) {
	return "'" + this.getErrorDisplayForChar(c) + "'";
};

// Lexers can normally match any char in it's vocabulary after matching
// a token, so do the easy thing and just kill a character and hope
// it all works out. You can instead use the rule invocation stack
// to do sophisticated error recovery if you are in a fragment rule.
// /
Lexer.prototype.recover = function(re) {
	if (this._input.LA(1) !== Token.EOF) {
		if (re instanceof LexerNoViableAltException) {
			// skip a char and try again
			this._interp.consume(this._input);
		} else {
			// TODO: Do we lose character or line position information?
			this._input.consume();
		}
	}
};

exports.Lexer = Lexer;

},{"./CommonTokenFactory":27,"./Recognizer":37,"./Token":39,"./error/Errors":64}],34:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

var Token = require('./Token').Token;
var ParseTreeListener = require('./tree/Tree').ParseTreeListener;
var Recognizer = require('./Recognizer').Recognizer;
var DefaultErrorStrategy = require('./error/ErrorStrategy').DefaultErrorStrategy;
var ATNDeserializer = require('./atn/ATNDeserializer').ATNDeserializer;
var ATNDeserializationOptions = require('./atn/ATNDeserializationOptions').ATNDeserializationOptions;
var TerminalNode = require('./tree/Tree').TerminalNode;
var ErrorNode = require('./tree/Tree').ErrorNode;

function TraceListener(parser) {
	ParseTreeListener.call(this);
    this.parser = parser;
	return this;
}

TraceListener.prototype = Object.create(ParseTreeListener.prototype);
TraceListener.prototype.constructor = TraceListener;

TraceListener.prototype.enterEveryRule = function(ctx) {
	console.log("enter   " + this.parser.ruleNames[ctx.ruleIndex] + ", LT(1)=" + this.parser._input.LT(1).text);
};

TraceListener.prototype.visitTerminal = function( node) {
	console.log("consume " + node.symbol + " rule " + this.parser.ruleNames[this.parser._ctx.ruleIndex]);
};

TraceListener.prototype.exitEveryRule = function(ctx) {
	console.log("exit    " + this.parser.ruleNames[ctx.ruleIndex] + ", LT(1)=" + this.parser._input.LT(1).text);
};

// this is all the parsing support code essentially; most of it is error
// recovery stuff.//
function Parser(input) {
	Recognizer.call(this);
	// The input stream.
	this._input = null;
	// The error handling strategy for the parser. The default value is a new
	// instance of {@link DefaultErrorStrategy}.
	this._errHandler = new DefaultErrorStrategy();
	this._precedenceStack = [];
	this._precedenceStack.push(0);
	// The {@link ParserRuleContext} object for the currently executing rule.
	// this is always non-null during the parsing process.
	this._ctx = null;
	// Specifies whether or not the parser should construct a parse tree during
	// the parsing process. The default value is {@code true}.
	this.buildParseTrees = true;
	// When {@link //setTrace}{@code (true)} is called, a reference to the
	// {@link TraceListener} is stored here so it can be easily removed in a
	// later call to {@link //setTrace}{@code (false)}. The listener itself is
	// implemented as a parser listener so this field is not directly used by
	// other parser methods.
	this._tracer = null;
	// The list of {@link ParseTreeListener} listeners registered to receive
	// events during the parse.
	this._parseListeners = null;
	// The number of syntax errors reported during parsing. this value is
	// incremented each time {@link //notifyErrorListeners} is called.
	this._syntaxErrors = 0;
	this.setInputStream(input);
	return this;
}

Parser.prototype = Object.create(Recognizer.prototype);
Parser.prototype.contructor = Parser;

// this field maps from the serialized ATN string to the deserialized {@link
// ATN} with
// bypass alternatives.
//
// @see ATNDeserializationOptions//isGenerateRuleBypassTransitions()
//
Parser.bypassAltsAtnCache = {};

// reset the parser's state//
Parser.prototype.reset = function() {
	if (this._input !== null) {
		this._input.seek(0);
	}
	this._errHandler.reset(this);
	this._ctx = null;
	this._syntaxErrors = 0;
	this.setTrace(false);
	this._precedenceStack = [];
	this._precedenceStack.push(0);
	if (this._interp !== null) {
		this._interp.reset();
	}
};

// Match current input symbol against {@code ttype}. If the symbol type
// matches, {@link ANTLRErrorStrategy//reportMatch} and {@link //consume} are
// called to complete the match process.
//
// <p>If the symbol type does not match,
// {@link ANTLRErrorStrategy//recoverInline} is called on the current error
// strategy to attempt recovery. If {@link //getBuildParseTree} is
// {@code true} and the token index of the symbol returned by
// {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to
// the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>
//
// @param ttype the token type to match
// @return the matched symbol
// @throws RecognitionException if the current input symbol did not match
// {@code ttype} and the error strategy could not recover from the
// mismatched symbol

Parser.prototype.match = function(ttype) {
	var t = this.getCurrentToken();
	if (t.type === ttype) {
		this._errHandler.reportMatch(this);
		this.consume();
	} else {
		t = this._errHandler.recoverInline(this);
		if (this.buildParseTrees && t.tokenIndex === -1) {
			// we must have conjured up a new token during single token
			// insertion
			// if it's not the current symbol
			this._ctx.addErrorNode(t);
		}
	}
	return t;
};
// Match current input symbol as a wildcard. If the symbol type matches
// (i.e. has a value greater than 0), {@link ANTLRErrorStrategy//reportMatch}
// and {@link //consume} are called to complete the match process.
//
// <p>If the symbol type does not match,
// {@link ANTLRErrorStrategy//recoverInline} is called on the current error
// strategy to attempt recovery. If {@link //getBuildParseTree} is
// {@code true} and the token index of the symbol returned by
// {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to
// the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>
//
// @return the matched symbol
// @throws RecognitionException if the current input symbol did not match
// a wildcard and the error strategy could not recover from the mismatched
// symbol

Parser.prototype.matchWildcard = function() {
	var t = this.getCurrentToken();
	if (t.type > 0) {
		this._errHandler.reportMatch(this);
		this.consume();
	} else {
		t = this._errHandler.recoverInline(this);
		if (this._buildParseTrees && t.tokenIndex === -1) {
			// we must have conjured up a new token during single token
			// insertion
			// if it's not the current symbol
			this._ctx.addErrorNode(t);
		}
	}
	return t;
};

Parser.prototype.getParseListeners = function() {
	return this._parseListeners || [];
};

// Registers {@code listener} to receive events during the parsing process.
//
// <p>To support output-preserving grammar transformations (including but not
// limited to left-recursion removal, automated left-factoring, and
// optimized code generation), calls to listener methods during the parse
// may differ substantially from calls made by
// {@link ParseTreeWalker//DEFAULT} used after the parse is complete. In
// particular, rule entry and exit events may occur in a different order
// during the parse than after the parser. In addition, calls to certain
// rule entry methods may be omitted.</p>
//
// <p>With the following specific exceptions, calls to listener events are
// <em>deterministic</em>, i.e. for identical input the calls to listener
// methods will be the same.</p>
//
// <ul>
// <li>Alterations to the grammar used to generate code may change the
// behavior of the listener calls.</li>
// <li>Alterations to the command line options passed to ANTLR 4 when
// generating the parser may change the behavior of the listener calls.</li>
// <li>Changing the version of the ANTLR Tool used to generate the parser
// may change the behavior of the listener calls.</li>
// </ul>
//
// @param listener the listener to add
//
// @throws NullPointerException if {@code} listener is {@code null}
//
Parser.prototype.addParseListener = function(listener) {
	if (listener === null) {
		throw "listener";
	}
	if (this._parseListeners === null) {
		this._parseListeners = [];
	}
	this._parseListeners.push(listener);
};

//
// Remove {@code listener} from the list of parse listeners.
//
// <p>If {@code listener} is {@code null} or has not been added as a parse
// listener, this method does nothing.</p>
// @param listener the listener to remove
//
Parser.prototype.removeParseListener = function(listener) {
	if (this._parseListeners !== null) {
		var idx = this._parseListeners.indexOf(listener);
		if (idx >= 0) {
			this._parseListeners.splice(idx, 1);
		}
		if (this._parseListeners.length === 0) {
			this._parseListeners = null;
		}
	}
};

// Remove all parse listeners.
Parser.prototype.removeParseListeners = function() {
	this._parseListeners = null;
};

// Notify any parse listeners of an enter rule event.
Parser.prototype.triggerEnterRuleEvent = function() {
	if (this._parseListeners !== null) {
        var ctx = this._ctx;
		this._parseListeners.map(function(listener) {
			listener.enterEveryRule(ctx);
			ctx.enterRule(listener);
		});
	}
};

//
// Notify any parse listeners of an exit rule event.
//
// @see //addParseListener
//
Parser.prototype.triggerExitRuleEvent = function() {
	if (this._parseListeners !== null) {
		// reverse order walk of listeners
        var ctx = this._ctx;
		this._parseListeners.slice(0).reverse().map(function(listener) {
			ctx.exitRule(listener);
			listener.exitEveryRule(ctx);
		});
	}
};

Parser.prototype.getTokenFactory = function() {
	return this._input.tokenSource._factory;
};

// Tell our token source and error strategy about a new way to create tokens.//
Parser.prototype.setTokenFactory = function(factory) {
	this._input.tokenSource._factory = factory;
};

// The ATN with bypass alternatives is expensive to create so we create it
// lazily.
//
// @throws UnsupportedOperationException if the current parser does not
// implement the {@link //getSerializedATN()} method.
//
Parser.prototype.getATNWithBypassAlts = function() {
	var serializedAtn = this.getSerializedATN();
	if (serializedAtn === null) {
		throw "The current parser does not support an ATN with bypass alternatives.";
	}
	var result = this.bypassAltsAtnCache[serializedAtn];
	if (result === null) {
		var deserializationOptions = new ATNDeserializationOptions();
		deserializationOptions.generateRuleBypassTransitions = true;
		result = new ATNDeserializer(deserializationOptions)
				.deserialize(serializedAtn);
		this.bypassAltsAtnCache[serializedAtn] = result;
	}
	return result;
};

// The preferred method of getting a tree pattern. For example, here's a
// sample use:
//
// <pre>
// ParseTree t = parser.expr();
// ParseTreePattern p = parser.compileParseTreePattern("&lt;ID&gt;+0",
// MyParser.RULE_expr);
// ParseTreeMatch m = p.match(t);
// String id = m.get("ID");
// </pre>

var Lexer = require('./Lexer').Lexer;

Parser.prototype.compileParseTreePattern = function(pattern, patternRuleIndex, lexer) {
	lexer = lexer || null;
	if (lexer === null) {
		if (this.getTokenStream() !== null) {
			var tokenSource = this.getTokenStream().tokenSource;
			if (tokenSource instanceof Lexer) {
				lexer = tokenSource;
			}
		}
	}
	if (lexer === null) {
		throw "Parser can't discover a lexer to use";
	}
	var m = new ParseTreePatternMatcher(lexer, this);
	return m.compile(pattern, patternRuleIndex);
};

Parser.prototype.getInputStream = function() {
	return this.getTokenStream();
};

Parser.prototype.setInputStream = function(input) {
	this.setTokenStream(input);
};

Parser.prototype.getTokenStream = function() {
	return this._input;
};

// Set the token stream and reset the parser.//
Parser.prototype.setTokenStream = function(input) {
	this._input = null;
	this.reset();
	this._input = input;
};

// Match needs to return the current input symbol, which gets put
// into the label for the associated token ref; e.g., x=ID.
//
Parser.prototype.getCurrentToken = function() {
	return this._input.LT(1);
};

Parser.prototype.notifyErrorListeners = function(msg, offendingToken, err) {
	offendingToken = offendingToken || null;
	err = err || null;
	if (offendingToken === null) {
		offendingToken = this.getCurrentToken();
	}
	this._syntaxErrors += 1;
	var line = offendingToken.line;
	var column = offendingToken.column;
	var listener = this.getErrorListenerDispatch();
	listener.syntaxError(this, offendingToken, line, column, msg, err);
};

//
// Consume and return the {@linkplain //getCurrentToken current symbol}.
//
// <p>E.g., given the following input with {@code A} being the current
// lookahead symbol, this function moves the cursor to {@code B} and returns
// {@code A}.</p>
//
// <pre>
// A B
// ^
// </pre>
//
// If the parser is not in error recovery mode, the consumed symbol is added
// to the parse tree using {@link ParserRuleContext//addChild(Token)}, and
// {@link ParseTreeListener//visitTerminal} is called on any parse listeners.
// If the parser <em>is</em> in error recovery mode, the consumed symbol is
// added to the parse tree using
// {@link ParserRuleContext//addErrorNode(Token)}, and
// {@link ParseTreeListener//visitErrorNode} is called on any parse
// listeners.
//
Parser.prototype.consume = function() {
	var o = this.getCurrentToken();
	if (o.type !== Token.EOF) {
		this.getInputStream().consume();
	}
	var hasListener = this._parseListeners !== null && this._parseListeners.length > 0;
	if (this.buildParseTrees || hasListener) {
		var node;
		if (this._errHandler.inErrorRecoveryMode(this)) {
			node = this._ctx.addErrorNode(o);
		} else {
			node = this._ctx.addTokenNode(o);
		}
        node.invokingState = this.state;
		if (hasListener) {
			this._parseListeners.map(function(listener) {
				if (node instanceof ErrorNode || (node.isErrorNode !== undefined && node.isErrorNode())) {
					listener.visitErrorNode(node);
				} else if (node instanceof TerminalNode) {
					listener.visitTerminal(node);
				}
			});
		}
	}
	return o;
};

Parser.prototype.addContextToParseTree = function() {
	// add current context to parent if we have a parent
	if (this._ctx.parentCtx !== null) {
		this._ctx.parentCtx.addChild(this._ctx);
	}
};

// Always called by generated parsers upon entry to a rule. Access field
// {@link //_ctx} get the current context.

Parser.prototype.enterRule = function(localctx, state, ruleIndex) {
	this.state = state;
	this._ctx = localctx;
	this._ctx.start = this._input.LT(1);
	if (this.buildParseTrees) {
		this.addContextToParseTree();
	}
	if (this._parseListeners !== null) {
		this.triggerEnterRuleEvent();
	}
};

Parser.prototype.exitRule = function() {
	this._ctx.stop = this._input.LT(-1);
	// trigger event on _ctx, before it reverts to parent
	if (this._parseListeners !== null) {
		this.triggerExitRuleEvent();
	}
	this.state = this._ctx.invokingState;
	this._ctx = this._ctx.parentCtx;
};

Parser.prototype.enterOuterAlt = function(localctx, altNum) {
   	localctx.setAltNumber(altNum);
	// if we have new localctx, make sure we replace existing ctx
	// that is previous child of parse tree
	if (this.buildParseTrees && this._ctx !== localctx) {
		if (this._ctx.parentCtx !== null) {
			this._ctx.parentCtx.removeLastChild();
			this._ctx.parentCtx.addChild(localctx);
		}
	}
	this._ctx = localctx;
};

// Get the precedence level for the top-most precedence rule.
//
// @return The precedence level for the top-most precedence rule, or -1 if
// the parser context is not nested within a precedence rule.

Parser.prototype.getPrecedence = function() {
	if (this._precedenceStack.length === 0) {
		return -1;
	} else {
		return this._precedenceStack[this._precedenceStack.length-1];
	}
};

Parser.prototype.enterRecursionRule = function(localctx, state, ruleIndex,
		precedence) {
	this.state = state;
	this._precedenceStack.push(precedence);
	this._ctx = localctx;
	this._ctx.start = this._input.LT(1);
	if (this._parseListeners !== null) {
		this.triggerEnterRuleEvent(); // simulates rule entry for
										// left-recursive rules
	}
};

//
// Like {@link //enterRule} but for recursive rules.

Parser.prototype.pushNewRecursionContext = function(localctx, state, ruleIndex) {
	var previous = this._ctx;
	previous.parentCtx = localctx;
	previous.invokingState = state;
	previous.stop = this._input.LT(-1);

	this._ctx = localctx;
	this._ctx.start = previous.start;
	if (this.buildParseTrees) {
		this._ctx.addChild(previous);
	}
	if (this._parseListeners !== null) {
		this.triggerEnterRuleEvent(); // simulates rule entry for
										// left-recursive rules
	}
};

Parser.prototype.unrollRecursionContexts = function(parentCtx) {
	this._precedenceStack.pop();
	this._ctx.stop = this._input.LT(-1);
	var retCtx = this._ctx; // save current ctx (return value)
	// unroll so _ctx is as it was before call to recursive method
	if (this._parseListeners !== null) {
		while (this._ctx !== parentCtx) {
			this.triggerExitRuleEvent();
			this._ctx = this._ctx.parentCtx;
		}
	} else {
		this._ctx = parentCtx;
	}
	// hook into tree
	retCtx.parentCtx = parentCtx;
	if (this.buildParseTrees && parentCtx !== null) {
		// add return ctx into invoking rule's tree
		parentCtx.addChild(retCtx);
	}
};

Parser.prototype.getInvokingContext = function(ruleIndex) {
	var ctx = this._ctx;
	while (ctx !== null) {
		if (ctx.ruleIndex === ruleIndex) {
			return ctx;
		}
		ctx = ctx.parentCtx;
	}
	return null;
};

Parser.prototype.precpred = function(localctx, precedence) {
	return precedence >= this._precedenceStack[this._precedenceStack.length-1];
};

Parser.prototype.inContext = function(context) {
	// TODO: useful in parser?
	return false;
};

//
// Checks whether or not {@code symbol} can follow the current state in the
// ATN. The behavior of this method is equivalent to the following, but is
// implemented such that the complete context-sensitive follow set does not
// need to be explicitly constructed.
//
// <pre>
// return getExpectedTokens().contains(symbol);
// </pre>
//
// @param symbol the symbol type to check
// @return {@code true} if {@code symbol} can follow the current state in
// the ATN, otherwise {@code false}.

Parser.prototype.isExpectedToken = function(symbol) {
	var atn = this._interp.atn;
	var ctx = this._ctx;
	var s = atn.states[this.state];
	var following = atn.nextTokens(s);
	if (following.contains(symbol)) {
		return true;
	}
	if (!following.contains(Token.EPSILON)) {
		return false;
	}
	while (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {
		var invokingState = atn.states[ctx.invokingState];
		var rt = invokingState.transitions[0];
		following = atn.nextTokens(rt.followState);
		if (following.contains(symbol)) {
			return true;
		}
		ctx = ctx.parentCtx;
	}
	if (following.contains(Token.EPSILON) && symbol === Token.EOF) {
		return true;
	} else {
		return false;
	}
};

// Computes the set of input symbols which could follow the current parser
// state and context, as given by {@link //getState} and {@link //getContext},
// respectively.
//
// @see ATN//getExpectedTokens(int, RuleContext)
//
Parser.prototype.getExpectedTokens = function() {
	return this._interp.atn.getExpectedTokens(this.state, this._ctx);
};

Parser.prototype.getExpectedTokensWithinCurrentRule = function() {
	var atn = this._interp.atn;
	var s = atn.states[this.state];
	return atn.nextTokens(s);
};

// Get a rule's index (i.e., {@code RULE_ruleName} field) or -1 if not found.//
Parser.prototype.getRuleIndex = function(ruleName) {
	var ruleIndex = this.getRuleIndexMap()[ruleName];
	if (ruleIndex !== null) {
		return ruleIndex;
	} else {
		return -1;
	}
};

// Return List&lt;String&gt; of the rule names in your parser instance
// leading up to a call to the current rule. You could override if
// you want more details such as the file/line info of where
// in the ATN a rule is invoked.
//
// this is very useful for error messages.
//
Parser.prototype.getRuleInvocationStack = function(p) {
	p = p || null;
	if (p === null) {
		p = this._ctx;
	}
	var stack = [];
	while (p !== null) {
		// compute what follows who invoked us
		var ruleIndex = p.ruleIndex;
		if (ruleIndex < 0) {
			stack.push("n/a");
		} else {
			stack.push(this.ruleNames[ruleIndex]);
		}
		p = p.parentCtx;
	}
	return stack;
};

// For debugging and other purposes.//
Parser.prototype.getDFAStrings = function() {
	return this._interp.decisionToDFA.toString();
};
// For debugging and other purposes.//
Parser.prototype.dumpDFA = function() {
	var seenOne = false;
	for (var i = 0; i < this._interp.decisionToDFA.length; i++) {
		var dfa = this._interp.decisionToDFA[i];
		if (dfa.states.length > 0) {
			if (seenOne) {
				console.log();
			}
			this.printer.println("Decision " + dfa.decision + ":");
			this.printer.print(dfa.toString(this.literalNames, this.symbolicNames));
			seenOne = true;
		}
	}
};

/*
"			printer = function() {\r\n" +
"				this.println = function(s) { document.getElementById('output') += s + '\\n'; }\r\n" +
"				this.print = function(s) { document.getElementById('output') += s; }\r\n" +
"			};\r\n" +
*/

Parser.prototype.getSourceName = function() {
	return this._input.sourceName;
};

// During a parse is sometimes useful to listen in on the rule entry and exit
// events as well as token matches. this is for quick and dirty debugging.
//
Parser.prototype.setTrace = function(trace) {
	if (!trace) {
		this.removeParseListener(this._tracer);
		this._tracer = null;
	} else {
		if (this._tracer !== null) {
			this.removeParseListener(this._tracer);
		}
		this._tracer = new TraceListener(this);
		this.addParseListener(this._tracer);
	}
};

exports.Parser = Parser;
},{"./Lexer":33,"./Recognizer":37,"./Token":39,"./atn/ATNDeserializationOptions":44,"./atn/ATNDeserializer":45,"./error/ErrorStrategy":63,"./tree/Tree":69}],35:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

//* A rule invocation record for parsing.
//
//  Contains all of the information about the current rule not stored in the
//  RuleContext. It handles parse tree children list, Any ATN state
//  tracing, and the default values available for rule indications:
//  start, stop, rule index, current alt number, current
//  ATN state.
//
//  Subclasses made for each rule and grammar track the parameters,
//  return values, locals, and labels specific to that rule. These
//  are the objects that are returned from rules.
//
//  Note text is not an actual field of a rule return value; it is computed
//  from start and stop using the input stream's toString() method.  I
//  could add a ctor to this so that we can pass in and store the input
//  stream, but I'm not sure we want to do that.  It would seem to be undefined
//  to get the .text property anyway if the rule matches tokens from multiple
//  input streams.
//
//  I do not use getters for fields of objects that are used simply to
//  group values such as this aggregate.  The getters/setters are there to
//  satisfy the superclass interface.

var RuleContext = require('./RuleContext').RuleContext;
var Tree = require('./tree/Tree');
var INVALID_INTERVAL = Tree.INVALID_INTERVAL;
var TerminalNode = Tree.TerminalNode;
var TerminalNodeImpl = Tree.TerminalNodeImpl;
var ErrorNodeImpl = Tree.ErrorNodeImpl;
var Interval = require("./IntervalSet").Interval;

function ParserRuleContext(parent, invokingStateNumber) {
	parent = parent || null;
	invokingStateNumber = invokingStateNumber || null;
	RuleContext.call(this, parent, invokingStateNumber);
	this.ruleIndex = -1;
    // * If we are debugging or building a parse tree for a visitor,
    // we need to track all of the tokens and rule invocations associated
    // with this rule's context. This is empty for parsing w/o tree constr.
    // operation because we don't the need to track the details about
    // how we parse this rule.
    // /
    this.children = null;
    this.start = null;
    this.stop = null;
    // The exception that forced this rule to return. If the rule successfully
    // completed, this is {@code null}.
    this.exception = null;
}

ParserRuleContext.prototype = Object.create(RuleContext.prototype);
ParserRuleContext.prototype.constructor = ParserRuleContext;

// * COPY a ctx (I'm deliberately not using copy constructor)///
ParserRuleContext.prototype.copyFrom = function(ctx) {
    // from RuleContext
    this.parentCtx = ctx.parentCtx;
    this.invokingState = ctx.invokingState;
    this.children = null;
    this.start = ctx.start;
    this.stop = ctx.stop;
    // copy any error nodes to alt label node
    if(ctx.children) {
        this.children = [];
        // reset parent pointer for any error nodes
    	ctx.children.map(function(child) {
    		if (child instanceof ErrorNodeImpl) {
                this.children.push(child);
                child.parentCtx = this;
            }
		}, this);
	}
};

// Double dispatch methods for listeners
ParserRuleContext.prototype.enterRule = function(listener) {
};

ParserRuleContext.prototype.exitRule = function(listener) {
};

// * Does not set parent link; other add methods do that///
ParserRuleContext.prototype.addChild = function(child) {
    if (this.children === null) {
        this.children = [];
    }
    this.children.push(child);
    return child;
};

// * Used by enterOuterAlt to toss out a RuleContext previously added as
// we entered a rule. If we have // label, we will need to remove
// generic ruleContext object.
// /
ParserRuleContext.prototype.removeLastChild = function() {
    if (this.children !== null) {
        this.children.pop();
    }
};

ParserRuleContext.prototype.addTokenNode = function(token) {
    var node = new TerminalNodeImpl(token);
    this.addChild(node);
    node.parentCtx = this;
    return node;
};

ParserRuleContext.prototype.addErrorNode = function(badToken) {
    var node = new ErrorNodeImpl(badToken);
    this.addChild(node);
    node.parentCtx = this;
    return node;
};

ParserRuleContext.prototype.getChild = function(i, type) {
	type = type || null;
	if (this.children === null || i < 0 || i >= this.children.length) {
		return null;
	}
	if (type === null) {
		return this.children[i];
	} else {
		for(var j=0; j<this.children.length; j++) {
			var child = this.children[j];
			if(child instanceof type) {
				if(i===0) {
					return child;
				} else {
					i -= 1;
				}
			}
		}
		return null;
    }
};


ParserRuleContext.prototype.getToken = function(ttype, i) {
	if (this.children === null || i < 0 || i >= this.children.length) {
		return null;
	}
	for(var j=0; j<this.children.length; j++) {
		var child = this.children[j];
		if (child instanceof TerminalNode) {
			if (child.symbol.type === ttype) {
				if(i===0) {
					return child;
				} else {
					i -= 1;
				}
			}
        }
	}
    return null;
};

ParserRuleContext.prototype.getTokens = function(ttype ) {
    if (this.children=== null) {
        return [];
    } else {
		var tokens = [];
		for(var j=0; j<this.children.length; j++) {
			var child = this.children[j];
			if (child instanceof TerminalNode) {
				if (child.symbol.type === ttype) {
					tokens.push(child);
				}
			}
		}
		return tokens;
    }
};

ParserRuleContext.prototype.getTypedRuleContext = function(ctxType, i) {
    return this.getChild(i, ctxType);
};

ParserRuleContext.prototype.getTypedRuleContexts = function(ctxType) {
    if (this.children=== null) {
        return [];
    } else {
		var contexts = [];
		for(var j=0; j<this.children.length; j++) {
			var child = this.children[j];
			if (child instanceof ctxType) {
				contexts.push(child);
			}
		}
		return contexts;
	}
};

ParserRuleContext.prototype.getChildCount = function() {
	if (this.children=== null) {
		return 0;
	} else {
		return this.children.length;
	}
};

ParserRuleContext.prototype.getSourceInterval = function() {
    if( this.start === null || this.stop === null) {
        return INVALID_INTERVAL;
    } else {
        return new Interval(this.start.tokenIndex, this.stop.tokenIndex);
    }
};

RuleContext.EMPTY = new ParserRuleContext();

function InterpreterRuleContext(parent, invokingStateNumber, ruleIndex) {
	ParserRuleContext.call(parent, invokingStateNumber);
    this.ruleIndex = ruleIndex;
    return this;
}

InterpreterRuleContext.prototype = Object.create(ParserRuleContext.prototype);
InterpreterRuleContext.prototype.constructor = InterpreterRuleContext;

exports.ParserRuleContext = ParserRuleContext;
},{"./IntervalSet":31,"./RuleContext":38,"./tree/Tree":69}],36:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
///

var RuleContext = require('./RuleContext').RuleContext;
var Hash = require('./Utils').Hash;
var Map = require('./Utils').Map;

function PredictionContext(cachedHashCode) {
	this.cachedHashCode = cachedHashCode;
}

// Represents {@code $} in local context prediction, which means wildcard.
// {@code//+x =//}.
// /
PredictionContext.EMPTY = null;

// Represents {@code $} in an array in full context mode, when {@code $}
// doesn't mean wildcard: {@code $ + x = [$,x]}. Here,
// {@code $} = {@link //EMPTY_RETURN_STATE}.
// /
PredictionContext.EMPTY_RETURN_STATE = 0x7FFFFFFF;

PredictionContext.globalNodeCount = 1;
PredictionContext.id = PredictionContext.globalNodeCount;

// Stores the computed hash code of this {@link PredictionContext}. The hash
// code is computed in parts to match the following reference algorithm.
//
// <pre>
// private int referenceHashCode() {
// int hash = {@link MurmurHash//initialize MurmurHash.initialize}({@link
// //INITIAL_HASH});
//
// for (int i = 0; i &lt; {@link //size()}; i++) {
// hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link //getParent
// getParent}(i));
// }
//
// for (int i = 0; i &lt; {@link //size()}; i++) {
// hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link
// //getReturnState getReturnState}(i));
// }
//
// hash = {@link MurmurHash//finish MurmurHash.finish}(hash, 2// {@link
// //size()});
// return hash;
// }
// </pre>
// /

// This means only the {@link //EMPTY} context is in set.
PredictionContext.prototype.isEmpty = function() {
	return this === PredictionContext.EMPTY;
};

PredictionContext.prototype.hasEmptyPath = function() {
	return this.getReturnState(this.length - 1) === PredictionContext.EMPTY_RETURN_STATE;
};

PredictionContext.prototype.hashCode = function() {
	return this.cachedHashCode;
};


PredictionContext.prototype.updateHashCode = function(hash) {
    hash.update(this.cachedHashCode);
};
/*
function calculateHashString(parent, returnState) {
	return "" + parent + returnState;
}
*/

// Used to cache {@link PredictionContext} objects. Its used for the shared
// context cash associated with contexts in DFA states. This cache
// can be used for both lexers and parsers.

function PredictionContextCache() {
	this.cache = new Map();
	return this;
}

// Add a context to the cache and return it. If the context already exists,
// return that one instead and do not add a new context to the cache.
// Protect shared cache from unsafe thread access.
//
PredictionContextCache.prototype.add = function(ctx) {
	if (ctx === PredictionContext.EMPTY) {
		return PredictionContext.EMPTY;
	}
	var existing = this.cache.get(ctx) || null;
	if (existing !== null) {
		return existing;
	}
	this.cache.put(ctx, ctx);
	return ctx;
};

PredictionContextCache.prototype.get = function(ctx) {
	return this.cache.get(ctx) || null;
};

Object.defineProperty(PredictionContextCache.prototype, "length", {
	get : function() {
		return this.cache.length;
	}
});

function SingletonPredictionContext(parent, returnState) {
	var hashCode = 0;
	var hash = new Hash();
	if(parent !== null) {
		hash.update(parent, returnState);
	} else {
		hash.update(1);
	}
	hashCode = hash.finish();
	PredictionContext.call(this, hashCode);
	this.parentCtx = parent;
	this.returnState = returnState;
}

SingletonPredictionContext.prototype = Object.create(PredictionContext.prototype);
SingletonPredictionContext.prototype.contructor = SingletonPredictionContext;

SingletonPredictionContext.create = function(parent, returnState) {
	if (returnState === PredictionContext.EMPTY_RETURN_STATE && parent === null) {
		// someone can pass in the bits of an array ctx that mean $
		return PredictionContext.EMPTY;
	} else {
		return new SingletonPredictionContext(parent, returnState);
	}
};

Object.defineProperty(SingletonPredictionContext.prototype, "length", {
	get : function() {
		return 1;
	}
});

SingletonPredictionContext.prototype.getParent = function(index) {
	return this.parentCtx;
};

SingletonPredictionContext.prototype.getReturnState = function(index) {
	return this.returnState;
};

SingletonPredictionContext.prototype.equals = function(other) {
	if (this === other) {
		return true;
	} else if (!(other instanceof SingletonPredictionContext)) {
		return false;
	} else if (this.hashCode() !== other.hashCode()) {
		return false; // can't be same if hash is different
	} else {
		if(this.returnState !== other.returnState)
            return false;
        else if(this.parentCtx==null)
            return other.parentCtx==null
		else
            return this.parentCtx.equals(other.parentCtx);
	}
};

SingletonPredictionContext.prototype.toString = function() {
	var up = this.parentCtx === null ? "" : this.parentCtx.toString();
	if (up.length === 0) {
		if (this.returnState === PredictionContext.EMPTY_RETURN_STATE) {
			return "$";
		} else {
			return "" + this.returnState;
		}
	} else {
		return "" + this.returnState + " " + up;
	}
};

function EmptyPredictionContext() {
	SingletonPredictionContext.call(this, null, PredictionContext.EMPTY_RETURN_STATE);
	return this;
}

EmptyPredictionContext.prototype = Object.create(SingletonPredictionContext.prototype);
EmptyPredictionContext.prototype.constructor = EmptyPredictionContext;

EmptyPredictionContext.prototype.isEmpty = function() {
	return true;
};

EmptyPredictionContext.prototype.getParent = function(index) {
	return null;
};

EmptyPredictionContext.prototype.getReturnState = function(index) {
	return this.returnState;
};

EmptyPredictionContext.prototype.equals = function(other) {
	return this === other;
};

EmptyPredictionContext.prototype.toString = function() {
	return "$";
};

PredictionContext.EMPTY = new EmptyPredictionContext();

function ArrayPredictionContext(parents, returnStates) {
	// Parent can be null only if full ctx mode and we make an array
	// from {@link //EMPTY} and non-empty. We merge {@link //EMPTY} by using
	// null parent and
	// returnState == {@link //EMPTY_RETURN_STATE}.
	var h = new Hash();
	h.update(parents, returnStates);
	var hashCode = h.finish();
	PredictionContext.call(this, hashCode);
	this.parents = parents;
	this.returnStates = returnStates;
	return this;
}

ArrayPredictionContext.prototype = Object.create(PredictionContext.prototype);
ArrayPredictionContext.prototype.constructor = ArrayPredictionContext;

ArrayPredictionContext.prototype.isEmpty = function() {
	// since EMPTY_RETURN_STATE can only appear in the last position, we
	// don't need to verify that size==1
	return this.returnStates[0] === PredictionContext.EMPTY_RETURN_STATE;
};

Object.defineProperty(ArrayPredictionContext.prototype, "length", {
	get : function() {
		return this.returnStates.length;
	}
});

ArrayPredictionContext.prototype.getParent = function(index) {
	return this.parents[index];
};

ArrayPredictionContext.prototype.getReturnState = function(index) {
	return this.returnStates[index];
};

ArrayPredictionContext.prototype.equals = function(other) {
	if (this === other) {
		return true;
	} else if (!(other instanceof ArrayPredictionContext)) {
		return false;
	} else if (this.hashCode() !== other.hashCode()) {
		return false; // can't be same if hash is different
	} else {
		return this.returnStates === other.returnStates &&
				this.parents === other.parents;
	}
};

ArrayPredictionContext.prototype.toString = function() {
	if (this.isEmpty()) {
		return "[]";
	} else {
		var s = "[";
		for (var i = 0; i < this.returnStates.length; i++) {
			if (i > 0) {
				s = s + ", ";
			}
			if (this.returnStates[i] === PredictionContext.EMPTY_RETURN_STATE) {
				s = s + "$";
				continue;
			}
			s = s + this.returnStates[i];
			if (this.parents[i] !== null) {
				s = s + " " + this.parents[i];
			} else {
				s = s + "null";
			}
		}
		return s + "]";
	}
};

// Convert a {@link RuleContext} tree to a {@link PredictionContext} graph.
// Return {@link //EMPTY} if {@code outerContext} is empty or null.
// /
function predictionContextFromRuleContext(atn, outerContext) {
	if (outerContext === undefined || outerContext === null) {
		outerContext = RuleContext.EMPTY;
	}
	// if we are in RuleContext of start rule, s, then PredictionContext
	// is EMPTY. Nobody called us. (if we are empty, return empty)
	if (outerContext.parentCtx === null || outerContext === RuleContext.EMPTY) {
		return PredictionContext.EMPTY;
	}
	// If we have a parent, convert it to a PredictionContext graph
	var parent = predictionContextFromRuleContext(atn, outerContext.parentCtx);
	var state = atn.states[outerContext.invokingState];
	var transition = state.transitions[0];
	return SingletonPredictionContext.create(parent, transition.followState.stateNumber);
}
/*
function calculateListsHashString(parents, returnStates) {
	var s = "";
	parents.map(function(p) {
		s = s + p;
	});
	returnStates.map(function(r) {
		s = s + r;
	});
	return s;
}
*/
function merge(a, b, rootIsWildcard, mergeCache) {
	// share same graph if both same
	if (a === b) {
		return a;
	}
	if (a instanceof SingletonPredictionContext && b instanceof SingletonPredictionContext) {
		return mergeSingletons(a, b, rootIsWildcard, mergeCache);
	}
	// At least one of a or b is array
	// If one is $ and rootIsWildcard, return $ as// wildcard
	if (rootIsWildcard) {
		if (a instanceof EmptyPredictionContext) {
			return a;
		}
		if (b instanceof EmptyPredictionContext) {
			return b;
		}
	}
	// convert singleton so both are arrays to normalize
	if (a instanceof SingletonPredictionContext) {
		a = new ArrayPredictionContext([a.getParent()], [a.returnState]);
	}
	if (b instanceof SingletonPredictionContext) {
		b = new ArrayPredictionContext([b.getParent()], [b.returnState]);
	}
	return mergeArrays(a, b, rootIsWildcard, mergeCache);
}

//
// Merge two {@link SingletonPredictionContext} instances.
//
// <p>Stack tops equal, parents merge is same; return left graph.<br>
// <embed src="images/SingletonMerge_SameRootSamePar.svg"
// type="image/svg+xml"/></p>
//
// <p>Same stack top, parents differ; merge parents giving array node, then
// remainders of those graphs. A new root node is created to point to the
// merged parents.<br>
// <embed src="images/SingletonMerge_SameRootDiffPar.svg"
// type="image/svg+xml"/></p>
//
// <p>Different stack tops pointing to same parent. Make array node for the
// root where both element in the root point to the same (original)
// parent.<br>
// <embed src="images/SingletonMerge_DiffRootSamePar.svg"
// type="image/svg+xml"/></p>
//
// <p>Different stack tops pointing to different parents. Make array node for
// the root where each element points to the corresponding original
// parent.<br>
// <embed src="images/SingletonMerge_DiffRootDiffPar.svg"
// type="image/svg+xml"/></p>
//
// @param a the first {@link SingletonPredictionContext}
// @param b the second {@link SingletonPredictionContext}
// @param rootIsWildcard {@code true} if this is a local-context merge,
// otherwise false to indicate a full-context merge
// @param mergeCache
// /
function mergeSingletons(a, b, rootIsWildcard, mergeCache) {
	if (mergeCache !== null) {
		var previous = mergeCache.get(a, b);
		if (previous !== null) {
			return previous;
		}
		previous = mergeCache.get(b, a);
		if (previous !== null) {
			return previous;
		}
	}

	var rootMerge = mergeRoot(a, b, rootIsWildcard);
	if (rootMerge !== null) {
		if (mergeCache !== null) {
			mergeCache.set(a, b, rootMerge);
		}
		return rootMerge;
	}
	if (a.returnState === b.returnState) {
		var parent = merge(a.parentCtx, b.parentCtx, rootIsWildcard, mergeCache);
		// if parent is same as existing a or b parent or reduced to a parent,
		// return it
		if (parent === a.parentCtx) {
			return a; // ax + bx = ax, if a=b
		}
		if (parent === b.parentCtx) {
			return b; // ax + bx = bx, if a=b
		}
		// else: ax + ay = a'[x,y]
		// merge parents x and y, giving array node with x,y then remainders
		// of those graphs. dup a, a' points at merged array
		// new joined parent so create new singleton pointing to it, a'
		var spc = SingletonPredictionContext.create(parent, a.returnState);
		if (mergeCache !== null) {
			mergeCache.set(a, b, spc);
		}
		return spc;
	} else { // a != b payloads differ
		// see if we can collapse parents due to $+x parents if local ctx
		var singleParent = null;
		if (a === b || (a.parentCtx !== null && a.parentCtx === b.parentCtx)) { // ax +
																				// bx =
																				// [a,b]x
			singleParent = a.parentCtx;
		}
		if (singleParent !== null) { // parents are same
			// sort payloads and use same parent
			var payloads = [ a.returnState, b.returnState ];
			if (a.returnState > b.returnState) {
				payloads[0] = b.returnState;
				payloads[1] = a.returnState;
			}
			var parents = [ singleParent, singleParent ];
			var apc = new ArrayPredictionContext(parents, payloads);
			if (mergeCache !== null) {
				mergeCache.set(a, b, apc);
			}
			return apc;
		}
		// parents differ and can't merge them. Just pack together
		// into array; can't merge.
		// ax + by = [ax,by]
		var payloads = [ a.returnState, b.returnState ];
		var parents = [ a.parentCtx, b.parentCtx ];
		if (a.returnState > b.returnState) { // sort by payload
			payloads[0] = b.returnState;
			payloads[1] = a.returnState;
			parents = [ b.parentCtx, a.parentCtx ];
		}
		var a_ = new ArrayPredictionContext(parents, payloads);
		if (mergeCache !== null) {
			mergeCache.set(a, b, a_);
		}
		return a_;
	}
}

//
// Handle case where at least one of {@code a} or {@code b} is
// {@link //EMPTY}. In the following diagrams, the symbol {@code $} is used
// to represent {@link //EMPTY}.
//
// <h2>Local-Context Merges</h2>
//
// <p>These local-context merge operations are used when {@code rootIsWildcard}
// is true.</p>
//
// <p>{@link //EMPTY} is superset of any graph; return {@link //EMPTY}.<br>
// <embed src="images/LocalMerge_EmptyRoot.svg" type="image/svg+xml"/></p>
//
// <p>{@link //EMPTY} and anything is {@code //EMPTY}, so merged parent is
// {@code //EMPTY}; return left graph.<br>
// <embed src="images/LocalMerge_EmptyParent.svg" type="image/svg+xml"/></p>
//
// <p>Special case of last merge if local context.<br>
// <embed src="images/LocalMerge_DiffRoots.svg" type="image/svg+xml"/></p>
//
// <h2>Full-Context Merges</h2>
//
// <p>These full-context merge operations are used when {@code rootIsWildcard}
// is false.</p>
//
// <p><embed src="images/FullMerge_EmptyRoots.svg" type="image/svg+xml"/></p>
//
// <p>Must keep all contexts; {@link //EMPTY} in array is a special value (and
// null parent).<br>
// <embed src="images/FullMerge_EmptyRoot.svg" type="image/svg+xml"/></p>
//
// <p><embed src="images/FullMerge_SameRoot.svg" type="image/svg+xml"/></p>
//
// @param a the first {@link SingletonPredictionContext}
// @param b the second {@link SingletonPredictionContext}
// @param rootIsWildcard {@code true} if this is a local-context merge,
// otherwise false to indicate a full-context merge
// /
function mergeRoot(a, b, rootIsWildcard) {
	if (rootIsWildcard) {
		if (a === PredictionContext.EMPTY) {
			return PredictionContext.EMPTY; // // + b =//
		}
		if (b === PredictionContext.EMPTY) {
			return PredictionContext.EMPTY; // a +// =//
		}
	} else {
		if (a === PredictionContext.EMPTY && b === PredictionContext.EMPTY) {
			return PredictionContext.EMPTY; // $ + $ = $
		} else if (a === PredictionContext.EMPTY) { // $ + x = [$,x]
			var payloads = [ b.returnState,
					PredictionContext.EMPTY_RETURN_STATE ];
			var parents = [ b.parentCtx, null ];
			return new ArrayPredictionContext(parents, payloads);
		} else if (b === PredictionContext.EMPTY) { // x + $ = [$,x] ($ is always first if present)
			var payloads = [ a.returnState, PredictionContext.EMPTY_RETURN_STATE ];
			var parents = [ a.parentCtx, null ];
			return new ArrayPredictionContext(parents, payloads);
		}
	}
	return null;
}

//
// Merge two {@link ArrayPredictionContext} instances.
//
// <p>Different tops, different parents.<br>
// <embed src="images/ArrayMerge_DiffTopDiffPar.svg" type="image/svg+xml"/></p>
//
// <p>Shared top, same parents.<br>
// <embed src="images/ArrayMerge_ShareTopSamePar.svg" type="image/svg+xml"/></p>
//
// <p>Shared top, different parents.<br>
// <embed src="images/ArrayMerge_ShareTopDiffPar.svg" type="image/svg+xml"/></p>
//
// <p>Shared top, all shared parents.<br>
// <embed src="images/ArrayMerge_ShareTopSharePar.svg"
// type="image/svg+xml"/></p>
//
// <p>Equal tops, merge parents and reduce top to
// {@link SingletonPredictionContext}.<br>
// <embed src="images/ArrayMerge_EqualTop.svg" type="image/svg+xml"/></p>
// /
function mergeArrays(a, b, rootIsWildcard, mergeCache) {
	if (mergeCache !== null) {
		var previous = mergeCache.get(a, b);
		if (previous !== null) {
			return previous;
		}
		previous = mergeCache.get(b, a);
		if (previous !== null) {
			return previous;
		}
	}
	// merge sorted payloads a + b => M
	var i = 0; // walks a
	var j = 0; // walks b
	var k = 0; // walks target M array

	var mergedReturnStates = [];
	var mergedParents = [];
	// walk and merge to yield mergedParents, mergedReturnStates
	while (i < a.returnStates.length && j < b.returnStates.length) {
		var a_parent = a.parents[i];
		var b_parent = b.parents[j];
		if (a.returnStates[i] === b.returnStates[j]) {
			// same payload (stack tops are equal), must yield merged singleton
			var payload = a.returnStates[i];
			// $+$ = $
			var bothDollars = payload === PredictionContext.EMPTY_RETURN_STATE &&
					a_parent === null && b_parent === null;
			var ax_ax = (a_parent !== null && b_parent !== null && a_parent === b_parent); // ax+ax
																							// ->
																							// ax
			if (bothDollars || ax_ax) {
				mergedParents[k] = a_parent; // choose left
				mergedReturnStates[k] = payload;
			} else { // ax+ay -> a'[x,y]
				var mergedParent = merge(a_parent, b_parent, rootIsWildcard, mergeCache);
				mergedParents[k] = mergedParent;
				mergedReturnStates[k] = payload;
			}
			i += 1; // hop over left one as usual
			j += 1; // but also skip one in right side since we merge
		} else if (a.returnStates[i] < b.returnStates[j]) { // copy a[i] to M
			mergedParents[k] = a_parent;
			mergedReturnStates[k] = a.returnStates[i];
			i += 1;
		} else { // b > a, copy b[j] to M
			mergedParents[k] = b_parent;
			mergedReturnStates[k] = b.returnStates[j];
			j += 1;
		}
		k += 1;
	}
	// copy over any payloads remaining in either array
	if (i < a.returnStates.length) {
		for (var p = i; p < a.returnStates.length; p++) {
			mergedParents[k] = a.parents[p];
			mergedReturnStates[k] = a.returnStates[p];
			k += 1;
		}
	} else {
		for (var p = j; p < b.returnStates.length; p++) {
			mergedParents[k] = b.parents[p];
			mergedReturnStates[k] = b.returnStates[p];
			k += 1;
		}
	}
	// trim merged if we combined a few that had same stack tops
	if (k < mergedParents.length) { // write index < last position; trim
		if (k === 1) { // for just one merged element, return singleton top
			var a_ = SingletonPredictionContext.create(mergedParents[0],
					mergedReturnStates[0]);
			if (mergeCache !== null) {
				mergeCache.set(a, b, a_);
			}
			return a_;
		}
		mergedParents = mergedParents.slice(0, k);
		mergedReturnStates = mergedReturnStates.slice(0, k);
	}

	var M = new ArrayPredictionContext(mergedParents, mergedReturnStates);

	// if we created same array as a or b, return that instead
	// TODO: track whether this is possible above during merge sort for speed
	if (M === a) {
		if (mergeCache !== null) {
			mergeCache.set(a, b, a);
		}
		return a;
	}
	if (M === b) {
		if (mergeCache !== null) {
			mergeCache.set(a, b, b);
		}
		return b;
	}
	combineCommonParents(mergedParents);

	if (mergeCache !== null) {
		mergeCache.set(a, b, M);
	}
	return M;
}

//
// Make pass over all <em>M</em> {@code parents}; merge any {@code equals()}
// ones.
// /
function combineCommonParents(parents) {
	var uniqueParents = new Map();

	for (var p = 0; p < parents.length; p++) {
		var parent = parents[p];
		if (!(uniqueParents.containsKey(parent))) {
			uniqueParents.put(parent, parent);
		}
	}
	for (var q = 0; q < parents.length; q++) {
		parents[q] = uniqueParents.get(parents[q]);
	}
}

function getCachedPredictionContext(context, contextCache, visited) {
	if (context.isEmpty()) {
		return context;
	}
	var existing = visited.get(context) || null;
	if (existing !== null) {
		return existing;
	}
	existing = contextCache.get(context);
	if (existing !== null) {
		visited.put(context, existing);
		return existing;
	}
	var changed = false;
	var parents = [];
	for (var i = 0; i < parents.length; i++) {
		var parent = getCachedPredictionContext(context.getParent(i), contextCache, visited);
		if (changed || parent !== context.getParent(i)) {
			if (!changed) {
				parents = [];
				for (var j = 0; j < context.length; j++) {
					parents[j] = context.getParent(j);
				}
				changed = true;
			}
			parents[i] = parent;
		}
	}
	if (!changed) {
		contextCache.add(context);
		visited.put(context, context);
		return context;
	}
	var updated = null;
	if (parents.length === 0) {
		updated = PredictionContext.EMPTY;
	} else if (parents.length === 1) {
		updated = SingletonPredictionContext.create(parents[0], context
				.getReturnState(0));
	} else {
		updated = new ArrayPredictionContext(parents, context.returnStates);
	}
	contextCache.add(updated);
	visited.put(updated, updated);
	visited.put(context, updated);

	return updated;
}

// ter's recursive version of Sam's getAllNodes()
function getAllContextNodes(context, nodes, visited) {
	if (nodes === null) {
		nodes = [];
		return getAllContextNodes(context, nodes, visited);
	} else if (visited === null) {
		visited = new Map();
		return getAllContextNodes(context, nodes, visited);
	} else {
		if (context === null || visited.containsKey(context)) {
			return nodes;
		}
		visited.put(context, context);
		nodes.push(context);
		for (var i = 0; i < context.length; i++) {
			getAllContextNodes(context.getParent(i), nodes, visited);
		}
		return nodes;
	}
}

exports.merge = merge;
exports.PredictionContext = PredictionContext;
exports.PredictionContextCache = PredictionContextCache;
exports.SingletonPredictionContext = SingletonPredictionContext;
exports.predictionContextFromRuleContext = predictionContextFromRuleContext;
exports.getCachedPredictionContext = getCachedPredictionContext;

},{"./RuleContext":38,"./Utils":40}],37:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
//

var Token = require('./Token').Token;
var ConsoleErrorListener = require('./error/ErrorListener').ConsoleErrorListener;
var ProxyErrorListener = require('./error/ErrorListener').ProxyErrorListener;

function Recognizer() {
    this._listeners = [ ConsoleErrorListener.INSTANCE ];
    this._interp = null;
    this._stateNumber = -1;
    return this;
}

Recognizer.tokenTypeMapCache = {};
Recognizer.ruleIndexMapCache = {};


Recognizer.prototype.checkVersion = function(toolVersion) {
    var runtimeVersion = "4.8";
    if (runtimeVersion!==toolVersion) {
        console.log("ANTLR runtime and generated code versions disagree: "+runtimeVersion+"!="+toolVersion);
    }
};

Recognizer.prototype.addErrorListener = function(listener) {
    this._listeners.push(listener);
};

Recognizer.prototype.removeErrorListeners = function() {
    this._listeners = [];
};

Recognizer.prototype.getTokenTypeMap = function() {
    var tokenNames = this.getTokenNames();
    if (tokenNames===null) {
        throw("The current recognizer does not provide a list of token names.");
    }
    var result = this.tokenTypeMapCache[tokenNames];
    if(result===undefined) {
        result = tokenNames.reduce(function(o, k, i) { o[k] = i; });
        result.EOF = Token.EOF;
        this.tokenTypeMapCache[tokenNames] = result;
    }
    return result;
};

// Get a map from rule names to rule indexes.
//
// <p>Used for XPath and tree pattern compilation.</p>
//
Recognizer.prototype.getRuleIndexMap = function() {
    var ruleNames = this.ruleNames;
    if (ruleNames===null) {
        throw("The current recognizer does not provide a list of rule names.");
    }
    var result = this.ruleIndexMapCache[ruleNames];
    if(result===undefined) {
        result = ruleNames.reduce(function(o, k, i) { o[k] = i; });
        this.ruleIndexMapCache[ruleNames] = result;
    }
    return result;
};

Recognizer.prototype.getTokenType = function(tokenName) {
    var ttype = this.getTokenTypeMap()[tokenName];
    if (ttype !==undefined) {
        return ttype;
    } else {
        return Token.INVALID_TYPE;
    }
};


// What is the error header, normally line/character position information?//
Recognizer.prototype.getErrorHeader = function(e) {
    var line = e.getOffendingToken().line;
    var column = e.getOffendingToken().column;
    return "line " + line + ":" + column;
};


// How should a token be displayed in an error message? The default
//  is to display just the text, but during development you might
//  want to have a lot of information spit out.  Override in that case
//  to use t.toString() (which, for CommonToken, dumps everything about
//  the token). This is better than forcing you to override a method in
//  your token objects because you don't have to go modify your lexer
//  so that it creates a new Java type.
//
// @deprecated This method is not called by the ANTLR 4 Runtime. Specific
// implementations of {@link ANTLRErrorStrategy} may provide a similar
// feature when necessary. For example, see
// {@link DefaultErrorStrategy//getTokenErrorDisplay}.
//
Recognizer.prototype.getTokenErrorDisplay = function(t) {
    if (t===null) {
        return "<no token>";
    }
    var s = t.text;
    if (s===null) {
        if (t.type===Token.EOF) {
            s = "<EOF>";
        } else {
            s = "<" + t.type + ">";
        }
    }
    s = s.replace("\n","\\n").replace("\r","\\r").replace("\t","\\t");
    return "'" + s + "'";
};

Recognizer.prototype.getErrorListenerDispatch = function() {
    return new ProxyErrorListener(this._listeners);
};

// subclass needs to override these if there are sempreds or actions
// that the ATN interp needs to execute
Recognizer.prototype.sempred = function(localctx, ruleIndex, actionIndex) {
    return true;
};

Recognizer.prototype.precpred = function(localctx , precedence) {
    return true;
};

//Indicate that the recognizer has changed internal state that is
//consistent with the ATN state passed in.  This way we always know
//where we are in the ATN as the parser goes along. The rule
//context objects form a stack that lets us see the stack of
//invoking rules. Combine this and we have complete ATN
//configuration information.

Object.defineProperty(Recognizer.prototype, "state", {
	get : function() {
		return this._stateNumber;
	},
	set : function(state) {
		this._stateNumber = state;
	}
});


exports.Recognizer = Recognizer;

},{"./Token":39,"./error/ErrorListener":62}],38:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
///

//  A rule context is a record of a single rule invocation. It knows
//  which context invoked it, if any. If there is no parent context, then
//  naturally the invoking state is not valid.  The parent link
//  provides a chain upwards from the current rule invocation to the root
//  of the invocation tree, forming a stack. We actually carry no
//  information about the rule associated with this context (except
//  when parsing). We keep only the state number of the invoking state from
//  the ATN submachine that invoked this. Contrast this with the s
//  pointer inside ParserRuleContext that tracks the current state
//  being "executed" for the current rule.
//
//  The parent contexts are useful for computing lookahead sets and
//  getting error information.
//
//  These objects are used during parsing and prediction.
//  For the special case of parsers, we use the subclass
//  ParserRuleContext.
//
//  @see ParserRuleContext
///

var RuleNode = require('./tree/Tree').RuleNode;
var INVALID_INTERVAL = require('./tree/Tree').INVALID_INTERVAL;
var INVALID_ALT_NUMBER = require('./atn/ATN').INVALID_ALT_NUMBER;

function RuleContext(parent, invokingState) {
	RuleNode.call(this);
	// What context invoked this rule?
	this.parentCtx = parent || null;
	// What state invoked the rule associated with this context?
	// The "return address" is the followState of invokingState
	// If parent is null, this should be -1.
	this.invokingState = invokingState || -1;
	return this;
}

RuleContext.prototype = Object.create(RuleNode.prototype);
RuleContext.prototype.constructor = RuleContext;

RuleContext.prototype.depth = function() {
	var n = 0;
	var p = this;
	while (p !== null) {
		p = p.parentCtx;
		n += 1;
	}
	return n;
};

// A context is empty if there is no invoking state; meaning nobody call
// current context.
RuleContext.prototype.isEmpty = function() {
	return this.invokingState === -1;
};

// satisfy the ParseTree / SyntaxTree interface

RuleContext.prototype.getSourceInterval = function() {
	return INVALID_INTERVAL;
};

RuleContext.prototype.getRuleContext = function() {
	return this;
};

RuleContext.prototype.getPayload = function() {
	return this;
};

// Return the combined text of all child nodes. This method only considers
// tokens which have been added to the parse tree.
// <p>
// Since tokens on hidden channels (e.g. whitespace or comments) are not
// added to the parse trees, they will not appear in the output of this
// method.
// /
RuleContext.prototype.getText = function() {
	if (this.getChildCount() === 0) {
		return "";
	} else {
		return this.children.map(function(child) {
			return child.getText();
		}).join("");
	}
};

// For rule associated with this parse tree internal node, return
// the outer alternative number used to match the input. Default
// implementation does not compute nor store this alt num. Create
// a subclass of ParserRuleContext with backing field and set
// option contextSuperClass.
// to set it.
RuleContext.prototype.getAltNumber = function() { return INVALID_ALT_NUMBER; }

// Set the outer alternative number for this context node. Default
// implementation does nothing to avoid backing field overhead for
// trees that don't need it.  Create
// a subclass of ParserRuleContext with backing field and set
// option contextSuperClass.
RuleContext.prototype.setAltNumber = function(altNumber) { }

RuleContext.prototype.getChild = function(i) {
	return null;
};

RuleContext.prototype.getChildCount = function() {
	return 0;
};

RuleContext.prototype.accept = function(visitor) {
	return visitor.visitChildren(this);
};

//need to manage circular dependencies, so export now
exports.RuleContext = RuleContext;
var Trees = require('./tree/Trees').Trees;


// Print out a whole tree, not just a node, in LISP format
// (root child1 .. childN). Print just a node if this is a leaf.
//

RuleContext.prototype.toStringTree = function(ruleNames, recog) {
	return Trees.toStringTree(this, ruleNames, recog);
};

RuleContext.prototype.toString = function(ruleNames, stop) {
	ruleNames = ruleNames || null;
	stop = stop || null;
	var p = this;
	var s = "[";
	while (p !== null && p !== stop) {
		if (ruleNames === null) {
			if (!p.isEmpty()) {
				s += p.invokingState;
			}
		} else {
			var ri = p.ruleIndex;
			var ruleName = (ri >= 0 && ri < ruleNames.length) ? ruleNames[ri]
					: "" + ri;
			s += ruleName;
		}
		if (p.parentCtx !== null && (ruleNames !== null || !p.parentCtx.isEmpty())) {
			s += " ";
		}
		p = p.parentCtx;
	}
	s += "]";
	return s;
};


},{"./atn/ATN":41,"./tree/Tree":69,"./tree/Trees":70}],39:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
//

// A token has properties: text, type, line, character position in the line
// (so we can ignore tabs), token channel, index, and source from which
// we obtained this token.

function Token() {
	this.source = null;
	this.type = null; // token type of the token
	this.channel = null; // The parser ignores everything not on DEFAULT_CHANNEL
	this.start = null; // optional; return -1 if not implemented.
	this.stop = null; // optional; return -1 if not implemented.
	this.tokenIndex = null; // from 0..n-1 of the token object in the input stream
	this.line = null; // line=1..n of the 1st character
	this.column = null; // beginning of the line at which it occurs, 0..n-1
	this._text = null; // text of the token.
	return this;
}

Token.INVALID_TYPE = 0;

// During lookahead operations, this "token" signifies we hit rule end ATN state
// and did not follow it despite needing to.
Token.EPSILON = -2;

Token.MIN_USER_TOKEN_TYPE = 1;

Token.EOF = -1;

// All tokens go to the parser (unless skip() is called in that rule)
// on a particular "channel". The parser tunes to a particular channel
// so that whitespace etc... can go to the parser on a "hidden" channel.

Token.DEFAULT_CHANNEL = 0;

// Anything on different channel than DEFAULT_CHANNEL is not parsed
// by parser.

Token.HIDDEN_CHANNEL = 1;

// Explicitly set the text for this token. If {code text} is not
// {@code null}, then {@link //getText} will return this value rather than
// extracting the text from the input.
//
// @param text The explicit text of the token, or {@code null} if the text
// should be obtained from the input along with the start and stop indexes
// of the token.

Object.defineProperty(Token.prototype, "text", {
	get : function() {
		return this._text;
	},
	set : function(text) {
		this._text = text;
	}
});

Token.prototype.getTokenSource = function() {
	return this.source[0];
};

Token.prototype.getInputStream = function() {
	return this.source[1];
};

function CommonToken(source, type, channel, start, stop) {
	Token.call(this);
	this.source = source !== undefined ? source : CommonToken.EMPTY_SOURCE;
	this.type = type !== undefined ? type : null;
	this.channel = channel !== undefined ? channel : Token.DEFAULT_CHANNEL;
	this.start = start !== undefined ? start : -1;
	this.stop = stop !== undefined ? stop : -1;
	this.tokenIndex = -1;
	if (this.source[0] !== null) {
		this.line = source[0].line;
		this.column = source[0].column;
	} else {
		this.column = -1;
	}
	return this;
}

CommonToken.prototype = Object.create(Token.prototype);
CommonToken.prototype.constructor = CommonToken;

// An empty {@link Pair} which is used as the default value of
// {@link //source} for tokens that do not have a source.
CommonToken.EMPTY_SOURCE = [ null, null ];

// Constructs a new {@link CommonToken} as a copy of another {@link Token}.
//
// <p>
// If {@code oldToken} is also a {@link CommonToken} instance, the newly
// constructed token will share a reference to the {@link //text} field and
// the {@link Pair} stored in {@link //source}. Otherwise, {@link //text} will
// be assigned the result of calling {@link //getText}, and {@link //source}
// will be constructed from the result of {@link Token//getTokenSource} and
// {@link Token//getInputStream}.</p>
//
// @param oldToken The token to copy.
//
CommonToken.prototype.clone = function() {
	var t = new CommonToken(this.source, this.type, this.channel, this.start,
			this.stop);
	t.tokenIndex = this.tokenIndex;
	t.line = this.line;
	t.column = this.column;
	t.text = this.text;
	return t;
};

Object.defineProperty(CommonToken.prototype, "text", {
	get : function() {
		if (this._text !== null) {
			return this._text;
		}
		var input = this.getInputStream();
		if (input === null) {
			return null;
		}
		var n = input.size;
		if (this.start < n && this.stop < n) {
			return input.getText(this.start, this.stop);
		} else {
			return "<EOF>";
		}
	},
	set : function(text) {
		this._text = text;
	}
});

CommonToken.prototype.toString = function() {
	var txt = this.text;
	if (txt !== null) {
		txt = txt.replace(/\n/g, "\\n").replace(/\r/g, "\\r").replace(/\t/g, "\\t");
	} else {
		txt = "<no text>";
	}
	return "[@" + this.tokenIndex + "," + this.start + ":" + this.stop + "='" +
			txt + "',<" + this.type + ">" +
			(this.channel > 0 ? ",channel=" + this.channel : "") + "," +
			this.line + ":" + this.column + "]";
};

exports.Token = Token;
exports.CommonToken = CommonToken;

},{}],40:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

function arrayToString(a) {
    return "[" + a.join(", ") + "]";
}

String.prototype.seed = String.prototype.seed || Math.round(Math.random() * Math.pow(2, 32));

String.prototype.hashCode = function () {
    var remainder, bytes, h1, h1b, c1, c1b, c2, c2b, k1, i,
        key = this.toString();

    remainder = key.length & 3; // key.length % 4
    bytes = key.length - remainder;
    h1 = String.prototype.seed;
    c1 = 0xcc9e2d51;
    c2 = 0x1b873593;
    i = 0;

    while (i < bytes) {
        k1 =
            ((key.charCodeAt(i) & 0xff)) |
            ((key.charCodeAt(++i) & 0xff) << 8) |
            ((key.charCodeAt(++i) & 0xff) << 16) |
            ((key.charCodeAt(++i) & 0xff) << 24);
        ++i;

        k1 = ((((k1 & 0xffff) * c1) + ((((k1 >>> 16) * c1) & 0xffff) << 16))) & 0xffffffff;
        k1 = (k1 << 15) | (k1 >>> 17);
        k1 = ((((k1 & 0xffff) * c2) + ((((k1 >>> 16) * c2) & 0xffff) << 16))) & 0xffffffff;

        h1 ^= k1;
        h1 = (h1 << 13) | (h1 >>> 19);
        h1b = ((((h1 & 0xffff) * 5) + ((((h1 >>> 16) * 5) & 0xffff) << 16))) & 0xffffffff;
        h1 = (((h1b & 0xffff) + 0x6b64) + ((((h1b >>> 16) + 0xe654) & 0xffff) << 16));
    }

    k1 = 0;

    switch (remainder) {
        case 3:
            k1 ^= (key.charCodeAt(i + 2) & 0xff) << 16;
        case 2:
            k1 ^= (key.charCodeAt(i + 1) & 0xff) << 8;
        case 1:
            k1 ^= (key.charCodeAt(i) & 0xff);

            k1 = (((k1 & 0xffff) * c1) + ((((k1 >>> 16) * c1) & 0xffff) << 16)) & 0xffffffff;
            k1 = (k1 << 15) | (k1 >>> 17);
            k1 = (((k1 & 0xffff) * c2) + ((((k1 >>> 16) * c2) & 0xffff) << 16)) & 0xffffffff;
            h1 ^= k1;
    }

    h1 ^= key.length;

    h1 ^= h1 >>> 16;
    h1 = (((h1 & 0xffff) * 0x85ebca6b) + ((((h1 >>> 16) * 0x85ebca6b) & 0xffff) << 16)) & 0xffffffff;
    h1 ^= h1 >>> 13;
    h1 = ((((h1 & 0xffff) * 0xc2b2ae35) + ((((h1 >>> 16) * 0xc2b2ae35) & 0xffff) << 16))) & 0xffffffff;
    h1 ^= h1 >>> 16;

    return h1 >>> 0;
};

function standardEqualsFunction(a, b) {
    return a.equals(b);
}

function standardHashCodeFunction(a) {
    return a.hashCode();
}

function Set(hashFunction, equalsFunction) {
    this.data = {};
    this.hashFunction = hashFunction || standardHashCodeFunction;
    this.equalsFunction = equalsFunction || standardEqualsFunction;
    return this;
}

Object.defineProperty(Set.prototype, "length", {
    get: function () {
        var l = 0;
        for (var key in this.data) {
            if (key.indexOf("hash_") === 0) {
                l = l + this.data[key].length;
            }
        }
        return l;
    }
});

Set.prototype.add = function (value) {
    var hash = this.hashFunction(value);
    var key = "hash_" + hash;
    if (key in this.data) {
        var values = this.data[key];
        for (var i = 0; i < values.length; i++) {
            if (this.equalsFunction(value, values[i])) {
                return values[i];
            }
        }
        values.push(value);
        return value;
    } else {
        this.data[key] = [value];
        return value;
    }
};

Set.prototype.contains = function (value) {
    return this.get(value) != null;
};

Set.prototype.get = function (value) {
    var hash = this.hashFunction(value);
    var key = "hash_" + hash;
    if (key in this.data) {
        var values = this.data[key];
        for (var i = 0; i < values.length; i++) {
            if (this.equalsFunction(value, values[i])) {
                return values[i];
            }
        }
    }
    return null;
};

Set.prototype.values = function () {
    var l = [];
    for (var key in this.data) {
        if (key.indexOf("hash_") === 0) {
            l = l.concat(this.data[key]);
        }
    }
    return l;
};

Set.prototype.toString = function () {
    return arrayToString(this.values());
};

function BitSet() {
    this.data = [];
    return this;
}

BitSet.prototype.add = function (value) {
    this.data[value] = true;
};

BitSet.prototype.or = function (set) {
    var bits = this;
    Object.keys(set.data).map(function (alt) {
        bits.add(alt);
    });
};

BitSet.prototype.remove = function (value) {
    delete this.data[value];
};

BitSet.prototype.contains = function (value) {
    return this.data[value] === true;
};

BitSet.prototype.values = function () {
    return Object.keys(this.data);
};

BitSet.prototype.minValue = function () {
    return Math.min.apply(null, this.values());
};

BitSet.prototype.hashCode = function () {
    var hash = new Hash();
    hash.update(this.values());
    return hash.finish();
};

BitSet.prototype.equals = function (other) {
    if (!(other instanceof BitSet)) {
        return false;
    }
    return this.hashCode() === other.hashCode();
};

Object.defineProperty(BitSet.prototype, "length", {
    get: function () {
        return this.values().length;
    }
});

BitSet.prototype.toString = function () {
    return "{" + this.values().join(", ") + "}";
};

function Map(hashFunction, equalsFunction) {
    this.data = {};
    this.hashFunction = hashFunction || standardHashCodeFunction;
    this.equalsFunction = equalsFunction || standardEqualsFunction;
    return this;
}

Object.defineProperty(Map.prototype, "length", {
    get: function () {
        var l = 0;
        for (var hashKey in this.data) {
            if (hashKey.indexOf("hash_") === 0) {
                l = l + this.data[hashKey].length;
            }
        }
        return l;
    }
});

Map.prototype.put = function (key, value) {
    var hashKey = "hash_" + this.hashFunction(key);
    if (hashKey in this.data) {
        var entries = this.data[hashKey];
        for (var i = 0; i < entries.length; i++) {
            var entry = entries[i];
            if (this.equalsFunction(key, entry.key)) {
                var oldValue = entry.value;
                entry.value = value;
                return oldValue;
            }
        }
        entries.push({key:key, value:value});
        return value;
    } else {
        this.data[hashKey] = [{key:key, value:value}];
        return value;
    }
};

Map.prototype.containsKey = function (key) {
    var hashKey = "hash_" + this.hashFunction(key);
    if(hashKey in this.data) {
        var entries = this.data[hashKey];
        for (var i = 0; i < entries.length; i++) {
            var entry = entries[i];
            if (this.equalsFunction(key, entry.key))
                return true;
        }
    }
    return false;
};

Map.prototype.get = function (key) {
    var hashKey = "hash_" + this.hashFunction(key);
    if(hashKey in this.data) {
        var entries = this.data[hashKey];
        for (var i = 0; i < entries.length; i++) {
            var entry = entries[i];
            if (this.equalsFunction(key, entry.key))
                return entry.value;
        }
    }
    return null;
};

Map.prototype.entries = function () {
    var l = [];
    for (var key in this.data) {
        if (key.indexOf("hash_") === 0) {
            l = l.concat(this.data[key]);
        }
    }
    return l;
};


Map.prototype.getKeys = function () {
    return this.entries().map(function(e) {
        return e.key;
    });
};


Map.prototype.getValues = function () {
    return this.entries().map(function(e) {
            return e.value;
    });
};


Map.prototype.toString = function () {
    var ss = this.entries().map(function(entry) {
        return '{' + entry.key + ':' + entry.value + '}';
    });
    return '[' + ss.join(", ") + ']';
};


function AltDict() {
    this.data = {};
    return this;
}


AltDict.prototype.get = function (key) {
    key = "k-" + key;
    if (key in this.data) {
        return this.data[key];
    } else {
        return null;
    }
};

AltDict.prototype.put = function (key, value) {
    key = "k-" + key;
    this.data[key] = value;
};

AltDict.prototype.values = function () {
    var data = this.data;
    var keys = Object.keys(this.data);
    return keys.map(function (key) {
        return data[key];
    });
};

function DoubleDict(defaultMapCtor) {
    this.defaultMapCtor = defaultMapCtor || Map;
    this.cacheMap = new this.defaultMapCtor();
    return this;
}

function Hash() {
    this.count = 0;
    this.hash = 0;
    return this;
}

Hash.prototype.update = function () {
    for(var i=0;i<arguments.length;i++) {
        var value = arguments[i];
        if (value == null)
            continue;
        if(Array.isArray(value))
            this.update.apply(this, value);
        else {
            var k = 0;
            switch (typeof(value)) {
                case 'undefined':
                case 'function':
                    continue;
                case 'number':
                case 'boolean':
                    k = value;
                    break;
                case 'string':
                    k = value.hashCode();
                    break;
                default:
                    if(value.updateHashCode)
                        value.updateHashCode(this);
                    else
                        console.log("No updateHashCode for " + value.toString())
                    continue;
            }
            k = k * 0xCC9E2D51;
            k = (k << 15) | (k >>> (32 - 15));
            k = k * 0x1B873593;
            this.count = this.count + 1;
            var hash = this.hash ^ k;
            hash = (hash << 13) | (hash >>> (32 - 13));
            hash = hash * 5 + 0xE6546B64;
            this.hash = hash;
        }
    }
};

Hash.prototype.finish = function () {
    var hash = this.hash ^ (this.count * 4);
    hash = hash ^ (hash >>> 16);
    hash = hash * 0x85EBCA6B;
    hash = hash ^ (hash >>> 13);
    hash = hash * 0xC2B2AE35;
    hash = hash ^ (hash >>> 16);
    return hash;
};

function hashStuff() {
    var hash = new Hash();
    hash.update.apply(hash, arguments);
    return hash.finish();
}

DoubleDict.prototype.get = function (a, b) {
    var d = this.cacheMap.get(a) || null;
    return d === null ? null : (d.get(b) || null);
};

DoubleDict.prototype.set = function (a, b, o) {
    var d = this.cacheMap.get(a) || null;
    if (d === null) {
        d = new this.defaultMapCtor();
        this.cacheMap.put(a, d);
    }
    d.put(b, o);
};


function escapeWhitespace(s, escapeSpaces) {
    s = s.replace(/\t/g, "\\t")
         .replace(/\n/g, "\\n")
         .replace(/\r/g, "\\r");
    if (escapeSpaces) {
        s = s.replace(/ /g, "\u00B7");
    }
    return s;
}

function titleCase(str) {
    return str.replace(/\w\S*/g, function (txt) {
        return txt.charAt(0).toUpperCase() + txt.substr(1);
    });
};

function equalArrays(a, b)
{
    if (!Array.isArray(a) || !Array.isArray(b))
        return false;
    if (a == b)
        return true;
    if (a.length != b.length)
        return false;
    for (var i = 0; i < a.length; i++) {
        if (a[i] == b[i])
            continue;
        if (!a[i].equals(b[i]))
            return false;
    }
    return true;
};

exports.Hash = Hash;
exports.Set = Set;
exports.Map = Map;
exports.BitSet = BitSet;
exports.AltDict = AltDict;
exports.DoubleDict = DoubleDict;
exports.hashStuff = hashStuff;
exports.escapeWhitespace = escapeWhitespace;
exports.arrayToString = arrayToString;
exports.titleCase = titleCase;
exports.equalArrays = equalArrays;

},{}],41:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

var LL1Analyzer = require('./../LL1Analyzer').LL1Analyzer;
var IntervalSet = require('./../IntervalSet').IntervalSet;

function ATN(grammarType , maxTokenType) {

    // Used for runtime deserialization of ATNs from strings///
    // The type of the ATN.
    this.grammarType = grammarType;
    // The maximum value for any symbol recognized by a transition in the ATN.
    this.maxTokenType = maxTokenType;
    this.states = [];
    // Each subrule/rule is a decision point and we must track them so we
    //  can go back later and build DFA predictors for them.  This includes
    //  all the rules, subrules, optional blocks, ()+, ()* etc...
    this.decisionToState = [];
    // Maps from rule index to starting state number.
    this.ruleToStartState = [];
    // Maps from rule index to stop state number.
    this.ruleToStopState = null;
    this.modeNameToStartState = {};
    // For lexer ATNs, this maps the rule index to the resulting token type.
    // For parser ATNs, this maps the rule index to the generated bypass token
    // type if the
    // {@link ATNDeserializationOptions//isGenerateRuleBypassTransitions}
    // deserialization option was specified; otherwise, this is {@code null}.
    this.ruleToTokenType = null;
    // For lexer ATNs, this is an array of {@link LexerAction} objects which may
    // be referenced by action transitions in the ATN.
    this.lexerActions = null;
    this.modeToStartState = [];

    return this;
}

// Compute the set of valid tokens that can occur starting in state {@code s}.
//  If {@code ctx} is null, the set of tokens will not include what can follow
//  the rule surrounding {@code s}. In other words, the set will be
//  restricted to tokens reachable staying within {@code s}'s rule.
ATN.prototype.nextTokensInContext = function(s, ctx) {
    var anal = new LL1Analyzer(this);
    return anal.LOOK(s, null, ctx);
};

// Compute the set of valid tokens that can occur starting in {@code s} and
// staying in same rule. {@link Token//EPSILON} is in set if we reach end of
// rule.
ATN.prototype.nextTokensNoContext = function(s) {
    if (s.nextTokenWithinRule !== null ) {
        return s.nextTokenWithinRule;
    }
    s.nextTokenWithinRule = this.nextTokensInContext(s, null);
    s.nextTokenWithinRule.readOnly = true;
    return s.nextTokenWithinRule;
};

ATN.prototype.nextTokens = function(s, ctx) {
    if ( ctx===undefined ) {
        return this.nextTokensNoContext(s);
    } else {
        return this.nextTokensInContext(s, ctx);
    }
};

ATN.prototype.addState = function( state) {
    if ( state !== null ) {
        state.atn = this;
        state.stateNumber = this.states.length;
    }
    this.states.push(state);
};

ATN.prototype.removeState = function( state) {
    this.states[state.stateNumber] = null; // just free mem, don't shift states in list
};

ATN.prototype.defineDecisionState = function( s) {
    this.decisionToState.push(s);
    s.decision = this.decisionToState.length-1;
    return s.decision;
};

ATN.prototype.getDecisionState = function( decision) {
    if (this.decisionToState.length===0) {
        return null;
    } else {
        return this.decisionToState[decision];
    }
};

// Computes the set of input symbols which could follow ATN state number
// {@code stateNumber} in the specified full {@code context}. This method
// considers the complete parser context, but does not evaluate semantic
// predicates (i.e. all predicates encountered during the calculation are
// assumed true). If a path in the ATN exists from the starting state to the
// {@link RuleStopState} of the outermost context without matching any
// symbols, {@link Token//EOF} is added to the returned set.
//
// <p>If {@code context} is {@code null}, it is treated as
// {@link ParserRuleContext//EMPTY}.</p>
//
// @param stateNumber the ATN state number
// @param context the full parse context
// @return The set of potentially valid input symbols which could follow the
// specified state in the specified context.
// @throws IllegalArgumentException if the ATN does not contain a state with
// number {@code stateNumber}
var Token = require('./../Token').Token;

ATN.prototype.getExpectedTokens = function( stateNumber, ctx ) {
    if ( stateNumber < 0 || stateNumber >= this.states.length ) {
        throw("Invalid state number.");
    }
    var s = this.states[stateNumber];
    var following = this.nextTokens(s);
    if (!following.contains(Token.EPSILON)) {
        return following;
    }
    var expected = new IntervalSet();
    expected.addSet(following);
    expected.removeOne(Token.EPSILON);
    while (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {
        var invokingState = this.states[ctx.invokingState];
        var rt = invokingState.transitions[0];
        following = this.nextTokens(rt.followState);
        expected.addSet(following);
        expected.removeOne(Token.EPSILON);
        ctx = ctx.parentCtx;
    }
    if (following.contains(Token.EPSILON)) {
        expected.addOne(Token.EOF);
    }
    return expected;
};

ATN.INVALID_ALT_NUMBER = 0;

exports.ATN = ATN;
},{"./../IntervalSet":31,"./../LL1Analyzer":32,"./../Token":39}],42:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
///

// A tuple: (ATN state, predicted alt, syntactic, semantic context).
//  The syntactic context is a graph-structured stack node whose
//  path(s) to the root is the rule invocation(s)
//  chain used to arrive at the state.  The semantic context is
//  the tree of semantic predicates encountered before reaching
//  an ATN state.
///

var DecisionState = require('./ATNState').DecisionState;
var SemanticContext = require('./SemanticContext').SemanticContext;
var Hash = require("../Utils").Hash;


function checkParams(params, isCfg) {
	if(params===null) {
		var result = { state:null, alt:null, context:null, semanticContext:null };
		if(isCfg) {
			result.reachesIntoOuterContext = 0;
		}
		return result;
	} else {
		var props = {};
		props.state = params.state || null;
		props.alt = (params.alt === undefined) ? null : params.alt;
		props.context = params.context || null;
		props.semanticContext = params.semanticContext || null;
		if(isCfg) {
			props.reachesIntoOuterContext = params.reachesIntoOuterContext || 0;
			props.precedenceFilterSuppressed = params.precedenceFilterSuppressed || false;
		}
		return props;
	}
}

function ATNConfig(params, config) {
	this.checkContext(params, config);
	params = checkParams(params);
	config = checkParams(config, true);
    // The ATN state associated with this configuration///
    this.state = params.state!==null ? params.state : config.state;
    // What alt (or lexer rule) is predicted by this configuration///
    this.alt = params.alt!==null ? params.alt : config.alt;
    // The stack of invoking states leading to the rule/states associated
    //  with this config.  We track only those contexts pushed during
    //  execution of the ATN simulator.
    this.context = params.context!==null ? params.context : config.context;
    this.semanticContext = params.semanticContext!==null ? params.semanticContext :
        (config.semanticContext!==null ? config.semanticContext : SemanticContext.NONE);
    // We cannot execute predicates dependent upon local context unless
    // we know for sure we are in the correct context. Because there is
    // no way to do this efficiently, we simply cannot evaluate
    // dependent predicates unless we are in the rule that initially
    // invokes the ATN simulator.
    //
    // closure() tracks the depth of how far we dip into the
    // outer context: depth &gt; 0.  Note that it may not be totally
    // accurate depth since I don't ever decrement. TODO: make it a boolean then
    this.reachesIntoOuterContext = config.reachesIntoOuterContext;
    this.precedenceFilterSuppressed = config.precedenceFilterSuppressed;
    return this;
}

ATNConfig.prototype.checkContext = function(params, config) {
	if((params.context===null || params.context===undefined) &&
			(config===null || config.context===null || config.context===undefined)) {
		this.context = null;
	}
};


ATNConfig.prototype.hashCode = function() {
    var hash = new Hash();
    this.updateHashCode(hash);
    return hash.finish();
};


ATNConfig.prototype.updateHashCode = function(hash) {
    hash.update(this.state.stateNumber, this.alt, this.context, this.semanticContext);
};

// An ATN configuration is equal to another if both have
//  the same state, they predict the same alternative, and
//  syntactic/semantic contexts are the same.

ATNConfig.prototype.equals = function(other) {
    if (this === other) {
        return true;
    } else if (! (other instanceof ATNConfig)) {
        return false;
    } else {
        return this.state.stateNumber===other.state.stateNumber &&
            this.alt===other.alt &&
            (this.context===null ? other.context===null : this.context.equals(other.context)) &&
            this.semanticContext.equals(other.semanticContext) &&
            this.precedenceFilterSuppressed===other.precedenceFilterSuppressed;
    }
};


ATNConfig.prototype.hashCodeForConfigSet = function() {
    var hash = new Hash();
    hash.update(this.state.stateNumber, this.alt, this.semanticContext);
    return hash.finish();
};


ATNConfig.prototype.equalsForConfigSet = function(other) {
    if (this === other) {
        return true;
    } else if (! (other instanceof ATNConfig)) {
        return false;
    } else {
        return this.state.stateNumber===other.state.stateNumber &&
            this.alt===other.alt &&
            this.semanticContext.equals(other.semanticContext);
    }
};


ATNConfig.prototype.toString = function() {
    return "(" + this.state + "," + this.alt +
        (this.context!==null ? ",[" + this.context.toString() + "]" : "") +
        (this.semanticContext !== SemanticContext.NONE ?
                ("," + this.semanticContext.toString())
                : "") +
        (this.reachesIntoOuterContext>0 ?
                (",up=" + this.reachesIntoOuterContext)
                : "") + ")";
};


function LexerATNConfig(params, config) {
	ATNConfig.call(this, params, config);

    // This is the backing field for {@link //getLexerActionExecutor}.
	var lexerActionExecutor = params.lexerActionExecutor || null;
    this.lexerActionExecutor = lexerActionExecutor || (config!==null ? config.lexerActionExecutor : null);
    this.passedThroughNonGreedyDecision = config!==null ? this.checkNonGreedyDecision(config, this.state) : false;
    return this;
}

LexerATNConfig.prototype = Object.create(ATNConfig.prototype);
LexerATNConfig.prototype.constructor = LexerATNConfig;

LexerATNConfig.prototype.updateHashCode = function(hash) {
    hash.update(this.state.stateNumber, this.alt, this.context, this.semanticContext, this.passedThroughNonGreedyDecision, this.lexerActionExecutor);
};

LexerATNConfig.prototype.equals = function(other) {
    return this === other ||
            (other instanceof LexerATNConfig &&
            this.passedThroughNonGreedyDecision == other.passedThroughNonGreedyDecision &&
            (this.lexerActionExecutor ? this.lexerActionExecutor.equals(other.lexerActionExecutor) : !other.lexerActionExecutor) &&
            ATNConfig.prototype.equals.call(this, other));
};

LexerATNConfig.prototype.hashCodeForConfigSet = LexerATNConfig.prototype.hashCode;

LexerATNConfig.prototype.equalsForConfigSet = LexerATNConfig.prototype.equals;


LexerATNConfig.prototype.checkNonGreedyDecision = function(source, target) {
    return source.passedThroughNonGreedyDecision ||
        (target instanceof DecisionState) && target.nonGreedy;
};

exports.ATNConfig = ATNConfig;
exports.LexerATNConfig = LexerATNConfig;
},{"../Utils":40,"./ATNState":47,"./SemanticContext":54}],43:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

//
// Specialized {@link Set}{@code <}{@link ATNConfig}{@code >} that can track
// info about the set, with support for combining similar configurations using a
// graph-structured stack.
///

var ATN = require('./ATN').ATN;
var Utils = require('./../Utils');
var Hash = Utils.Hash;
var Set = Utils.Set;
var SemanticContext = require('./SemanticContext').SemanticContext;
var merge = require('./../PredictionContext').merge;

function hashATNConfig(c) {
	return c.hashCodeForConfigSet();
}

function equalATNConfigs(a, b) {
	if ( a===b ) {
		return true;
	} else if ( a===null || b===null ) {
		return false;
	} else
       return a.equalsForConfigSet(b);
 }


function ATNConfigSet(fullCtx) {
	//
	// The reason that we need this is because we don't want the hash map to use
	// the standard hash code and equals. We need all configurations with the
	// same
	// {@code (s,i,_,semctx)} to be equal. Unfortunately, this key effectively
	// doubles
	// the number of objects associated with ATNConfigs. The other solution is
	// to
	// use a hash table that lets us specify the equals/hashcode operation.
	// All configs but hashed by (s, i, _, pi) not including context. Wiped out
	// when we go readonly as this set becomes a DFA state.
	this.configLookup = new Set(hashATNConfig, equalATNConfigs);
	// Indicates that this configuration set is part of a full context
	// LL prediction. It will be used to determine how to merge $. With SLL
	// it's a wildcard whereas it is not for LL context merge.
	this.fullCtx = fullCtx === undefined ? true : fullCtx;
	// Indicates that the set of configurations is read-only. Do not
	// allow any code to manipulate the set; DFA states will point at
	// the sets and they must not change. This does not protect the other
	// fields; in particular, conflictingAlts is set after
	// we've made this readonly.
	this.readOnly = false;
	// Track the elements as they are added to the set; supports get(i)///
	this.configs = [];

	// TODO: these fields make me pretty uncomfortable but nice to pack up info
	// together, saves recomputation
	// TODO: can we track conflicts as they are added to save scanning configs
	// later?
	this.uniqueAlt = 0;
	this.conflictingAlts = null;

	// Used in parser and lexer. In lexer, it indicates we hit a pred
	// while computing a closure operation. Don't make a DFA state from this.
	this.hasSemanticContext = false;
	this.dipsIntoOuterContext = false;

	this.cachedHashCode = -1;

	return this;
}

// Adding a new config means merging contexts with existing configs for
// {@code (s, i, pi, _)}, where {@code s} is the
// {@link ATNConfig//state}, {@code i} is the {@link ATNConfig//alt}, and
// {@code pi} is the {@link ATNConfig//semanticContext}. We use
// {@code (s,i,pi)} as key.
//
// <p>This method updates {@link //dipsIntoOuterContext} and
// {@link //hasSemanticContext} when necessary.</p>
// /
ATNConfigSet.prototype.add = function(config, mergeCache) {
	if (mergeCache === undefined) {
		mergeCache = null;
	}
	if (this.readOnly) {
		throw "This set is readonly";
	}
	if (config.semanticContext !== SemanticContext.NONE) {
		this.hasSemanticContext = true;
	}
	if (config.reachesIntoOuterContext > 0) {
		this.dipsIntoOuterContext = true;
	}
	var existing = this.configLookup.add(config);
	if (existing === config) {
		this.cachedHashCode = -1;
		this.configs.push(config); // track order here
		return true;
	}
	// a previous (s,i,pi,_), merge with it and save result
	var rootIsWildcard = !this.fullCtx;
	var merged = merge(existing.context, config.context, rootIsWildcard, mergeCache);
	// no need to check for existing.context, config.context in cache
	// since only way to create new graphs is "call rule" and here. We
	// cache at both places.
	existing.reachesIntoOuterContext = Math.max( existing.reachesIntoOuterContext, config.reachesIntoOuterContext);
	// make sure to preserve the precedence filter suppression during the merge
	if (config.precedenceFilterSuppressed) {
		existing.precedenceFilterSuppressed = true;
	}
	existing.context = merged; // replace context; no need to alt mapping
	return true;
};

ATNConfigSet.prototype.getStates = function() {
	var states = new Set();
	for (var i = 0; i < this.configs.length; i++) {
		states.add(this.configs[i].state);
	}
	return states;
};

ATNConfigSet.prototype.getPredicates = function() {
	var preds = [];
	for (var i = 0; i < this.configs.length; i++) {
		var c = this.configs[i].semanticContext;
		if (c !== SemanticContext.NONE) {
			preds.push(c.semanticContext);
		}
	}
	return preds;
};

Object.defineProperty(ATNConfigSet.prototype, "items", {
	get : function() {
		return this.configs;
	}
});

ATNConfigSet.prototype.optimizeConfigs = function(interpreter) {
	if (this.readOnly) {
		throw "This set is readonly";
	}
	if (this.configLookup.length === 0) {
		return;
	}
	for (var i = 0; i < this.configs.length; i++) {
		var config = this.configs[i];
		config.context = interpreter.getCachedContext(config.context);
	}
};

ATNConfigSet.prototype.addAll = function(coll) {
	for (var i = 0; i < coll.length; i++) {
		this.add(coll[i]);
	}
	return false;
};

ATNConfigSet.prototype.equals = function(other) {
	return this === other ||
		(other instanceof ATNConfigSet &&
		Utils.equalArrays(this.configs, other.configs) &&
		this.fullCtx === other.fullCtx &&
		this.uniqueAlt === other.uniqueAlt &&
		this.conflictingAlts === other.conflictingAlts &&
		this.hasSemanticContext === other.hasSemanticContext &&
		this.dipsIntoOuterContext === other.dipsIntoOuterContext);
};

ATNConfigSet.prototype.hashCode = function() {
    var hash = new Hash();
	hash.update(this.configs);
    return hash.finish();
};


ATNConfigSet.prototype.updateHashCode = function(hash) {
	if (this.readOnly) {
		if (this.cachedHashCode === -1) {
            this.cachedHashCode = this.hashCode();
		}
        hash.update(this.cachedHashCode);
	} else {
        hash.update(this.hashCode());
	}
};


Object.defineProperty(ATNConfigSet.prototype, "length", {
	get : function() {
		return this.configs.length;
	}
});

ATNConfigSet.prototype.isEmpty = function() {
	return this.configs.length === 0;
};

ATNConfigSet.prototype.contains = function(item) {
	if (this.configLookup === null) {
		throw "This method is not implemented for readonly sets.";
	}
	return this.configLookup.contains(item);
};

ATNConfigSet.prototype.containsFast = function(item) {
	if (this.configLookup === null) {
		throw "This method is not implemented for readonly sets.";
	}
	return this.configLookup.containsFast(item);
};

ATNConfigSet.prototype.clear = function() {
	if (this.readOnly) {
		throw "This set is readonly";
	}
	this.configs = [];
	this.cachedHashCode = -1;
	this.configLookup = new Set();
};

ATNConfigSet.prototype.setReadonly = function(readOnly) {
	this.readOnly = readOnly;
	if (readOnly) {
		this.configLookup = null; // can't mod, no need for lookup cache
	}
};

ATNConfigSet.prototype.toString = function() {
	return Utils.arrayToString(this.configs) +
		(this.hasSemanticContext ? ",hasSemanticContext=" + this.hasSemanticContext : "") +
		(this.uniqueAlt !== ATN.INVALID_ALT_NUMBER ? ",uniqueAlt=" + this.uniqueAlt : "") +
		(this.conflictingAlts !== null ? ",conflictingAlts=" + this.conflictingAlts : "") +
		(this.dipsIntoOuterContext ? ",dipsIntoOuterContext" : "");
};

function OrderedATNConfigSet() {
	ATNConfigSet.call(this);
	this.configLookup = new Set();
	return this;
}

OrderedATNConfigSet.prototype = Object.create(ATNConfigSet.prototype);
OrderedATNConfigSet.prototype.constructor = OrderedATNConfigSet;

exports.ATNConfigSet = ATNConfigSet;
exports.OrderedATNConfigSet = OrderedATNConfigSet;

},{"./../PredictionContext":36,"./../Utils":40,"./ATN":41,"./SemanticContext":54}],44:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

function ATNDeserializationOptions(copyFrom) {
	if(copyFrom===undefined) {
		copyFrom = null;
	}
	this.readOnly = false;
    this.verifyATN = copyFrom===null ? true : copyFrom.verifyATN;
    this.generateRuleBypassTransitions = copyFrom===null ? false : copyFrom.generateRuleBypassTransitions;

    return this;
}

ATNDeserializationOptions.defaultOptions = new ATNDeserializationOptions();
ATNDeserializationOptions.defaultOptions.readOnly = true;

//    def __setattr__(self, key, value):
//        if key!="readOnly" and self.readOnly:
//            raise Exception("The object is read only.")
//        super(type(self), self).__setattr__(key,value)

exports.ATNDeserializationOptions = ATNDeserializationOptions;

},{}],45:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

var Token = require('./../Token').Token;
var ATN = require('./ATN').ATN;
var ATNType = require('./ATNType').ATNType;
var ATNStates = require('./ATNState');
var ATNState = ATNStates.ATNState;
var BasicState = ATNStates.BasicState;
var DecisionState = ATNStates.DecisionState;
var BlockStartState = ATNStates.BlockStartState;
var BlockEndState = ATNStates.BlockEndState;
var LoopEndState = ATNStates.LoopEndState;
var RuleStartState = ATNStates.RuleStartState;
var RuleStopState = ATNStates.RuleStopState;
var TokensStartState = ATNStates.TokensStartState;
var PlusLoopbackState = ATNStates.PlusLoopbackState;
var StarLoopbackState = ATNStates.StarLoopbackState;
var StarLoopEntryState = ATNStates.StarLoopEntryState;
var PlusBlockStartState = ATNStates.PlusBlockStartState;
var StarBlockStartState = ATNStates.StarBlockStartState;
var BasicBlockStartState = ATNStates.BasicBlockStartState;
var Transitions = require('./Transition');
var Transition = Transitions.Transition;
var AtomTransition = Transitions.AtomTransition;
var SetTransition = Transitions.SetTransition;
var NotSetTransition = Transitions.NotSetTransition;
var RuleTransition = Transitions.RuleTransition;
var RangeTransition = Transitions.RangeTransition;
var ActionTransition = Transitions.ActionTransition;
var EpsilonTransition = Transitions.EpsilonTransition;
var WildcardTransition = Transitions.WildcardTransition;
var PredicateTransition = Transitions.PredicateTransition;
var PrecedencePredicateTransition = Transitions.PrecedencePredicateTransition;
var IntervalSet = require('./../IntervalSet').IntervalSet;
var Interval = require('./../IntervalSet').Interval;
var ATNDeserializationOptions = require('./ATNDeserializationOptions').ATNDeserializationOptions;
var LexerActions = require('./LexerAction');
var LexerActionType = LexerActions.LexerActionType;
var LexerSkipAction = LexerActions.LexerSkipAction;
var LexerChannelAction = LexerActions.LexerChannelAction;
var LexerCustomAction = LexerActions.LexerCustomAction;
var LexerMoreAction = LexerActions.LexerMoreAction;
var LexerTypeAction = LexerActions.LexerTypeAction;
var LexerPushModeAction = LexerActions.LexerPushModeAction;
var LexerPopModeAction = LexerActions.LexerPopModeAction;
var LexerModeAction = LexerActions.LexerModeAction;
// This is the earliest supported serialized UUID.
// stick to serialized version for now, we don't need a UUID instance
var BASE_SERIALIZED_UUID = "AADB8D7E-AEEF-4415-AD2B-8204D6CF042E";

//
// This UUID indicates the serialized ATN contains two sets of
// IntervalSets, where the second set's values are encoded as
// 32-bit integers to support the full Unicode SMP range up to U+10FFFF.
//
var ADDED_UNICODE_SMP = "59627784-3BE5-417A-B9EB-8131A7286089";

// This list contains all of the currently supported UUIDs, ordered by when
// the feature first appeared in this branch.
var SUPPORTED_UUIDS = [ BASE_SERIALIZED_UUID, ADDED_UNICODE_SMP ];

var SERIALIZED_VERSION = 3;

// This is the current serialized UUID.
var SERIALIZED_UUID = ADDED_UNICODE_SMP;

function initArray( length, value) {
	var tmp = [];
	tmp[length-1] = value;
	return tmp.map(function(i) {return value;});
}

function ATNDeserializer (options) {

    if ( options=== undefined || options === null ) {
        options = ATNDeserializationOptions.defaultOptions;
    }
    this.deserializationOptions = options;
    this.stateFactories = null;
    this.actionFactories = null;

    return this;
}

// Determines if a particular serialized representation of an ATN supports
// a particular feature, identified by the {@link UUID} used for serializing
// the ATN at the time the feature was first introduced.
//
// @param feature The {@link UUID} marking the first time the feature was
// supported in the serialized ATN.
// @param actualUuid The {@link UUID} of the actual serialized ATN which is
// currently being deserialized.
// @return {@code true} if the {@code actualUuid} value represents a
// serialized ATN at or after the feature identified by {@code feature} was
// introduced; otherwise, {@code false}.

ATNDeserializer.prototype.isFeatureSupported = function(feature, actualUuid) {
    var idx1 = SUPPORTED_UUIDS.indexOf(feature);
    if (idx1<0) {
        return false;
    }
    var idx2 = SUPPORTED_UUIDS.indexOf(actualUuid);
    return idx2 >= idx1;
};

ATNDeserializer.prototype.deserialize = function(data) {
    this.reset(data);
    this.checkVersion();
    this.checkUUID();
    var atn = this.readATN();
    this.readStates(atn);
    this.readRules(atn);
    this.readModes(atn);
    var sets = [];
    // First, deserialize sets with 16-bit arguments <= U+FFFF.
    this.readSets(atn, sets, this.readInt.bind(this));
    // Next, if the ATN was serialized with the Unicode SMP feature,
    // deserialize sets with 32-bit arguments <= U+10FFFF.
    if (this.isFeatureSupported(ADDED_UNICODE_SMP, this.uuid)) {
        this.readSets(atn, sets, this.readInt32.bind(this));
    }
    this.readEdges(atn, sets);
    this.readDecisions(atn);
    this.readLexerActions(atn);
    this.markPrecedenceDecisions(atn);
    this.verifyATN(atn);
    if (this.deserializationOptions.generateRuleBypassTransitions && atn.grammarType === ATNType.PARSER ) {
        this.generateRuleBypassTransitions(atn);
        // re-verify after modification
        this.verifyATN(atn);
    }
    return atn;
};

ATNDeserializer.prototype.reset = function(data) {
	var adjust = function(c) {
        var v = c.charCodeAt(0);
        return v>1  ? v-2 : v + 65534;
	};
    var temp = data.split("").map(adjust);
    // don't adjust the first value since that's the version number
    temp[0] = data.charCodeAt(0);
    this.data = temp;
    this.pos = 0;
};

ATNDeserializer.prototype.checkVersion = function() {
    var version = this.readInt();
    if ( version !== SERIALIZED_VERSION ) {
        throw ("Could not deserialize ATN with version " + version + " (expected " + SERIALIZED_VERSION + ").");
    }
};

ATNDeserializer.prototype.checkUUID = function() {
    var uuid = this.readUUID();
    if (SUPPORTED_UUIDS.indexOf(uuid)<0) {
        throw ("Could not deserialize ATN with UUID: " + uuid +
                        " (expected " + SERIALIZED_UUID + " or a legacy UUID).", uuid, SERIALIZED_UUID);
    }
    this.uuid = uuid;
};

ATNDeserializer.prototype.readATN = function() {
    var grammarType = this.readInt();
    var maxTokenType = this.readInt();
    return new ATN(grammarType, maxTokenType);
};

ATNDeserializer.prototype.readStates = function(atn) {
	var j, pair, stateNumber;
    var loopBackStateNumbers = [];
    var endStateNumbers = [];
    var nstates = this.readInt();
    for(var i=0; i<nstates; i++) {
        var stype = this.readInt();
        // ignore bad type of states
        if (stype===ATNState.INVALID_TYPE) {
            atn.addState(null);
            continue;
        }
        var ruleIndex = this.readInt();
        if (ruleIndex === 0xFFFF) {
            ruleIndex = -1;
        }
        var s = this.stateFactory(stype, ruleIndex);
        if (stype === ATNState.LOOP_END) { // special case
            var loopBackStateNumber = this.readInt();
            loopBackStateNumbers.push([s, loopBackStateNumber]);
        } else if(s instanceof BlockStartState) {
            var endStateNumber = this.readInt();
            endStateNumbers.push([s, endStateNumber]);
        }
        atn.addState(s);
    }
    // delay the assignment of loop back and end states until we know all the
	// state instances have been initialized
    for (j=0; j<loopBackStateNumbers.length; j++) {
        pair = loopBackStateNumbers[j];
        pair[0].loopBackState = atn.states[pair[1]];
    }

    for (j=0; j<endStateNumbers.length; j++) {
        pair = endStateNumbers[j];
        pair[0].endState = atn.states[pair[1]];
    }

    var numNonGreedyStates = this.readInt();
    for (j=0; j<numNonGreedyStates; j++) {
        stateNumber = this.readInt();
        atn.states[stateNumber].nonGreedy = true;
    }

    var numPrecedenceStates = this.readInt();
    for (j=0; j<numPrecedenceStates; j++) {
        stateNumber = this.readInt();
        atn.states[stateNumber].isPrecedenceRule = true;
    }
};

ATNDeserializer.prototype.readRules = function(atn) {
    var i;
    var nrules = this.readInt();
    if (atn.grammarType === ATNType.LEXER ) {
        atn.ruleToTokenType = initArray(nrules, 0);
    }
    atn.ruleToStartState = initArray(nrules, 0);
    for (i=0; i<nrules; i++) {
        var s = this.readInt();
        var startState = atn.states[s];
        atn.ruleToStartState[i] = startState;
        if ( atn.grammarType === ATNType.LEXER ) {
            var tokenType = this.readInt();
            if (tokenType === 0xFFFF) {
                tokenType = Token.EOF;
            }
            atn.ruleToTokenType[i] = tokenType;
        }
    }
    atn.ruleToStopState = initArray(nrules, 0);
    for (i=0; i<atn.states.length; i++) {
        var state = atn.states[i];
        if (!(state instanceof RuleStopState)) {
            continue;
        }
        atn.ruleToStopState[state.ruleIndex] = state;
        atn.ruleToStartState[state.ruleIndex].stopState = state;
    }
};

ATNDeserializer.prototype.readModes = function(atn) {
    var nmodes = this.readInt();
    for (var i=0; i<nmodes; i++) {
        var s = this.readInt();
        atn.modeToStartState.push(atn.states[s]);
    }
};

ATNDeserializer.prototype.readSets = function(atn, sets, readUnicode) {
    var m = this.readInt();
    for (var i=0; i<m; i++) {
        var iset = new IntervalSet();
        sets.push(iset);
        var n = this.readInt();
        var containsEof = this.readInt();
        if (containsEof!==0) {
            iset.addOne(-1);
        }
        for (var j=0; j<n; j++) {
            var i1 = readUnicode();
            var i2 = readUnicode();
            iset.addRange(i1, i2);
        }
    }
};

ATNDeserializer.prototype.readEdges = function(atn, sets) {
	var i, j, state, trans, target;
    var nedges = this.readInt();
    for (i=0; i<nedges; i++) {
        var src = this.readInt();
        var trg = this.readInt();
        var ttype = this.readInt();
        var arg1 = this.readInt();
        var arg2 = this.readInt();
        var arg3 = this.readInt();
        trans = this.edgeFactory(atn, ttype, src, trg, arg1, arg2, arg3, sets);
        var srcState = atn.states[src];
        srcState.addTransition(trans);
    }
    // edges for rule stop states can be derived, so they aren't serialized
    for (i=0; i<atn.states.length; i++) {
        state = atn.states[i];
        for (j=0; j<state.transitions.length; j++) {
            var t = state.transitions[j];
            if (!(t instanceof RuleTransition)) {
                continue;
            }
			var outermostPrecedenceReturn = -1;
			if (atn.ruleToStartState[t.target.ruleIndex].isPrecedenceRule) {
				if (t.precedence === 0) {
					outermostPrecedenceReturn = t.target.ruleIndex;
				}
			}

			trans = new EpsilonTransition(t.followState, outermostPrecedenceReturn);
            atn.ruleToStopState[t.target.ruleIndex].addTransition(trans);
        }
    }

    for (i=0; i<atn.states.length; i++) {
        state = atn.states[i];
        if (state instanceof BlockStartState) {
            // we need to know the end state to set its start state
            if (state.endState === null) {
                throw ("IllegalState");
            }
            // block end states can only be associated to a single block start
			// state
            if ( state.endState.startState !== null) {
                throw ("IllegalState");
            }
            state.endState.startState = state;
        }
        if (state instanceof PlusLoopbackState) {
            for (j=0; j<state.transitions.length; j++) {
                target = state.transitions[j].target;
                if (target instanceof PlusBlockStartState) {
                    target.loopBackState = state;
                }
            }
        } else if (state instanceof StarLoopbackState) {
            for (j=0; j<state.transitions.length; j++) {
                target = state.transitions[j].target;
                if (target instanceof StarLoopEntryState) {
                    target.loopBackState = state;
                }
            }
        }
    }
};

ATNDeserializer.prototype.readDecisions = function(atn) {
    var ndecisions = this.readInt();
    for (var i=0; i<ndecisions; i++) {
        var s = this.readInt();
        var decState = atn.states[s];
        atn.decisionToState.push(decState);
        decState.decision = i;
    }
};

ATNDeserializer.prototype.readLexerActions = function(atn) {
    if (atn.grammarType === ATNType.LEXER) {
        var count = this.readInt();
        atn.lexerActions = initArray(count, null);
        for (var i=0; i<count; i++) {
            var actionType = this.readInt();
            var data1 = this.readInt();
            if (data1 === 0xFFFF) {
                data1 = -1;
            }
            var data2 = this.readInt();
            if (data2 === 0xFFFF) {
                data2 = -1;
            }
            var lexerAction = this.lexerActionFactory(actionType, data1, data2);
            atn.lexerActions[i] = lexerAction;
        }
    }
};

ATNDeserializer.prototype.generateRuleBypassTransitions = function(atn) {
	var i;
    var count = atn.ruleToStartState.length;
    for(i=0; i<count; i++) {
        atn.ruleToTokenType[i] = atn.maxTokenType + i + 1;
    }
    for(i=0; i<count; i++) {
        this.generateRuleBypassTransition(atn, i);
    }
};

ATNDeserializer.prototype.generateRuleBypassTransition = function(atn, idx) {
	var i, state;
    var bypassStart = new BasicBlockStartState();
    bypassStart.ruleIndex = idx;
    atn.addState(bypassStart);

    var bypassStop = new BlockEndState();
    bypassStop.ruleIndex = idx;
    atn.addState(bypassStop);

    bypassStart.endState = bypassStop;
    atn.defineDecisionState(bypassStart);

    bypassStop.startState = bypassStart;

    var excludeTransition = null;
    var endState = null;

    if (atn.ruleToStartState[idx].isPrecedenceRule) {
        // wrap from the beginning of the rule to the StarLoopEntryState
        endState = null;
        for(i=0; i<atn.states.length; i++) {
            state = atn.states[i];
            if (this.stateIsEndStateFor(state, idx)) {
                endState = state;
                excludeTransition = state.loopBackState.transitions[0];
                break;
            }
        }
        if (excludeTransition === null) {
            throw ("Couldn't identify final state of the precedence rule prefix section.");
        }
    } else {
        endState = atn.ruleToStopState[idx];
    }

    // all non-excluded transitions that currently target end state need to
	// target blockEnd instead
    for(i=0; i<atn.states.length; i++) {
        state = atn.states[i];
        for(var j=0; j<state.transitions.length; j++) {
            var transition = state.transitions[j];
            if (transition === excludeTransition) {
                continue;
            }
            if (transition.target === endState) {
                transition.target = bypassStop;
            }
        }
    }

    // all transitions leaving the rule start state need to leave blockStart
	// instead
    var ruleToStartState = atn.ruleToStartState[idx];
    var count = ruleToStartState.transitions.length;
    while ( count > 0) {
        bypassStart.addTransition(ruleToStartState.transitions[count-1]);
        ruleToStartState.transitions = ruleToStartState.transitions.slice(-1);
    }
    // link the new states
    atn.ruleToStartState[idx].addTransition(new EpsilonTransition(bypassStart));
    bypassStop.addTransition(new EpsilonTransition(endState));

    var matchState = new BasicState();
    atn.addState(matchState);
    matchState.addTransition(new AtomTransition(bypassStop, atn.ruleToTokenType[idx]));
    bypassStart.addTransition(new EpsilonTransition(matchState));
};

ATNDeserializer.prototype.stateIsEndStateFor = function(state, idx) {
    if ( state.ruleIndex !== idx) {
        return null;
    }
    if (!( state instanceof StarLoopEntryState)) {
        return null;
    }
    var maybeLoopEndState = state.transitions[state.transitions.length - 1].target;
    if (!( maybeLoopEndState instanceof LoopEndState)) {
        return null;
    }
    if (maybeLoopEndState.epsilonOnlyTransitions &&
        (maybeLoopEndState.transitions[0].target instanceof RuleStopState)) {
        return state;
    } else {
        return null;
    }
};

//
// Analyze the {@link StarLoopEntryState} states in the specified ATN to set
// the {@link StarLoopEntryState//isPrecedenceDecision} field to the
// correct value.
//
// @param atn The ATN.
//
ATNDeserializer.prototype.markPrecedenceDecisions = function(atn) {
	for(var i=0; i<atn.states.length; i++) {
		var state = atn.states[i];
		if (!( state instanceof StarLoopEntryState)) {
            continue;
        }
        // We analyze the ATN to determine if this ATN decision state is the
        // decision for the closure block that determines whether a
        // precedence rule should continue or complete.
        //
        if ( atn.ruleToStartState[state.ruleIndex].isPrecedenceRule) {
            var maybeLoopEndState = state.transitions[state.transitions.length - 1].target;
            if (maybeLoopEndState instanceof LoopEndState) {
                if ( maybeLoopEndState.epsilonOnlyTransitions &&
                        (maybeLoopEndState.transitions[0].target instanceof RuleStopState)) {
                    state.isPrecedenceDecision = true;
                }
            }
        }
	}
};

ATNDeserializer.prototype.verifyATN = function(atn) {
    if (!this.deserializationOptions.verifyATN) {
        return;
    }
    // verify assumptions
	for(var i=0; i<atn.states.length; i++) {
        var state = atn.states[i];
        if (state === null) {
            continue;
        }
        this.checkCondition(state.epsilonOnlyTransitions || state.transitions.length <= 1);
        if (state instanceof PlusBlockStartState) {
            this.checkCondition(state.loopBackState !== null);
        } else  if (state instanceof StarLoopEntryState) {
            this.checkCondition(state.loopBackState !== null);
            this.checkCondition(state.transitions.length === 2);
            if (state.transitions[0].target instanceof StarBlockStartState) {
                this.checkCondition(state.transitions[1].target instanceof LoopEndState);
                this.checkCondition(!state.nonGreedy);
            } else if (state.transitions[0].target instanceof LoopEndState) {
                this.checkCondition(state.transitions[1].target instanceof StarBlockStartState);
                this.checkCondition(state.nonGreedy);
            } else {
                throw("IllegalState");
            }
        } else if (state instanceof StarLoopbackState) {
            this.checkCondition(state.transitions.length === 1);
            this.checkCondition(state.transitions[0].target instanceof StarLoopEntryState);
        } else if (state instanceof LoopEndState) {
            this.checkCondition(state.loopBackState !== null);
        } else if (state instanceof RuleStartState) {
            this.checkCondition(state.stopState !== null);
        } else if (state instanceof BlockStartState) {
            this.checkCondition(state.endState !== null);
        } else if (state instanceof BlockEndState) {
            this.checkCondition(state.startState !== null);
        } else if (state instanceof DecisionState) {
            this.checkCondition(state.transitions.length <= 1 || state.decision >= 0);
        } else {
            this.checkCondition(state.transitions.length <= 1 || (state instanceof RuleStopState));
        }
	}
};

ATNDeserializer.prototype.checkCondition = function(condition, message) {
    if (!condition) {
        if (message === undefined || message===null) {
            message = "IllegalState";
        }
        throw (message);
    }
};

ATNDeserializer.prototype.readInt = function() {
    return this.data[this.pos++];
};

ATNDeserializer.prototype.readInt32 = function() {
    var low = this.readInt();
    var high = this.readInt();
    return low | (high << 16);
};

ATNDeserializer.prototype.readLong = function() {
    var low = this.readInt32();
    var high = this.readInt32();
    return (low & 0x00000000FFFFFFFF) | (high << 32);
};

function createByteToHex() {
	var bth = [];
	for (var i = 0; i < 256; i++) {
		bth[i] = (i + 0x100).toString(16).substr(1).toUpperCase();
	}
	return bth;
}

var byteToHex = createByteToHex();

ATNDeserializer.prototype.readUUID = function() {
	var bb = [];
	for(var i=7;i>=0;i--) {
		var int = this.readInt();
		/* jshint bitwise: false */
		bb[(2*i)+1] = int & 0xFF;
		bb[2*i] = (int >> 8) & 0xFF;
	}
    return byteToHex[bb[0]] + byteToHex[bb[1]] +
    byteToHex[bb[2]] + byteToHex[bb[3]] + '-' +
    byteToHex[bb[4]] + byteToHex[bb[5]] + '-' +
    byteToHex[bb[6]] + byteToHex[bb[7]] + '-' +
    byteToHex[bb[8]] + byteToHex[bb[9]] + '-' +
    byteToHex[bb[10]] + byteToHex[bb[11]] +
    byteToHex[bb[12]] + byteToHex[bb[13]] +
    byteToHex[bb[14]] + byteToHex[bb[15]];
};

ATNDeserializer.prototype.edgeFactory = function(atn, type, src, trg, arg1, arg2, arg3, sets) {
    var target = atn.states[trg];
    switch(type) {
    case Transition.EPSILON:
        return new EpsilonTransition(target);
    case Transition.RANGE:
        return arg3 !== 0 ? new RangeTransition(target, Token.EOF, arg2) : new RangeTransition(target, arg1, arg2);
    case Transition.RULE:
        return new RuleTransition(atn.states[arg1], arg2, arg3, target);
    case Transition.PREDICATE:
        return new PredicateTransition(target, arg1, arg2, arg3 !== 0);
    case Transition.PRECEDENCE:
        return new PrecedencePredicateTransition(target, arg1);
    case Transition.ATOM:
        return arg3 !== 0 ? new AtomTransition(target, Token.EOF) : new AtomTransition(target, arg1);
    case Transition.ACTION:
        return new ActionTransition(target, arg1, arg2, arg3 !== 0);
    case Transition.SET:
        return new SetTransition(target, sets[arg1]);
    case Transition.NOT_SET:
        return new NotSetTransition(target, sets[arg1]);
    case Transition.WILDCARD:
        return new WildcardTransition(target);
    default:
        throw "The specified transition type: " + type + " is not valid.";
    }
};

ATNDeserializer.prototype.stateFactory = function(type, ruleIndex) {
    if (this.stateFactories === null) {
        var sf = [];
        sf[ATNState.INVALID_TYPE] = null;
        sf[ATNState.BASIC] = function() { return new BasicState(); };
        sf[ATNState.RULE_START] = function() { return new RuleStartState(); };
        sf[ATNState.BLOCK_START] = function() { return new BasicBlockStartState(); };
        sf[ATNState.PLUS_BLOCK_START] = function() { return new PlusBlockStartState(); };
        sf[ATNState.STAR_BLOCK_START] = function() { return new StarBlockStartState(); };
        sf[ATNState.TOKEN_START] = function() { return new TokensStartState(); };
        sf[ATNState.RULE_STOP] = function() { return new RuleStopState(); };
        sf[ATNState.BLOCK_END] = function() { return new BlockEndState(); };
        sf[ATNState.STAR_LOOP_BACK] = function() { return new StarLoopbackState(); };
        sf[ATNState.STAR_LOOP_ENTRY] = function() { return new StarLoopEntryState(); };
        sf[ATNState.PLUS_LOOP_BACK] = function() { return new PlusLoopbackState(); };
        sf[ATNState.LOOP_END] = function() { return new LoopEndState(); };
        this.stateFactories = sf;
    }
    if (type>this.stateFactories.length || this.stateFactories[type] === null) {
        throw("The specified state type " + type + " is not valid.");
    } else {
        var s = this.stateFactories[type]();
        if (s!==null) {
            s.ruleIndex = ruleIndex;
            return s;
        }
    }
};

ATNDeserializer.prototype.lexerActionFactory = function(type, data1, data2) {
    if (this.actionFactories === null) {
        var af = [];
        af[LexerActionType.CHANNEL] = function(data1, data2) { return new LexerChannelAction(data1); };
        af[LexerActionType.CUSTOM] = function(data1, data2) { return new LexerCustomAction(data1, data2); };
        af[LexerActionType.MODE] = function(data1, data2) { return new LexerModeAction(data1); };
        af[LexerActionType.MORE] = function(data1, data2) { return LexerMoreAction.INSTANCE; };
        af[LexerActionType.POP_MODE] = function(data1, data2) { return LexerPopModeAction.INSTANCE; };
        af[LexerActionType.PUSH_MODE] = function(data1, data2) { return new LexerPushModeAction(data1); };
        af[LexerActionType.SKIP] = function(data1, data2) { return LexerSkipAction.INSTANCE; };
        af[LexerActionType.TYPE] = function(data1, data2) { return new LexerTypeAction(data1); };
        this.actionFactories = af;
    }
    if (type>this.actionFactories.length || this.actionFactories[type] === null) {
        throw("The specified lexer action type " + type + " is not valid.");
    } else {
        return this.actionFactories[type](data1, data2);
    }
};


exports.ATNDeserializer = ATNDeserializer;
},{"./../IntervalSet":31,"./../Token":39,"./ATN":41,"./ATNDeserializationOptions":44,"./ATNState":47,"./ATNType":48,"./LexerAction":50,"./Transition":55}],46:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
///

var DFAState = require('./../dfa/DFAState').DFAState;
var ATNConfigSet = require('./ATNConfigSet').ATNConfigSet;
var getCachedPredictionContext = require('./../PredictionContext').getCachedPredictionContext;
var Map = require('./../Utils').Map;

function ATNSimulator(atn, sharedContextCache) {

    // The context cache maps all PredictionContext objects that are ==
    //  to a single cached copy. This cache is shared across all contexts
    //  in all ATNConfigs in all DFA states.  We rebuild each ATNConfigSet
    //  to use only cached nodes/graphs in addDFAState(). We don't want to
    //  fill this during closure() since there are lots of contexts that
    //  pop up but are not used ever again. It also greatly slows down closure().
    //
    //  <p>This cache makes a huge difference in memory and a little bit in speed.
    //  For the Java grammar on java.*, it dropped the memory requirements
    //  at the end from 25M to 16M. We don't store any of the full context
    //  graphs in the DFA because they are limited to local context only,
    //  but apparently there's a lot of repetition there as well. We optimize
    //  the config contexts before storing the config set in the DFA states
    //  by literally rebuilding them with cached subgraphs only.</p>
    //
    //  <p>I tried a cache for use during closure operations, that was
    //  whacked after each adaptivePredict(). It cost a little bit
    //  more time I think and doesn't save on the overall footprint
    //  so it's not worth the complexity.</p>
    ///
    this.atn = atn;
    this.sharedContextCache = sharedContextCache;
    return this;
}

// Must distinguish between missing edge and edge we know leads nowhere///
ATNSimulator.ERROR = new DFAState(0x7FFFFFFF, new ATNConfigSet());


ATNSimulator.prototype.getCachedContext = function(context) {
    if (this.sharedContextCache ===null) {
        return context;
    }
    var visited = new Map();
    return getCachedPredictionContext(context, this.sharedContextCache, visited);
};

exports.ATNSimulator = ATNSimulator;

},{"./../PredictionContext":36,"./../Utils":40,"./../dfa/DFAState":59,"./ATNConfigSet":43}],47:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
//

// The following images show the relation of states and
// {@link ATNState//transitions} for various grammar constructs.
//
// <ul>
//
// <li>Solid edges marked with an &//0949; indicate a required
// {@link EpsilonTransition}.</li>
//
// <li>Dashed edges indicate locations where any transition derived from
// {@link Transition} might appear.</li>
//
// <li>Dashed nodes are place holders for either a sequence of linked
// {@link BasicState} states or the inclusion of a block representing a nested
// construct in one of the forms below.</li>
//
// <li>Nodes showing multiple outgoing alternatives with a {@code ...} support
// any number of alternatives (one or more). Nodes without the {@code ...} only
// support the exact number of alternatives shown in the diagram.</li>
//
// </ul>
//
// <h2>Basic Blocks</h2>
//
// <h3>Rule</h3>
//
// <embed src="images/Rule.svg" type="image/svg+xml"/>
//
// <h3>Block of 1 or more alternatives</h3>
//
// <embed src="images/Block.svg" type="image/svg+xml"/>
//
// <h2>Greedy Loops</h2>
//
// <h3>Greedy Closure: {@code (...)*}</h3>
//
// <embed src="images/ClosureGreedy.svg" type="image/svg+xml"/>
//
// <h3>Greedy Positive Closure: {@code (...)+}</h3>
//
// <embed src="images/PositiveClosureGreedy.svg" type="image/svg+xml"/>
//
// <h3>Greedy Optional: {@code (...)?}</h3>
//
// <embed src="images/OptionalGreedy.svg" type="image/svg+xml"/>
//
// <h2>Non-Greedy Loops</h2>
//
// <h3>Non-Greedy Closure: {@code (...)*?}</h3>
//
// <embed src="images/ClosureNonGreedy.svg" type="image/svg+xml"/>
//
// <h3>Non-Greedy Positive Closure: {@code (...)+?}</h3>
//
// <embed src="images/PositiveClosureNonGreedy.svg" type="image/svg+xml"/>
//
// <h3>Non-Greedy Optional: {@code (...)??}</h3>
//
// <embed src="images/OptionalNonGreedy.svg" type="image/svg+xml"/>
//

var INITIAL_NUM_TRANSITIONS = 4;

function ATNState() {
    // Which ATN are we in?
    this.atn = null;
    this.stateNumber = ATNState.INVALID_STATE_NUMBER;
    this.stateType = null;
    this.ruleIndex = 0; // at runtime, we don't have Rule objects
    this.epsilonOnlyTransitions = false;
    // Track the transitions emanating from this ATN state.
    this.transitions = [];
    // Used to cache lookahead during parsing, not used during construction
    this.nextTokenWithinRule = null;
    return this;
}

// constants for serialization
ATNState.INVALID_TYPE = 0;
ATNState.BASIC = 1;
ATNState.RULE_START = 2;
ATNState.BLOCK_START = 3;
ATNState.PLUS_BLOCK_START = 4;
ATNState.STAR_BLOCK_START = 5;
ATNState.TOKEN_START = 6;
ATNState.RULE_STOP = 7;
ATNState.BLOCK_END = 8;
ATNState.STAR_LOOP_BACK = 9;
ATNState.STAR_LOOP_ENTRY = 10;
ATNState.PLUS_LOOP_BACK = 11;
ATNState.LOOP_END = 12;

ATNState.serializationNames = [
            "INVALID",
            "BASIC",
            "RULE_START",
            "BLOCK_START",
            "PLUS_BLOCK_START",
            "STAR_BLOCK_START",
            "TOKEN_START",
            "RULE_STOP",
            "BLOCK_END",
            "STAR_LOOP_BACK",
            "STAR_LOOP_ENTRY",
            "PLUS_LOOP_BACK",
            "LOOP_END" ];

ATNState.INVALID_STATE_NUMBER = -1;

ATNState.prototype.toString = function() {
	return this.stateNumber;
};

ATNState.prototype.equals = function(other) {
    if (other instanceof ATNState) {
        return this.stateNumber===other.stateNumber;
    } else {
        return false;
    }
};

ATNState.prototype.isNonGreedyExitState = function() {
    return false;
};


ATNState.prototype.addTransition = function(trans, index) {
	if(index===undefined) {
		index = -1;
	}
    if (this.transitions.length===0) {
        this.epsilonOnlyTransitions = trans.isEpsilon;
    } else if(this.epsilonOnlyTransitions !== trans.isEpsilon) {
        this.epsilonOnlyTransitions = false;
    }
    if (index===-1) {
        this.transitions.push(trans);
    } else {
        this.transitions.splice(index, 1, trans);
    }
};

function BasicState() {
	ATNState.call(this);
    this.stateType = ATNState.BASIC;
    return this;
}

BasicState.prototype = Object.create(ATNState.prototype);
BasicState.prototype.constructor = BasicState;


function DecisionState() {
	ATNState.call(this);
    this.decision = -1;
    this.nonGreedy = false;
    return this;
}

DecisionState.prototype = Object.create(ATNState.prototype);
DecisionState.prototype.constructor = DecisionState;


//  The start of a regular {@code (...)} block.
function BlockStartState() {
	DecisionState.call(this);
	this.endState = null;
	return this;
}

BlockStartState.prototype = Object.create(DecisionState.prototype);
BlockStartState.prototype.constructor = BlockStartState;


function BasicBlockStartState() {
	BlockStartState.call(this);
	this.stateType = ATNState.BLOCK_START;
	return this;
}

BasicBlockStartState.prototype = Object.create(BlockStartState.prototype);
BasicBlockStartState.prototype.constructor = BasicBlockStartState;


// Terminal node of a simple {@code (a|b|c)} block.
function BlockEndState() {
	ATNState.call(this);
	this.stateType = ATNState.BLOCK_END;
    this.startState = null;
    return this;
}

BlockEndState.prototype = Object.create(ATNState.prototype);
BlockEndState.prototype.constructor = BlockEndState;


// The last node in the ATN for a rule, unless that rule is the start symbol.
//  In that case, there is one transition to EOF. Later, we might encode
//  references to all calls to this rule to compute FOLLOW sets for
//  error handling.
//
function RuleStopState() {
	ATNState.call(this);
    this.stateType = ATNState.RULE_STOP;
    return this;
}

RuleStopState.prototype = Object.create(ATNState.prototype);
RuleStopState.prototype.constructor = RuleStopState;

function RuleStartState() {
	ATNState.call(this);
	this.stateType = ATNState.RULE_START;
	this.stopState = null;
	this.isPrecedenceRule = false;
	return this;
}

RuleStartState.prototype = Object.create(ATNState.prototype);
RuleStartState.prototype.constructor = RuleStartState;

// Decision state for {@code A+} and {@code (A|B)+}.  It has two transitions:
//  one to the loop back to start of the block and one to exit.
//
function PlusLoopbackState() {
	DecisionState.call(this);
	this.stateType = ATNState.PLUS_LOOP_BACK;
	return this;
}

PlusLoopbackState.prototype = Object.create(DecisionState.prototype);
PlusLoopbackState.prototype.constructor = PlusLoopbackState;


// Start of {@code (A|B|...)+} loop. Technically a decision state, but
//  we don't use for code generation; somebody might need it, so I'm defining
//  it for completeness. In reality, the {@link PlusLoopbackState} node is the
//  real decision-making note for {@code A+}.
//
function PlusBlockStartState() {
	BlockStartState.call(this);
	this.stateType = ATNState.PLUS_BLOCK_START;
    this.loopBackState = null;
    return this;
}

PlusBlockStartState.prototype = Object.create(BlockStartState.prototype);
PlusBlockStartState.prototype.constructor = PlusBlockStartState;

// The block that begins a closure loop.
function StarBlockStartState() {
	BlockStartState.call(this);
	this.stateType = ATNState.STAR_BLOCK_START;
	return this;
}

StarBlockStartState.prototype = Object.create(BlockStartState.prototype);
StarBlockStartState.prototype.constructor = StarBlockStartState;


function StarLoopbackState() {
	ATNState.call(this);
	this.stateType = ATNState.STAR_LOOP_BACK;
	return this;
}

StarLoopbackState.prototype = Object.create(ATNState.prototype);
StarLoopbackState.prototype.constructor = StarLoopbackState;


function StarLoopEntryState() {
	DecisionState.call(this);
	this.stateType = ATNState.STAR_LOOP_ENTRY;
    this.loopBackState = null;
    // Indicates whether this state can benefit from a precedence DFA during SLL decision making.
    this.isPrecedenceDecision = null;
    return this;
}

StarLoopEntryState.prototype = Object.create(DecisionState.prototype);
StarLoopEntryState.prototype.constructor = StarLoopEntryState;


// Mark the end of a * or + loop.
function LoopEndState() {
	ATNState.call(this);
	this.stateType = ATNState.LOOP_END;
	this.loopBackState = null;
	return this;
}

LoopEndState.prototype = Object.create(ATNState.prototype);
LoopEndState.prototype.constructor = LoopEndState;


// The Tokens rule start state linking to each lexer rule start state */
function TokensStartState() {
	DecisionState.call(this);
	this.stateType = ATNState.TOKEN_START;
	return this;
}

TokensStartState.prototype = Object.create(DecisionState.prototype);
TokensStartState.prototype.constructor = TokensStartState;

exports.ATNState = ATNState;
exports.BasicState = BasicState;
exports.DecisionState = DecisionState;
exports.BlockStartState = BlockStartState;
exports.BlockEndState = BlockEndState;
exports.LoopEndState = LoopEndState;
exports.RuleStartState = RuleStartState;
exports.RuleStopState = RuleStopState;
exports.TokensStartState = TokensStartState;
exports.PlusLoopbackState = PlusLoopbackState;
exports.StarLoopbackState = StarLoopbackState;
exports.StarLoopEntryState = StarLoopEntryState;
exports.PlusBlockStartState = PlusBlockStartState;
exports.StarBlockStartState = StarBlockStartState;
exports.BasicBlockStartState = BasicBlockStartState;

},{}],48:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
///

// Represents the type of recognizer an ATN applies to.

function ATNType() {

}

ATNType.LEXER = 0;
ATNType.PARSER = 1;

exports.ATNType = ATNType;


},{}],49:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
///

// When we hit an accept state in either the DFA or the ATN, we
//  have to notify the character stream to start buffering characters
//  via {@link IntStream//mark} and record the current state. The current sim state
//  includes the current index into the input, the current line,
//  and current character position in that line. Note that the Lexer is
//  tracking the starting line and characterization of the token. These
//  variables track the "state" of the simulator when it hits an accept state.
//
//  <p>We track these variables separately for the DFA and ATN simulation
//  because the DFA simulation often has to fail over to the ATN
//  simulation. If the ATN simulation fails, we need the DFA to fall
//  back to its previously accepted state, if any. If the ATN succeeds,
//  then the ATN does the accept and the DFA simulator that invoked it
//  can simply return the predicted token type.</p>
///

var Token = require('./../Token').Token;
var Lexer = require('./../Lexer').Lexer;
var ATN = require('./ATN').ATN;
var ATNSimulator = require('./ATNSimulator').ATNSimulator;
var DFAState = require('./../dfa/DFAState').DFAState;
var ATNConfigSet = require('./ATNConfigSet').ATNConfigSet;
var OrderedATNConfigSet = require('./ATNConfigSet').OrderedATNConfigSet;
var PredictionContext = require('./../PredictionContext').PredictionContext;
var SingletonPredictionContext = require('./../PredictionContext').SingletonPredictionContext;
var RuleStopState = require('./ATNState').RuleStopState;
var LexerATNConfig = require('./ATNConfig').LexerATNConfig;
var Transition = require('./Transition').Transition;
var LexerActionExecutor = require('./LexerActionExecutor').LexerActionExecutor;
var LexerNoViableAltException = require('./../error/Errors').LexerNoViableAltException;

function resetSimState(sim) {
	sim.index = -1;
	sim.line = 0;
	sim.column = -1;
	sim.dfaState = null;
}

function SimState() {
	resetSimState(this);
	return this;
}

SimState.prototype.reset = function() {
	resetSimState(this);
};

function LexerATNSimulator(recog, atn, decisionToDFA, sharedContextCache) {
	ATNSimulator.call(this, atn, sharedContextCache);
	this.decisionToDFA = decisionToDFA;
	this.recog = recog;
	// The current token's starting index into the character stream.
	// Shared across DFA to ATN simulation in case the ATN fails and the
	// DFA did not have a previous accept state. In this case, we use the
	// ATN-generated exception object.
	this.startIndex = -1;
	// line number 1..n within the input///
	this.line = 1;
	// The index of the character relative to the beginning of the line
	// 0..n-1///
	this.column = 0;
	this.mode = Lexer.DEFAULT_MODE;
	// Used during DFA/ATN exec to record the most recent accept configuration
	// info
	this.prevAccept = new SimState();
	// done
	return this;
}

LexerATNSimulator.prototype = Object.create(ATNSimulator.prototype);
LexerATNSimulator.prototype.constructor = LexerATNSimulator;

LexerATNSimulator.debug = false;
LexerATNSimulator.dfa_debug = false;

LexerATNSimulator.MIN_DFA_EDGE = 0;
LexerATNSimulator.MAX_DFA_EDGE = 127; // forces unicode to stay in ATN

LexerATNSimulator.match_calls = 0;

LexerATNSimulator.prototype.copyState = function(simulator) {
	this.column = simulator.column;
	this.line = simulator.line;
	this.mode = simulator.mode;
	this.startIndex = simulator.startIndex;
};

LexerATNSimulator.prototype.match = function(input, mode) {
	this.match_calls += 1;
	this.mode = mode;
	var mark = input.mark();
	try {
		this.startIndex = input.index;
		this.prevAccept.reset();
		var dfa = this.decisionToDFA[mode];
		if (dfa.s0 === null) {
			return this.matchATN(input);
		} else {
			return this.execATN(input, dfa.s0);
		}
	} finally {
		input.release(mark);
	}
};

LexerATNSimulator.prototype.reset = function() {
	this.prevAccept.reset();
	this.startIndex = -1;
	this.line = 1;
	this.column = 0;
	this.mode = Lexer.DEFAULT_MODE;
};

LexerATNSimulator.prototype.matchATN = function(input) {
	var startState = this.atn.modeToStartState[this.mode];

	if (LexerATNSimulator.debug) {
		console.log("matchATN mode " + this.mode + " start: " + startState);
	}
	var old_mode = this.mode;
	var s0_closure = this.computeStartState(input, startState);
	var suppressEdge = s0_closure.hasSemanticContext;
	s0_closure.hasSemanticContext = false;

	var next = this.addDFAState(s0_closure);
	if (!suppressEdge) {
		this.decisionToDFA[this.mode].s0 = next;
	}

	var predict = this.execATN(input, next);

	if (LexerATNSimulator.debug) {
		console.log("DFA after matchATN: " + this.decisionToDFA[old_mode].toLexerString());
	}
	return predict;
};

LexerATNSimulator.prototype.execATN = function(input, ds0) {
	if (LexerATNSimulator.debug) {
		console.log("start state closure=" + ds0.configs);
	}
	if (ds0.isAcceptState) {
		// allow zero-length tokens
		this.captureSimState(this.prevAccept, input, ds0);
	}
	var t = input.LA(1);
	var s = ds0; // s is current/from DFA state

	while (true) { // while more work
		if (LexerATNSimulator.debug) {
			console.log("execATN loop starting closure: " + s.configs);
		}

		// As we move src->trg, src->trg, we keep track of the previous trg to
		// avoid looking up the DFA state again, which is expensive.
		// If the previous target was already part of the DFA, we might
		// be able to avoid doing a reach operation upon t. If s!=null,
		// it means that semantic predicates didn't prevent us from
		// creating a DFA state. Once we know s!=null, we check to see if
		// the DFA state has an edge already for t. If so, we can just reuse
		// it's configuration set; there's no point in re-computing it.
		// This is kind of like doing DFA simulation within the ATN
		// simulation because DFA simulation is really just a way to avoid
		// computing reach/closure sets. Technically, once we know that
		// we have a previously added DFA state, we could jump over to
		// the DFA simulator. But, that would mean popping back and forth
		// a lot and making things more complicated algorithmically.
		// This optimization makes a lot of sense for loops within DFA.
		// A character will take us back to an existing DFA state
		// that already has lots of edges out of it. e.g., .* in comments.
		// print("Target for:" + str(s) + " and:" + str(t))
		var target = this.getExistingTargetState(s, t);
		// print("Existing:" + str(target))
		if (target === null) {
			target = this.computeTargetState(input, s, t);
			// print("Computed:" + str(target))
		}
		if (target === ATNSimulator.ERROR) {
			break;
		}
		// If this is a consumable input element, make sure to consume before
		// capturing the accept state so the input index, line, and char
		// position accurately reflect the state of the interpreter at the
		// end of the token.
		if (t !== Token.EOF) {
			this.consume(input);
		}
		if (target.isAcceptState) {
			this.captureSimState(this.prevAccept, input, target);
			if (t === Token.EOF) {
				break;
			}
		}
		t = input.LA(1);
		s = target; // flip; current DFA target becomes new src/from state
	}
	return this.failOrAccept(this.prevAccept, input, s.configs, t);
};

// Get an existing target state for an edge in the DFA. If the target state
// for the edge has not yet been computed or is otherwise not available,
// this method returns {@code null}.
//
// @param s The current DFA state
// @param t The next input symbol
// @return The existing target DFA state for the given input symbol
// {@code t}, or {@code null} if the target state for this edge is not
// already cached
LexerATNSimulator.prototype.getExistingTargetState = function(s, t) {
	if (s.edges === null || t < LexerATNSimulator.MIN_DFA_EDGE || t > LexerATNSimulator.MAX_DFA_EDGE) {
		return null;
	}

	var target = s.edges[t - LexerATNSimulator.MIN_DFA_EDGE];
	if(target===undefined) {
		target = null;
	}
	if (LexerATNSimulator.debug && target !== null) {
		console.log("reuse state " + s.stateNumber + " edge to " + target.stateNumber);
	}
	return target;
};

// Compute a target state for an edge in the DFA, and attempt to add the
// computed state and corresponding edge to the DFA.
//
// @param input The input stream
// @param s The current DFA state
// @param t The next input symbol
//
// @return The computed target DFA state for the given input symbol
// {@code t}. If {@code t} does not lead to a valid DFA state, this method
// returns {@link //ERROR}.
LexerATNSimulator.prototype.computeTargetState = function(input, s, t) {
	var reach = new OrderedATNConfigSet();
	// if we don't find an existing DFA state
	// Fill reach starting from closure, following t transitions
	this.getReachableConfigSet(input, s.configs, reach, t);

	if (reach.items.length === 0) { // we got nowhere on t from s
		if (!reach.hasSemanticContext) {
			// we got nowhere on t, don't throw out this knowledge; it'd
			// cause a failover from DFA later.
			this.addDFAEdge(s, t, ATNSimulator.ERROR);
		}
		// stop when we can't match any more char
		return ATNSimulator.ERROR;
	}
	// Add an edge from s to target DFA found/created for reach
	return this.addDFAEdge(s, t, null, reach);
};

LexerATNSimulator.prototype.failOrAccept = function(prevAccept, input, reach, t) {
	if (this.prevAccept.dfaState !== null) {
		var lexerActionExecutor = prevAccept.dfaState.lexerActionExecutor;
		this.accept(input, lexerActionExecutor, this.startIndex,
				prevAccept.index, prevAccept.line, prevAccept.column);
		return prevAccept.dfaState.prediction;
	} else {
		// if no accept and EOF is first char, return EOF
		if (t === Token.EOF && input.index === this.startIndex) {
			return Token.EOF;
		}
		throw new LexerNoViableAltException(this.recog, input, this.startIndex, reach);
	}
};

// Given a starting configuration set, figure out all ATN configurations
// we can reach upon input {@code t}. Parameter {@code reach} is a return
// parameter.
LexerATNSimulator.prototype.getReachableConfigSet = function(input, closure,
		reach, t) {
	// this is used to skip processing for configs which have a lower priority
	// than a config that already reached an accept state for the same rule
	var skipAlt = ATN.INVALID_ALT_NUMBER;
	for (var i = 0; i < closure.items.length; i++) {
		var cfg = closure.items[i];
		var currentAltReachedAcceptState = (cfg.alt === skipAlt);
		if (currentAltReachedAcceptState && cfg.passedThroughNonGreedyDecision) {
			continue;
		}
		if (LexerATNSimulator.debug) {
			console.log("testing %s at %s\n", this.getTokenName(t), cfg
					.toString(this.recog, true));
		}
		for (var j = 0; j < cfg.state.transitions.length; j++) {
			var trans = cfg.state.transitions[j]; // for each transition
			var target = this.getReachableTarget(trans, t);
			if (target !== null) {
				var lexerActionExecutor = cfg.lexerActionExecutor;
				if (lexerActionExecutor !== null) {
					lexerActionExecutor = lexerActionExecutor.fixOffsetBeforeMatch(input.index - this.startIndex);
				}
				var treatEofAsEpsilon = (t === Token.EOF);
				var config = new LexerATNConfig({state:target, lexerActionExecutor:lexerActionExecutor}, cfg);
				if (this.closure(input, config, reach,
						currentAltReachedAcceptState, true, treatEofAsEpsilon)) {
					// any remaining configs for this alt have a lower priority
					// than the one that just reached an accept state.
					skipAlt = cfg.alt;
				}
			}
		}
	}
};

LexerATNSimulator.prototype.accept = function(input, lexerActionExecutor,
		startIndex, index, line, charPos) {
	if (LexerATNSimulator.debug) {
		console.log("ACTION %s\n", lexerActionExecutor);
	}
	// seek to after last char in token
	input.seek(index);
	this.line = line;
	this.column = charPos;
	if (lexerActionExecutor !== null && this.recog !== null) {
		lexerActionExecutor.execute(this.recog, input, startIndex);
	}
};

LexerATNSimulator.prototype.getReachableTarget = function(trans, t) {
	if (trans.matches(t, 0, Lexer.MAX_CHAR_VALUE)) {
		return trans.target;
	} else {
		return null;
	}
};

LexerATNSimulator.prototype.computeStartState = function(input, p) {
	var initialContext = PredictionContext.EMPTY;
	var configs = new OrderedATNConfigSet();
	for (var i = 0; i < p.transitions.length; i++) {
		var target = p.transitions[i].target;
        var cfg = new LexerATNConfig({state:target, alt:i+1, context:initialContext}, null);
		this.closure(input, cfg, configs, false, false, false);
	}
	return configs;
};

// Since the alternatives within any lexer decision are ordered by
// preference, this method stops pursuing the closure as soon as an accept
// state is reached. After the first accept state is reached by depth-first
// search from {@code config}, all other (potentially reachable) states for
// this rule would have a lower priority.
//
// @return {@code true} if an accept state is reached, otherwise
// {@code false}.
LexerATNSimulator.prototype.closure = function(input, config, configs,
		currentAltReachedAcceptState, speculative, treatEofAsEpsilon) {
	var cfg = null;
	if (LexerATNSimulator.debug) {
		console.log("closure(" + config.toString(this.recog, true) + ")");
	}
	if (config.state instanceof RuleStopState) {
		if (LexerATNSimulator.debug) {
			if (this.recog !== null) {
				console.log("closure at %s rule stop %s\n", this.recog.ruleNames[config.state.ruleIndex], config);
			} else {
				console.log("closure at rule stop %s\n", config);
			}
		}
		if (config.context === null || config.context.hasEmptyPath()) {
			if (config.context === null || config.context.isEmpty()) {
				configs.add(config);
				return true;
			} else {
				configs.add(new LexerATNConfig({ state:config.state, context:PredictionContext.EMPTY}, config));
				currentAltReachedAcceptState = true;
			}
		}
		if (config.context !== null && !config.context.isEmpty()) {
			for (var i = 0; i < config.context.length; i++) {
				if (config.context.getReturnState(i) !== PredictionContext.EMPTY_RETURN_STATE) {
					var newContext = config.context.getParent(i); // "pop" return state
					var returnState = this.atn.states[config.context.getReturnState(i)];
					cfg = new LexerATNConfig({ state:returnState, context:newContext }, config);
					currentAltReachedAcceptState = this.closure(input, cfg,
							configs, currentAltReachedAcceptState, speculative,
							treatEofAsEpsilon);
				}
			}
		}
		return currentAltReachedAcceptState;
	}
	// optimization
	if (!config.state.epsilonOnlyTransitions) {
		if (!currentAltReachedAcceptState || !config.passedThroughNonGreedyDecision) {
			configs.add(config);
		}
	}
	for (var j = 0; j < config.state.transitions.length; j++) {
		var trans = config.state.transitions[j];
		cfg = this.getEpsilonTarget(input, config, trans, configs, speculative, treatEofAsEpsilon);
		if (cfg !== null) {
			currentAltReachedAcceptState = this.closure(input, cfg, configs,
					currentAltReachedAcceptState, speculative, treatEofAsEpsilon);
		}
	}
	return currentAltReachedAcceptState;
};

// side-effect: can alter configs.hasSemanticContext
LexerATNSimulator.prototype.getEpsilonTarget = function(input, config, trans,
		configs, speculative, treatEofAsEpsilon) {
	var cfg = null;
	if (trans.serializationType === Transition.RULE) {
		var newContext = SingletonPredictionContext.create(config.context, trans.followState.stateNumber);
		cfg = new LexerATNConfig( { state:trans.target, context:newContext}, config);
	} else if (trans.serializationType === Transition.PRECEDENCE) {
		throw "Precedence predicates are not supported in lexers.";
	} else if (trans.serializationType === Transition.PREDICATE) {
		// Track traversing semantic predicates. If we traverse,
		// we cannot add a DFA state for this "reach" computation
		// because the DFA would not test the predicate again in the
		// future. Rather than creating collections of semantic predicates
		// like v3 and testing them on prediction, v4 will test them on the
		// fly all the time using the ATN not the DFA. This is slower but
		// semantically it's not used that often. One of the key elements to
		// this predicate mechanism is not adding DFA states that see
		// predicates immediately afterwards in the ATN. For example,

		// a : ID {p1}? | ID {p2}? ;

		// should create the start state for rule 'a' (to save start state
		// competition), but should not create target of ID state. The
		// collection of ATN states the following ID references includes
		// states reached by traversing predicates. Since this is when we
		// test them, we cannot cash the DFA state target of ID.

		if (LexerATNSimulator.debug) {
			console.log("EVAL rule " + trans.ruleIndex + ":" + trans.predIndex);
		}
		configs.hasSemanticContext = true;
		if (this.evaluatePredicate(input, trans.ruleIndex, trans.predIndex, speculative)) {
			cfg = new LexerATNConfig({ state:trans.target}, config);
		}
	} else if (trans.serializationType === Transition.ACTION) {
		if (config.context === null || config.context.hasEmptyPath()) {
			// execute actions anywhere in the start rule for a token.
			//
			// TODO: if the entry rule is invoked recursively, some
			// actions may be executed during the recursive call. The
			// problem can appear when hasEmptyPath() is true but
			// isEmpty() is false. In this case, the config needs to be
			// split into two contexts - one with just the empty path
			// and another with everything but the empty path.
			// Unfortunately, the current algorithm does not allow
			// getEpsilonTarget to return two configurations, so
			// additional modifications are needed before we can support
			// the split operation.
			var lexerActionExecutor = LexerActionExecutor.append(config.lexerActionExecutor,
					this.atn.lexerActions[trans.actionIndex]);
			cfg = new LexerATNConfig({ state:trans.target, lexerActionExecutor:lexerActionExecutor }, config);
		} else {
			// ignore actions in referenced rules
			cfg = new LexerATNConfig( { state:trans.target}, config);
		}
	} else if (trans.serializationType === Transition.EPSILON) {
		cfg = new LexerATNConfig({ state:trans.target}, config);
	} else if (trans.serializationType === Transition.ATOM ||
				trans.serializationType === Transition.RANGE ||
				trans.serializationType === Transition.SET) {
		if (treatEofAsEpsilon) {
			if (trans.matches(Token.EOF, 0, Lexer.MAX_CHAR_VALUE)) {
				cfg = new LexerATNConfig( { state:trans.target }, config);
			}
		}
	}
	return cfg;
};

// Evaluate a predicate specified in the lexer.
//
// <p>If {@code speculative} is {@code true}, this method was called before
// {@link //consume} for the matched character. This method should call
// {@link //consume} before evaluating the predicate to ensure position
// sensitive values, including {@link Lexer//getText}, {@link Lexer//getLine},
// and {@link Lexer//getcolumn}, properly reflect the current
// lexer state. This method should restore {@code input} and the simulator
// to the original state before returning (i.e. undo the actions made by the
// call to {@link //consume}.</p>
//
// @param input The input stream.
// @param ruleIndex The rule containing the predicate.
// @param predIndex The index of the predicate within the rule.
// @param speculative {@code true} if the current index in {@code input} is
// one character before the predicate's location.
//
// @return {@code true} if the specified predicate evaluates to
// {@code true}.
// /
LexerATNSimulator.prototype.evaluatePredicate = function(input, ruleIndex,
		predIndex, speculative) {
	// assume true if no recognizer was provided
	if (this.recog === null) {
		return true;
	}
	if (!speculative) {
		return this.recog.sempred(null, ruleIndex, predIndex);
	}
	var savedcolumn = this.column;
	var savedLine = this.line;
	var index = input.index;
	var marker = input.mark();
	try {
		this.consume(input);
		return this.recog.sempred(null, ruleIndex, predIndex);
	} finally {
		this.column = savedcolumn;
		this.line = savedLine;
		input.seek(index);
		input.release(marker);
	}
};

LexerATNSimulator.prototype.captureSimState = function(settings, input, dfaState) {
	settings.index = input.index;
	settings.line = this.line;
	settings.column = this.column;
	settings.dfaState = dfaState;
};

LexerATNSimulator.prototype.addDFAEdge = function(from_, tk, to, cfgs) {
	if (to === undefined) {
		to = null;
	}
	if (cfgs === undefined) {
		cfgs = null;
	}
	if (to === null && cfgs !== null) {
		// leading to this call, ATNConfigSet.hasSemanticContext is used as a
		// marker indicating dynamic predicate evaluation makes this edge
		// dependent on the specific input sequence, so the static edge in the
		// DFA should be omitted. The target DFAState is still created since
		// execATN has the ability to resynchronize with the DFA state cache
		// following the predicate evaluation step.
		//
		// TJP notes: next time through the DFA, we see a pred again and eval.
		// If that gets us to a previously created (but dangling) DFA
		// state, we can continue in pure DFA mode from there.
		// /
		var suppressEdge = cfgs.hasSemanticContext;
		cfgs.hasSemanticContext = false;

		to = this.addDFAState(cfgs);

		if (suppressEdge) {
			return to;
		}
	}
	// add the edge
	if (tk < LexerATNSimulator.MIN_DFA_EDGE || tk > LexerATNSimulator.MAX_DFA_EDGE) {
		// Only track edges within the DFA bounds
		return to;
	}
	if (LexerATNSimulator.debug) {
		console.log("EDGE " + from_ + " -> " + to + " upon " + tk);
	}
	if (from_.edges === null) {
		// make room for tokens 1..n and -1 masquerading as index 0
		from_.edges = [];
	}
	from_.edges[tk - LexerATNSimulator.MIN_DFA_EDGE] = to; // connect

	return to;
};

// Add a new DFA state if there isn't one with this set of
// configurations already. This method also detects the first
// configuration containing an ATN rule stop state. Later, when
// traversing the DFA, we will know which rule to accept.
LexerATNSimulator.prototype.addDFAState = function(configs) {
	var proposed = new DFAState(null, configs);
	var firstConfigWithRuleStopState = null;
	for (var i = 0; i < configs.items.length; i++) {
		var cfg = configs.items[i];
		if (cfg.state instanceof RuleStopState) {
			firstConfigWithRuleStopState = cfg;
			break;
		}
	}
	if (firstConfigWithRuleStopState !== null) {
		proposed.isAcceptState = true;
		proposed.lexerActionExecutor = firstConfigWithRuleStopState.lexerActionExecutor;
		proposed.prediction = this.atn.ruleToTokenType[firstConfigWithRuleStopState.state.ruleIndex];
	}
	var dfa = this.decisionToDFA[this.mode];
	var existing = dfa.states.get(proposed);
	if (existing!==null) {
		return existing;
	}
	var newState = proposed;
	newState.stateNumber = dfa.states.length;
	configs.setReadonly(true);
	newState.configs = configs;
	dfa.states.add(newState);
	return newState;
};

LexerATNSimulator.prototype.getDFA = function(mode) {
	return this.decisionToDFA[mode];
};

// Get the text matched so far for the current token.
LexerATNSimulator.prototype.getText = function(input) {
	// index is first lookahead char, don't include.
	return input.getText(this.startIndex, input.index - 1);
};

LexerATNSimulator.prototype.consume = function(input) {
	var curChar = input.LA(1);
	if (curChar === "\n".charCodeAt(0)) {
		this.line += 1;
		this.column = 0;
	} else {
		this.column += 1;
	}
	input.consume();
};

LexerATNSimulator.prototype.getTokenName = function(tt) {
	if (tt === -1) {
		return "EOF";
	} else {
		return "'" + String.fromCharCode(tt) + "'";
	}
};

exports.LexerATNSimulator = LexerATNSimulator;

},{"./../Lexer":33,"./../PredictionContext":36,"./../Token":39,"./../dfa/DFAState":59,"./../error/Errors":64,"./ATN":41,"./ATNConfig":42,"./ATNConfigSet":43,"./ATNSimulator":46,"./ATNState":47,"./LexerActionExecutor":51,"./Transition":55}],50:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
 //

function LexerActionType() {
}

LexerActionType.CHANNEL = 0;     //The type of a {@link LexerChannelAction} action.
LexerActionType.CUSTOM = 1;      //The type of a {@link LexerCustomAction} action.
LexerActionType.MODE = 2;        //The type of a {@link LexerModeAction} action.
LexerActionType.MORE = 3;        //The type of a {@link LexerMoreAction} action.
LexerActionType.POP_MODE = 4;    //The type of a {@link LexerPopModeAction} action.
LexerActionType.PUSH_MODE = 5;   //The type of a {@link LexerPushModeAction} action.
LexerActionType.SKIP = 6;        //The type of a {@link LexerSkipAction} action.
LexerActionType.TYPE = 7;        //The type of a {@link LexerTypeAction} action.

function LexerAction(action) {
    this.actionType = action;
    this.isPositionDependent = false;
    return this;
}

LexerAction.prototype.hashCode = function() {
    var hash = new Hash();
    this.updateHashCode(hash);
    return hash.finish()
};

LexerAction.prototype.updateHashCode = function(hash) {
    hash.update(this.actionType);
};

LexerAction.prototype.equals = function(other) {
    return this === other;
};



//
// Implements the {@code skip} lexer action by calling {@link Lexer//skip}.
//
// <p>The {@code skip} command does not have any parameters, so this action is
// implemented as a singleton instance exposed by {@link //INSTANCE}.</p>
function LexerSkipAction() {
	LexerAction.call(this, LexerActionType.SKIP);
	return this;
}

LexerSkipAction.prototype = Object.create(LexerAction.prototype);
LexerSkipAction.prototype.constructor = LexerSkipAction;

// Provides a singleton instance of this parameterless lexer action.
LexerSkipAction.INSTANCE = new LexerSkipAction();

LexerSkipAction.prototype.execute = function(lexer) {
    lexer.skip();
};

LexerSkipAction.prototype.toString = function() {
	return "skip";
};

//  Implements the {@code type} lexer action by calling {@link Lexer//setType}
// with the assigned type.
function LexerTypeAction(type) {
	LexerAction.call(this, LexerActionType.TYPE);
	this.type = type;
	return this;
}

LexerTypeAction.prototype = Object.create(LexerAction.prototype);
LexerTypeAction.prototype.constructor = LexerTypeAction;

LexerTypeAction.prototype.execute = function(lexer) {
    lexer.type = this.type;
};

LexerTypeAction.prototype.updateHashCode = function(hash) {
    hash.update(this.actionType, this.type);
};


LexerTypeAction.prototype.equals = function(other) {
    if(this === other) {
        return true;
    } else if (! (other instanceof LexerTypeAction)) {
        return false;
    } else {
        return this.type === other.type;
    }
};

LexerTypeAction.prototype.toString = function() {
    return "type(" + this.type + ")";
};

// Implements the {@code pushMode} lexer action by calling
// {@link Lexer//pushMode} with the assigned mode.
function LexerPushModeAction(mode) {
	LexerAction.call(this, LexerActionType.PUSH_MODE);
    this.mode = mode;
    return this;
}

LexerPushModeAction.prototype = Object.create(LexerAction.prototype);
LexerPushModeAction.prototype.constructor = LexerPushModeAction;

// <p>This action is implemented by calling {@link Lexer//pushMode} with the
// value provided by {@link //getMode}.</p>
LexerPushModeAction.prototype.execute = function(lexer) {
    lexer.pushMode(this.mode);
};

LexerPushModeAction.prototype.updateHashCode = function(hash) {
    hash.update(this.actionType, this.mode);
};

LexerPushModeAction.prototype.equals = function(other) {
    if (this === other) {
        return true;
    } else if (! (other instanceof LexerPushModeAction)) {
        return false;
    } else {
        return this.mode === other.mode;
    }
};

LexerPushModeAction.prototype.toString = function() {
	return "pushMode(" + this.mode + ")";
};


// Implements the {@code popMode} lexer action by calling {@link Lexer//popMode}.
//
// <p>The {@code popMode} command does not have any parameters, so this action is
// implemented as a singleton instance exposed by {@link //INSTANCE}.</p>
function LexerPopModeAction() {
	LexerAction.call(this,LexerActionType.POP_MODE);
	return this;
}

LexerPopModeAction.prototype = Object.create(LexerAction.prototype);
LexerPopModeAction.prototype.constructor = LexerPopModeAction;

LexerPopModeAction.INSTANCE = new LexerPopModeAction();

// <p>This action is implemented by calling {@link Lexer//popMode}.</p>
LexerPopModeAction.prototype.execute = function(lexer) {
    lexer.popMode();
};

LexerPopModeAction.prototype.toString = function() {
	return "popMode";
};

// Implements the {@code more} lexer action by calling {@link Lexer//more}.
//
// <p>The {@code more} command does not have any parameters, so this action is
// implemented as a singleton instance exposed by {@link //INSTANCE}.</p>
function LexerMoreAction() {
	LexerAction.call(this, LexerActionType.MORE);
	return this;
}

LexerMoreAction.prototype = Object.create(LexerAction.prototype);
LexerMoreAction.prototype.constructor = LexerMoreAction;

LexerMoreAction.INSTANCE = new LexerMoreAction();

// <p>This action is implemented by calling {@link Lexer//popMode}.</p>
LexerMoreAction.prototype.execute = function(lexer) {
    lexer.more();
};

LexerMoreAction.prototype.toString = function() {
    return "more";
};


// Implements the {@code mode} lexer action by calling {@link Lexer//mode} with
// the assigned mode.
function LexerModeAction(mode) {
	LexerAction.call(this, LexerActionType.MODE);
    this.mode = mode;
    return this;
}

LexerModeAction.prototype = Object.create(LexerAction.prototype);
LexerModeAction.prototype.constructor = LexerModeAction;

// <p>This action is implemented by calling {@link Lexer//mode} with the
// value provided by {@link //getMode}.</p>
LexerModeAction.prototype.execute = function(lexer) {
    lexer.mode(this.mode);
};

LexerModeAction.prototype.updateHashCode = function(hash) {
    hash.update(this.actionType, this.mode);
};

LexerModeAction.prototype.equals = function(other) {
    if (this === other) {
        return true;
    } else if (! (other instanceof LexerModeAction)) {
        return false;
    } else {
        return this.mode === other.mode;
    }
};

LexerModeAction.prototype.toString = function() {
    return "mode(" + this.mode + ")";
};

// Executes a custom lexer action by calling {@link Recognizer//action} with the
// rule and action indexes assigned to the custom action. The implementation of
// a custom action is added to the generated code for the lexer in an override
// of {@link Recognizer//action} when the grammar is compiled.
//
// <p>This class may represent embedded actions created with the <code>{...}</code>
// syntax in ANTLR 4, as well as actions created for lexer commands where the
// command argument could not be evaluated when the grammar was compiled.</p>


    // Constructs a custom lexer action with the specified rule and action
    // indexes.
    //
    // @param ruleIndex The rule index to use for calls to
    // {@link Recognizer//action}.
    // @param actionIndex The action index to use for calls to
    // {@link Recognizer//action}.

function LexerCustomAction(ruleIndex, actionIndex) {
	LexerAction.call(this, LexerActionType.CUSTOM);
    this.ruleIndex = ruleIndex;
    this.actionIndex = actionIndex;
    this.isPositionDependent = true;
    return this;
}

LexerCustomAction.prototype = Object.create(LexerAction.prototype);
LexerCustomAction.prototype.constructor = LexerCustomAction;

// <p>Custom actions are implemented by calling {@link Lexer//action} with the
// appropriate rule and action indexes.</p>
LexerCustomAction.prototype.execute = function(lexer) {
    lexer.action(null, this.ruleIndex, this.actionIndex);
};

LexerCustomAction.prototype.updateHashCode = function(hash) {
    hash.update(this.actionType, this.ruleIndex, this.actionIndex);
};

LexerCustomAction.prototype.equals = function(other) {
    if (this === other) {
        return true;
    } else if (! (other instanceof LexerCustomAction)) {
        return false;
    } else {
        return this.ruleIndex === other.ruleIndex && this.actionIndex === other.actionIndex;
    }
};

// Implements the {@code channel} lexer action by calling
// {@link Lexer//setChannel} with the assigned channel.
// Constructs a new {@code channel} action with the specified channel value.
// @param channel The channel value to pass to {@link Lexer//setChannel}.
function LexerChannelAction(channel) {
	LexerAction.call(this, LexerActionType.CHANNEL);
    this.channel = channel;
    return this;
}

LexerChannelAction.prototype = Object.create(LexerAction.prototype);
LexerChannelAction.prototype.constructor = LexerChannelAction;

// <p>This action is implemented by calling {@link Lexer//setChannel} with the
// value provided by {@link //getChannel}.</p>
LexerChannelAction.prototype.execute = function(lexer) {
    lexer._channel = this.channel;
};

LexerChannelAction.prototype.updateHashCode = function(hash) {
    hash.update(this.actionType, this.channel);
};

LexerChannelAction.prototype.equals = function(other) {
    if (this === other) {
        return true;
    } else if (! (other instanceof LexerChannelAction)) {
        return false;
    } else {
        return this.channel === other.channel;
    }
};

LexerChannelAction.prototype.toString = function() {
    return "channel(" + this.channel + ")";
};

// This implementation of {@link LexerAction} is used for tracking input offsets
// for position-dependent actions within a {@link LexerActionExecutor}.
//
// <p>This action is not serialized as part of the ATN, and is only required for
// position-dependent lexer actions which appear at a location other than the
// end of a rule. For more information about DFA optimizations employed for
// lexer actions, see {@link LexerActionExecutor//append} and
// {@link LexerActionExecutor//fixOffsetBeforeMatch}.</p>

// Constructs a new indexed custom action by associating a character offset
// with a {@link LexerAction}.
//
// <p>Note: This class is only required for lexer actions for which
// {@link LexerAction//isPositionDependent} returns {@code true}.</p>
//
// @param offset The offset into the input {@link CharStream}, relative to
// the token start index, at which the specified lexer action should be
// executed.
// @param action The lexer action to execute at a particular offset in the
// input {@link CharStream}.
function LexerIndexedCustomAction(offset, action) {
	LexerAction.call(this, action.actionType);
    this.offset = offset;
    this.action = action;
    this.isPositionDependent = true;
    return this;
}

LexerIndexedCustomAction.prototype = Object.create(LexerAction.prototype);
LexerIndexedCustomAction.prototype.constructor = LexerIndexedCustomAction;

// <p>This method calls {@link //execute} on the result of {@link //getAction}
// using the provided {@code lexer}.</p>
LexerIndexedCustomAction.prototype.execute = function(lexer) {
    // assume the input stream position was properly set by the calling code
    this.action.execute(lexer);
};

LexerIndexedCustomAction.prototype.updateHashCode = function(hash) {
    hash.update(this.actionType, this.offset, this.action);
};

LexerIndexedCustomAction.prototype.equals = function(other) {
    if (this === other) {
        return true;
    } else if (! (other instanceof LexerIndexedCustomAction)) {
        return false;
    } else {
        return this.offset === other.offset && this.action === other.action;
    }
};


exports.LexerActionType = LexerActionType;
exports.LexerSkipAction = LexerSkipAction;
exports.LexerChannelAction = LexerChannelAction;
exports.LexerCustomAction = LexerCustomAction;
exports.LexerIndexedCustomAction = LexerIndexedCustomAction;
exports.LexerMoreAction = LexerMoreAction;
exports.LexerTypeAction = LexerTypeAction;
exports.LexerPushModeAction = LexerPushModeAction;
exports.LexerPopModeAction = LexerPopModeAction;
exports.LexerModeAction = LexerModeAction;
},{}],51:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
///

// Represents an executor for a sequence of lexer actions which traversed during
// the matching operation of a lexer rule (token).
//
// <p>The executor tracks position information for position-dependent lexer actions
// efficiently, ensuring that actions appearing only at the end of the rule do
// not cause bloating of the {@link DFA} created for the lexer.</p>

var hashStuff = require("../Utils").hashStuff;
var LexerIndexedCustomAction = require('./LexerAction').LexerIndexedCustomAction;

function LexerActionExecutor(lexerActions) {
	this.lexerActions = lexerActions === null ? [] : lexerActions;
	// Caches the result of {@link //hashCode} since the hash code is an element
	// of the performance-critical {@link LexerATNConfig//hashCode} operation.
	this.cachedHashCode = hashStuff(lexerActions); // "".join([str(la) for la in
	// lexerActions]))
	return this;
}

// Creates a {@link LexerActionExecutor} which executes the actions for
// the input {@code lexerActionExecutor} followed by a specified
// {@code lexerAction}.
//
// @param lexerActionExecutor The executor for actions already traversed by
// the lexer while matching a token within a particular
// {@link LexerATNConfig}. If this is {@code null}, the method behaves as
// though it were an empty executor.
// @param lexerAction The lexer action to execute after the actions
// specified in {@code lexerActionExecutor}.
//
// @return A {@link LexerActionExecutor} for executing the combine actions
// of {@code lexerActionExecutor} and {@code lexerAction}.
LexerActionExecutor.append = function(lexerActionExecutor, lexerAction) {
	if (lexerActionExecutor === null) {
		return new LexerActionExecutor([ lexerAction ]);
	}
	var lexerActions = lexerActionExecutor.lexerActions.concat([ lexerAction ]);
	return new LexerActionExecutor(lexerActions);
};

// Creates a {@link LexerActionExecutor} which encodes the current offset
// for position-dependent lexer actions.
//
// <p>Normally, when the executor encounters lexer actions where
// {@link LexerAction//isPositionDependent} returns {@code true}, it calls
// {@link IntStream//seek} on the input {@link CharStream} to set the input
// position to the <em>end</em> of the current token. This behavior provides
// for efficient DFA representation of lexer actions which appear at the end
// of a lexer rule, even when the lexer rule matches a variable number of
// characters.</p>
//
// <p>Prior to traversing a match transition in the ATN, the current offset
// from the token start index is assigned to all position-dependent lexer
// actions which have not already been assigned a fixed offset. By storing
// the offsets relative to the token start index, the DFA representation of
// lexer actions which appear in the middle of tokens remains efficient due
// to sharing among tokens of the same length, regardless of their absolute
// position in the input stream.</p>
//
// <p>If the current executor already has offsets assigned to all
// position-dependent lexer actions, the method returns {@code this}.</p>
//
// @param offset The current offset to assign to all position-dependent
// lexer actions which do not already have offsets assigned.
//
// @return A {@link LexerActionExecutor} which stores input stream offsets
// for all position-dependent lexer actions.
// /
LexerActionExecutor.prototype.fixOffsetBeforeMatch = function(offset) {
	var updatedLexerActions = null;
	for (var i = 0; i < this.lexerActions.length; i++) {
		if (this.lexerActions[i].isPositionDependent &&
				!(this.lexerActions[i] instanceof LexerIndexedCustomAction)) {
			if (updatedLexerActions === null) {
				updatedLexerActions = this.lexerActions.concat([]);
			}
			updatedLexerActions[i] = new LexerIndexedCustomAction(offset,
					this.lexerActions[i]);
		}
	}
	if (updatedLexerActions === null) {
		return this;
	} else {
		return new LexerActionExecutor(updatedLexerActions);
	}
};

// Execute the actions encapsulated by this executor within the context of a
// particular {@link Lexer}.
//
// <p>This method calls {@link IntStream//seek} to set the position of the
// {@code input} {@link CharStream} prior to calling
// {@link LexerAction//execute} on a position-dependent action. Before the
// method returns, the input position will be restored to the same position
// it was in when the method was invoked.</p>
//
// @param lexer The lexer instance.
// @param input The input stream which is the source for the current token.
// When this method is called, the current {@link IntStream//index} for
// {@code input} should be the start of the following token, i.e. 1
// character past the end of the current token.
// @param startIndex The token start index. This value may be passed to
// {@link IntStream//seek} to set the {@code input} position to the beginning
// of the token.
// /
LexerActionExecutor.prototype.execute = function(lexer, input, startIndex) {
	var requiresSeek = false;
	var stopIndex = input.index;
	try {
		for (var i = 0; i < this.lexerActions.length; i++) {
			var lexerAction = this.lexerActions[i];
			if (lexerAction instanceof LexerIndexedCustomAction) {
				var offset = lexerAction.offset;
				input.seek(startIndex + offset);
				lexerAction = lexerAction.action;
				requiresSeek = (startIndex + offset) !== stopIndex;
			} else if (lexerAction.isPositionDependent) {
				input.seek(stopIndex);
				requiresSeek = false;
			}
			lexerAction.execute(lexer);
		}
	} finally {
		if (requiresSeek) {
			input.seek(stopIndex);
		}
	}
};

LexerActionExecutor.prototype.hashCode = function() {
	return this.cachedHashCode;
};

LexerActionExecutor.prototype.updateHashCode = function(hash) {
    hash.update(this.cachedHashCode);
};


LexerActionExecutor.prototype.equals = function(other) {
	if (this === other) {
		return true;
	} else if (!(other instanceof LexerActionExecutor)) {
		return false;
	} else if (this.cachedHashCode != other.cachedHashCode) {
		return false;
	} else if (this.lexerActions.length != other.lexerActions.length) {
		return false;
	} else {
		var numActions = this.lexerActions.length
		for (var idx = 0; idx < numActions; ++idx) {
			if (!this.lexerActions[idx].equals(other.lexerActions[idx])) {
				return false;
			}
		}
		return true;
	}
};

exports.LexerActionExecutor = LexerActionExecutor;

},{"../Utils":40,"./LexerAction":50}],52:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
//

//
// The embodiment of the adaptive LL(*), ALL(*), parsing strategy.
//
// <p>
// The basic complexity of the adaptive strategy makes it harder to understand.
// We begin with ATN simulation to build paths in a DFA. Subsequent prediction
// requests go through the DFA first. If they reach a state without an edge for
// the current symbol, the algorithm fails over to the ATN simulation to
// complete the DFA path for the current input (until it finds a conflict state
// or uniquely predicting state).</p>
//
// <p>
// All of that is done without using the outer context because we want to create
// a DFA that is not dependent upon the rule invocation stack when we do a
// prediction. One DFA works in all contexts. We avoid using context not
// necessarily because it's slower, although it can be, but because of the DFA
// caching problem. The closure routine only considers the rule invocation stack
// created during prediction beginning in the decision rule. For example, if
// prediction occurs without invoking another rule's ATN, there are no context
// stacks in the configurations. When lack of context leads to a conflict, we
// don't know if it's an ambiguity or a weakness in the strong LL(*) parsing
// strategy (versus full LL(*)).</p>
//
// <p>
// When SLL yields a configuration set with conflict, we rewind the input and
// retry the ATN simulation, this time using full outer context without adding
// to the DFA. Configuration context stacks will be the full invocation stacks
// from the start rule. If we get a conflict using full context, then we can
// definitively say we have a true ambiguity for that input sequence. If we
// don't get a conflict, it implies that the decision is sensitive to the outer
// context. (It is not context-sensitive in the sense of context-sensitive
// grammars.)</p>
//
// <p>
// The next time we reach this DFA state with an SLL conflict, through DFA
// simulation, we will again retry the ATN simulation using full context mode.
// This is slow because we can't save the results and have to "interpret" the
// ATN each time we get that input.</p>
//
// <p>
// <strong>CACHING FULL CONTEXT PREDICTIONS</strong></p>
//
// <p>
// We could cache results from full context to predicted alternative easily and
// that saves a lot of time but doesn't work in presence of predicates. The set
// of visible predicates from the ATN start state changes depending on the
// context, because closure can fall off the end of a rule. I tried to cache
// tuples (stack context, semantic context, predicted alt) but it was slower
// than interpreting and much more complicated. Also required a huge amount of
// memory. The goal is not to create the world's fastest parser anyway. I'd like
// to keep this algorithm simple. By launching multiple threads, we can improve
// the speed of parsing across a large number of files.</p>
//
// <p>
// There is no strict ordering between the amount of input used by SLL vs LL,
// which makes it really hard to build a cache for full context. Let's say that
// we have input A B C that leads to an SLL conflict with full context X. That
// implies that using X we might only use A B but we could also use A B C D to
// resolve conflict. Input A B C D could predict alternative 1 in one position
// in the input and A B C E could predict alternative 2 in another position in
// input. The conflicting SLL configurations could still be non-unique in the
// full context prediction, which would lead us to requiring more input than the
// original A B C.	To make a	prediction cache work, we have to track	the exact
// input	used during the previous prediction. That amounts to a cache that maps
// X to a specific DFA for that context.</p>
//
// <p>
// Something should be done for left-recursive expression predictions. They are
// likely LL(1) + pred eval. Easier to do the whole SLL unless error and retry
// with full LL thing Sam does.</p>
//
// <p>
// <strong>AVOIDING FULL CONTEXT PREDICTION</strong></p>
//
// <p>
// We avoid doing full context retry when the outer context is empty, we did not
// dip into the outer context by falling off the end of the decision state rule,
// or when we force SLL mode.</p>
//
// <p>
// As an example of the not dip into outer context case, consider as super
// constructor calls versus function calls. One grammar might look like
// this:</p>
//
// <pre>
// ctorBody
//   : '{' superCall? stat* '}'
//   ;
// </pre>
//
// <p>
// Or, you might see something like</p>
//
// <pre>
// stat
//   : superCall ';'
//   | expression ';'
//   | ...
//   ;
// </pre>
//
// <p>
// In both cases I believe that no closure operations will dip into the outer
// context. In the first case ctorBody in the worst case will stop at the '}'.
// In the 2nd case it should stop at the ';'. Both cases should stay within the
// entry rule and not dip into the outer context.</p>
//
// <p>
// <strong>PREDICATES</strong></p>
//
// <p>
// Predicates are always evaluated if present in either SLL or LL both. SLL and
// LL simulation deals with predicates differently. SLL collects predicates as
// it performs closure operations like ANTLR v3 did. It delays predicate
// evaluation until it reaches and accept state. This allows us to cache the SLL
// ATN simulation whereas, if we had evaluated predicates on-the-fly during
// closure, the DFA state configuration sets would be different and we couldn't
// build up a suitable DFA.</p>
//
// <p>
// When building a DFA accept state during ATN simulation, we evaluate any
// predicates and return the sole semantically valid alternative. If there is
// more than 1 alternative, we report an ambiguity. If there are 0 alternatives,
// we throw an exception. Alternatives without predicates act like they have
// true predicates. The simple way to think about it is to strip away all
// alternatives with false predicates and choose the minimum alternative that
// remains.</p>
//
// <p>
// When we start in the DFA and reach an accept state that's predicated, we test
// those and return the minimum semantically viable alternative. If no
// alternatives are viable, we throw an exception.</p>
//
// <p>
// During full LL ATN simulation, closure always evaluates predicates and
// on-the-fly. This is crucial to reducing the configuration set size during
// closure. It hits a landmine when parsing with the Java grammar, for example,
// without this on-the-fly evaluation.</p>
//
// <p>
// <strong>SHARING DFA</strong></p>
//
// <p>
// All instances of the same parser share the same decision DFAs through a
// static field. Each instance gets its own ATN simulator but they share the
// same {@link //decisionToDFA} field. They also share a
// {@link PredictionContextCache} object that makes sure that all
// {@link PredictionContext} objects are shared among the DFA states. This makes
// a big size difference.</p>
//
// <p>
// <strong>THREAD SAFETY</strong></p>
//
// <p>
// The {@link ParserATNSimulator} locks on the {@link //decisionToDFA} field when
// it adds a new DFA object to that array. {@link //addDFAEdge}
// locks on the DFA for the current decision when setting the
// {@link DFAState//edges} field. {@link //addDFAState} locks on
// the DFA for the current decision when looking up a DFA state to see if it
// already exists. We must make sure that all requests to add DFA states that
// are equivalent result in the same shared DFA object. This is because lots of
// threads will be trying to update the DFA at once. The
// {@link //addDFAState} method also locks inside the DFA lock
// but this time on the shared context cache when it rebuilds the
// configurations' {@link PredictionContext} objects using cached
// subgraphs/nodes. No other locking occurs, even during DFA simulation. This is
// safe as long as we can guarantee that all threads referencing
// {@code s.edge[t]} get the same physical target {@link DFAState}, or
// {@code null}. Once into the DFA, the DFA simulation does not reference the
// {@link DFA//states} map. It follows the {@link DFAState//edges} field to new
// targets. The DFA simulator will either find {@link DFAState//edges} to be
// {@code null}, to be non-{@code null} and {@code dfa.edges[t]} null, or
// {@code dfa.edges[t]} to be non-null. The
// {@link //addDFAEdge} method could be racing to set the field
// but in either case the DFA simulator works; if {@code null}, and requests ATN
// simulation. It could also race trying to get {@code dfa.edges[t]}, but either
// way it will work because it's not doing a test and set operation.</p>
//
// <p>
// <strong>Starting with SLL then failing to combined SLL/LL (Two-Stage
// Parsing)</strong></p>
//
// <p>
// Sam pointed out that if SLL does not give a syntax error, then there is no
// point in doing full LL, which is slower. We only have to try LL if we get a
// syntax error. For maximum speed, Sam starts the parser set to pure SLL
// mode with the {@link BailErrorStrategy}:</p>
//
// <pre>
// parser.{@link Parser//getInterpreter() getInterpreter()}.{@link //setPredictionMode setPredictionMode}{@code (}{@link PredictionMode//SLL}{@code )};
// parser.{@link Parser//setErrorHandler setErrorHandler}(new {@link BailErrorStrategy}());
// </pre>
//
// <p>
// If it does not get a syntax error, then we're done. If it does get a syntax
// error, we need to retry with the combined SLL/LL strategy.</p>
//
// <p>
// The reason this works is as follows. If there are no SLL conflicts, then the
// grammar is SLL (at least for that input set). If there is an SLL conflict,
// the full LL analysis must yield a set of viable alternatives which is a
// subset of the alternatives reported by SLL. If the LL set is a singleton,
// then the grammar is LL but not SLL. If the LL set is the same size as the SLL
// set, the decision is SLL. If the LL set has size &gt; 1, then that decision
// is truly ambiguous on the current input. If the LL set is smaller, then the
// SLL conflict resolution might choose an alternative that the full LL would
// rule out as a possibility based upon better context information. If that's
// the case, then the SLL parse will definitely get an error because the full LL
// analysis says it's not viable. If SLL conflict resolution chooses an
// alternative within the LL set, them both SLL and LL would choose the same
// alternative because they both choose the minimum of multiple conflicting
// alternatives.</p>
//
// <p>
// Let's say we have a set of SLL conflicting alternatives {@code {1, 2, 3}} and
// a smaller LL set called <em>s</em>. If <em>s</em> is {@code {2, 3}}, then SLL
// parsing will get an error because SLL will pursue alternative 1. If
// <em>s</em> is {@code {1, 2}} or {@code {1, 3}} then both SLL and LL will
// choose the same alternative because alternative one is the minimum of either
// set. If <em>s</em> is {@code {2}} or {@code {3}} then SLL will get a syntax
// error. If <em>s</em> is {@code {1}} then SLL will succeed.</p>
//
// <p>
// Of course, if the input is invalid, then we will get an error for sure in
// both SLL and LL parsing. Erroneous input will therefore require 2 passes over
// the input.</p>
//

var Utils = require('./../Utils');
var Set = Utils.Set;
var BitSet = Utils.BitSet;
var DoubleDict = Utils.DoubleDict;
var ATN = require('./ATN').ATN;
var ATNState = require('./ATNState').ATNState;
var ATNConfig = require('./ATNConfig').ATNConfig;
var ATNConfigSet = require('./ATNConfigSet').ATNConfigSet;
var Token = require('./../Token').Token;
var DFAState = require('./../dfa/DFAState').DFAState;
var PredPrediction = require('./../dfa/DFAState').PredPrediction;
var ATNSimulator = require('./ATNSimulator').ATNSimulator;
var PredictionMode = require('./PredictionMode').PredictionMode;
var RuleContext = require('./../RuleContext').RuleContext;
var ParserRuleContext = require('./../ParserRuleContext').ParserRuleContext;
var SemanticContext = require('./SemanticContext').SemanticContext;
var StarLoopEntryState = require('./ATNState').StarLoopEntryState;
var RuleStopState = require('./ATNState').RuleStopState;
var PredictionContext = require('./../PredictionContext').PredictionContext;
var Interval = require('./../IntervalSet').Interval;
var Transitions = require('./Transition');
var Transition = Transitions.Transition;
var SetTransition = Transitions.SetTransition;
var NotSetTransition = Transitions.NotSetTransition;
var RuleTransition = Transitions.RuleTransition;
var ActionTransition = Transitions.ActionTransition;
var NoViableAltException = require('./../error/Errors').NoViableAltException;

var SingletonPredictionContext = require('./../PredictionContext').SingletonPredictionContext;
var predictionContextFromRuleContext = require('./../PredictionContext').predictionContextFromRuleContext;

function ParserATNSimulator(parser, atn, decisionToDFA, sharedContextCache) {
	ATNSimulator.call(this, atn, sharedContextCache);
    this.parser = parser;
    this.decisionToDFA = decisionToDFA;
    // SLL, LL, or LL + exact ambig detection?//
    this.predictionMode = PredictionMode.LL;
    // LAME globals to avoid parameters!!!!! I need these down deep in predTransition
    this._input = null;
    this._startIndex = 0;
    this._outerContext = null;
    this._dfa = null;
    // Each prediction operation uses a cache for merge of prediction contexts.
    //  Don't keep around as it wastes huge amounts of memory. DoubleKeyMap
    //  isn't synchronized but we're ok since two threads shouldn't reuse same
    //  parser/atnsim object because it can only handle one input at a time.
    //  This maps graphs a and b to merged result c. (a,b)&rarr;c. We can avoid
    //  the merge if we ever see a and b again.  Note that (b,a)&rarr;c should
    //  also be examined during cache lookup.
    //
    this.mergeCache = null;
    return this;
}

ParserATNSimulator.prototype = Object.create(ATNSimulator.prototype);
ParserATNSimulator.prototype.constructor = ParserATNSimulator;

ParserATNSimulator.prototype.debug = false;
ParserATNSimulator.prototype.debug_closure = false;
ParserATNSimulator.prototype.debug_add = false;
ParserATNSimulator.prototype.debug_list_atn_decisions = false;
ParserATNSimulator.prototype.dfa_debug = false;
ParserATNSimulator.prototype.retry_debug = false;


ParserATNSimulator.prototype.reset = function() {
};

ParserATNSimulator.prototype.adaptivePredict = function(input, decision, outerContext) {
    if (this.debug || this.debug_list_atn_decisions) {
        console.log("adaptivePredict decision " + decision +
                               " exec LA(1)==" + this.getLookaheadName(input) +
                               " line " + input.LT(1).line + ":" +
                               input.LT(1).column);
    }
    this._input = input;
    this._startIndex = input.index;
    this._outerContext = outerContext;

    var dfa = this.decisionToDFA[decision];
    this._dfa = dfa;
    var m = input.mark();
    var index = input.index;

    // Now we are certain to have a specific decision's DFA
    // But, do we still need an initial state?
    try {
        var s0;
        if (dfa.precedenceDfa) {
            // the start state for a precedence DFA depends on the current
            // parser precedence, and is provided by a DFA method.
            s0 = dfa.getPrecedenceStartState(this.parser.getPrecedence());
        } else {
            // the start state for a "regular" DFA is just s0
            s0 = dfa.s0;
        }
        if (s0===null) {
            if (outerContext===null) {
                outerContext = RuleContext.EMPTY;
            }
            if (this.debug || this.debug_list_atn_decisions) {
                console.log("predictATN decision " + dfa.decision +
                                   " exec LA(1)==" + this.getLookaheadName(input) +
                                   ", outerContext=" + outerContext.toString(this.parser.ruleNames));
            }

            var fullCtx = false;
            var s0_closure = this.computeStartState(dfa.atnStartState, RuleContext.EMPTY, fullCtx);

            if( dfa.precedenceDfa) {
                // If this is a precedence DFA, we use applyPrecedenceFilter
                // to convert the computed start state to a precedence start
                // state. We then use DFA.setPrecedenceStartState to set the
                // appropriate start state for the precedence level rather
                // than simply setting DFA.s0.
                //
                dfa.s0.configs = s0_closure; // not used for prediction but useful to know start configs anyway
                s0_closure = this.applyPrecedenceFilter(s0_closure);
                s0 = this.addDFAState(dfa, new DFAState(null, s0_closure));
                dfa.setPrecedenceStartState(this.parser.getPrecedence(), s0);
            } else {
                s0 = this.addDFAState(dfa, new DFAState(null, s0_closure));
                dfa.s0 = s0;
            }
        }
        var alt = this.execATN(dfa, s0, input, index, outerContext);
        if (this.debug) {
            console.log("DFA after predictATN: " + dfa.toString(this.parser.literalNames));
        }
        return alt;
    } finally {
        this._dfa = null;
        this.mergeCache = null; // wack cache after each prediction
        input.seek(index);
        input.release(m);
    }
};
// Performs ATN simulation to compute a predicted alternative based
//  upon the remaining input, but also updates the DFA cache to avoid
//  having to traverse the ATN again for the same input sequence.

// There are some key conditions we're looking for after computing a new
// set of ATN configs (proposed DFA state):
      // if the set is empty, there is no viable alternative for current symbol
      // does the state uniquely predict an alternative?
      // does the state have a conflict that would prevent us from
      //   putting it on the work list?

// We also have some key operations to do:
      // add an edge from previous DFA state to potentially new DFA state, D,
      //   upon current symbol but only if adding to work list, which means in all
      //   cases except no viable alternative (and possibly non-greedy decisions?)
      // collecting predicates and adding semantic context to DFA accept states
      // adding rule context to context-sensitive DFA accept states
      // consuming an input symbol
      // reporting a conflict
      // reporting an ambiguity
      // reporting a context sensitivity
      // reporting insufficient predicates

// cover these cases:
//    dead end
//    single alt
//    single alt + preds
//    conflict
//    conflict + preds
//
ParserATNSimulator.prototype.execATN = function(dfa, s0, input, startIndex, outerContext ) {
    if (this.debug || this.debug_list_atn_decisions) {
        console.log("execATN decision " + dfa.decision +
                " exec LA(1)==" + this.getLookaheadName(input) +
                " line " + input.LT(1).line + ":" + input.LT(1).column);
    }
    var alt;
    var previousD = s0;

    if (this.debug) {
        console.log("s0 = " + s0);
    }
    var t = input.LA(1);
    while(true) { // while more work
        var D = this.getExistingTargetState(previousD, t);
        if(D===null) {
            D = this.computeTargetState(dfa, previousD, t);
        }
        if(D===ATNSimulator.ERROR) {
            // if any configs in previous dipped into outer context, that
            // means that input up to t actually finished entry rule
            // at least for SLL decision. Full LL doesn't dip into outer
            // so don't need special case.
            // We will get an error no matter what so delay until after
            // decision; better error message. Also, no reachable target
            // ATN states in SLL implies LL will also get nowhere.
            // If conflict in states that dip out, choose min since we
            // will get error no matter what.
            var e = this.noViableAlt(input, outerContext, previousD.configs, startIndex);
            input.seek(startIndex);
            alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previousD.configs, outerContext);
            if(alt!==ATN.INVALID_ALT_NUMBER) {
                return alt;
            } else {
                throw e;
            }
        }
        if(D.requiresFullContext && this.predictionMode !== PredictionMode.SLL) {
            // IF PREDS, MIGHT RESOLVE TO SINGLE ALT => SLL (or syntax error)
            var conflictingAlts = null;
            if (D.predicates!==null) {
                if (this.debug) {
                    console.log("DFA state has preds in DFA sim LL failover");
                }
                var conflictIndex = input.index;
                if(conflictIndex !== startIndex) {
                    input.seek(startIndex);
                }
                conflictingAlts = this.evalSemanticContext(D.predicates, outerContext, true);
                if (conflictingAlts.length===1) {
                    if(this.debug) {
                        console.log("Full LL avoided");
                    }
                    return conflictingAlts.minValue();
                }
                if (conflictIndex !== startIndex) {
                    // restore the index so reporting the fallback to full
                    // context occurs with the index at the correct spot
                    input.seek(conflictIndex);
                }
            }
            if (this.dfa_debug) {
                console.log("ctx sensitive state " + outerContext +" in " + D);
            }
            var fullCtx = true;
            var s0_closure = this.computeStartState(dfa.atnStartState, outerContext, fullCtx);
            this.reportAttemptingFullContext(dfa, conflictingAlts, D.configs, startIndex, input.index);
            alt = this.execATNWithFullContext(dfa, D, s0_closure, input, startIndex, outerContext);
            return alt;
        }
        if (D.isAcceptState) {
            if (D.predicates===null) {
                return D.prediction;
            }
            var stopIndex = input.index;
            input.seek(startIndex);
            var alts = this.evalSemanticContext(D.predicates, outerContext, true);
            if (alts.length===0) {
                throw this.noViableAlt(input, outerContext, D.configs, startIndex);
            } else if (alts.length===1) {
                return alts.minValue();
            } else {
                // report ambiguity after predicate evaluation to make sure the correct set of ambig alts is reported.
                this.reportAmbiguity(dfa, D, startIndex, stopIndex, false, alts, D.configs);
                return alts.minValue();
            }
        }
        previousD = D;

        if (t !== Token.EOF) {
            input.consume();
            t = input.LA(1);
        }
    }
};
//
// Get an existing target state for an edge in the DFA. If the target state
// for the edge has not yet been computed or is otherwise not available,
// this method returns {@code null}.
//
// @param previousD The current DFA state
// @param t The next input symbol
// @return The existing target DFA state for the given input symbol
// {@code t}, or {@code null} if the target state for this edge is not
// already cached
//
ParserATNSimulator.prototype.getExistingTargetState = function(previousD, t) {
    var edges = previousD.edges;
    if (edges===null) {
        return null;
    } else {
        return edges[t + 1] || null;
    }
};
//
// Compute a target state for an edge in the DFA, and attempt to add the
// computed state and corresponding edge to the DFA.
//
// @param dfa The DFA
// @param previousD The current DFA state
// @param t The next input symbol
//
// @return The computed target DFA state for the given input symbol
// {@code t}. If {@code t} does not lead to a valid DFA state, this method
// returns {@link //ERROR}.
//
ParserATNSimulator.prototype.computeTargetState = function(dfa, previousD, t) {
   var reach = this.computeReachSet(previousD.configs, t, false);
    if(reach===null) {
        this.addDFAEdge(dfa, previousD, t, ATNSimulator.ERROR);
        return ATNSimulator.ERROR;
    }
    // create new target state; we'll add to DFA after it's complete
    var D = new DFAState(null, reach);

    var predictedAlt = this.getUniqueAlt(reach);

    if (this.debug) {
        var altSubSets = PredictionMode.getConflictingAltSubsets(reach);
        console.log("SLL altSubSets=" + Utils.arrayToString(altSubSets) +
                    ", previous=" + previousD.configs +
                    ", configs=" + reach +
                    ", predict=" + predictedAlt +
                    ", allSubsetsConflict=" +
                    PredictionMode.allSubsetsConflict(altSubSets) + ", conflictingAlts=" +
                    this.getConflictingAlts(reach));
    }
    if (predictedAlt!==ATN.INVALID_ALT_NUMBER) {
        // NO CONFLICT, UNIQUELY PREDICTED ALT
        D.isAcceptState = true;
        D.configs.uniqueAlt = predictedAlt;
        D.prediction = predictedAlt;
    } else if (PredictionMode.hasSLLConflictTerminatingPrediction(this.predictionMode, reach)) {
        // MORE THAN ONE VIABLE ALTERNATIVE
        D.configs.conflictingAlts = this.getConflictingAlts(reach);
        D.requiresFullContext = true;
        // in SLL-only mode, we will stop at this state and return the minimum alt
        D.isAcceptState = true;
        D.prediction = D.configs.conflictingAlts.minValue();
    }
    if (D.isAcceptState && D.configs.hasSemanticContext) {
        this.predicateDFAState(D, this.atn.getDecisionState(dfa.decision));
        if( D.predicates!==null) {
            D.prediction = ATN.INVALID_ALT_NUMBER;
        }
    }
    // all adds to dfa are done after we've created full D state
    D = this.addDFAEdge(dfa, previousD, t, D);
    return D;
};

ParserATNSimulator.prototype.predicateDFAState = function(dfaState, decisionState) {
    // We need to test all predicates, even in DFA states that
    // uniquely predict alternative.
    var nalts = decisionState.transitions.length;
    // Update DFA so reach becomes accept state with (predicate,alt)
    // pairs if preds found for conflicting alts
    var altsToCollectPredsFrom = this.getConflictingAltsOrUniqueAlt(dfaState.configs);
    var altToPred = this.getPredsForAmbigAlts(altsToCollectPredsFrom, dfaState.configs, nalts);
    if (altToPred!==null) {
        dfaState.predicates = this.getPredicatePredictions(altsToCollectPredsFrom, altToPred);
        dfaState.prediction = ATN.INVALID_ALT_NUMBER; // make sure we use preds
    } else {
        // There are preds in configs but they might go away
        // when OR'd together like {p}? || NONE == NONE. If neither
        // alt has preds, resolve to min alt
        dfaState.prediction = altsToCollectPredsFrom.minValue();
    }
};

// comes back with reach.uniqueAlt set to a valid alt
ParserATNSimulator.prototype.execATNWithFullContext = function(dfa, D, // how far we got before failing over
                                     s0,
                                     input,
                                     startIndex,
                                     outerContext) {
    if (this.debug || this.debug_list_atn_decisions) {
        console.log("execATNWithFullContext "+s0);
    }
    var fullCtx = true;
    var foundExactAmbig = false;
    var reach = null;
    var previous = s0;
    input.seek(startIndex);
    var t = input.LA(1);
    var predictedAlt = -1;
    while (true) { // while more work
        reach = this.computeReachSet(previous, t, fullCtx);
        if (reach===null) {
            // if any configs in previous dipped into outer context, that
            // means that input up to t actually finished entry rule
            // at least for LL decision. Full LL doesn't dip into outer
            // so don't need special case.
            // We will get an error no matter what so delay until after
            // decision; better error message. Also, no reachable target
            // ATN states in SLL implies LL will also get nowhere.
            // If conflict in states that dip out, choose min since we
            // will get error no matter what.
            var e = this.noViableAlt(input, outerContext, previous, startIndex);
            input.seek(startIndex);
            var alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previous, outerContext);
            if(alt!==ATN.INVALID_ALT_NUMBER) {
                return alt;
            } else {
                throw e;
            }
        }
        var altSubSets = PredictionMode.getConflictingAltSubsets(reach);
        if(this.debug) {
            console.log("LL altSubSets=" + altSubSets + ", predict=" +
                  PredictionMode.getUniqueAlt(altSubSets) + ", resolvesToJustOneViableAlt=" +
                  PredictionMode.resolvesToJustOneViableAlt(altSubSets));
        }
        reach.uniqueAlt = this.getUniqueAlt(reach);
        // unique prediction?
        if(reach.uniqueAlt!==ATN.INVALID_ALT_NUMBER) {
            predictedAlt = reach.uniqueAlt;
            break;
        } else if (this.predictionMode !== PredictionMode.LL_EXACT_AMBIG_DETECTION) {
            predictedAlt = PredictionMode.resolvesToJustOneViableAlt(altSubSets);
            if(predictedAlt !== ATN.INVALID_ALT_NUMBER) {
                break;
            }
        } else {
            // In exact ambiguity mode, we never try to terminate early.
            // Just keeps scarfing until we know what the conflict is
            if (PredictionMode.allSubsetsConflict(altSubSets) && PredictionMode.allSubsetsEqual(altSubSets)) {
                foundExactAmbig = true;
                predictedAlt = PredictionMode.getSingleViableAlt(altSubSets);
                break;
            }
            // else there are multiple non-conflicting subsets or
            // we're not sure what the ambiguity is yet.
            // So, keep going.
        }
        previous = reach;
        if( t !== Token.EOF) {
            input.consume();
            t = input.LA(1);
        }
    }
    // If the configuration set uniquely predicts an alternative,
    // without conflict, then we know that it's a full LL decision
    // not SLL.
    if (reach.uniqueAlt !== ATN.INVALID_ALT_NUMBER ) {
        this.reportContextSensitivity(dfa, predictedAlt, reach, startIndex, input.index);
        return predictedAlt;
    }
    // We do not check predicates here because we have checked them
    // on-the-fly when doing full context prediction.

    //
    // In non-exact ambiguity detection mode, we might	actually be able to
    // detect an exact ambiguity, but I'm not going to spend the cycles
    // needed to check. We only emit ambiguity warnings in exact ambiguity
    // mode.
    //
    // For example, we might know that we have conflicting configurations.
    // But, that does not mean that there is no way forward without a
    // conflict. It's possible to have nonconflicting alt subsets as in:

    // altSubSets=[{1, 2}, {1, 2}, {1}, {1, 2}]

    // from
    //
    //    [(17,1,[5 $]), (13,1,[5 10 $]), (21,1,[5 10 $]), (11,1,[$]),
    //     (13,2,[5 10 $]), (21,2,[5 10 $]), (11,2,[$])]
    //
    // In this case, (17,1,[5 $]) indicates there is some next sequence that
    // would resolve this without conflict to alternative 1. Any other viable
    // next sequence, however, is associated with a conflict.  We stop
    // looking for input because no amount of further lookahead will alter
    // the fact that we should predict alternative 1.  We just can't say for
    // sure that there is an ambiguity without looking further.

    this.reportAmbiguity(dfa, D, startIndex, input.index, foundExactAmbig, null, reach);

    return predictedAlt;
};

ParserATNSimulator.prototype.computeReachSet = function(closure, t, fullCtx) {
    if (this.debug) {
        console.log("in computeReachSet, starting closure: " + closure);
    }
    if( this.mergeCache===null) {
        this.mergeCache = new DoubleDict();
    }
    var intermediate = new ATNConfigSet(fullCtx);

    // Configurations already in a rule stop state indicate reaching the end
    // of the decision rule (local context) or end of the start rule (full
    // context). Once reached, these configurations are never updated by a
    // closure operation, so they are handled separately for the performance
    // advantage of having a smaller intermediate set when calling closure.
    //
    // For full-context reach operations, separate handling is required to
    // ensure that the alternative matching the longest overall sequence is
    // chosen when multiple such configurations can match the input.

    var skippedStopStates = null;

    // First figure out where we can reach on input t
    for (var i=0; i<closure.items.length;i++) {
        var c = closure.items[i];
        if(this.debug_add) {
            console.log("testing " + this.getTokenName(t) + " at " + c);
        }
        if (c.state instanceof RuleStopState) {
            if (fullCtx || t === Token.EOF) {
                if (skippedStopStates===null) {
                    skippedStopStates = [];
                }
                skippedStopStates.push(c);
                if(this.debug_add) {
                    console.log("added " + c + " to skippedStopStates");
                }
            }
            continue;
        }
        for(var j=0;j<c.state.transitions.length;j++) {
            var trans = c.state.transitions[j];
            var target = this.getReachableTarget(trans, t);
            if (target!==null) {
                var cfg = new ATNConfig({state:target}, c);
                intermediate.add(cfg, this.mergeCache);
                if(this.debug_add) {
                    console.log("added " + cfg + " to intermediate");
                }
            }
        }
    }
    // Now figure out where the reach operation can take us...
    var reach = null;

    // This block optimizes the reach operation for intermediate sets which
    // trivially indicate a termination state for the overall
    // adaptivePredict operation.
    //
    // The conditions assume that intermediate
    // contains all configurations relevant to the reach set, but this
    // condition is not true when one or more configurations have been
    // withheld in skippedStopStates, or when the current symbol is EOF.
    //
    if (skippedStopStates===null && t!==Token.EOF) {
        if (intermediate.items.length===1) {
            // Don't pursue the closure if there is just one state.
            // It can only have one alternative; just add to result
            // Also don't pursue the closure if there is unique alternative
            // among the configurations.
            reach = intermediate;
        } else if (this.getUniqueAlt(intermediate)!==ATN.INVALID_ALT_NUMBER) {
            // Also don't pursue the closure if there is unique alternative
            // among the configurations.
            reach = intermediate;
        }
    }
    // If the reach set could not be trivially determined, perform a closure
    // operation on the intermediate set to compute its initial value.
    //
    if (reach===null) {
        reach = new ATNConfigSet(fullCtx);
        var closureBusy = new Set();
        var treatEofAsEpsilon = t === Token.EOF;
        for (var k=0; k<intermediate.items.length;k++) {
            this.closure(intermediate.items[k], reach, closureBusy, false, fullCtx, treatEofAsEpsilon);
        }
    }
    if (t === Token.EOF) {
        // After consuming EOF no additional input is possible, so we are
        // only interested in configurations which reached the end of the
        // decision rule (local context) or end of the start rule (full
        // context). Update reach to contain only these configurations. This
        // handles both explicit EOF transitions in the grammar and implicit
        // EOF transitions following the end of the decision or start rule.
        //
        // When reach==intermediate, no closure operation was performed. In
        // this case, removeAllConfigsNotInRuleStopState needs to check for
        // reachable rule stop states as well as configurations already in
        // a rule stop state.
        //
        // This is handled before the configurations in skippedStopStates,
        // because any configurations potentially added from that list are
        // already guaranteed to meet this condition whether or not it's
        // required.
        //
        reach = this.removeAllConfigsNotInRuleStopState(reach, reach === intermediate);
    }
    // If skippedStopStates!==null, then it contains at least one
    // configuration. For full-context reach operations, these
    // configurations reached the end of the start rule, in which case we
    // only add them back to reach if no configuration during the current
    // closure operation reached such a state. This ensures adaptivePredict
    // chooses an alternative matching the longest overall sequence when
    // multiple alternatives are viable.
    //
    if (skippedStopStates!==null && ( (! fullCtx) || (! PredictionMode.hasConfigInRuleStopState(reach)))) {
        for (var l=0; l<skippedStopStates.length;l++) {
            reach.add(skippedStopStates[l], this.mergeCache);
        }
    }
    if (reach.items.length===0) {
        return null;
    } else {
        return reach;
    }
};
//
// Return a configuration set containing only the configurations from
// {@code configs} which are in a {@link RuleStopState}. If all
// configurations in {@code configs} are already in a rule stop state, this
// method simply returns {@code configs}.
//
// <p>When {@code lookToEndOfRule} is true, this method uses
// {@link ATN//nextTokens} for each configuration in {@code configs} which is
// not already in a rule stop state to see if a rule stop state is reachable
// from the configuration via epsilon-only transitions.</p>
//
// @param configs the configuration set to update
// @param lookToEndOfRule when true, this method checks for rule stop states
// reachable by epsilon-only transitions from each configuration in
// {@code configs}.
//
// @return {@code configs} if all configurations in {@code configs} are in a
// rule stop state, otherwise return a new configuration set containing only
// the configurations from {@code configs} which are in a rule stop state
//
ParserATNSimulator.prototype.removeAllConfigsNotInRuleStopState = function(configs, lookToEndOfRule) {
    if (PredictionMode.allConfigsInRuleStopStates(configs)) {
        return configs;
    }
    var result = new ATNConfigSet(configs.fullCtx);
    for(var i=0; i<configs.items.length;i++) {
        var config = configs.items[i];
        if (config.state instanceof RuleStopState) {
            result.add(config, this.mergeCache);
            continue;
        }
        if (lookToEndOfRule && config.state.epsilonOnlyTransitions) {
            var nextTokens = this.atn.nextTokens(config.state);
            if (nextTokens.contains(Token.EPSILON)) {
                var endOfRuleState = this.atn.ruleToStopState[config.state.ruleIndex];
                result.add(new ATNConfig({state:endOfRuleState}, config), this.mergeCache);
            }
        }
    }
    return result;
};

ParserATNSimulator.prototype.computeStartState = function(p, ctx, fullCtx) {
    // always at least the implicit call to start rule
    var initialContext = predictionContextFromRuleContext(this.atn, ctx);
    var configs = new ATNConfigSet(fullCtx);
    for(var i=0;i<p.transitions.length;i++) {
        var target = p.transitions[i].target;
        var c = new ATNConfig({ state:target, alt:i+1, context:initialContext }, null);
        var closureBusy = new Set();
        this.closure(c, configs, closureBusy, true, fullCtx, false);
    }
    return configs;
};

//
// This method transforms the start state computed by
// {@link //computeStartState} to the special start state used by a
// precedence DFA for a particular precedence value. The transformation
// process applies the following changes to the start state's configuration
// set.
//
// <ol>
// <li>Evaluate the precedence predicates for each configuration using
// {@link SemanticContext//evalPrecedence}.</li>
// <li>Remove all configurations which predict an alternative greater than
// 1, for which another configuration that predicts alternative 1 is in the
// same ATN state with the same prediction context. This transformation is
// valid for the following reasons:
// <ul>
// <li>The closure block cannot contain any epsilon transitions which bypass
// the body of the closure, so all states reachable via alternative 1 are
// part of the precedence alternatives of the transformed left-recursive
// rule.</li>
// <li>The "primary" portion of a left recursive rule cannot contain an
// epsilon transition, so the only way an alternative other than 1 can exist
// in a state that is also reachable via alternative 1 is by nesting calls
// to the left-recursive rule, with the outer calls not being at the
// preferred precedence level.</li>
// </ul>
// </li>
// </ol>
//
// <p>
// The prediction context must be considered by this filter to address
// situations like the following.
// </p>
// <code>
// <pre>
// grammar TA;
// prog: statement* EOF;
// statement: letterA | statement letterA 'b' ;
// letterA: 'a';
// </pre>
// </code>
// <p>
// If the above grammar, the ATN state immediately before the token
// reference {@code 'a'} in {@code letterA} is reachable from the left edge
// of both the primary and closure blocks of the left-recursive rule
// {@code statement}. The prediction context associated with each of these
// configurations distinguishes between them, and prevents the alternative
// which stepped out to {@code prog} (and then back in to {@code statement}
// from being eliminated by the filter.
// </p>
//
// @param configs The configuration set computed by
// {@link //computeStartState} as the start state for the DFA.
// @return The transformed configuration set representing the start state
// for a precedence DFA at a particular precedence level (determined by
// calling {@link Parser//getPrecedence}).
//
ParserATNSimulator.prototype.applyPrecedenceFilter = function(configs) {
	var config;
	var statesFromAlt1 = [];
    var configSet = new ATNConfigSet(configs.fullCtx);
    for(var i=0; i<configs.items.length; i++) {
        config = configs.items[i];
        // handle alt 1 first
        if (config.alt !== 1) {
            continue;
        }
        var updatedContext = config.semanticContext.evalPrecedence(this.parser, this._outerContext);
        if (updatedContext===null) {
            // the configuration was eliminated
            continue;
        }
        statesFromAlt1[config.state.stateNumber] = config.context;
        if (updatedContext !== config.semanticContext) {
            configSet.add(new ATNConfig({semanticContext:updatedContext}, config), this.mergeCache);
        } else {
            configSet.add(config, this.mergeCache);
        }
    }
    for(i=0; i<configs.items.length; i++) {
        config = configs.items[i];
        if (config.alt === 1) {
            // already handled
            continue;
        }
        // In the future, this elimination step could be updated to also
        // filter the prediction context for alternatives predicting alt>1
        // (basically a graph subtraction algorithm).
		if (!config.precedenceFilterSuppressed) {
            var context = statesFromAlt1[config.state.stateNumber] || null;
            if (context!==null && context.equals(config.context)) {
                // eliminated
                continue;
            }
		}
        configSet.add(config, this.mergeCache);
    }
    return configSet;
};

ParserATNSimulator.prototype.getReachableTarget = function(trans, ttype) {
    if (trans.matches(ttype, 0, this.atn.maxTokenType)) {
        return trans.target;
    } else {
        return null;
    }
};

ParserATNSimulator.prototype.getPredsForAmbigAlts = function(ambigAlts, configs, nalts) {
    // REACH=[1|1|[]|0:0, 1|2|[]|0:1]
    // altToPred starts as an array of all null contexts. The entry at index i
    // corresponds to alternative i. altToPred[i] may have one of three values:
    //   1. null: no ATNConfig c is found such that c.alt==i
    //   2. SemanticContext.NONE: At least one ATNConfig c exists such that
    //      c.alt==i and c.semanticContext==SemanticContext.NONE. In other words,
    //      alt i has at least one unpredicated config.
    //   3. Non-NONE Semantic Context: There exists at least one, and for all
    //      ATNConfig c such that c.alt==i, c.semanticContext!=SemanticContext.NONE.
    //
    // From this, it is clear that NONE||anything==NONE.
    //
    var altToPred = [];
    for(var i=0;i<configs.items.length;i++) {
        var c = configs.items[i];
        if(ambigAlts.contains( c.alt )) {
            altToPred[c.alt] = SemanticContext.orContext(altToPred[c.alt] || null, c.semanticContext);
        }
    }
    var nPredAlts = 0;
    for (i =1;i< nalts+1;i++) {
        var pred = altToPred[i] || null;
        if (pred===null) {
            altToPred[i] = SemanticContext.NONE;
        } else if (pred !== SemanticContext.NONE) {
            nPredAlts += 1;
        }
    }
    // nonambig alts are null in altToPred
    if (nPredAlts===0) {
        altToPred = null;
    }
    if (this.debug) {
        console.log("getPredsForAmbigAlts result " + Utils.arrayToString(altToPred));
    }
    return altToPred;
};

ParserATNSimulator.prototype.getPredicatePredictions = function(ambigAlts, altToPred) {
    var pairs = [];
    var containsPredicate = false;
    for (var i=1; i<altToPred.length;i++) {
        var pred = altToPred[i];
        // unpredicated is indicated by SemanticContext.NONE
        if( ambigAlts!==null && ambigAlts.contains( i )) {
            pairs.push(new PredPrediction(pred, i));
        }
        if (pred !== SemanticContext.NONE) {
            containsPredicate = true;
        }
    }
    if (! containsPredicate) {
        return null;
    }
    return pairs;
};

//
// This method is used to improve the localization of error messages by
// choosing an alternative rather than throwing a
// {@link NoViableAltException} in particular prediction scenarios where the
// {@link //ERROR} state was reached during ATN simulation.
//
// <p>
// The default implementation of this method uses the following
// algorithm to identify an ATN configuration which successfully parsed the
// decision entry rule. Choosing such an alternative ensures that the
// {@link ParserRuleContext} returned by the calling rule will be complete
// and valid, and the syntax error will be reported later at a more
// localized location.</p>
//
// <ul>
// <li>If a syntactically valid path or paths reach the end of the decision rule and
// they are semantically valid if predicated, return the min associated alt.</li>
// <li>Else, if a semantically invalid but syntactically valid path exist
// or paths exist, return the minimum associated alt.
// </li>
// <li>Otherwise, return {@link ATN//INVALID_ALT_NUMBER}.</li>
// </ul>
//
// <p>
// In some scenarios, the algorithm described above could predict an
// alternative which will result in a {@link FailedPredicateException} in
// the parser. Specifically, this could occur if the <em>only</em> configuration
// capable of successfully parsing to the end of the decision rule is
// blocked by a semantic predicate. By choosing this alternative within
// {@link //adaptivePredict} instead of throwing a
// {@link NoViableAltException}, the resulting
// {@link FailedPredicateException} in the parser will identify the specific
// predicate which is preventing the parser from successfully parsing the
// decision rule, which helps developers identify and correct logic errors
// in semantic predicates.
// </p>
//
// @param configs The ATN configurations which were valid immediately before
// the {@link //ERROR} state was reached
// @param outerContext The is the \gamma_0 initial parser context from the paper
// or the parser stack at the instant before prediction commences.
//
// @return The value to return from {@link //adaptivePredict}, or
// {@link ATN//INVALID_ALT_NUMBER} if a suitable alternative was not
// identified and {@link //adaptivePredict} should report an error instead.
//
ParserATNSimulator.prototype.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule = function(configs, outerContext) {
    var cfgs = this.splitAccordingToSemanticValidity(configs, outerContext);
    var semValidConfigs = cfgs[0];
    var semInvalidConfigs = cfgs[1];
    var alt = this.getAltThatFinishedDecisionEntryRule(semValidConfigs);
    if (alt!==ATN.INVALID_ALT_NUMBER) { // semantically/syntactically viable path exists
        return alt;
    }
    // Is there a syntactically valid path with a failed pred?
    if (semInvalidConfigs.items.length>0) {
        alt = this.getAltThatFinishedDecisionEntryRule(semInvalidConfigs);
        if (alt!==ATN.INVALID_ALT_NUMBER) { // syntactically viable path exists
            return alt;
        }
    }
    return ATN.INVALID_ALT_NUMBER;
};

ParserATNSimulator.prototype.getAltThatFinishedDecisionEntryRule = function(configs) {
    var alts = [];
    for(var i=0;i<configs.items.length; i++) {
        var c = configs.items[i];
        if (c.reachesIntoOuterContext>0 || ((c.state instanceof RuleStopState) && c.context.hasEmptyPath())) {
            if(alts.indexOf(c.alt)<0) {
                alts.push(c.alt);
            }
        }
    }
    if (alts.length===0) {
        return ATN.INVALID_ALT_NUMBER;
    } else {
        return Math.min.apply(null, alts);
    }
};
// Walk the list of configurations and split them according to
//  those that have preds evaluating to true/false.  If no pred, assume
//  true pred and include in succeeded set.  Returns Pair of sets.
//
//  Create a new set so as not to alter the incoming parameter.
//
//  Assumption: the input stream has been restored to the starting point
//  prediction, which is where predicates need to evaluate.
//
ParserATNSimulator.prototype.splitAccordingToSemanticValidity = function( configs, outerContext) {
    var succeeded = new ATNConfigSet(configs.fullCtx);
    var failed = new ATNConfigSet(configs.fullCtx);
    for(var i=0;i<configs.items.length; i++) {
        var c = configs.items[i];
        if (c.semanticContext !== SemanticContext.NONE) {
            var predicateEvaluationResult = c.semanticContext.evaluate(this.parser, outerContext);
            if (predicateEvaluationResult) {
                succeeded.add(c);
            } else {
                failed.add(c);
            }
        } else {
            succeeded.add(c);
        }
    }
    return [succeeded, failed];
};

// Look through a list of predicate/alt pairs, returning alts for the
//  pairs that win. A {@code NONE} predicate indicates an alt containing an
//  unpredicated config which behaves as "always true." If !complete
//  then we stop at the first predicate that evaluates to true. This
//  includes pairs with null predicates.
//
ParserATNSimulator.prototype.evalSemanticContext = function(predPredictions, outerContext, complete) {
    var predictions = new BitSet();
    for(var i=0;i<predPredictions.length;i++) {
    	var pair = predPredictions[i];
        if (pair.pred === SemanticContext.NONE) {
            predictions.add(pair.alt);
            if (! complete) {
                break;
            }
            continue;
        }
        var predicateEvaluationResult = pair.pred.evaluate(this.parser, outerContext);
        if (this.debug || this.dfa_debug) {
            console.log("eval pred " + pair + "=" + predicateEvaluationResult);
        }
        if (predicateEvaluationResult) {
            if (this.debug || this.dfa_debug) {
                console.log("PREDICT " + pair.alt);
            }
            predictions.add(pair.alt);
            if (! complete) {
                break;
            }
        }
    }
    return predictions;
};

// TODO: If we are doing predicates, there is no point in pursuing
//     closure operations if we reach a DFA state that uniquely predicts
//     alternative. We will not be caching that DFA state and it is a
//     waste to pursue the closure. Might have to advance when we do
//     ambig detection thought :(
//

ParserATNSimulator.prototype.closure = function(config, configs, closureBusy, collectPredicates, fullCtx, treatEofAsEpsilon) {
    var initialDepth = 0;
    this.closureCheckingStopState(config, configs, closureBusy, collectPredicates,
                             fullCtx, initialDepth, treatEofAsEpsilon);
};


ParserATNSimulator.prototype.closureCheckingStopState = function(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {
    if (this.debug || this.debug_closure) {
        console.log("closure(" + config.toString(this.parser,true) + ")");
        // console.log("configs(" + configs.toString() + ")");
        if(config.reachesIntoOuterContext>50) {
            throw "problem";
        }
    }
    if (config.state instanceof RuleStopState) {
        // We hit rule end. If we have context info, use it
        // run thru all possible stack tops in ctx
        if (! config.context.isEmpty()) {
            for ( var i =0; i<config.context.length; i++) {
                if (config.context.getReturnState(i) === PredictionContext.EMPTY_RETURN_STATE) {
                    if (fullCtx) {
                        configs.add(new ATNConfig({state:config.state, context:PredictionContext.EMPTY}, config), this.mergeCache);
                        continue;
                    } else {
                        // we have no context info, just chase follow links (if greedy)
                        if (this.debug) {
                            console.log("FALLING off rule " + this.getRuleName(config.state.ruleIndex));
                        }
                        this.closure_(config, configs, closureBusy, collectPredicates,
                                 fullCtx, depth, treatEofAsEpsilon);
                    }
                    continue;
                }
                var returnState = this.atn.states[config.context.getReturnState(i)];
                var newContext = config.context.getParent(i); // "pop" return state
                var parms = {state:returnState, alt:config.alt, context:newContext, semanticContext:config.semanticContext};
                var c = new ATNConfig(parms, null);
                // While we have context to pop back from, we may have
                // gotten that context AFTER having falling off a rule.
                // Make sure we track that we are now out of context.
                c.reachesIntoOuterContext = config.reachesIntoOuterContext;
                this.closureCheckingStopState(c, configs, closureBusy, collectPredicates, fullCtx, depth - 1, treatEofAsEpsilon);
            }
            return;
        } else if( fullCtx) {
            // reached end of start rule
            configs.add(config, this.mergeCache);
            return;
        } else {
            // else if we have no context info, just chase follow links (if greedy)
            if (this.debug) {
                console.log("FALLING off rule " + this.getRuleName(config.state.ruleIndex));
            }
        }
    }
    this.closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon);
};


// Do the actual work of walking epsilon edges//
ParserATNSimulator.prototype.closure_ = function(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {
    var p = config.state;
    // optimization
    if (! p.epsilonOnlyTransitions) {
        configs.add(config, this.mergeCache);
        // make sure to not return here, because EOF transitions can act as
        // both epsilon transitions and non-epsilon transitions.
    }
    for(var i = 0;i<p.transitions.length; i++) {
        if(i==0 && this.canDropLoopEntryEdgeInLeftRecursiveRule(config))
            continue;

        var t = p.transitions[i];
        var continueCollecting = collectPredicates && !(t instanceof ActionTransition);
        var c = this.getEpsilonTarget(config, t, continueCollecting, depth === 0, fullCtx, treatEofAsEpsilon);
        if (c!==null) {
            var newDepth = depth;
            if ( config.state instanceof RuleStopState) {
                // target fell off end of rule; mark resulting c as having dipped into outer context
                // We can't get here if incoming config was rule stop and we had context
                // track how far we dip into outer context.  Might
                // come in handy and we avoid evaluating context dependent
                // preds if this is > 0.
				if (this._dfa !== null && this._dfa.precedenceDfa) {
					if (t.outermostPrecedenceReturn === this._dfa.atnStartState.ruleIndex) {
						c.precedenceFilterSuppressed = true;
					}
				}

                c.reachesIntoOuterContext += 1;
                if (closureBusy.add(c)!==c) {
                    // avoid infinite recursion for right-recursive rules
                    continue;
                }
                configs.dipsIntoOuterContext = true; // TODO: can remove? only care when we add to set per middle of this method
                newDepth -= 1;
                if (this.debug) {
                    console.log("dips into outer ctx: " + c);
                }
            } else {
                if (!t.isEpsilon && closureBusy.add(c)!==c){
                    // avoid infinite recursion for EOF* and EOF+
                    continue;
                }
                if (t instanceof RuleTransition) {
                    // latch when newDepth goes negative - once we step out of the entry context we can't return
                    if (newDepth >= 0) {
                        newDepth += 1;
                    }
                }
            }
            this.closureCheckingStopState(c, configs, closureBusy, continueCollecting, fullCtx, newDepth, treatEofAsEpsilon);
        }
    }
};


ParserATNSimulator.prototype.canDropLoopEntryEdgeInLeftRecursiveRule = function(config) {
    // return False
    var p = config.state;
    // First check to see if we are in StarLoopEntryState generated during
    // left-recursion elimination. For efficiency, also check if
    // the context has an empty stack case. If so, it would mean
    // global FOLLOW so we can't perform optimization
    // Are we the special loop entry/exit state? or SLL wildcard
    if(p.stateType != ATNState.STAR_LOOP_ENTRY)
        return false;
    if(p.stateType != ATNState.STAR_LOOP_ENTRY || !p.isPrecedenceDecision ||
           config.context.isEmpty() || config.context.hasEmptyPath())
        return false;

    // Require all return states to return back to the same rule that p is in.
    var numCtxs = config.context.length;
    for(var i=0; i<numCtxs; i++) { // for each stack context
        var returnState = this.atn.states[config.context.getReturnState(i)];
        if (returnState.ruleIndex != p.ruleIndex)
            return false;
    }

    var decisionStartState = p.transitions[0].target;
    var blockEndStateNum = decisionStartState.endState.stateNumber;
    var blockEndState = this.atn.states[blockEndStateNum];

    // Verify that the top of each stack context leads to loop entry/exit
    // state through epsilon edges and w/o leaving rule.
    for(var i=0; i<numCtxs; i++) { // for each stack context
        var returnStateNumber = config.context.getReturnState(i);
        var returnState = this.atn.states[returnStateNumber];
        // all states must have single outgoing epsilon edge
        if (returnState.transitions.length != 1 || !returnState.transitions[0].isEpsilon)
            return false;

        // Look for prefix op case like 'not expr', (' type ')' expr
        var returnStateTarget = returnState.transitions[0].target;
        if ( returnState.stateType == ATNState.BLOCK_END && returnStateTarget == p )
            continue;

        // Look for 'expr op expr' or case where expr's return state is block end
        // of (...)* internal block; the block end points to loop back
        // which points to p but we don't need to check that
        if ( returnState == blockEndState )
            continue;

        // Look for ternary expr ? expr : expr. The return state points at block end,
        // which points at loop entry state
        if ( returnStateTarget == blockEndState )
            continue;

        // Look for complex prefix 'between expr and expr' case where 2nd expr's
        // return state points at block end state of (...)* internal block
        if (returnStateTarget.stateType == ATNState.BLOCK_END && returnStateTarget.transitions.length == 1
                && returnStateTarget.transitions[0].isEpsilon && returnStateTarget.transitions[0].target == p)
            continue;

        // anything else ain't conforming
        return false;
    }
    return true;
};


ParserATNSimulator.prototype.getRuleName = function( index) {
    if (this.parser!==null && index>=0) {
        return this.parser.ruleNames[index];
    } else {
        return "<rule " + index + ">";
    }
};

ParserATNSimulator.prototype.getEpsilonTarget = function(config, t, collectPredicates, inContext, fullCtx, treatEofAsEpsilon) {
    switch(t.serializationType) {
    case Transition.RULE:
        return this.ruleTransition(config, t);
    case Transition.PRECEDENCE:
        return this.precedenceTransition(config, t, collectPredicates, inContext, fullCtx);
    case Transition.PREDICATE:
        return this.predTransition(config, t, collectPredicates, inContext, fullCtx);
    case Transition.ACTION:
        return this.actionTransition(config, t);
    case Transition.EPSILON:
        return new ATNConfig({state:t.target}, config);
    case Transition.ATOM:
    case Transition.RANGE:
    case Transition.SET:
        // EOF transitions act like epsilon transitions after the first EOF
        // transition is traversed
        if (treatEofAsEpsilon) {
            if (t.matches(Token.EOF, 0, 1)) {
                return new ATNConfig({state: t.target}, config);
            }
        }
        return null;
    default:
    	return null;
    }
};

ParserATNSimulator.prototype.actionTransition = function(config, t) {
    if (this.debug) {
        var index = t.actionIndex==-1 ? 65535 : t.actionIndex;
        console.log("ACTION edge " + t.ruleIndex + ":" + index);
    }
    return new ATNConfig({state:t.target}, config);
};

ParserATNSimulator.prototype.precedenceTransition = function(config, pt,  collectPredicates, inContext, fullCtx) {
    if (this.debug) {
        console.log("PRED (collectPredicates=" + collectPredicates + ") " +
                pt.precedence + ">=_p, ctx dependent=true");
        if (this.parser!==null) {
        	console.log("context surrounding pred is " + Utils.arrayToString(this.parser.getRuleInvocationStack()));
        }
    }
    var c = null;
    if (collectPredicates && inContext) {
        if (fullCtx) {
            // In full context mode, we can evaluate predicates on-the-fly
            // during closure, which dramatically reduces the size of
            // the config sets. It also obviates the need to test predicates
            // later during conflict resolution.
            var currentPosition = this._input.index;
            this._input.seek(this._startIndex);
            var predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);
            this._input.seek(currentPosition);
            if (predSucceeds) {
                c = new ATNConfig({state:pt.target}, config); // no pred context
            }
        } else {
            var newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());
            c = new ATNConfig({state:pt.target, semanticContext:newSemCtx}, config);
        }
    } else {
        c = new ATNConfig({state:pt.target}, config);
    }
    if (this.debug) {
        console.log("config from pred transition=" + c);
    }
    return c;
};

ParserATNSimulator.prototype.predTransition = function(config, pt, collectPredicates, inContext, fullCtx) {
    if (this.debug) {
        console.log("PRED (collectPredicates=" + collectPredicates + ") " + pt.ruleIndex +
                ":" + pt.predIndex + ", ctx dependent=" + pt.isCtxDependent);
        if (this.parser!==null) {
            console.log("context surrounding pred is " + Utils.arrayToString(this.parser.getRuleInvocationStack()));
        }
    }
    var c = null;
    if (collectPredicates && ((pt.isCtxDependent && inContext) || ! pt.isCtxDependent)) {
        if (fullCtx) {
            // In full context mode, we can evaluate predicates on-the-fly
            // during closure, which dramatically reduces the size of
            // the config sets. It also obviates the need to test predicates
            // later during conflict resolution.
            var currentPosition = this._input.index;
            this._input.seek(this._startIndex);
            var predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);
            this._input.seek(currentPosition);
            if (predSucceeds) {
                c = new ATNConfig({state:pt.target}, config); // no pred context
            }
        } else {
            var newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());
            c = new ATNConfig({state:pt.target, semanticContext:newSemCtx}, config);
        }
    } else {
        c = new ATNConfig({state:pt.target}, config);
    }
    if (this.debug) {
        console.log("config from pred transition=" + c);
    }
    return c;
};

ParserATNSimulator.prototype.ruleTransition = function(config, t) {
    if (this.debug) {
        console.log("CALL rule " + this.getRuleName(t.target.ruleIndex) + ", ctx=" + config.context);
    }
    var returnState = t.followState;
    var newContext = SingletonPredictionContext.create(config.context, returnState.stateNumber);
    return new ATNConfig({state:t.target, context:newContext}, config );
};

ParserATNSimulator.prototype.getConflictingAlts = function(configs) {
    var altsets = PredictionMode.getConflictingAltSubsets(configs);
    return PredictionMode.getAlts(altsets);
};

 // Sam pointed out a problem with the previous definition, v3, of
 // ambiguous states. If we have another state associated with conflicting
 // alternatives, we should keep going. For example, the following grammar
 //
 // s : (ID | ID ID?) ';' ;
 //
 // When the ATN simulation reaches the state before ';', it has a DFA
 // state that looks like: [12|1|[], 6|2|[], 12|2|[]]. Naturally
 // 12|1|[] and 12|2|[] conflict, but we cannot stop processing this node
 // because alternative to has another way to continue, via [6|2|[]].
 // The key is that we have a single state that has config's only associated
 // with a single alternative, 2, and crucially the state transitions
 // among the configurations are all non-epsilon transitions. That means
 // we don't consider any conflicts that include alternative 2. So, we
 // ignore the conflict between alts 1 and 2. We ignore a set of
 // conflicting alts when there is an intersection with an alternative
 // associated with a single alt state in the state&rarr;config-list map.
 //
 // It's also the case that we might have two conflicting configurations but
 // also a 3rd nonconflicting configuration for a different alternative:
 // [1|1|[], 1|2|[], 8|3|[]]. This can come about from grammar:
 //
 // a : A | A | A B ;
 //
 // After matching input A, we reach the stop state for rule A, state 1.
 // State 8 is the state right before B. Clearly alternatives 1 and 2
 // conflict and no amount of further lookahead will separate the two.
 // However, alternative 3 will be able to continue and so we do not
 // stop working on this state. In the previous example, we're concerned
 // with states associated with the conflicting alternatives. Here alt
 // 3 is not associated with the conflicting configs, but since we can continue
 // looking for input reasonably, I don't declare the state done. We
 // ignore a set of conflicting alts when we have an alternative
 // that we still need to pursue.
//

ParserATNSimulator.prototype.getConflictingAltsOrUniqueAlt = function(configs) {
    var conflictingAlts = null;
    if (configs.uniqueAlt!== ATN.INVALID_ALT_NUMBER) {
        conflictingAlts = new BitSet();
        conflictingAlts.add(configs.uniqueAlt);
    } else {
        conflictingAlts = configs.conflictingAlts;
    }
    return conflictingAlts;
};

ParserATNSimulator.prototype.getTokenName = function( t) {
    if (t===Token.EOF) {
        return "EOF";
    }
    if( this.parser!==null && this.parser.literalNames!==null) {
        if (t >= this.parser.literalNames.length && t >= this.parser.symbolicNames.length) {
            console.log("" + t + " ttype out of range: " + this.parser.literalNames);
            console.log("" + this.parser.getInputStream().getTokens());
        } else {
            var name = this.parser.literalNames[t] || this.parser.symbolicNames[t];
            return name + "<" + t + ">";
        }
    }
    return "" + t;
};

ParserATNSimulator.prototype.getLookaheadName = function(input) {
    return this.getTokenName(input.LA(1));
};

// Used for debugging in adaptivePredict around execATN but I cut
//  it out for clarity now that alg. works well. We can leave this
//  "dead" code for a bit.
//
ParserATNSimulator.prototype.dumpDeadEndConfigs = function(nvae) {
    console.log("dead end configs: ");
    var decs = nvae.getDeadEndConfigs();
    for(var i=0; i<decs.length; i++) {
    	var c = decs[i];
        var trans = "no edges";
        if (c.state.transitions.length>0) {
            var t = c.state.transitions[0];
            if (t instanceof AtomTransition) {
                trans = "Atom "+ this.getTokenName(t.label);
            } else if (t instanceof SetTransition) {
                var neg = (t instanceof NotSetTransition);
                trans = (neg ? "~" : "") + "Set " + t.set;
            }
        }
        console.error(c.toString(this.parser, true) + ":" + trans);
    }
};

ParserATNSimulator.prototype.noViableAlt = function(input, outerContext, configs, startIndex) {
    return new NoViableAltException(this.parser, input, input.get(startIndex), input.LT(1), configs, outerContext);
};

ParserATNSimulator.prototype.getUniqueAlt = function(configs) {
    var alt = ATN.INVALID_ALT_NUMBER;
    for(var i=0;i<configs.items.length;i++) {
    	var c = configs.items[i];
        if (alt === ATN.INVALID_ALT_NUMBER) {
            alt = c.alt // found first alt
        } else if( c.alt!==alt) {
            return ATN.INVALID_ALT_NUMBER;
        }
    }
    return alt;
};

//
// Add an edge to the DFA, if possible. This method calls
// {@link //addDFAState} to ensure the {@code to} state is present in the
// DFA. If {@code from} is {@code null}, or if {@code t} is outside the
// range of edges that can be represented in the DFA tables, this method
// returns without adding the edge to the DFA.
//
// <p>If {@code to} is {@code null}, this method returns {@code null}.
// Otherwise, this method returns the {@link DFAState} returned by calling
// {@link //addDFAState} for the {@code to} state.</p>
//
// @param dfa The DFA
// @param from The source state for the edge
// @param t The input symbol
// @param to The target state for the edge
//
// @return If {@code to} is {@code null}, this method returns {@code null};
// otherwise this method returns the result of calling {@link //addDFAState}
// on {@code to}
//
ParserATNSimulator.prototype.addDFAEdge = function(dfa, from_, t, to) {
    if( this.debug) {
        console.log("EDGE " + from_ + " -> " + to + " upon " + this.getTokenName(t));
    }
    if (to===null) {
        return null;
    }
    to = this.addDFAState(dfa, to); // used existing if possible not incoming
    if (from_===null || t < -1 || t > this.atn.maxTokenType) {
        return to;
    }
    if (from_.edges===null) {
        from_.edges = [];
    }
    from_.edges[t+1] = to; // connect

    if (this.debug) {
        var literalNames = this.parser===null ? null : this.parser.literalNames;
        var symbolicNames = this.parser===null ? null : this.parser.symbolicNames;
        console.log("DFA=\n" + dfa.toString(literalNames, symbolicNames));
    }
    return to;
};
//
// Add state {@code D} to the DFA if it is not already present, and return
// the actual instance stored in the DFA. If a state equivalent to {@code D}
// is already in the DFA, the existing state is returned. Otherwise this
// method returns {@code D} after adding it to the DFA.
//
// <p>If {@code D} is {@link //ERROR}, this method returns {@link //ERROR} and
// does not change the DFA.</p>
//
// @param dfa The dfa
// @param D The DFA state to add
// @return The state stored in the DFA. This will be either the existing
// state if {@code D} is already in the DFA, or {@code D} itself if the
// state was not already present.
//
ParserATNSimulator.prototype.addDFAState = function(dfa, D) {
    if (D == ATNSimulator.ERROR) {
        return D;
    }
    var existing = dfa.states.get(D);
    if(existing!==null) {
        return existing;
    }
    D.stateNumber = dfa.states.length;
    if (! D.configs.readOnly) {
        D.configs.optimizeConfigs(this);
        D.configs.setReadonly(true);
    }
    dfa.states.add(D);
    if (this.debug) {
        console.log("adding new DFA state: " + D);
    }
    return D;
};

ParserATNSimulator.prototype.reportAttemptingFullContext = function(dfa, conflictingAlts, configs, startIndex, stopIndex) {
    if (this.debug || this.retry_debug) {
        var interval = new Interval(startIndex, stopIndex + 1);
        console.log("reportAttemptingFullContext decision=" + dfa.decision + ":" + configs +
                           ", input=" + this.parser.getTokenStream().getText(interval));
    }
    if (this.parser!==null) {
        this.parser.getErrorListenerDispatch().reportAttemptingFullContext(this.parser, dfa, startIndex, stopIndex, conflictingAlts, configs);
    }
};

ParserATNSimulator.prototype.reportContextSensitivity = function(dfa, prediction, configs, startIndex, stopIndex) {
    if (this.debug || this.retry_debug) {
        var interval = new Interval(startIndex, stopIndex + 1);
        console.log("reportContextSensitivity decision=" + dfa.decision + ":" + configs +
                           ", input=" + this.parser.getTokenStream().getText(interval));
    }
    if (this.parser!==null) {
        this.parser.getErrorListenerDispatch().reportContextSensitivity(this.parser, dfa, startIndex, stopIndex, prediction, configs);
    }
};

// If context sensitive parsing, we know it's ambiguity not conflict//
ParserATNSimulator.prototype.reportAmbiguity = function(dfa, D, startIndex, stopIndex,
                               exact, ambigAlts, configs ) {
    if (this.debug || this.retry_debug) {
        var interval = new Interval(startIndex, stopIndex + 1);
        console.log("reportAmbiguity " + ambigAlts + ":" + configs +
                           ", input=" + this.parser.getTokenStream().getText(interval));
    }
    if (this.parser!==null) {
        this.parser.getErrorListenerDispatch().reportAmbiguity(this.parser, dfa, startIndex, stopIndex, exact, ambigAlts, configs);
    }
};

exports.ParserATNSimulator = ParserATNSimulator;
},{"./../IntervalSet":31,"./../ParserRuleContext":35,"./../PredictionContext":36,"./../RuleContext":38,"./../Token":39,"./../Utils":40,"./../dfa/DFAState":59,"./../error/Errors":64,"./ATN":41,"./ATNConfig":42,"./ATNConfigSet":43,"./ATNSimulator":46,"./ATNState":47,"./PredictionMode":53,"./SemanticContext":54,"./Transition":55}],53:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
//
//
// This enumeration defines the prediction modes available in ANTLR 4 along with
// utility methods for analyzing configuration sets for conflicts and/or
// ambiguities.

var Set = require('./../Utils').Set;
var Map = require('./../Utils').Map;
var BitSet = require('./../Utils').BitSet;
var AltDict = require('./../Utils').AltDict;
var ATN = require('./ATN').ATN;
var RuleStopState = require('./ATNState').RuleStopState;
var ATNConfigSet = require('./ATNConfigSet').ATNConfigSet;
var ATNConfig = require('./ATNConfig').ATNConfig;
var SemanticContext = require('./SemanticContext').SemanticContext;
var Hash = require("../Utils").Hash;
var hashStuff = require('./../Utils').hashStuff;
var equalArrays = require('./../Utils').equalArrays;

function PredictionMode() {
	return this;
}

//
// The SLL(*) prediction mode. This prediction mode ignores the current
// parser context when making predictions. This is the fastest prediction
// mode, and provides correct results for many grammars. This prediction
// mode is more powerful than the prediction mode provided by ANTLR 3, but
// may result in syntax errors for grammar and input combinations which are
// not SLL.
//
// <p>
// When using this prediction mode, the parser will either return a correct
// parse tree (i.e. the same parse tree that would be returned with the
// {@link //LL} prediction mode), or it will report a syntax error. If a
// syntax error is encountered when using the {@link //SLL} prediction mode,
// it may be due to either an actual syntax error in the input or indicate
// that the particular combination of grammar and input requires the more
// powerful {@link //LL} prediction abilities to complete successfully.</p>
//
// <p>
// This prediction mode does not provide any guarantees for prediction
// behavior for syntactically-incorrect inputs.</p>
//
PredictionMode.SLL = 0;
//
// The LL(*) prediction mode. This prediction mode allows the current parser
// context to be used for resolving SLL conflicts that occur during
// prediction. This is the fastest prediction mode that guarantees correct
// parse results for all combinations of grammars with syntactically correct
// inputs.
//
// <p>
// When using this prediction mode, the parser will make correct decisions
// for all syntactically-correct grammar and input combinations. However, in
// cases where the grammar is truly ambiguous this prediction mode might not
// report a precise answer for <em>exactly which</em> alternatives are
// ambiguous.</p>
//
// <p>
// This prediction mode does not provide any guarantees for prediction
// behavior for syntactically-incorrect inputs.</p>
//
PredictionMode.LL = 1;
//
// The LL(*) prediction mode with exact ambiguity detection. In addition to
// the correctness guarantees provided by the {@link //LL} prediction mode,
// this prediction mode instructs the prediction algorithm to determine the
// complete and exact set of ambiguous alternatives for every ambiguous
// decision encountered while parsing.
//
// <p>
// This prediction mode may be used for diagnosing ambiguities during
// grammar development. Due to the performance overhead of calculating sets
// of ambiguous alternatives, this prediction mode should be avoided when
// the exact results are not necessary.</p>
//
// <p>
// This prediction mode does not provide any guarantees for prediction
// behavior for syntactically-incorrect inputs.</p>
//
PredictionMode.LL_EXACT_AMBIG_DETECTION = 2;


//
// Computes the SLL prediction termination condition.
//
// <p>
// This method computes the SLL prediction termination condition for both of
// the following cases.</p>
//
// <ul>
// <li>The usual SLL+LL fallback upon SLL conflict</li>
// <li>Pure SLL without LL fallback</li>
// </ul>
//
// <p><strong>COMBINED SLL+LL PARSING</strong></p>
//
// <p>When LL-fallback is enabled upon SLL conflict, correct predictions are
// ensured regardless of how the termination condition is computed by this
// method. Due to the substantially higher cost of LL prediction, the
// prediction should only fall back to LL when the additional lookahead
// cannot lead to a unique SLL prediction.</p>
//
// <p>Assuming combined SLL+LL parsing, an SLL configuration set with only
// conflicting subsets should fall back to full LL, even if the
// configuration sets don't resolve to the same alternative (e.g.
// {@code {1,2}} and {@code {3,4}}. If there is at least one non-conflicting
// configuration, SLL could continue with the hopes that more lookahead will
// resolve via one of those non-conflicting configurations.</p>
//
// <p>Here's the prediction termination rule them: SLL (for SLL+LL parsing)
// stops when it sees only conflicting configuration subsets. In contrast,
// full LL keeps going when there is uncertainty.</p>
//
// <p><strong>HEURISTIC</strong></p>
//
// <p>As a heuristic, we stop prediction when we see any conflicting subset
// unless we see a state that only has one alternative associated with it.
// The single-alt-state thing lets prediction continue upon rules like
// (otherwise, it would admit defeat too soon):</p>
//
// <p>{@code [12|1|[], 6|2|[], 12|2|[]]. s : (ID | ID ID?) ';' ;}</p>
//
// <p>When the ATN simulation reaches the state before {@code ';'}, it has a
// DFA state that looks like: {@code [12|1|[], 6|2|[], 12|2|[]]}. Naturally
// {@code 12|1|[]} and {@code 12|2|[]} conflict, but we cannot stop
// processing this node because alternative to has another way to continue,
// via {@code [6|2|[]]}.</p>
//
// <p>It also let's us continue for this rule:</p>
//
// <p>{@code [1|1|[], 1|2|[], 8|3|[]] a : A | A | A B ;}</p>
//
// <p>After matching input A, we reach the stop state for rule A, state 1.
// State 8 is the state right before B. Clearly alternatives 1 and 2
// conflict and no amount of further lookahead will separate the two.
// However, alternative 3 will be able to continue and so we do not stop
// working on this state. In the previous example, we're concerned with
// states associated with the conflicting alternatives. Here alt 3 is not
// associated with the conflicting configs, but since we can continue
// looking for input reasonably, don't declare the state done.</p>
//
// <p><strong>PURE SLL PARSING</strong></p>
//
// <p>To handle pure SLL parsing, all we have to do is make sure that we
// combine stack contexts for configurations that differ only by semantic
// predicate. From there, we can do the usual SLL termination heuristic.</p>
//
// <p><strong>PREDICATES IN SLL+LL PARSING</strong></p>
//
// <p>SLL decisions don't evaluate predicates until after they reach DFA stop
// states because they need to create the DFA cache that works in all
// semantic situations. In contrast, full LL evaluates predicates collected
// during start state computation so it can ignore predicates thereafter.
// This means that SLL termination detection can totally ignore semantic
// predicates.</p>
//
// <p>Implementation-wise, {@link ATNConfigSet} combines stack contexts but not
// semantic predicate contexts so we might see two configurations like the
// following.</p>
//
// <p>{@code (s, 1, x, {}), (s, 1, x', {p})}</p>
//
// <p>Before testing these configurations against others, we have to merge
// {@code x} and {@code x'} (without modifying the existing configurations).
// For example, we test {@code (x+x')==x''} when looking for conflicts in
// the following configurations.</p>
//
// <p>{@code (s, 1, x, {}), (s, 1, x', {p}), (s, 2, x'', {})}</p>
//
// <p>If the configuration set has predicates (as indicated by
// {@link ATNConfigSet//hasSemanticContext}), this algorithm makes a copy of
// the configurations to strip out all of the predicates so that a standard
// {@link ATNConfigSet} will merge everything ignoring predicates.</p>
//
PredictionMode.hasSLLConflictTerminatingPrediction = function( mode, configs) {
    // Configs in rule stop states indicate reaching the end of the decision
    // rule (local context) or end of start rule (full context). If all
    // configs meet this condition, then none of the configurations is able
    // to match additional input so we terminate prediction.
    //
    if (PredictionMode.allConfigsInRuleStopStates(configs)) {
        return true;
    }
    // pure SLL mode parsing
    if (mode === PredictionMode.SLL) {
        // Don't bother with combining configs from different semantic
        // contexts if we can fail over to full LL; costs more time
        // since we'll often fail over anyway.
        if (configs.hasSemanticContext) {
            // dup configs, tossing out semantic predicates
            var dup = new ATNConfigSet();
            for(var i=0;i<configs.items.length;i++) {
            	var c = configs.items[i];
                c = new ATNConfig({semanticContext:SemanticContext.NONE}, c);
                dup.add(c);
            }
            configs = dup;
        }
        // now we have combined contexts for configs with dissimilar preds
    }
    // pure SLL or combined SLL+LL mode parsing
    var altsets = PredictionMode.getConflictingAltSubsets(configs);
    return PredictionMode.hasConflictingAltSet(altsets) && !PredictionMode.hasStateAssociatedWithOneAlt(configs);
};

// Checks if any configuration in {@code configs} is in a
// {@link RuleStopState}. Configurations meeting this condition have reached
// the end of the decision rule (local context) or end of start rule (full
// context).
//
// @param configs the configuration set to test
// @return {@code true} if any configuration in {@code configs} is in a
// {@link RuleStopState}, otherwise {@code false}
PredictionMode.hasConfigInRuleStopState = function(configs) {
	for(var i=0;i<configs.items.length;i++) {
		var c = configs.items[i];
        if (c.state instanceof RuleStopState) {
            return true;
        }
	}
    return false;
};

// Checks if all configurations in {@code configs} are in a
// {@link RuleStopState}. Configurations meeting this condition have reached
// the end of the decision rule (local context) or end of start rule (full
// context).
//
// @param configs the configuration set to test
// @return {@code true} if all configurations in {@code configs} are in a
// {@link RuleStopState}, otherwise {@code false}
PredictionMode.allConfigsInRuleStopStates = function(configs) {
	for(var i=0;i<configs.items.length;i++) {
		var c = configs.items[i];
        if (!(c.state instanceof RuleStopState)) {
            return false;
        }
	}
    return true;
};

//
// Full LL prediction termination.
//
// <p>Can we stop looking ahead during ATN simulation or is there some
// uncertainty as to which alternative we will ultimately pick, after
// consuming more input? Even if there are partial conflicts, we might know
// that everything is going to resolve to the same minimum alternative. That
// means we can stop since no more lookahead will change that fact. On the
// other hand, there might be multiple conflicts that resolve to different
// minimums. That means we need more look ahead to decide which of those
// alternatives we should predict.</p>
//
// <p>The basic idea is to split the set of configurations {@code C}, into
// conflicting subsets {@code (s, _, ctx, _)} and singleton subsets with
// non-conflicting configurations. Two configurations conflict if they have
// identical {@link ATNConfig//state} and {@link ATNConfig//context} values
// but different {@link ATNConfig//alt} value, e.g. {@code (s, i, ctx, _)}
// and {@code (s, j, ctx, _)} for {@code i!=j}.</p>
//
// <p>Reduce these configuration subsets to the set of possible alternatives.
// You can compute the alternative subsets in one pass as follows:</p>
//
// <p>{@code A_s,ctx = {i | (s, i, ctx, _)}} for each configuration in
// {@code C} holding {@code s} and {@code ctx} fixed.</p>
//
// <p>Or in pseudo-code, for each configuration {@code c} in {@code C}:</p>
//
// <pre>
// map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not
// alt and not pred
// </pre>
//
// <p>The values in {@code map} are the set of {@code A_s,ctx} sets.</p>
//
// <p>If {@code |A_s,ctx|=1} then there is no conflict associated with
// {@code s} and {@code ctx}.</p>
//
// <p>Reduce the subsets to singletons by choosing a minimum of each subset. If
// the union of these alternative subsets is a singleton, then no amount of
// more lookahead will help us. We will always pick that alternative. If,
// however, there is more than one alternative, then we are uncertain which
// alternative to predict and must continue looking for resolution. We may
// or may not discover an ambiguity in the future, even if there are no
// conflicting subsets this round.</p>
//
// <p>The biggest sin is to terminate early because it means we've made a
// decision but were uncertain as to the eventual outcome. We haven't used
// enough lookahead. On the other hand, announcing a conflict too late is no
// big deal; you will still have the conflict. It's just inefficient. It
// might even look until the end of file.</p>
//
// <p>No special consideration for semantic predicates is required because
// predicates are evaluated on-the-fly for full LL prediction, ensuring that
// no configuration contains a semantic context during the termination
// check.</p>
//
// <p><strong>CONFLICTING CONFIGS</strong></p>
//
// <p>Two configurations {@code (s, i, x)} and {@code (s, j, x')}, conflict
// when {@code i!=j} but {@code x=x'}. Because we merge all
// {@code (s, i, _)} configurations together, that means that there are at
// most {@code n} configurations associated with state {@code s} for
// {@code n} possible alternatives in the decision. The merged stacks
// complicate the comparison of configuration contexts {@code x} and
// {@code x'}. Sam checks to see if one is a subset of the other by calling
// merge and checking to see if the merged result is either {@code x} or
// {@code x'}. If the {@code x} associated with lowest alternative {@code i}
// is the superset, then {@code i} is the only possible prediction since the
// others resolve to {@code min(i)} as well. However, if {@code x} is
// associated with {@code j>i} then at least one stack configuration for
// {@code j} is not in conflict with alternative {@code i}. The algorithm
// should keep going, looking for more lookahead due to the uncertainty.</p>
//
// <p>For simplicity, I'm doing a equality check between {@code x} and
// {@code x'} that lets the algorithm continue to consume lookahead longer
// than necessary. The reason I like the equality is of course the
// simplicity but also because that is the test you need to detect the
// alternatives that are actually in conflict.</p>
//
// <p><strong>CONTINUE/STOP RULE</strong></p>
//
// <p>Continue if union of resolved alternative sets from non-conflicting and
// conflicting alternative subsets has more than one alternative. We are
// uncertain about which alternative to predict.</p>
//
// <p>The complete set of alternatives, {@code [i for (_,i,_)]}, tells us which
// alternatives are still in the running for the amount of input we've
// consumed at this point. The conflicting sets let us to strip away
// configurations that won't lead to more states because we resolve
// conflicts to the configuration with a minimum alternate for the
// conflicting set.</p>
//
// <p><strong>CASES</strong></p>
//
// <ul>
//
// <li>no conflicts and more than 1 alternative in set =&gt; continue</li>
//
// <li> {@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s, 3, z)},
// {@code (s', 1, y)}, {@code (s', 2, y)} yields non-conflicting set
// {@code {3}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =
// {@code {1,3}} =&gt; continue
// </li>
//
// <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},
// {@code (s', 2, y)}, {@code (s'', 1, z)} yields non-conflicting set
// {@code {1}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =
// {@code {1}} =&gt; stop and predict 1</li>
//
// <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},
// {@code (s', 2, y)} yields conflicting, reduced sets {@code {1}} U
// {@code {1}} = {@code {1}} =&gt; stop and predict 1, can announce
// ambiguity {@code {1,2}}</li>
//
// <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 2, y)},
// {@code (s', 3, y)} yields conflicting, reduced sets {@code {1}} U
// {@code {2}} = {@code {1,2}} =&gt; continue</li>
//
// <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 3, y)},
// {@code (s', 4, y)} yields conflicting, reduced sets {@code {1}} U
// {@code {3}} = {@code {1,3}} =&gt; continue</li>
//
// </ul>
//
// <p><strong>EXACT AMBIGUITY DETECTION</strong></p>
//
// <p>If all states report the same conflicting set of alternatives, then we
// know we have the exact ambiguity set.</p>
//
// <p><code>|A_<em>i</em>|&gt;1</code> and
// <code>A_<em>i</em> = A_<em>j</em></code> for all <em>i</em>, <em>j</em>.</p>
//
// <p>In other words, we continue examining lookahead until all {@code A_i}
// have more than one alternative and all {@code A_i} are the same. If
// {@code A={{1,2}, {1,3}}}, then regular LL prediction would terminate
// because the resolved set is {@code {1}}. To determine what the real
// ambiguity is, we have to know whether the ambiguity is between one and
// two or one and three so we keep going. We can only stop prediction when
// we need exact ambiguity detection when the sets look like
// {@code A={{1,2}}} or {@code {{1,2},{1,2}}}, etc...</p>
//
PredictionMode.resolvesToJustOneViableAlt = function(altsets) {
    return PredictionMode.getSingleViableAlt(altsets);
};

//
// Determines if every alternative subset in {@code altsets} contains more
// than one alternative.
//
// @param altsets a collection of alternative subsets
// @return {@code true} if every {@link BitSet} in {@code altsets} has
// {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}
//
PredictionMode.allSubsetsConflict = function(altsets) {
    return ! PredictionMode.hasNonConflictingAltSet(altsets);
};
//
// Determines if any single alternative subset in {@code altsets} contains
// exactly one alternative.
//
// @param altsets a collection of alternative subsets
// @return {@code true} if {@code altsets} contains a {@link BitSet} with
// {@link BitSet//cardinality cardinality} 1, otherwise {@code false}
//
PredictionMode.hasNonConflictingAltSet = function(altsets) {
	for(var i=0;i<altsets.length;i++) {
		var alts = altsets[i];
        if (alts.length===1) {
            return true;
        }
	}
    return false;
};

//
// Determines if any single alternative subset in {@code altsets} contains
// more than one alternative.
//
// @param altsets a collection of alternative subsets
// @return {@code true} if {@code altsets} contains a {@link BitSet} with
// {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}
//
PredictionMode.hasConflictingAltSet = function(altsets) {
	for(var i=0;i<altsets.length;i++) {
		var alts = altsets[i];
        if (alts.length>1) {
            return true;
        }
	}
    return false;
};

//
// Determines if every alternative subset in {@code altsets} is equivalent.
//
// @param altsets a collection of alternative subsets
// @return {@code true} if every member of {@code altsets} is equal to the
// others, otherwise {@code false}
//
PredictionMode.allSubsetsEqual = function(altsets) {
    var first = null;
	for(var i=0;i<altsets.length;i++) {
		var alts = altsets[i];
        if (first === null) {
            first = alts;
        } else if (alts!==first) {
            return false;
        }
	}
    return true;
};

//
// Returns the unique alternative predicted by all alternative subsets in
// {@code altsets}. If no such alternative exists, this method returns
// {@link ATN//INVALID_ALT_NUMBER}.
//
// @param altsets a collection of alternative subsets
//
PredictionMode.getUniqueAlt = function(altsets) {
    var all = PredictionMode.getAlts(altsets);
    if (all.length===1) {
        return all.minValue();
    } else {
        return ATN.INVALID_ALT_NUMBER;
    }
};

// Gets the complete set of represented alternatives for a collection of
// alternative subsets. This method returns the union of each {@link BitSet}
// in {@code altsets}.
//
// @param altsets a collection of alternative subsets
// @return the set of represented alternatives in {@code altsets}
//
PredictionMode.getAlts = function(altsets) {
    var all = new BitSet();
    altsets.map( function(alts) { all.or(alts); });
    return all;
};

//
// This function gets the conflicting alt subsets from a configuration set.
// For each configuration {@code c} in {@code configs}:
//
// <pre>
// map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not
// alt and not pred
// </pre>

PredictionMode.getConflictingAltSubsets = function(configs) {
    var configToAlts = new Map();
    configToAlts.hashFunction = function(cfg) { hashStuff(cfg.state.stateNumber, cfg.context); };
    configToAlts.equalsFunction = function(c1, c2) { return c1.state.stateNumber==c2.state.stateNumber && c1.context.equals(c2.context);}
    configs.items.map(function(cfg) {
        var alts = configToAlts.get(cfg);
        if (alts === null) {
            alts = new BitSet();
            configToAlts.put(cfg, alts);
        }
        alts.add(cfg.alt);
	});
    return configToAlts.getValues();
};

//
// Get a map from state to alt subset from a configuration set. For each
// configuration {@code c} in {@code configs}:
//
// <pre>
// map[c.{@link ATNConfig//state state}] U= c.{@link ATNConfig//alt alt}
// </pre>
//
PredictionMode.getStateToAltMap = function(configs) {
    var m = new AltDict();
    configs.items.map(function(c) {
        var alts = m.get(c.state);
        if (alts === null) {
            alts = new BitSet();
            m.put(c.state, alts);
        }
        alts.add(c.alt);
    });
    return m;
};

PredictionMode.hasStateAssociatedWithOneAlt = function(configs) {
    var values = PredictionMode.getStateToAltMap(configs).values();
    for(var i=0;i<values.length;i++) {
        if (values[i].length===1) {
            return true;
        }
    }
    return false;
};

PredictionMode.getSingleViableAlt = function(altsets) {
    var result = null;
	for(var i=0;i<altsets.length;i++) {
		var alts = altsets[i];
        var minAlt = alts.minValue();
        if(result===null) {
            result = minAlt;
        } else if(result!==minAlt) { // more than 1 viable alt
            return ATN.INVALID_ALT_NUMBER;
        }
	}
    return result;
};

exports.PredictionMode = PredictionMode;

},{"../Utils":40,"./../Utils":40,"./ATN":41,"./ATNConfig":42,"./ATNConfigSet":43,"./ATNState":47,"./SemanticContext":54}],54:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
//

// A tree structure used to record the semantic context in which
//  an ATN configuration is valid.  It's either a single predicate,
//  a conjunction {@code p1&&p2}, or a sum of products {@code p1||p2}.
//
//  <p>I have scoped the {@link AND}, {@link OR}, and {@link Predicate} subclasses of
//  {@link SemanticContext} within the scope of this outer class.</p>
//

var Set = require('./../Utils').Set;
var Hash = require('./../Utils').Hash;

function SemanticContext() {
	return this;
}

SemanticContext.prototype.hashCode = function() {
    var hash = new Hash();
    this.updateHashCode(hash);
    return hash.finish();
};

// For context independent predicates, we evaluate them without a local
// context (i.e., null context). That way, we can evaluate them without
// having to create proper rule-specific context during prediction (as
// opposed to the parser, which creates them naturally). In a practical
// sense, this avoids a cast exception from RuleContext to myruleContext.
//
// <p>For context dependent predicates, we must pass in a local context so that
// references such as $arg evaluate properly as _localctx.arg. We only
// capture context dependent predicates in the context in which we begin
// prediction, so we passed in the outer context here in case of context
// dependent predicate evaluation.</p>
//
SemanticContext.prototype.evaluate = function(parser, outerContext) {
};

//
// Evaluate the precedence predicates for the context and reduce the result.
//
// @param parser The parser instance.
// @param outerContext The current parser context object.
// @return The simplified semantic context after precedence predicates are
// evaluated, which will be one of the following values.
// <ul>
// <li>{@link //NONE}: if the predicate simplifies to {@code true} after
// precedence predicates are evaluated.</li>
// <li>{@code null}: if the predicate simplifies to {@code false} after
// precedence predicates are evaluated.</li>
// <li>{@code this}: if the semantic context is not changed as a result of
// precedence predicate evaluation.</li>
// <li>A non-{@code null} {@link SemanticContext}: the new simplified
// semantic context after precedence predicates are evaluated.</li>
// </ul>
//
SemanticContext.prototype.evalPrecedence = function(parser, outerContext) {
	return this;
};

SemanticContext.andContext = function(a, b) {
	if (a === null || a === SemanticContext.NONE) {
		return b;
	}
	if (b === null || b === SemanticContext.NONE) {
		return a;
	}
	var result = new AND(a, b);
	if (result.opnds.length === 1) {
		return result.opnds[0];
	} else {
		return result;
	}
};

SemanticContext.orContext = function(a, b) {
	if (a === null) {
		return b;
	}
	if (b === null) {
		return a;
	}
	if (a === SemanticContext.NONE || b === SemanticContext.NONE) {
		return SemanticContext.NONE;
	}
	var result = new OR(a, b);
	if (result.opnds.length === 1) {
		return result.opnds[0];
	} else {
		return result;
	}
};

function Predicate(ruleIndex, predIndex, isCtxDependent) {
	SemanticContext.call(this);
	this.ruleIndex = ruleIndex === undefined ? -1 : ruleIndex;
	this.predIndex = predIndex === undefined ? -1 : predIndex;
	this.isCtxDependent = isCtxDependent === undefined ? false : isCtxDependent; // e.g., $i ref in pred
	return this;
}

Predicate.prototype = Object.create(SemanticContext.prototype);
Predicate.prototype.constructor = Predicate;

//The default {@link SemanticContext}, which is semantically equivalent to
//a predicate of the form {@code {true}?}.
//
SemanticContext.NONE = new Predicate();


Predicate.prototype.evaluate = function(parser, outerContext) {
	var localctx = this.isCtxDependent ? outerContext : null;
	return parser.sempred(localctx, this.ruleIndex, this.predIndex);
};

Predicate.prototype.updateHashCode = function(hash) {
	hash.update(this.ruleIndex, this.predIndex, this.isCtxDependent);
};

Predicate.prototype.equals = function(other) {
	if (this === other) {
		return true;
	} else if (!(other instanceof Predicate)) {
		return false;
	} else {
		return this.ruleIndex === other.ruleIndex &&
				this.predIndex === other.predIndex &&
				this.isCtxDependent === other.isCtxDependent;
	}
};

Predicate.prototype.toString = function() {
	return "{" + this.ruleIndex + ":" + this.predIndex + "}?";
};

function PrecedencePredicate(precedence) {
	SemanticContext.call(this);
	this.precedence = precedence === undefined ? 0 : precedence;
}

PrecedencePredicate.prototype = Object.create(SemanticContext.prototype);
PrecedencePredicate.prototype.constructor = PrecedencePredicate;

PrecedencePredicate.prototype.evaluate = function(parser, outerContext) {
	return parser.precpred(outerContext, this.precedence);
};

PrecedencePredicate.prototype.evalPrecedence = function(parser, outerContext) {
	if (parser.precpred(outerContext, this.precedence)) {
		return SemanticContext.NONE;
	} else {
		return null;
	}
};

PrecedencePredicate.prototype.compareTo = function(other) {
	return this.precedence - other.precedence;
};

PrecedencePredicate.prototype.updateHashCode = function(hash) {
    hash.update(31);
};

PrecedencePredicate.prototype.equals = function(other) {
	if (this === other) {
		return true;
	} else if (!(other instanceof PrecedencePredicate)) {
		return false;
	} else {
		return this.precedence === other.precedence;
	}
};

PrecedencePredicate.prototype.toString = function() {
	return "{"+this.precedence+">=prec}?";
};



PrecedencePredicate.filterPrecedencePredicates = function(set) {
	var result = [];
	set.values().map( function(context) {
		if (context instanceof PrecedencePredicate) {
			result.push(context);
		}
	});
	return result;
};


// A semantic context which is true whenever none of the contained contexts
// is false.
//
function AND(a, b) {
	SemanticContext.call(this);
	var operands = new Set();
	if (a instanceof AND) {
		a.opnds.map(function(o) {
			operands.add(o);
		});
	} else {
		operands.add(a);
	}
	if (b instanceof AND) {
		b.opnds.map(function(o) {
			operands.add(o);
		});
	} else {
		operands.add(b);
	}
	var precedencePredicates = PrecedencePredicate.filterPrecedencePredicates(operands);
	if (precedencePredicates.length > 0) {
		// interested in the transition with the lowest precedence
		var reduced = null;
		precedencePredicates.map( function(p) {
			if(reduced===null || p.precedence<reduced.precedence) {
				reduced = p;
			}
		});
		operands.add(reduced);
	}
	this.opnds = operands.values();
	return this;
}

AND.prototype = Object.create(SemanticContext.prototype);
AND.prototype.constructor = AND;

AND.prototype.equals = function(other) {
	if (this === other) {
		return true;
	} else if (!(other instanceof AND)) {
		return false;
	} else {
		return this.opnds === other.opnds;
	}
};

AND.prototype.updateHashCode = function(hash) {
    hash.update(this.opnds, "AND");
};
//
// {@inheritDoc}
//
// <p>
// The evaluation of predicates by this context is short-circuiting, but
// unordered.</p>
//
AND.prototype.evaluate = function(parser, outerContext) {
	for (var i = 0; i < this.opnds.length; i++) {
		if (!this.opnds[i].evaluate(parser, outerContext)) {
			return false;
		}
	}
	return true;
};

AND.prototype.evalPrecedence = function(parser, outerContext) {
	var differs = false;
	var operands = [];
	for (var i = 0; i < this.opnds.length; i++) {
		var context = this.opnds[i];
		var evaluated = context.evalPrecedence(parser, outerContext);
		differs |= (evaluated !== context);
		if (evaluated === null) {
			// The AND context is false if any element is false
			return null;
		} else if (evaluated !== SemanticContext.NONE) {
			// Reduce the result by skipping true elements
			operands.push(evaluated);
		}
	}
	if (!differs) {
		return this;
	}
	if (operands.length === 0) {
		// all elements were true, so the AND context is true
		return SemanticContext.NONE;
	}
	var result = null;
	operands.map(function(o) {
		result = result === null ? o : SemanticContext.andContext(result, o);
	});
	return result;
};

AND.prototype.toString = function() {
	var s = "";
	this.opnds.map(function(o) {
		s += "&& " + o.toString();
	});
	return s.length > 3 ? s.slice(3) : s;
};

//
// A semantic context which is true whenever at least one of the contained
// contexts is true.
//
function OR(a, b) {
	SemanticContext.call(this);
	var operands = new Set();
	if (a instanceof OR) {
		a.opnds.map(function(o) {
			operands.add(o);
		});
	} else {
		operands.add(a);
	}
	if (b instanceof OR) {
		b.opnds.map(function(o) {
			operands.add(o);
		});
	} else {
		operands.add(b);
	}

	var precedencePredicates = PrecedencePredicate.filterPrecedencePredicates(operands);
	if (precedencePredicates.length > 0) {
		// interested in the transition with the highest precedence
		var s = precedencePredicates.sort(function(a, b) {
			return a.compareTo(b);
		});
		var reduced = s[s.length-1];
		operands.add(reduced);
	}
	this.opnds = operands.values();
	return this;
}

OR.prototype = Object.create(SemanticContext.prototype);
OR.prototype.constructor = OR;

OR.prototype.constructor = function(other) {
	if (this === other) {
		return true;
	} else if (!(other instanceof OR)) {
		return false;
	} else {
		return this.opnds === other.opnds;
	}
};

OR.prototype.updateHashCode = function(hash) {
    hash.update(this.opnds, "OR");
};

// <p>
// The evaluation of predicates by this context is short-circuiting, but
// unordered.</p>
//
OR.prototype.evaluate = function(parser, outerContext) {
	for (var i = 0; i < this.opnds.length; i++) {
		if (this.opnds[i].evaluate(parser, outerContext)) {
			return true;
		}
	}
	return false;
};

OR.prototype.evalPrecedence = function(parser, outerContext) {
	var differs = false;
	var operands = [];
	for (var i = 0; i < this.opnds.length; i++) {
		var context = this.opnds[i];
		var evaluated = context.evalPrecedence(parser, outerContext);
		differs |= (evaluated !== context);
		if (evaluated === SemanticContext.NONE) {
			// The OR context is true if any element is true
			return SemanticContext.NONE;
		} else if (evaluated !== null) {
			// Reduce the result by skipping false elements
			operands.push(evaluated);
		}
	}
	if (!differs) {
		return this;
	}
	if (operands.length === 0) {
		// all elements were false, so the OR context is false
		return null;
	}
	var result = null;
	operands.map(function(o) {
		return result === null ? o : SemanticContext.orContext(result, o);
	});
	return result;
};

OR.prototype.toString = function() {
	var s = "";
	this.opnds.map(function(o) {
		s += "|| " + o.toString();
	});
	return s.length > 3 ? s.slice(3) : s;
};

exports.SemanticContext = SemanticContext;
exports.PrecedencePredicate = PrecedencePredicate;
exports.Predicate = Predicate;

},{"./../Utils":40}],55:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
//

//  An ATN transition between any two ATN states.  Subclasses define
//  atom, set, epsilon, action, predicate, rule transitions.
//
//  <p>This is a one way link.  It emanates from a state (usually via a list of
//  transitions) and has a target state.</p>
//
//  <p>Since we never have to change the ATN transitions once we construct it,
//  we can fix these transitions as specific classes. The DFA transitions
//  on the other hand need to update the labels as it adds transitions to
//  the states. We'll use the term Edge for the DFA to distinguish them from
//  ATN transitions.</p>

var Token = require('./../Token').Token;
var Interval = require('./../IntervalSet').Interval;
var IntervalSet = require('./../IntervalSet').IntervalSet;
var Predicate = require('./SemanticContext').Predicate;
var PrecedencePredicate = require('./SemanticContext').PrecedencePredicate;

function Transition (target) {
    // The target of this transition.
    if (target===undefined || target===null) {
        throw "target cannot be null.";
    }
    this.target = target;
    // Are we epsilon, action, sempred?
    this.isEpsilon = false;
    this.label = null;
    return this;
}
    // constants for serialization
Transition.EPSILON = 1;
Transition.RANGE = 2;
Transition.RULE = 3;
Transition.PREDICATE = 4; // e.g., {isType(input.LT(1))}?
Transition.ATOM = 5;
Transition.ACTION = 6;
Transition.SET = 7; // ~(A|B) or ~atom, wildcard, which convert to next 2
Transition.NOT_SET = 8;
Transition.WILDCARD = 9;
Transition.PRECEDENCE = 10;

Transition.serializationNames = [
            "INVALID",
            "EPSILON",
            "RANGE",
            "RULE",
            "PREDICATE",
            "ATOM",
            "ACTION",
            "SET",
            "NOT_SET",
            "WILDCARD",
            "PRECEDENCE"
        ];

Transition.serializationTypes = {
        EpsilonTransition: Transition.EPSILON,
        RangeTransition: Transition.RANGE,
        RuleTransition: Transition.RULE,
        PredicateTransition: Transition.PREDICATE,
        AtomTransition: Transition.ATOM,
        ActionTransition: Transition.ACTION,
        SetTransition: Transition.SET,
        NotSetTransition: Transition.NOT_SET,
        WildcardTransition: Transition.WILDCARD,
        PrecedencePredicateTransition: Transition.PRECEDENCE
    };


// TODO: make all transitions sets? no, should remove set edges
function AtomTransition(target, label) {
	Transition.call(this, target);
	this.label_ = label; // The token type or character value; or, signifies special label.
    this.label = this.makeLabel();
    this.serializationType = Transition.ATOM;
    return this;
}

AtomTransition.prototype = Object.create(Transition.prototype);
AtomTransition.prototype.constructor = AtomTransition;

AtomTransition.prototype.makeLabel = function() {
	var s = new IntervalSet();
    s.addOne(this.label_);
    return s;
};

AtomTransition.prototype.matches = function( symbol, minVocabSymbol,  maxVocabSymbol) {
    return this.label_ === symbol;
};

AtomTransition.prototype.toString = function() {
	return this.label_;
};

function RuleTransition(ruleStart, ruleIndex, precedence, followState) {
	Transition.call(this, ruleStart);
    this.ruleIndex = ruleIndex; // ptr to the rule definition object for this rule ref
    this.precedence = precedence;
    this.followState = followState; // what node to begin computations following ref to rule
    this.serializationType = Transition.RULE;
    this.isEpsilon = true;
    return this;
}

RuleTransition.prototype = Object.create(Transition.prototype);
RuleTransition.prototype.constructor = RuleTransition;

RuleTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {
	return false;
};


function EpsilonTransition(target, outermostPrecedenceReturn) {
	Transition.call(this, target);
    this.serializationType = Transition.EPSILON;
    this.isEpsilon = true;
    this.outermostPrecedenceReturn = outermostPrecedenceReturn;
    return this;
}

EpsilonTransition.prototype = Object.create(Transition.prototype);
EpsilonTransition.prototype.constructor = EpsilonTransition;

EpsilonTransition.prototype.matches = function( symbol, minVocabSymbol,  maxVocabSymbol) {
	return false;
};

EpsilonTransition.prototype.toString = function() {
	return "epsilon";
};

function RangeTransition(target, start, stop) {
	Transition.call(this, target);
	this.serializationType = Transition.RANGE;
    this.start = start;
    this.stop = stop;
    this.label = this.makeLabel();
    return this;
}

RangeTransition.prototype = Object.create(Transition.prototype);
RangeTransition.prototype.constructor = RangeTransition;

RangeTransition.prototype.makeLabel = function() {
    var s = new IntervalSet();
    s.addRange(this.start, this.stop);
    return s;
};

RangeTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {
	return symbol >= this.start && symbol <= this.stop;
};

RangeTransition.prototype.toString = function() {
	return "'" + String.fromCharCode(this.start) + "'..'" + String.fromCharCode(this.stop) + "'";
};

function AbstractPredicateTransition(target) {
	Transition.call(this, target);
	return this;
}

AbstractPredicateTransition.prototype = Object.create(Transition.prototype);
AbstractPredicateTransition.prototype.constructor = AbstractPredicateTransition;

function PredicateTransition(target, ruleIndex, predIndex, isCtxDependent) {
	AbstractPredicateTransition.call(this, target);
    this.serializationType = Transition.PREDICATE;
    this.ruleIndex = ruleIndex;
    this.predIndex = predIndex;
    this.isCtxDependent = isCtxDependent; // e.g., $i ref in pred
    this.isEpsilon = true;
    return this;
}

PredicateTransition.prototype = Object.create(AbstractPredicateTransition.prototype);
PredicateTransition.prototype.constructor = PredicateTransition;

PredicateTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {
	return false;
};

PredicateTransition.prototype.getPredicate = function() {
	return new Predicate(this.ruleIndex, this.predIndex, this.isCtxDependent);
};

PredicateTransition.prototype.toString = function() {
	return "pred_" + this.ruleIndex + ":" + this.predIndex;
};

function ActionTransition(target, ruleIndex, actionIndex, isCtxDependent) {
	Transition.call(this, target);
    this.serializationType = Transition.ACTION;
    this.ruleIndex = ruleIndex;
    this.actionIndex = actionIndex===undefined ? -1 : actionIndex;
    this.isCtxDependent = isCtxDependent===undefined ? false : isCtxDependent; // e.g., $i ref in pred
    this.isEpsilon = true;
    return this;
}

ActionTransition.prototype = Object.create(Transition.prototype);
ActionTransition.prototype.constructor = ActionTransition;


ActionTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {
	return false;
};

ActionTransition.prototype.toString = function() {
	return "action_" + this.ruleIndex + ":" + this.actionIndex;
};


// A transition containing a set of values.
function SetTransition(target, set) {
	Transition.call(this, target);
	this.serializationType = Transition.SET;
    if (set !==undefined && set !==null) {
        this.label = set;
    } else {
        this.label = new IntervalSet();
        this.label.addOne(Token.INVALID_TYPE);
    }
    return this;
}

SetTransition.prototype = Object.create(Transition.prototype);
SetTransition.prototype.constructor = SetTransition;

SetTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {
	return this.label.contains(symbol);
};


SetTransition.prototype.toString = function() {
	return this.label.toString();
};

function NotSetTransition(target, set) {
	SetTransition.call(this, target, set);
	this.serializationType = Transition.NOT_SET;
	return this;
}

NotSetTransition.prototype = Object.create(SetTransition.prototype);
NotSetTransition.prototype.constructor = NotSetTransition;

NotSetTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {
	return symbol >= minVocabSymbol && symbol <= maxVocabSymbol &&
			!SetTransition.prototype.matches.call(this, symbol, minVocabSymbol, maxVocabSymbol);
};

NotSetTransition.prototype.toString = function() {
	return '~' + SetTransition.prototype.toString.call(this);
};

function WildcardTransition(target) {
	Transition.call(this, target);
	this.serializationType = Transition.WILDCARD;
	return this;
}

WildcardTransition.prototype = Object.create(Transition.prototype);
WildcardTransition.prototype.constructor = WildcardTransition;


WildcardTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {
	return symbol >= minVocabSymbol && symbol <= maxVocabSymbol;
};

WildcardTransition.prototype.toString = function() {
	return ".";
};

function PrecedencePredicateTransition(target, precedence) {
	AbstractPredicateTransition.call(this, target);
    this.serializationType = Transition.PRECEDENCE;
    this.precedence = precedence;
    this.isEpsilon = true;
    return this;
}

PrecedencePredicateTransition.prototype = Object.create(AbstractPredicateTransition.prototype);
PrecedencePredicateTransition.prototype.constructor = PrecedencePredicateTransition;

PrecedencePredicateTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {
	return false;
};

PrecedencePredicateTransition.prototype.getPredicate = function() {
	return new PrecedencePredicate(this.precedence);
};

PrecedencePredicateTransition.prototype.toString = function() {
	return this.precedence + " >= _p";
};

exports.Transition = Transition;
exports.AtomTransition = AtomTransition;
exports.SetTransition = SetTransition;
exports.NotSetTransition = NotSetTransition;
exports.RuleTransition = RuleTransition;
exports.ActionTransition = ActionTransition;
exports.EpsilonTransition = EpsilonTransition;
exports.RangeTransition = RangeTransition;
exports.WildcardTransition = WildcardTransition;
exports.PredicateTransition = PredicateTransition;
exports.PrecedencePredicateTransition = PrecedencePredicateTransition;
exports.AbstractPredicateTransition = AbstractPredicateTransition;
},{"./../IntervalSet":31,"./../Token":39,"./SemanticContext":54}],56:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

exports.ATN = require('./ATN').ATN;
exports.ATNDeserializer = require('./ATNDeserializer').ATNDeserializer;
exports.LexerATNSimulator = require('./LexerATNSimulator').LexerATNSimulator;
exports.ParserATNSimulator = require('./ParserATNSimulator').ParserATNSimulator;
exports.PredictionMode = require('./PredictionMode').PredictionMode;

},{"./ATN":41,"./ATNDeserializer":45,"./LexerATNSimulator":49,"./ParserATNSimulator":52,"./PredictionMode":53}],57:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

var Set = require("../Utils").Set;
var DFAState = require('./DFAState').DFAState;
var StarLoopEntryState = require('../atn/ATNState').StarLoopEntryState;
var ATNConfigSet = require('./../atn/ATNConfigSet').ATNConfigSet;
var DFASerializer = require('./DFASerializer').DFASerializer;
var LexerDFASerializer = require('./DFASerializer').LexerDFASerializer;



function DFA(atnStartState, decision) {
	if (decision === undefined) {
		decision = 0;
	}
	// From which ATN state did we create this DFA?
	this.atnStartState = atnStartState;
	this.decision = decision;
	// A set of all DFA states. Use {@link Map} so we can get old state back
	// ({@link Set} only allows you to see if it's there).
	this._states = new Set();
	this.s0 = null;
	// {@code true} if this DFA is for a precedence decision; otherwise,
	// {@code false}. This is the backing field for {@link //isPrecedenceDfa},
	// {@link //setPrecedenceDfa}.
	this.precedenceDfa = false;
    if (atnStartState instanceof StarLoopEntryState)
    {
        if (atnStartState.isPrecedenceDecision) {
            this.precedenceDfa = true;
            var precedenceState = new DFAState(null, new ATNConfigSet());
            precedenceState.edges = [];
            precedenceState.isAcceptState = false;
            precedenceState.requiresFullContext = false;
            this.s0 = precedenceState;
        }
    }
	return this;
}

// Get the start state for a specific precedence value.
//
// @param precedence The current precedence.
// @return The start state corresponding to the specified precedence, or
// {@code null} if no start state exists for the specified precedence.
//
// @throws IllegalStateException if this is not a precedence DFA.
// @see //isPrecedenceDfa()

DFA.prototype.getPrecedenceStartState = function(precedence) {
	if (!(this.precedenceDfa)) {
		throw ("Only precedence DFAs may contain a precedence start state.");
	}
	// s0.edges is never null for a precedence DFA
	if (precedence < 0 || precedence >= this.s0.edges.length) {
		return null;
	}
	return this.s0.edges[precedence] || null;
};

// Set the start state for a specific precedence value.
//
// @param precedence The current precedence.
// @param startState The start state corresponding to the specified
// precedence.
//
// @throws IllegalStateException if this is not a precedence DFA.
// @see //isPrecedenceDfa()
//
DFA.prototype.setPrecedenceStartState = function(precedence, startState) {
	if (!(this.precedenceDfa)) {
		throw ("Only precedence DFAs may contain a precedence start state.");
	}
	if (precedence < 0) {
		return;
	}

	// synchronization on s0 here is ok. when the DFA is turned into a
	// precedence DFA, s0 will be initialized once and not updated again
	// s0.edges is never null for a precedence DFA
	this.s0.edges[precedence] = startState;
};

//
// Sets whether this is a precedence DFA. If the specified value differs
// from the current DFA configuration, the following actions are taken;
// otherwise no changes are made to the current DFA.
//
// <ul>
// <li>The {@link //states} map is cleared</li>
// <li>If {@code precedenceDfa} is {@code false}, the initial state
// {@link //s0} is set to {@code null}; otherwise, it is initialized to a new
// {@link DFAState} with an empty outgoing {@link DFAState//edges} array to
// store the start states for individual precedence values.</li>
// <li>The {@link //precedenceDfa} field is updated</li>
// </ul>
//
// @param precedenceDfa {@code true} if this is a precedence DFA; otherwise,
// {@code false}

DFA.prototype.setPrecedenceDfa = function(precedenceDfa) {
	if (this.precedenceDfa!==precedenceDfa) {
		this._states = new DFAStatesSet();
		if (precedenceDfa) {
			var precedenceState = new DFAState(null, new ATNConfigSet());
			precedenceState.edges = [];
			precedenceState.isAcceptState = false;
			precedenceState.requiresFullContext = false;
			this.s0 = precedenceState;
		} else {
			this.s0 = null;
		}
		this.precedenceDfa = precedenceDfa;
	}
};

Object.defineProperty(DFA.prototype, "states", {
	get : function() {
		return this._states;
	}
});

// Return a list of all states in this DFA, ordered by state number.
DFA.prototype.sortedStates = function() {
	var list = this._states.values();
	return list.sort(function(a, b) {
		return a.stateNumber - b.stateNumber;
	});
};

DFA.prototype.toString = function(literalNames, symbolicNames) {
	literalNames = literalNames || null;
	symbolicNames = symbolicNames || null;
	if (this.s0 === null) {
		return "";
	}
	var serializer = new DFASerializer(this, literalNames, symbolicNames);
	return serializer.toString();
};

DFA.prototype.toLexerString = function() {
	if (this.s0 === null) {
		return "";
	}
	var serializer = new LexerDFASerializer(this);
	return serializer.toString();
};

exports.DFA = DFA;

},{"../Utils":40,"../atn/ATNState":47,"./../atn/ATNConfigSet":43,"./DFASerializer":58,"./DFAState":59}],58:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

// A DFA walker that knows how to dump them to serialized strings.#/


function DFASerializer(dfa, literalNames, symbolicNames) {
	this.dfa = dfa;
	this.literalNames = literalNames || [];
	this.symbolicNames = symbolicNames || [];
	return this;
}

DFASerializer.prototype.toString = function() {
   if(this.dfa.s0 === null) {
       return null;
   }
   var buf = "";
   var states = this.dfa.sortedStates();
   for(var i=0;i<states.length;i++) {
       var s = states[i];
       if(s.edges!==null) {
            var n = s.edges.length;
            for(var j=0;j<n;j++) {
                var t = s.edges[j] || null;
                if(t!==null && t.stateNumber !== 0x7FFFFFFF) {
                    buf = buf.concat(this.getStateString(s));
                    buf = buf.concat("-");
                    buf = buf.concat(this.getEdgeLabel(j));
                    buf = buf.concat("->");
                    buf = buf.concat(this.getStateString(t));
                    buf = buf.concat('\n');
                }
            }
       }
   }
   return buf.length===0 ? null : buf;
};

DFASerializer.prototype.getEdgeLabel = function(i) {
    if (i===0) {
        return "EOF";
    } else if(this.literalNames !==null || this.symbolicNames!==null) {
        return this.literalNames[i-1] || this.symbolicNames[i-1];
    } else {
        return String.fromCharCode(i-1);
    }
};

DFASerializer.prototype.getStateString = function(s) {
    var baseStateStr = ( s.isAcceptState ? ":" : "") + "s" + s.stateNumber + ( s.requiresFullContext ? "^" : "");
    if(s.isAcceptState) {
        if (s.predicates !== null) {
            return baseStateStr + "=>" + s.predicates.toString();
        } else {
            return baseStateStr + "=>" + s.prediction.toString();
        }
    } else {
        return baseStateStr;
    }
};

function LexerDFASerializer(dfa) {
	DFASerializer.call(this, dfa, null);
	return this;
}

LexerDFASerializer.prototype = Object.create(DFASerializer.prototype);
LexerDFASerializer.prototype.constructor = LexerDFASerializer;

LexerDFASerializer.prototype.getEdgeLabel = function(i) {
	return "'" + String.fromCharCode(i) + "'";
};

exports.DFASerializer = DFASerializer;
exports.LexerDFASerializer = LexerDFASerializer;


},{}],59:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
///

var ATNConfigSet = require('./../atn/ATNConfigSet').ATNConfigSet;
var Utils = require('./../Utils');
var Hash = Utils.Hash;
var Set = Utils.Set;

// Map a predicate to a predicted alternative.///

function PredPrediction(pred, alt) {
	this.alt = alt;
	this.pred = pred;
	return this;
}

PredPrediction.prototype.toString = function() {
	return "(" + this.pred + ", " + this.alt + ")";
};

// A DFA state represents a set of possible ATN configurations.
// As Aho, Sethi, Ullman p. 117 says "The DFA uses its state
// to keep track of all possible states the ATN can be in after
// reading each input symbol. That is to say, after reading
// input a1a2..an, the DFA is in a state that represents the
// subset T of the states of the ATN that are reachable from the
// ATN's start state along some path labeled a1a2..an."
// In conventional NFA&rarr;DFA conversion, therefore, the subset T
// would be a bitset representing the set of states the
// ATN could be in. We need to track the alt predicted by each
// state as well, however. More importantly, we need to maintain
// a stack of states, tracking the closure operations as they
// jump from rule to rule, emulating rule invocations (method calls).
// I have to add a stack to simulate the proper lookahead sequences for
// the underlying LL grammar from which the ATN was derived.
//
// <p>I use a set of ATNConfig objects not simple states. An ATNConfig
// is both a state (ala normal conversion) and a RuleContext describing
// the chain of rules (if any) followed to arrive at that state.</p>
//
// <p>A DFA state may have multiple references to a particular state,
// but with different ATN contexts (with same or different alts)
// meaning that state was reached via a different set of rule invocations.</p>
// /

function DFAState(stateNumber, configs) {
	if (stateNumber === null) {
		stateNumber = -1;
	}
	if (configs === null) {
		configs = new ATNConfigSet();
	}
	this.stateNumber = stateNumber;
	this.configs = configs;
	// {@code edges[symbol]} points to target of symbol. Shift up by 1 so (-1)
	// {@link Token//EOF} maps to {@code edges[0]}.
	this.edges = null;
	this.isAcceptState = false;
	// if accept state, what ttype do we match or alt do we predict?
	// This is set to {@link ATN//INVALID_ALT_NUMBER} when {@link
	// //predicates}{@code !=null} or
	// {@link //requiresFullContext}.
	this.prediction = 0;
	this.lexerActionExecutor = null;
	// Indicates that this state was created during SLL prediction that
	// discovered a conflict between the configurations in the state. Future
	// {@link ParserATNSimulator//execATN} invocations immediately jumped doing
	// full context prediction if this field is true.
	this.requiresFullContext = false;
	// During SLL parsing, this is a list of predicates associated with the
	// ATN configurations of the DFA state. When we have predicates,
	// {@link //requiresFullContext} is {@code false} since full context
	// prediction evaluates predicates
	// on-the-fly. If this is not null, then {@link //prediction} is
	// {@link ATN//INVALID_ALT_NUMBER}.
	//
	// <p>We only use these for non-{@link //requiresFullContext} but
	// conflicting states. That
	// means we know from the context (it's $ or we don't dip into outer
	// context) that it's an ambiguity not a conflict.</p>
	//
	// <p>This list is computed by {@link
	// ParserATNSimulator//predicateDFAState}.</p>
	this.predicates = null;
	return this;
}

// Get the set of all alts mentioned by all ATN configurations in this
// DFA state.
DFAState.prototype.getAltSet = function() {
	var alts = new Set();
	if (this.configs !== null) {
		for (var i = 0; i < this.configs.length; i++) {
			var c = this.configs[i];
			alts.add(c.alt);
		}
	}
	if (alts.length === 0) {
		return null;
	} else {
		return alts;
	}
};

// Two {@link DFAState} instances are equal if their ATN configuration sets
// are the same. This method is used to see if a state already exists.
//
// <p>Because the number of alternatives and number of ATN configurations are
// finite, there is a finite number of DFA states that can be processed.
// This is necessary to show that the algorithm terminates.</p>
//
// <p>Cannot test the DFA state numbers here because in
// {@link ParserATNSimulator//addDFAState} we need to know if any other state
// exists that has this exact set of ATN configurations. The
// {@link //stateNumber} is irrelevant.</p>
DFAState.prototype.equals = function(other) {
	// compare set of ATN configurations in this set with other
	return this === other ||
			(other instanceof DFAState &&
				this.configs.equals(other.configs));
};

DFAState.prototype.toString = function() {
	var s = "" + this.stateNumber + ":" + this.configs;
	if(this.isAcceptState) {
        s = s + "=>";
        if (this.predicates !== null)
            s = s + this.predicates;
        else
            s = s + this.prediction;
    }
	return s;
};

DFAState.prototype.hashCode = function() {
	var hash = new Hash();
	hash.update(this.configs);
    return hash.finish();
};

exports.DFAState = DFAState;
exports.PredPrediction = PredPrediction;

},{"./../Utils":40,"./../atn/ATNConfigSet":43}],60:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

exports.DFA = require('./DFA').DFA;
exports.DFASerializer = require('./DFASerializer').DFASerializer;
exports.LexerDFASerializer = require('./DFASerializer').LexerDFASerializer;
exports.PredPrediction = require('./DFAState').PredPrediction;

},{"./DFA":57,"./DFASerializer":58,"./DFAState":59}],61:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
//

//
// This implementation of {@link ANTLRErrorListener} can be used to identify
// certain potential correctness and performance problems in grammars. "Reports"
// are made by calling {@link Parser//notifyErrorListeners} with the appropriate
// message.
//
// <ul>
// <li><b>Ambiguities</b>: These are cases where more than one path through the
// grammar can match the input.</li>
// <li><b>Weak context sensitivity</b>: These are cases where full-context
// prediction resolved an SLL conflict to a unique alternative which equaled the
// minimum alternative of the SLL conflict.</li>
// <li><b>Strong (forced) context sensitivity</b>: These are cases where the
// full-context prediction resolved an SLL conflict to a unique alternative,
// <em>and</em> the minimum alternative of the SLL conflict was found to not be
// a truly viable alternative. Two-stage parsing cannot be used for inputs where
// this situation occurs.</li>
// </ul>

var BitSet = require('./../Utils').BitSet;
var ErrorListener = require('./ErrorListener').ErrorListener;
var Interval = require('./../IntervalSet').Interval;

function DiagnosticErrorListener(exactOnly) {
	ErrorListener.call(this);
	exactOnly = exactOnly || true;
	// whether all ambiguities or only exact ambiguities are reported.
	this.exactOnly = exactOnly;
	return this;
}

DiagnosticErrorListener.prototype = Object.create(ErrorListener.prototype);
DiagnosticErrorListener.prototype.constructor = DiagnosticErrorListener;

DiagnosticErrorListener.prototype.reportAmbiguity = function(recognizer, dfa,
		startIndex, stopIndex, exact, ambigAlts, configs) {
	if (this.exactOnly && !exact) {
		return;
	}
	var msg = "reportAmbiguity d=" +
			this.getDecisionDescription(recognizer, dfa) +
			": ambigAlts=" +
			this.getConflictingAlts(ambigAlts, configs) +
			", input='" +
			recognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + "'";
	recognizer.notifyErrorListeners(msg);
};

DiagnosticErrorListener.prototype.reportAttemptingFullContext = function(
		recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {
	var msg = "reportAttemptingFullContext d=" +
			this.getDecisionDescription(recognizer, dfa) +
			", input='" +
			recognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + "'";
	recognizer.notifyErrorListeners(msg);
};

DiagnosticErrorListener.prototype.reportContextSensitivity = function(
		recognizer, dfa, startIndex, stopIndex, prediction, configs) {
	var msg = "reportContextSensitivity d=" +
			this.getDecisionDescription(recognizer, dfa) +
			", input='" +
			recognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + "'";
	recognizer.notifyErrorListeners(msg);
};

DiagnosticErrorListener.prototype.getDecisionDescription = function(recognizer, dfa) {
	var decision = dfa.decision;
	var ruleIndex = dfa.atnStartState.ruleIndex;

	var ruleNames = recognizer.ruleNames;
	if (ruleIndex < 0 || ruleIndex >= ruleNames.length) {
		return "" + decision;
	}
	var ruleName = ruleNames[ruleIndex] || null;
	if (ruleName === null || ruleName.length === 0) {
		return "" + decision;
	}
	return "" + decision + " (" + ruleName + ")";
};

//
// Computes the set of conflicting or ambiguous alternatives from a
// configuration set, if that information was not already provided by the
// parser.
//
// @param reportedAlts The set of conflicting or ambiguous alternatives, as
// reported by the parser.
// @param configs The conflicting or ambiguous configuration set.
// @return Returns {@code reportedAlts} if it is not {@code null}, otherwise
// returns the set of alternatives represented in {@code configs}.
//
DiagnosticErrorListener.prototype.getConflictingAlts = function(reportedAlts, configs) {
	if (reportedAlts !== null) {
		return reportedAlts;
	}
	var result = new BitSet();
	for (var i = 0; i < configs.items.length; i++) {
		result.add(configs.items[i].alt);
	}
	return "{" + result.values().join(", ") + "}";
};

exports.DiagnosticErrorListener = DiagnosticErrorListener;
},{"./../IntervalSet":31,"./../Utils":40,"./ErrorListener":62}],62:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

// Provides an empty default implementation of {@link ANTLRErrorListener}. The
// default implementation of each method does nothing, but can be overridden as
// necessary.

function ErrorListener() {
	return this;
}

ErrorListener.prototype.syntaxError = function(recognizer, offendingSymbol, line, column, msg, e) {
};

ErrorListener.prototype.reportAmbiguity = function(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {
};

ErrorListener.prototype.reportAttemptingFullContext = function(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {
};

ErrorListener.prototype.reportContextSensitivity = function(recognizer, dfa, startIndex, stopIndex, prediction, configs) {
};

function ConsoleErrorListener() {
	ErrorListener.call(this);
	return this;
}

ConsoleErrorListener.prototype = Object.create(ErrorListener.prototype);
ConsoleErrorListener.prototype.constructor = ConsoleErrorListener;

//
// Provides a default instance of {@link ConsoleErrorListener}.
//
ConsoleErrorListener.INSTANCE = new ConsoleErrorListener();

//
// {@inheritDoc}
//
// <p>
// This implementation prints messages to {@link System//err} containing the
// values of {@code line}, {@code charPositionInLine}, and {@code msg} using
// the following format.</p>
//
// <pre>
// line <em>line</em>:<em>charPositionInLine</em> <em>msg</em>
// </pre>
//
ConsoleErrorListener.prototype.syntaxError = function(recognizer, offendingSymbol, line, column, msg, e) {
    console.error("line " + line + ":" + column + " " + msg);
};

function ProxyErrorListener(delegates) {
	ErrorListener.call(this);
    if (delegates===null) {
        throw "delegates";
    }
    this.delegates = delegates;
	return this;
}

ProxyErrorListener.prototype = Object.create(ErrorListener.prototype);
ProxyErrorListener.prototype.constructor = ProxyErrorListener;

ProxyErrorListener.prototype.syntaxError = function(recognizer, offendingSymbol, line, column, msg, e) {
    this.delegates.map(function(d) { d.syntaxError(recognizer, offendingSymbol, line, column, msg, e); });
};

ProxyErrorListener.prototype.reportAmbiguity = function(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {
    this.delegates.map(function(d) { d.reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs); });
};

ProxyErrorListener.prototype.reportAttemptingFullContext = function(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {
	this.delegates.map(function(d) { d.reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs); });
};

ProxyErrorListener.prototype.reportContextSensitivity = function(recognizer, dfa, startIndex, stopIndex, prediction, configs) {
	this.delegates.map(function(d) { d.reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs); });
};

exports.ErrorListener = ErrorListener;
exports.ConsoleErrorListener = ConsoleErrorListener;
exports.ProxyErrorListener = ProxyErrorListener;


},{}],63:[function(require,module,exports){
//
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
//

var Token = require('./../Token').Token;
var Errors = require('./Errors');
var NoViableAltException = Errors.NoViableAltException;
var InputMismatchException = Errors.InputMismatchException;
var FailedPredicateException = Errors.FailedPredicateException;
var ParseCancellationException = Errors.ParseCancellationException;
var ATNState = require('./../atn/ATNState').ATNState;
var Interval = require('./../IntervalSet').Interval;
var IntervalSet = require('./../IntervalSet').IntervalSet;

function ErrorStrategy() {

}

ErrorStrategy.prototype.reset = function(recognizer){
};

ErrorStrategy.prototype.recoverInline = function(recognizer){
};

ErrorStrategy.prototype.recover = function(recognizer, e){
};

ErrorStrategy.prototype.sync = function(recognizer){
};

ErrorStrategy.prototype.inErrorRecoveryMode = function(recognizer){
};

ErrorStrategy.prototype.reportError = function(recognizer){
};



// This is the default implementation of {@link ANTLRErrorStrategy} used for
// error reporting and recovery in ANTLR parsers.
//
function DefaultErrorStrategy() {
	ErrorStrategy.call(this);
    // Indicates whether the error strategy is currently "recovering from an
    // error". This is used to suppress reporting multiple error messages while
    // attempting to recover from a detected syntax error.
    //
    // @see //inErrorRecoveryMode
    //
    this.errorRecoveryMode = false;

    // The index into the input stream where the last error occurred.
    // This is used to prevent infinite loops where an error is found
    // but no token is consumed during recovery...another error is found,
    // ad nauseum. This is a failsafe mechanism to guarantee that at least
    // one token/tree node is consumed for two errors.
    //
    this.lastErrorIndex = -1;
    this.lastErrorStates = null;
    return this;
}

DefaultErrorStrategy.prototype = Object.create(ErrorStrategy.prototype);
DefaultErrorStrategy.prototype.constructor = DefaultErrorStrategy;

// <p>The default implementation simply calls {@link //endErrorCondition} to
// ensure that the handler is not in error recovery mode.</p>
DefaultErrorStrategy.prototype.reset = function(recognizer) {
    this.endErrorCondition(recognizer);
};

//
// This method is called to enter error recovery mode when a recognition
// exception is reported.
//
// @param recognizer the parser instance
//
DefaultErrorStrategy.prototype.beginErrorCondition = function(recognizer) {
    this.errorRecoveryMode = true;
};

DefaultErrorStrategy.prototype.inErrorRecoveryMode = function(recognizer) {
    return this.errorRecoveryMode;
};

//
// This method is called to leave error recovery mode after recovering from
// a recognition exception.
//
// @param recognizer
//
DefaultErrorStrategy.prototype.endErrorCondition = function(recognizer) {
    this.errorRecoveryMode = false;
    this.lastErrorStates = null;
    this.lastErrorIndex = -1;
};

//
// {@inheritDoc}
//
// <p>The default implementation simply calls {@link //endErrorCondition}.</p>
//
DefaultErrorStrategy.prototype.reportMatch = function(recognizer) {
    this.endErrorCondition(recognizer);
};

//
// {@inheritDoc}
//
// <p>The default implementation returns immediately if the handler is already
// in error recovery mode. Otherwise, it calls {@link //beginErrorCondition}
// and dispatches the reporting task based on the runtime type of {@code e}
// according to the following table.</p>
//
// <ul>
// <li>{@link NoViableAltException}: Dispatches the call to
// {@link //reportNoViableAlternative}</li>
// <li>{@link InputMismatchException}: Dispatches the call to
// {@link //reportInputMismatch}</li>
// <li>{@link FailedPredicateException}: Dispatches the call to
// {@link //reportFailedPredicate}</li>
// <li>All other types: calls {@link Parser//notifyErrorListeners} to report
// the exception</li>
// </ul>
//
DefaultErrorStrategy.prototype.reportError = function(recognizer, e) {
   // if we've already reported an error and have not matched a token
   // yet successfully, don't report any errors.
    if(this.inErrorRecoveryMode(recognizer)) {
        return; // don't report spurious errors
    }
    this.beginErrorCondition(recognizer);
    if ( e instanceof NoViableAltException ) {
        this.reportNoViableAlternative(recognizer, e);
    } else if ( e instanceof InputMismatchException ) {
        this.reportInputMismatch(recognizer, e);
    } else if ( e instanceof FailedPredicateException ) {
        this.reportFailedPredicate(recognizer, e);
    } else {
        console.log("unknown recognition error type: " + e.constructor.name);
        console.log(e.stack);
        recognizer.notifyErrorListeners(e.getOffendingToken(), e.getMessage(), e);
    }
};
//
// {@inheritDoc}
//
// <p>The default implementation resynchronizes the parser by consuming tokens
// until we find one in the resynchronization set--loosely the set of tokens
// that can follow the current rule.</p>
//
DefaultErrorStrategy.prototype.recover = function(recognizer, e) {
    if (this.lastErrorIndex===recognizer.getInputStream().index &&
        this.lastErrorStates !== null && this.lastErrorStates.indexOf(recognizer.state)>=0) {
		// uh oh, another error at same token index and previously-visited
		// state in ATN; must be a case where LT(1) is in the recovery
		// token set so nothing got consumed. Consume a single token
		// at least to prevent an infinite loop; this is a failsafe.
		recognizer.consume();
    }
    this.lastErrorIndex = recognizer._input.index;
    if (this.lastErrorStates === null) {
        this.lastErrorStates = [];
    }
    this.lastErrorStates.push(recognizer.state);
    var followSet = this.getErrorRecoverySet(recognizer);
    this.consumeUntil(recognizer, followSet);
};

// The default implementation of {@link ANTLRErrorStrategy//sync} makes sure
// that the current lookahead symbol is consistent with what were expecting
// at this point in the ATN. You can call this anytime but ANTLR only
// generates code to check before subrules/loops and each iteration.
//
// <p>Implements Jim Idle's magic sync mechanism in closures and optional
// subrules. E.g.,</p>
//
// <pre>
// a : sync ( stuff sync )* ;
// sync : {consume to what can follow sync} ;
// </pre>
//
// At the start of a sub rule upon error, {@link //sync} performs single
// token deletion, if possible. If it can't do that, it bails on the current
// rule and uses the default error recovery, which consumes until the
// resynchronization set of the current rule.
//
// <p>If the sub rule is optional ({@code (...)?}, {@code (...)*}, or block
// with an empty alternative), then the expected set includes what follows
// the subrule.</p>
//
// <p>During loop iteration, it consumes until it sees a token that can start a
// sub rule or what follows loop. Yes, that is pretty aggressive. We opt to
// stay in the loop as long as possible.</p>
//
// <p><strong>ORIGINS</strong></p>
//
// <p>Previous versions of ANTLR did a poor job of their recovery within loops.
// A single mismatch token or missing token would force the parser to bail
// out of the entire rules surrounding the loop. So, for rule</p>
//
// <pre>
// classDef : 'class' ID '{' member* '}'
// </pre>
//
// input with an extra token between members would force the parser to
// consume until it found the next class definition rather than the next
// member definition of the current class.
//
// <p>This functionality cost a little bit of effort because the parser has to
// compare token set at the start of the loop and at each iteration. If for
// some reason speed is suffering for you, you can turn off this
// functionality by simply overriding this method as a blank { }.</p>
//
DefaultErrorStrategy.prototype.sync = function(recognizer) {
    // If already recovering, don't try to sync
    if (this.inErrorRecoveryMode(recognizer)) {
        return;
    }
    var s = recognizer._interp.atn.states[recognizer.state];
    var la = recognizer.getTokenStream().LA(1);
    // try cheaper subset first; might get lucky. seems to shave a wee bit off
    var nextTokens = recognizer.atn.nextTokens(s);
    if (nextTokens.contains(Token.EPSILON) || nextTokens.contains(la)) {
        return;
    }
    switch (s.stateType) {
    case ATNState.BLOCK_START:
    case ATNState.STAR_BLOCK_START:
    case ATNState.PLUS_BLOCK_START:
    case ATNState.STAR_LOOP_ENTRY:
       // report error and recover if possible
        if( this.singleTokenDeletion(recognizer) !== null) {
            return;
        } else {
            throw new InputMismatchException(recognizer);
        }
        break;
    case ATNState.PLUS_LOOP_BACK:
    case ATNState.STAR_LOOP_BACK:
        this.reportUnwantedToken(recognizer);
        var expecting = new IntervalSet();
        expecting.addSet(recognizer.getExpectedTokens());
        var whatFollowsLoopIterationOrRule = expecting.addSet(this.getErrorRecoverySet(recognizer));
        this.consumeUntil(recognizer, whatFollowsLoopIterationOrRule);
        break;
    default:
        // do nothing if we can't identify the exact kind of ATN state
    }
};

// This is called by {@link //reportError} when the exception is a
// {@link NoViableAltException}.
//
// @see //reportError
//
// @param recognizer the parser instance
// @param e the recognition exception
//
DefaultErrorStrategy.prototype.reportNoViableAlternative = function(recognizer, e) {
    var tokens = recognizer.getTokenStream();
    var input;
    if(tokens !== null) {
        if (e.startToken.type===Token.EOF) {
            input = "<EOF>";
        } else {
            input = tokens.getText(new Interval(e.startToken.tokenIndex, e.offendingToken.tokenIndex));
        }
    } else {
        input = "<unknown input>";
    }
    var msg = "no viable alternative at input " + this.escapeWSAndQuote(input);
    recognizer.notifyErrorListeners(msg, e.offendingToken, e);
};

//
// This is called by {@link //reportError} when the exception is an
// {@link InputMismatchException}.
//
// @see //reportError
//
// @param recognizer the parser instance
// @param e the recognition exception
//
DefaultErrorStrategy.prototype.reportInputMismatch = function(recognizer, e) {
    var msg = "mismatched input " + this.getTokenErrorDisplay(e.offendingToken) +
          " expecting " + e.getExpectedTokens().toString(recognizer.literalNames, recognizer.symbolicNames);
    recognizer.notifyErrorListeners(msg, e.offendingToken, e);
};

//
// This is called by {@link //reportError} when the exception is a
// {@link FailedPredicateException}.
//
// @see //reportError
//
// @param recognizer the parser instance
// @param e the recognition exception
//
DefaultErrorStrategy.prototype.reportFailedPredicate = function(recognizer, e) {
    var ruleName = recognizer.ruleNames[recognizer._ctx.ruleIndex];
    var msg = "rule " + ruleName + " " + e.message;
    recognizer.notifyErrorListeners(msg, e.offendingToken, e);
};

// This method is called to report a syntax error which requires the removal
// of a token from the input stream. At the time this method is called, the
// erroneous symbol is current {@code LT(1)} symbol and has not yet been
// removed from the input stream. When this method returns,
// {@code recognizer} is in error recovery mode.
//
// <p>This method is called when {@link //singleTokenDeletion} identifies
// single-token deletion as a viable recovery strategy for a mismatched
// input error.</p>
//
// <p>The default implementation simply returns if the handler is already in
// error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to
// enter error recovery mode, followed by calling
// {@link Parser//notifyErrorListeners}.</p>
//
// @param recognizer the parser instance
//
DefaultErrorStrategy.prototype.reportUnwantedToken = function(recognizer) {
    if (this.inErrorRecoveryMode(recognizer)) {
        return;
    }
    this.beginErrorCondition(recognizer);
    var t = recognizer.getCurrentToken();
    var tokenName = this.getTokenErrorDisplay(t);
    var expecting = this.getExpectedTokens(recognizer);
    var msg = "extraneous input " + tokenName + " expecting " +
        expecting.toString(recognizer.literalNames, recognizer.symbolicNames);
    recognizer.notifyErrorListeners(msg, t, null);
};
// This method is called to report a syntax error which requires the
// insertion of a missing token into the input stream. At the time this
// method is called, the missing token has not yet been inserted. When this
// method returns, {@code recognizer} is in error recovery mode.
//
// <p>This method is called when {@link //singleTokenInsertion} identifies
// single-token insertion as a viable recovery strategy for a mismatched
// input error.</p>
//
// <p>The default implementation simply returns if the handler is already in
// error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to
// enter error recovery mode, followed by calling
// {@link Parser//notifyErrorListeners}.</p>
//
// @param recognizer the parser instance
//
DefaultErrorStrategy.prototype.reportMissingToken = function(recognizer) {
    if ( this.inErrorRecoveryMode(recognizer)) {
        return;
    }
    this.beginErrorCondition(recognizer);
    var t = recognizer.getCurrentToken();
    var expecting = this.getExpectedTokens(recognizer);
    var msg = "missing " + expecting.toString(recognizer.literalNames, recognizer.symbolicNames) +
          " at " + this.getTokenErrorDisplay(t);
    recognizer.notifyErrorListeners(msg, t, null);
};

// <p>The default implementation attempts to recover from the mismatched input
// by using single token insertion and deletion as described below. If the
// recovery attempt fails, this method throws an
// {@link InputMismatchException}.</p>
//
// <p><strong>EXTRA TOKEN</strong> (single token deletion)</p>
//
// <p>{@code LA(1)} is not what we are looking for. If {@code LA(2)} has the
// right token, however, then assume {@code LA(1)} is some extra spurious
// token and delete it. Then consume and return the next token (which was
// the {@code LA(2)} token) as the successful result of the match operation.</p>
//
// <p>This recovery strategy is implemented by {@link
// //singleTokenDeletion}.</p>
//
// <p><strong>MISSING TOKEN</strong> (single token insertion)</p>
//
// <p>If current token (at {@code LA(1)}) is consistent with what could come
// after the expected {@code LA(1)} token, then assume the token is missing
// and use the parser's {@link TokenFactory} to create it on the fly. The
// "insertion" is performed by returning the created token as the successful
// result of the match operation.</p>
//
// <p>This recovery strategy is implemented by {@link
// //singleTokenInsertion}.</p>
//
// <p><strong>EXAMPLE</strong></p>
//
// <p>For example, Input {@code i=(3;} is clearly missing the {@code ')'}. When
// the parser returns from the nested call to {@code expr}, it will have
// call chain:</p>
//
// <pre>
// stat &rarr; expr &rarr; atom
// </pre>
//
// and it will be trying to match the {@code ')'} at this point in the
// derivation:
//
// <pre>
// =&gt; ID '=' '(' INT ')' ('+' atom)* ';'
// ^
// </pre>
//
// The attempt to match {@code ')'} will fail when it sees {@code ';'} and
// call {@link //recoverInline}. To recover, it sees that {@code LA(1)==';'}
// is in the set of tokens that can follow the {@code ')'} token reference
// in rule {@code atom}. It can assume that you forgot the {@code ')'}.
//
DefaultErrorStrategy.prototype.recoverInline = function(recognizer) {
    // SINGLE TOKEN DELETION
    var matchedSymbol = this.singleTokenDeletion(recognizer);
    if (matchedSymbol !== null) {
        // we have deleted the extra token.
        // now, move past ttype token as if all were ok
        recognizer.consume();
        return matchedSymbol;
    }
    // SINGLE TOKEN INSERTION
    if (this.singleTokenInsertion(recognizer)) {
        return this.getMissingSymbol(recognizer);
    }
    // even that didn't work; must throw the exception
    throw new InputMismatchException(recognizer);
};

//
// This method implements the single-token insertion inline error recovery
// strategy. It is called by {@link //recoverInline} if the single-token
// deletion strategy fails to recover from the mismatched input. If this
// method returns {@code true}, {@code recognizer} will be in error recovery
// mode.
//
// <p>This method determines whether or not single-token insertion is viable by
// checking if the {@code LA(1)} input symbol could be successfully matched
// if it were instead the {@code LA(2)} symbol. If this method returns
// {@code true}, the caller is responsible for creating and inserting a
// token with the correct type to produce this behavior.</p>
//
// @param recognizer the parser instance
// @return {@code true} if single-token insertion is a viable recovery
// strategy for the current mismatched input, otherwise {@code false}
//
DefaultErrorStrategy.prototype.singleTokenInsertion = function(recognizer) {
    var currentSymbolType = recognizer.getTokenStream().LA(1);
    // if current token is consistent with what could come after current
    // ATN state, then we know we're missing a token; error recovery
    // is free to conjure up and insert the missing token
    var atn = recognizer._interp.atn;
    var currentState = atn.states[recognizer.state];
    var next = currentState.transitions[0].target;
    var expectingAtLL2 = atn.nextTokens(next, recognizer._ctx);
    if (expectingAtLL2.contains(currentSymbolType) ){
        this.reportMissingToken(recognizer);
        return true;
    } else {
        return false;
    }
};

// This method implements the single-token deletion inline error recovery
// strategy. It is called by {@link //recoverInline} to attempt to recover
// from mismatched input. If this method returns null, the parser and error
// handler state will not have changed. If this method returns non-null,
// {@code recognizer} will <em>not</em> be in error recovery mode since the
// returned token was a successful match.
//
// <p>If the single-token deletion is successful, this method calls
// {@link //reportUnwantedToken} to report the error, followed by
// {@link Parser//consume} to actually "delete" the extraneous token. Then,
// before returning {@link //reportMatch} is called to signal a successful
// match.</p>
//
// @param recognizer the parser instance
// @return the successfully matched {@link Token} instance if single-token
// deletion successfully recovers from the mismatched input, otherwise
// {@code null}
//
DefaultErrorStrategy.prototype.singleTokenDeletion = function(recognizer) {
    var nextTokenType = recognizer.getTokenStream().LA(2);
    var expecting = this.getExpectedTokens(recognizer);
    if (expecting.contains(nextTokenType)) {
        this.reportUnwantedToken(recognizer);
        // print("recoverFromMismatchedToken deleting " \
        // + str(recognizer.getTokenStream().LT(1)) \
        // + " since " + str(recognizer.getTokenStream().LT(2)) \
        // + " is what we want", file=sys.stderr)
        recognizer.consume(); // simply delete extra token
        // we want to return the token we're actually matching
        var matchedSymbol = recognizer.getCurrentToken();
        this.reportMatch(recognizer); // we know current token is correct
        return matchedSymbol;
    } else {
        return null;
    }
};

// Conjure up a missing token during error recovery.
//
// The recognizer attempts to recover from single missing
// symbols. But, actions might refer to that missing symbol.
// For example, x=ID {f($x);}. The action clearly assumes
// that there has been an identifier matched previously and that
// $x points at that token. If that token is missing, but
// the next token in the stream is what we want we assume that
// this token is missing and we keep going. Because we
// have to return some token to replace the missing token,
// we have to conjure one up. This method gives the user control
// over the tokens returned for missing tokens. Mostly,
// you will want to create something special for identifier
// tokens. For literals such as '{' and ',', the default
// action in the parser or tree parser works. It simply creates
// a CommonToken of the appropriate type. The text will be the token.
// If you change what tokens must be created by the lexer,
// override this method to create the appropriate tokens.
//
DefaultErrorStrategy.prototype.getMissingSymbol = function(recognizer) {
    var currentSymbol = recognizer.getCurrentToken();
    var expecting = this.getExpectedTokens(recognizer);
    var expectedTokenType = expecting.first(); // get any element
    var tokenText;
    if (expectedTokenType===Token.EOF) {
        tokenText = "<missing EOF>";
    } else {
        tokenText = "<missing " + recognizer.literalNames[expectedTokenType] + ">";
    }
    var current = currentSymbol;
    var lookback = recognizer.getTokenStream().LT(-1);
    if (current.type===Token.EOF && lookback !== null) {
        current = lookback;
    }
    return recognizer.getTokenFactory().create(current.source,
        expectedTokenType, tokenText, Token.DEFAULT_CHANNEL,
        -1, -1, current.line, current.column);
};

DefaultErrorStrategy.prototype.getExpectedTokens = function(recognizer) {
    return recognizer.getExpectedTokens();
};

// How should a token be displayed in an error message? The default
// is to display just the text, but during development you might
// want to have a lot of information spit out. Override in that case
// to use t.toString() (which, for CommonToken, dumps everything about
// the token). This is better than forcing you to override a method in
// your token objects because you don't have to go modify your lexer
// so that it creates a new Java type.
//
DefaultErrorStrategy.prototype.getTokenErrorDisplay = function(t) {
    if (t === null) {
        return "<no token>";
    }
    var s = t.text;
    if (s === null) {
        if (t.type===Token.EOF) {
            s = "<EOF>";
        } else {
            s = "<" + t.type + ">";
        }
    }
    return this.escapeWSAndQuote(s);
};

DefaultErrorStrategy.prototype.escapeWSAndQuote = function(s) {
    s = s.replace(/\n/g,"\\n");
    s = s.replace(/\r/g,"\\r");
    s = s.replace(/\t/g,"\\t");
    return "'" + s + "'";
};

// Compute the error recovery set for the current rule. During
// rule invocation, the parser pushes the set of tokens that can
// follow that rule reference on the stack; this amounts to
// computing FIRST of what follows the rule reference in the
// enclosing rule. See LinearApproximator.FIRST().
// This local follow set only includes tokens
// from within the rule; i.e., the FIRST computation done by
// ANTLR stops at the end of a rule.
//
// EXAMPLE
//
// When you find a "no viable alt exception", the input is not
// consistent with any of the alternatives for rule r. The best
// thing to do is to consume tokens until you see something that
// can legally follow a call to r//or* any rule that called r.
// You don't want the exact set of viable next tokens because the
// input might just be missing a token--you might consume the
// rest of the input looking for one of the missing tokens.
//
// Consider grammar:
//
// a : '[' b ']'
// | '(' b ')'
// ;
// b : c '^' INT ;
// c : ID
// | INT
// ;
//
// At each rule invocation, the set of tokens that could follow
// that rule is pushed on a stack. Here are the various
// context-sensitive follow sets:
//
// FOLLOW(b1_in_a) = FIRST(']') = ']'
// FOLLOW(b2_in_a) = FIRST(')') = ')'
// FOLLOW(c_in_b) = FIRST('^') = '^'
//
// Upon erroneous input "[]", the call chain is
//
// a -> b -> c
//
// and, hence, the follow context stack is:
//
// depth follow set start of rule execution
// 0 <EOF> a (from main())
// 1 ']' b
// 2 '^' c
//
// Notice that ')' is not included, because b would have to have
// been called from a different context in rule a for ')' to be
// included.
//
// For error recovery, we cannot consider FOLLOW(c)
// (context-sensitive or otherwise). We need the combined set of
// all context-sensitive FOLLOW sets--the set of all tokens that
// could follow any reference in the call chain. We need to
// resync to one of those tokens. Note that FOLLOW(c)='^' and if
// we resync'd to that token, we'd consume until EOF. We need to
// sync to context-sensitive FOLLOWs for a, b, and c: {']','^'}.
// In this case, for input "[]", LA(1) is ']' and in the set, so we would
// not consume anything. After printing an error, rule c would
// return normally. Rule b would not find the required '^' though.
// At this point, it gets a mismatched token error and throws an
// exception (since LA(1) is not in the viable following token
// set). The rule exception handler tries to recover, but finds
// the same recovery set and doesn't consume anything. Rule b
// exits normally returning to rule a. Now it finds the ']' (and
// with the successful match exits errorRecovery mode).
//
// So, you can see that the parser walks up the call chain looking
// for the token that was a member of the recovery set.
//
// Errors are not generated in errorRecovery mode.
//
// ANTLR's error recovery mechanism is based upon original ideas:
//
// "Algorithms + Data Structures = Programs" by Niklaus Wirth
//
// and
//
// "A note on error recovery in recursive descent parsers":
// http://portal.acm.org/citation.cfm?id=947902.947905
//
// Later, Josef Grosch had some good ideas:
//
// "Efficient and Comfortable Error Recovery in Recursive Descent
// Parsers":
// ftp://www.cocolab.com/products/cocktail/doca4.ps/ell.ps.zip
//
// Like Grosch I implement context-sensitive FOLLOW sets that are combined
// at run-time upon error to avoid overhead during parsing.
//
DefaultErrorStrategy.prototype.getErrorRecoverySet = function(recognizer) {
    var atn = recognizer._interp.atn;
    var ctx = recognizer._ctx;
    var recoverSet = new IntervalSet();
    while (ctx !== null && ctx.invokingState>=0) {
        // compute what follows who invoked us
        var invokingState = atn.states[ctx.invokingState];
        var rt = invokingState.transitions[0];
        var follow = atn.nextTokens(rt.followState);
        recoverSet.addSet(follow);
        ctx = ctx.parentCtx;
    }
    recoverSet.removeOne(Token.EPSILON);
    return recoverSet;
};

// Consume tokens until one matches the given token set.//
DefaultErrorStrategy.prototype.consumeUntil = function(recognizer, set) {
    var ttype = recognizer.getTokenStream().LA(1);
    while( ttype !== Token.EOF && !set.contains(ttype)) {
        recognizer.consume();
        ttype = recognizer.getTokenStream().LA(1);
    }
};

//
// This implementation of {@link ANTLRErrorStrategy} responds to syntax errors
// by immediately canceling the parse operation with a
// {@link ParseCancellationException}. The implementation ensures that the
// {@link ParserRuleContext//exception} field is set for all parse tree nodes
// that were not completed prior to encountering the error.
//
// <p>
// This error strategy is useful in the following scenarios.</p>
//
// <ul>
// <li><strong>Two-stage parsing:</strong> This error strategy allows the first
// stage of two-stage parsing to immediately terminate if an error is
// encountered, and immediately fall back to the second stage. In addition to
// avoiding wasted work by attempting to recover from errors here, the empty
// implementation of {@link BailErrorStrategy//sync} improves the performance of
// the first stage.</li>
// <li><strong>Silent validation:</strong> When syntax errors are not being
// reported or logged, and the parse result is simply ignored if errors occur,
// the {@link BailErrorStrategy} avoids wasting work on recovering from errors
// when the result will be ignored either way.</li>
// </ul>
//
// <p>
// {@code myparser.setErrorHandler(new BailErrorStrategy());}</p>
//
// @see Parser//setErrorHandler(ANTLRErrorStrategy)
//
function BailErrorStrategy() {
	DefaultErrorStrategy.call(this);
	return this;
}

BailErrorStrategy.prototype = Object.create(DefaultErrorStrategy.prototype);
BailErrorStrategy.prototype.constructor = BailErrorStrategy;

// Instead of recovering from exception {@code e}, re-throw it wrapped
// in a {@link ParseCancellationException} so it is not caught by the
// rule function catches. Use {@link Exception//getCause()} to get the
// original {@link RecognitionException}.
//
BailErrorStrategy.prototype.recover = function(recognizer, e) {
    var context = recognizer._ctx;
    while (context !== null) {
        context.exception = e;
        context = context.parentCtx;
    }
    throw new ParseCancellationException(e);
};

// Make sure we don't attempt to recover inline; if the parser
// successfully recovers, it won't throw an exception.
//
BailErrorStrategy.prototype.recoverInline = function(recognizer) {
    this.recover(recognizer, new InputMismatchException(recognizer));
};

// Make sure we don't attempt to recover from problems in subrules.//
BailErrorStrategy.prototype.sync = function(recognizer) {
    // pass
};

exports.BailErrorStrategy = BailErrorStrategy;
exports.DefaultErrorStrategy = DefaultErrorStrategy;

},{"./../IntervalSet":31,"./../Token":39,"./../atn/ATNState":47,"./Errors":64}],64:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

// The root of the ANTLR exception hierarchy. In general, ANTLR tracks just
//  3 kinds of errors: prediction errors, failed predicate errors, and
//  mismatched input errors. In each case, the parser knows where it is
//  in the input, where it is in the ATN, the rule invocation stack,
//  and what kind of problem occurred.

var PredicateTransition = require('./../atn/Transition').PredicateTransition;

function RecognitionException(params) {
	Error.call(this);
	if (!!Error.captureStackTrace) {
        Error.captureStackTrace(this, RecognitionException);
	} else {
		var stack = new Error().stack;
	}
	this.message = params.message;
    this.recognizer = params.recognizer;
    this.input = params.input;
    this.ctx = params.ctx;
    // The current {@link Token} when an error occurred. Since not all streams
    // support accessing symbols by index, we have to track the {@link Token}
    // instance itself.
    this.offendingToken = null;
    // Get the ATN state number the parser was in at the time the error
    // occurred. For {@link NoViableAltException} and
    // {@link LexerNoViableAltException} exceptions, this is the
    // {@link DecisionState} number. For others, it is the state whose outgoing
    // edge we couldn't match.
    this.offendingState = -1;
    if (this.recognizer!==null) {
        this.offendingState = this.recognizer.state;
    }
    return this;
}

RecognitionException.prototype = Object.create(Error.prototype);
RecognitionException.prototype.constructor = RecognitionException;

// <p>If the state number is not known, this method returns -1.</p>

//
// Gets the set of input symbols which could potentially follow the
// previously matched symbol at the time this exception was thrown.
//
// <p>If the set of expected tokens is not known and could not be computed,
// this method returns {@code null}.</p>
//
// @return The set of token types that could potentially follow the current
// state in the ATN, or {@code null} if the information is not available.
// /
RecognitionException.prototype.getExpectedTokens = function() {
    if (this.recognizer!==null) {
        return this.recognizer.atn.getExpectedTokens(this.offendingState, this.ctx);
    } else {
        return null;
    }
};

RecognitionException.prototype.toString = function() {
    return this.message;
};

function LexerNoViableAltException(lexer, input, startIndex, deadEndConfigs) {
	RecognitionException.call(this, {message:"", recognizer:lexer, input:input, ctx:null});
    this.startIndex = startIndex;
    this.deadEndConfigs = deadEndConfigs;
    return this;
}

LexerNoViableAltException.prototype = Object.create(RecognitionException.prototype);
LexerNoViableAltException.prototype.constructor = LexerNoViableAltException;

LexerNoViableAltException.prototype.toString = function() {
    var symbol = "";
    if (this.startIndex >= 0 && this.startIndex < this.input.size) {
        symbol = this.input.getText((this.startIndex,this.startIndex));
    }
    return "LexerNoViableAltException" + symbol;
};

// Indicates that the parser could not decide which of two or more paths
// to take based upon the remaining input. It tracks the starting token
// of the offending input and also knows where the parser was
// in the various paths when the error. Reported by reportNoViableAlternative()
//
function NoViableAltException(recognizer, input, startToken, offendingToken, deadEndConfigs, ctx) {
	ctx = ctx || recognizer._ctx;
	offendingToken = offendingToken || recognizer.getCurrentToken();
	startToken = startToken || recognizer.getCurrentToken();
	input = input || recognizer.getInputStream();
	RecognitionException.call(this, {message:"", recognizer:recognizer, input:input, ctx:ctx});
    // Which configurations did we try at input.index() that couldn't match
	// input.LT(1)?//
    this.deadEndConfigs = deadEndConfigs;
    // The token object at the start index; the input stream might
    // not be buffering tokens so get a reference to it. (At the
    // time the error occurred, of course the stream needs to keep a
    // buffer all of the tokens but later we might not have access to those.)
    this.startToken = startToken;
    this.offendingToken = offendingToken;
}

NoViableAltException.prototype = Object.create(RecognitionException.prototype);
NoViableAltException.prototype.constructor = NoViableAltException;

// This signifies any kind of mismatched input exceptions such as
// when the current input does not match the expected token.
//
function InputMismatchException(recognizer) {
	RecognitionException.call(this, {message:"", recognizer:recognizer, input:recognizer.getInputStream(), ctx:recognizer._ctx});
    this.offendingToken = recognizer.getCurrentToken();
}

InputMismatchException.prototype = Object.create(RecognitionException.prototype);
InputMismatchException.prototype.constructor = InputMismatchException;

// A semantic predicate failed during validation. Validation of predicates
// occurs when normally parsing the alternative just like matching a token.
// Disambiguating predicate evaluation occurs when we test a predicate during
// prediction.

function FailedPredicateException(recognizer, predicate, message) {
	RecognitionException.call(this, {message:this.formatMessage(predicate,message || null), recognizer:recognizer,
                         input:recognizer.getInputStream(), ctx:recognizer._ctx});
    var s = recognizer._interp.atn.states[recognizer.state];
    var trans = s.transitions[0];
    if (trans instanceof PredicateTransition) {
        this.ruleIndex = trans.ruleIndex;
        this.predicateIndex = trans.predIndex;
    } else {
        this.ruleIndex = 0;
        this.predicateIndex = 0;
    }
    this.predicate = predicate;
    this.offendingToken = recognizer.getCurrentToken();
    return this;
}

FailedPredicateException.prototype = Object.create(RecognitionException.prototype);
FailedPredicateException.prototype.constructor = FailedPredicateException;

FailedPredicateException.prototype.formatMessage = function(predicate, message) {
    if (message !==null) {
        return message;
    } else {
        return "failed predicate: {" + predicate + "}?";
    }
};

function ParseCancellationException() {
	Error.call(this);
	Error.captureStackTrace(this, ParseCancellationException);
	return this;
}

ParseCancellationException.prototype = Object.create(Error.prototype);
ParseCancellationException.prototype.constructor = ParseCancellationException;

exports.RecognitionException = RecognitionException;
exports.NoViableAltException = NoViableAltException;
exports.LexerNoViableAltException = LexerNoViableAltException;
exports.InputMismatchException = InputMismatchException;
exports.FailedPredicateException = FailedPredicateException;
exports.ParseCancellationException = ParseCancellationException;

},{"./../atn/Transition":55}],65:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

exports.RecognitionException = require('./Errors').RecognitionException;
exports.NoViableAltException = require('./Errors').NoViableAltException;
exports.LexerNoViableAltException = require('./Errors').LexerNoViableAltException;
exports.InputMismatchException = require('./Errors').InputMismatchException;
exports.FailedPredicateException = require('./Errors').FailedPredicateException;
exports.DiagnosticErrorListener = require('./DiagnosticErrorListener').DiagnosticErrorListener;
exports.BailErrorStrategy = require('./ErrorStrategy').BailErrorStrategy;
exports.ErrorListener = require('./ErrorListener').ErrorListener;

},{"./DiagnosticErrorListener":61,"./ErrorListener":62,"./ErrorStrategy":63,"./Errors":64}],66:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
exports.atn = require('./atn/index');
exports.codepointat = require('./polyfills/codepointat');
exports.dfa = require('./dfa/index');
exports.fromcodepoint = require('./polyfills/fromcodepoint');
exports.tree = require('./tree/index');
exports.error = require('./error/index');
exports.Token = require('./Token').Token;
exports.CharStreams = require('./CharStreams').CharStreams;
exports.CommonToken = require('./Token').CommonToken;
exports.InputStream = require('./InputStream').InputStream;
exports.FileStream = require('./FileStream').FileStream;
exports.CommonTokenStream = require('./CommonTokenStream').CommonTokenStream;
exports.Lexer = require('./Lexer').Lexer;
exports.Parser = require('./Parser').Parser;
var pc = require('./PredictionContext');
exports.PredictionContextCache = pc.PredictionContextCache;
exports.ParserRuleContext = require('./ParserRuleContext').ParserRuleContext;
exports.Interval = require('./IntervalSet').Interval;
exports.Utils = require('./Utils');

},{"./CharStreams":26,"./CommonTokenStream":28,"./FileStream":29,"./InputStream":30,"./IntervalSet":31,"./Lexer":33,"./Parser":34,"./ParserRuleContext":35,"./PredictionContext":36,"./Token":39,"./Utils":40,"./atn/index":56,"./dfa/index":60,"./error/index":65,"./polyfills/codepointat":67,"./polyfills/fromcodepoint":68,"./tree/index":71}],67:[function(require,module,exports){
/*! https://mths.be/codepointat v0.2.0 by @mathias */
if (!String.prototype.codePointAt) {
	(function() {
		'use strict'; // needed to support `apply`/`call` with `undefined`/`null`
		var defineProperty = (function() {
			// IE 8 only supports `Object.defineProperty` on DOM elements
			try {
				var object = {};
				var $defineProperty = Object.defineProperty;
				var result = $defineProperty(object, object, object) && $defineProperty;
			} catch(error) {}
			return result;
		}());
		var codePointAt = function(position) {
			if (this == null) {
				throw TypeError();
			}
			var string = String(this);
			var size = string.length;
			// `ToInteger`
			var index = position ? Number(position) : 0;
			if (index != index) { // better `isNaN`
				index = 0;
			}
			// Account for out-of-bounds indices:
			if (index < 0 || index >= size) {
				return undefined;
			}
			// Get the first code unit
			var first = string.charCodeAt(index);
			var second;
			if ( // check if it’s the start of a surrogate pair
				first >= 0xD800 && first <= 0xDBFF && // high surrogate
				size > index + 1 // there is a next code unit
			) {
				second = string.charCodeAt(index + 1);
				if (second >= 0xDC00 && second <= 0xDFFF) { // low surrogate
					// https://mathiasbynens.be/notes/javascript-encoding#surrogate-formulae
					return (first - 0xD800) * 0x400 + second - 0xDC00 + 0x10000;
				}
			}
			return first;
		};
		if (defineProperty) {
			defineProperty(String.prototype, 'codePointAt', {
				'value': codePointAt,
				'configurable': true,
				'writable': true
			});
		} else {
			String.prototype.codePointAt = codePointAt;
		}
	}());
}

},{}],68:[function(require,module,exports){
/*! https://mths.be/fromcodepoint v0.2.1 by @mathias */
if (!String.fromCodePoint) {
	(function() {
		var defineProperty = (function() {
			// IE 8 only supports `Object.defineProperty` on DOM elements
			try {
				var object = {};
				var $defineProperty = Object.defineProperty;
				var result = $defineProperty(object, object, object) && $defineProperty;
			} catch(error) {}
			return result;
		}());
		var stringFromCharCode = String.fromCharCode;
		var floor = Math.floor;
		var fromCodePoint = function(_) {
			var MAX_SIZE = 0x4000;
			var codeUnits = [];
			var highSurrogate;
			var lowSurrogate;
			var index = -1;
			var length = arguments.length;
			if (!length) {
				return '';
			}
			var result = '';
			while (++index < length) {
				var codePoint = Number(arguments[index]);
				if (
					!isFinite(codePoint) || // `NaN`, `+Infinity`, or `-Infinity`
					codePoint < 0 || // not a valid Unicode code point
					codePoint > 0x10FFFF || // not a valid Unicode code point
					floor(codePoint) != codePoint // not an integer
				) {
					throw RangeError('Invalid code point: ' + codePoint);
				}
				if (codePoint <= 0xFFFF) { // BMP code point
					codeUnits.push(codePoint);
				} else { // Astral code point; split in surrogate halves
					// https://mathiasbynens.be/notes/javascript-encoding#surrogate-formulae
					codePoint -= 0x10000;
					highSurrogate = (codePoint >> 10) + 0xD800;
					lowSurrogate = (codePoint % 0x400) + 0xDC00;
					codeUnits.push(highSurrogate, lowSurrogate);
				}
				if (index + 1 == length || codeUnits.length > MAX_SIZE) {
					result += stringFromCharCode.apply(null, codeUnits);
					codeUnits.length = 0;
				}
			}
			return result;
		};
		if (defineProperty) {
			defineProperty(String, 'fromCodePoint', {
				'value': fromCodePoint,
				'configurable': true,
				'writable': true
			});
		} else {
			String.fromCodePoint = fromCodePoint;
		}
	}());
}

},{}],69:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
///

// The basic notion of a tree has a parent, a payload, and a list of children.
//  It is the most abstract interface for all the trees used by ANTLR.
///

var Token = require('./../Token').Token;
var Interval = require('./../IntervalSet').Interval;
var INVALID_INTERVAL = new Interval(-1, -2);
var Utils = require('../Utils.js');


function Tree() {
	return this;
}

function SyntaxTree() {
	Tree.call(this);
	return this;
}

SyntaxTree.prototype = Object.create(Tree.prototype);
SyntaxTree.prototype.constructor = SyntaxTree;

function ParseTree() {
	SyntaxTree.call(this);
	return this;
}

ParseTree.prototype = Object.create(SyntaxTree.prototype);
ParseTree.prototype.constructor = ParseTree;

function RuleNode() {
	ParseTree.call(this);
	return this;
}

RuleNode.prototype = Object.create(ParseTree.prototype);
RuleNode.prototype.constructor = RuleNode;

function TerminalNode() {
	ParseTree.call(this);
	return this;
}

TerminalNode.prototype = Object.create(ParseTree.prototype);
TerminalNode.prototype.constructor = TerminalNode;

function ErrorNode() {
	TerminalNode.call(this);
	return this;
}

ErrorNode.prototype = Object.create(TerminalNode.prototype);
ErrorNode.prototype.constructor = ErrorNode;

function ParseTreeVisitor() {
	return this;
}

ParseTreeVisitor.prototype.visit = function(ctx) {
 	if (Array.isArray(ctx)) {
		return ctx.map(function(child) {
            return child.accept(this);
        }, this);
	} else {
		return ctx.accept(this);
	}
};

ParseTreeVisitor.prototype.visitChildren = function(ctx) {
	if (ctx.children) {
		return this.visit(ctx.children);
	} else {
		return null;
	}
}

ParseTreeVisitor.prototype.visitTerminal = function(node) {
};

ParseTreeVisitor.prototype.visitErrorNode = function(node) {
};


function ParseTreeListener() {
	return this;
}

ParseTreeListener.prototype.visitTerminal = function(node) {
};

ParseTreeListener.prototype.visitErrorNode = function(node) {
};

ParseTreeListener.prototype.enterEveryRule = function(node) {
};

ParseTreeListener.prototype.exitEveryRule = function(node) {
};

function TerminalNodeImpl(symbol) {
	TerminalNode.call(this);
	this.parentCtx = null;
	this.symbol = symbol;
	return this;
}

TerminalNodeImpl.prototype = Object.create(TerminalNode.prototype);
TerminalNodeImpl.prototype.constructor = TerminalNodeImpl;

TerminalNodeImpl.prototype.getChild = function(i) {
	return null;
};

TerminalNodeImpl.prototype.getSymbol = function() {
	return this.symbol;
};

TerminalNodeImpl.prototype.getParent = function() {
	return this.parentCtx;
};

TerminalNodeImpl.prototype.getPayload = function() {
	return this.symbol;
};

TerminalNodeImpl.prototype.getSourceInterval = function() {
	if (this.symbol === null) {
		return INVALID_INTERVAL;
	}
	var tokenIndex = this.symbol.tokenIndex;
	return new Interval(tokenIndex, tokenIndex);
};

TerminalNodeImpl.prototype.getChildCount = function() {
	return 0;
};

TerminalNodeImpl.prototype.accept = function(visitor) {
	return visitor.visitTerminal(this);
};

TerminalNodeImpl.prototype.getText = function() {
	return this.symbol.text;
};

TerminalNodeImpl.prototype.toString = function() {
	if (this.symbol.type === Token.EOF) {
		return "<EOF>";
	} else {
		return this.symbol.text;
	}
};

// Represents a token that was consumed during resynchronization
// rather than during a valid match operation. For example,
// we will create this kind of a node during single token insertion
// and deletion as well as during "consume until error recovery set"
// upon no viable alternative exceptions.

function ErrorNodeImpl(token) {
	TerminalNodeImpl.call(this, token);
	return this;
}

ErrorNodeImpl.prototype = Object.create(TerminalNodeImpl.prototype);
ErrorNodeImpl.prototype.constructor = ErrorNodeImpl;

ErrorNodeImpl.prototype.isErrorNode = function() {
	return true;
};

ErrorNodeImpl.prototype.accept = function(visitor) {
	return visitor.visitErrorNode(this);
};

function ParseTreeWalker() {
	return this;
}

ParseTreeWalker.prototype.walk = function(listener, t) {
	var errorNode = t instanceof ErrorNode ||
			(t.isErrorNode !== undefined && t.isErrorNode());
	if (errorNode) {
		listener.visitErrorNode(t);
	} else if (t instanceof TerminalNode) {
		listener.visitTerminal(t);
	} else {
		this.enterRule(listener, t);
		for (var i = 0; i < t.getChildCount(); i++) {
			var child = t.getChild(i);
			this.walk(listener, child);
		}
		this.exitRule(listener, t);
	}
};
//
// The discovery of a rule node, involves sending two events: the generic
// {@link ParseTreeListener//enterEveryRule} and a
// {@link RuleContext}-specific event. First we trigger the generic and then
// the rule specific. We to them in reverse order upon finishing the node.
//
ParseTreeWalker.prototype.enterRule = function(listener, r) {
	var ctx = r.getRuleContext();
	listener.enterEveryRule(ctx);
	ctx.enterRule(listener);
};

ParseTreeWalker.prototype.exitRule = function(listener, r) {
	var ctx = r.getRuleContext();
	ctx.exitRule(listener);
	listener.exitEveryRule(ctx);
};

ParseTreeWalker.DEFAULT = new ParseTreeWalker();

exports.RuleNode = RuleNode;
exports.ErrorNode = ErrorNode;
exports.TerminalNode = TerminalNode;
exports.ErrorNodeImpl = ErrorNodeImpl;
exports.TerminalNodeImpl = TerminalNodeImpl;
exports.ParseTreeListener = ParseTreeListener;
exports.ParseTreeVisitor = ParseTreeVisitor;
exports.ParseTreeWalker = ParseTreeWalker;
exports.INVALID_INTERVAL = INVALID_INTERVAL;

},{"../Utils.js":40,"./../IntervalSet":31,"./../Token":39}],70:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

var Utils = require('./../Utils');
var Token = require('./../Token').Token;
var RuleNode = require('./Tree').RuleNode;
var ErrorNode = require('./Tree').ErrorNode;
var TerminalNode = require('./Tree').TerminalNode;
var ParserRuleContext = require('./../ParserRuleContext').ParserRuleContext;
var RuleContext = require('./../RuleContext').RuleContext;
var INVALID_ALT_NUMBER = require('./../atn/ATN').INVALID_ALT_NUMBER;


/** A set of utility routines useful for all kinds of ANTLR trees. */
function Trees() {
}

// Print out a whole tree in LISP form. {@link //getNodeText} is used on the
//  node payloads to get the text for the nodes.  Detect
//  parse trees and extract data appropriately.
Trees.toStringTree = function(tree, ruleNames, recog) {
	ruleNames = ruleNames || null;
	recog = recog || null;
    if(recog!==null) {
       ruleNames = recog.ruleNames;
    }
    var s = Trees.getNodeText(tree, ruleNames);
    s = Utils.escapeWhitespace(s, false);
    var c = tree.getChildCount();
    if(c===0) {
        return s;
    }
    var res = "(" + s + ' ';
    if(c>0) {
        s = Trees.toStringTree(tree.getChild(0), ruleNames);
        res = res.concat(s);
    }
    for(var i=1;i<c;i++) {
        s = Trees.toStringTree(tree.getChild(i), ruleNames);
        res = res.concat(' ' + s);
    }
    res = res.concat(")");
    return res;
};

Trees.getNodeText = function(t, ruleNames, recog) {
	ruleNames = ruleNames || null;
	recog = recog || null;
    if(recog!==null) {
        ruleNames = recog.ruleNames;
    }
    if(ruleNames!==null) {
       if (t instanceof RuleContext) {
           var altNumber = t.getAltNumber();
           if ( altNumber!=INVALID_ALT_NUMBER ) {
               return ruleNames[t.ruleIndex]+":"+altNumber;
           }
           return ruleNames[t.ruleIndex];
       } else if ( t instanceof ErrorNode) {
           return t.toString();
       } else if(t instanceof TerminalNode) {
           if(t.symbol!==null) {
               return t.symbol.text;
           }
       }
    }
    // no recog for rule names
    var payload = t.getPayload();
    if (payload instanceof Token ) {
       return payload.text;
    }
    return t.getPayload().toString();
};


// Return ordered list of all children of this node
Trees.getChildren = function(t) {
	var list = [];
	for(var i=0;i<t.getChildCount();i++) {
		list.push(t.getChild(i));
	}
	return list;
};

// Return a list of all ancestors of this node.  The first node of
//  list is the root and the last is the parent of this node.
//
Trees.getAncestors = function(t) {
    var ancestors = [];
    t = t.getParent();
    while(t!==null) {
        ancestors = [t].concat(ancestors);
        t = t.getParent();
    }
    return ancestors;
};

Trees.findAllTokenNodes = function(t, ttype) {
    return Trees.findAllNodes(t, ttype, true);
};

Trees.findAllRuleNodes = function(t, ruleIndex) {
	return Trees.findAllNodes(t, ruleIndex, false);
};

Trees.findAllNodes = function(t, index, findTokens) {
	var nodes = [];
	Trees._findAllNodes(t, index, findTokens, nodes);
	return nodes;
};

Trees._findAllNodes = function(t, index, findTokens, nodes) {
	// check this node (the root) first
	if(findTokens && (t instanceof TerminalNode)) {
		if(t.symbol.type===index) {
			nodes.push(t);
		}
	} else if(!findTokens && (t instanceof ParserRuleContext)) {
		if(t.ruleIndex===index) {
			nodes.push(t);
		}
	}
	// check children
	for(var i=0;i<t.getChildCount();i++) {
		Trees._findAllNodes(t.getChild(i), index, findTokens, nodes);
	}
};

Trees.descendants = function(t) {
	var nodes = [t];
    for(var i=0;i<t.getChildCount();i++) {
        nodes = nodes.concat(Trees.descendants(t.getChild(i)));
    }
    return nodes;
};


exports.Trees = Trees;
},{"./../ParserRuleContext":35,"./../RuleContext":38,"./../Token":39,"./../Utils":40,"./../atn/ATN":41,"./Tree":69}],71:[function(require,module,exports){
/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

var Tree = require('./Tree');
exports.Trees = require('./Trees').Trees;
exports.RuleNode = Tree.RuleNode;
exports.ParseTreeListener = Tree.ParseTreeListener;
exports.ParseTreeVisitor = Tree.ParseTreeVisitor;
exports.ParseTreeWalker = Tree.ParseTreeWalker;

},{"./Tree":69,"./Trees":70}],72:[function(require,module,exports){
'use strict'

exports.byteLength = byteLength
exports.toByteArray = toByteArray
exports.fromByteArray = fromByteArray

var lookup = []
var revLookup = []
var Arr = typeof Uint8Array !== 'undefined' ? Uint8Array : Array

var code = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'
for (var i = 0, len = code.length; i < len; ++i) {
  lookup[i] = code[i]
  revLookup[code.charCodeAt(i)] = i
}

// Support decoding URL-safe base64 strings, as Node.js does.
// See: https://en.wikipedia.org/wiki/Base64#URL_applications
revLookup['-'.charCodeAt(0)] = 62
revLookup['_'.charCodeAt(0)] = 63

function getLens (b64) {
  var len = b64.length

  if (len % 4 > 0) {
    throw new Error('Invalid string. Length must be a multiple of 4')
  }

  // Trim off extra bytes after placeholder bytes are found
  // See: https://github.com/beatgammit/base64-js/issues/42
  var validLen = b64.indexOf('=')
  if (validLen === -1) validLen = len

  var placeHoldersLen = validLen === len
    ? 0
    : 4 - (validLen % 4)

  return [validLen, placeHoldersLen]
}

// base64 is 4/3 + up to two characters of the original data
function byteLength (b64) {
  var lens = getLens(b64)
  var validLen = lens[0]
  var placeHoldersLen = lens[1]
  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen
}

function _byteLength (b64, validLen, placeHoldersLen) {
  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen
}

function toByteArray (b64) {
  var tmp
  var lens = getLens(b64)
  var validLen = lens[0]
  var placeHoldersLen = lens[1]

  var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen))

  var curByte = 0

  // if there are placeholders, only get up to the last complete 4 chars
  var len = placeHoldersLen > 0
    ? validLen - 4
    : validLen

  var i
  for (i = 0; i < len; i += 4) {
    tmp =
      (revLookup[b64.charCodeAt(i)] << 18) |
      (revLookup[b64.charCodeAt(i + 1)] << 12) |
      (revLookup[b64.charCodeAt(i + 2)] << 6) |
      revLookup[b64.charCodeAt(i + 3)]
    arr[curByte++] = (tmp >> 16) & 0xFF
    arr[curByte++] = (tmp >> 8) & 0xFF
    arr[curByte++] = tmp & 0xFF
  }

  if (placeHoldersLen === 2) {
    tmp =
      (revLookup[b64.charCodeAt(i)] << 2) |
      (revLookup[b64.charCodeAt(i + 1)] >> 4)
    arr[curByte++] = tmp & 0xFF
  }

  if (placeHoldersLen === 1) {
    tmp =
      (revLookup[b64.charCodeAt(i)] << 10) |
      (revLookup[b64.charCodeAt(i + 1)] << 4) |
      (revLookup[b64.charCodeAt(i + 2)] >> 2)
    arr[curByte++] = (tmp >> 8) & 0xFF
    arr[curByte++] = tmp & 0xFF
  }

  return arr
}

function tripletToBase64 (num) {
  return lookup[num >> 18 & 0x3F] +
    lookup[num >> 12 & 0x3F] +
    lookup[num >> 6 & 0x3F] +
    lookup[num & 0x3F]
}

function encodeChunk (uint8, start, end) {
  var tmp
  var output = []
  for (var i = start; i < end; i += 3) {
    tmp =
      ((uint8[i] << 16) & 0xFF0000) +
      ((uint8[i + 1] << 8) & 0xFF00) +
      (uint8[i + 2] & 0xFF)
    output.push(tripletToBase64(tmp))
  }
  return output.join('')
}

function fromByteArray (uint8) {
  var tmp
  var len = uint8.length
  var extraBytes = len % 3 // if we have 1 byte left, pad 2 bytes
  var parts = []
  var maxChunkLength = 16383 // must be multiple of 3

  // go through the array every three bytes, we'll deal with trailing stuff later
  for (var i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength) {
    parts.push(encodeChunk(
      uint8, i, (i + maxChunkLength) > len2 ? len2 : (i + maxChunkLength)
    ))
  }

  // pad the end with zeros, but make sure to not forget the extra bytes
  if (extraBytes === 1) {
    tmp = uint8[len - 1]
    parts.push(
      lookup[tmp >> 2] +
      lookup[(tmp << 4) & 0x3F] +
      '=='
    )
  } else if (extraBytes === 2) {
    tmp = (uint8[len - 2] << 8) + uint8[len - 1]
    parts.push(
      lookup[tmp >> 10] +
      lookup[(tmp >> 4) & 0x3F] +
      lookup[(tmp << 2) & 0x3F] +
      '='
    )
  }

  return parts.join('')
}

},{}],73:[function(require,module,exports){

},{}],74:[function(require,module,exports){
arguments[4][73][0].apply(exports,arguments)
},{"dup":73}],75:[function(require,module,exports){
(function (global){
/*! https://mths.be/punycode v1.4.1 by @mathias */
;(function(root) {

	/** Detect free variables */
	var freeExports = typeof exports == 'object' && exports &&
		!exports.nodeType && exports;
	var freeModule = typeof module == 'object' && module &&
		!module.nodeType && module;
	var freeGlobal = typeof global == 'object' && global;
	if (
		freeGlobal.global === freeGlobal ||
		freeGlobal.window === freeGlobal ||
		freeGlobal.self === freeGlobal
	) {
		root = freeGlobal;
	}

	/**
	 * The `punycode` object.
	 * @name punycode
	 * @type Object
	 */
	var punycode,

	/** Highest positive signed 32-bit float value */
	maxInt = 2147483647, // aka. 0x7FFFFFFF or 2^31-1

	/** Bootstring parameters */
	base = 36,
	tMin = 1,
	tMax = 26,
	skew = 38,
	damp = 700,
	initialBias = 72,
	initialN = 128, // 0x80
	delimiter = '-', // '\x2D'

	/** Regular expressions */
	regexPunycode = /^xn--/,
	regexNonASCII = /[^\x20-\x7E]/, // unprintable ASCII chars + non-ASCII chars
	regexSeparators = /[\x2E\u3002\uFF0E\uFF61]/g, // RFC 3490 separators

	/** Error messages */
	errors = {
		'overflow': 'Overflow: input needs wider integers to process',
		'not-basic': 'Illegal input >= 0x80 (not a basic code point)',
		'invalid-input': 'Invalid input'
	},

	/** Convenience shortcuts */
	baseMinusTMin = base - tMin,
	floor = Math.floor,
	stringFromCharCode = String.fromCharCode,

	/** Temporary variable */
	key;

	/*--------------------------------------------------------------------------*/

	/**
	 * A generic error utility function.
	 * @private
	 * @param {String} type The error type.
	 * @returns {Error} Throws a `RangeError` with the applicable error message.
	 */
	function error(type) {
		throw new RangeError(errors[type]);
	}

	/**
	 * A generic `Array#map` utility function.
	 * @private
	 * @param {Array} array The array to iterate over.
	 * @param {Function} callback The function that gets called for every array
	 * item.
	 * @returns {Array} A new array of values returned by the callback function.
	 */
	function map(array, fn) {
		var length = array.length;
		var result = [];
		while (length--) {
			result[length] = fn(array[length]);
		}
		return result;
	}

	/**
	 * A simple `Array#map`-like wrapper to work with domain name strings or email
	 * addresses.
	 * @private
	 * @param {String} domain The domain name or email address.
	 * @param {Function} callback The function that gets called for every
	 * character.
	 * @returns {Array} A new string of characters returned by the callback
	 * function.
	 */
	function mapDomain(string, fn) {
		var parts = string.split('@');
		var result = '';
		if (parts.length > 1) {
			// In email addresses, only the domain name should be punycoded. Leave
			// the local part (i.e. everything up to `@`) intact.
			result = parts[0] + '@';
			string = parts[1];
		}
		// Avoid `split(regex)` for IE8 compatibility. See #17.
		string = string.replace(regexSeparators, '\x2E');
		var labels = string.split('.');
		var encoded = map(labels, fn).join('.');
		return result + encoded;
	}

	/**
	 * Creates an array containing the numeric code points of each Unicode
	 * character in the string. While JavaScript uses UCS-2 internally,
	 * this function will convert a pair of surrogate halves (each of which
	 * UCS-2 exposes as separate characters) into a single code point,
	 * matching UTF-16.
	 * @see `punycode.ucs2.encode`
	 * @see <https://mathiasbynens.be/notes/javascript-encoding>
	 * @memberOf punycode.ucs2
	 * @name decode
	 * @param {String} string The Unicode input string (UCS-2).
	 * @returns {Array} The new array of code points.
	 */
	function ucs2decode(string) {
		var output = [],
		    counter = 0,
		    length = string.length,
		    value,
		    extra;
		while (counter < length) {
			value = string.charCodeAt(counter++);
			if (value >= 0xD800 && value <= 0xDBFF && counter < length) {
				// high surrogate, and there is a next character
				extra = string.charCodeAt(counter++);
				if ((extra & 0xFC00) == 0xDC00) { // low surrogate
					output.push(((value & 0x3FF) << 10) + (extra & 0x3FF) + 0x10000);
				} else {
					// unmatched surrogate; only append this code unit, in case the next
					// code unit is the high surrogate of a surrogate pair
					output.push(value);
					counter--;
				}
			} else {
				output.push(value);
			}
		}
		return output;
	}

	/**
	 * Creates a string based on an array of numeric code points.
	 * @see `punycode.ucs2.decode`
	 * @memberOf punycode.ucs2
	 * @name encode
	 * @param {Array} codePoints The array of numeric code points.
	 * @returns {String} The new Unicode string (UCS-2).
	 */
	function ucs2encode(array) {
		return map(array, function(value) {
			var output = '';
			if (value > 0xFFFF) {
				value -= 0x10000;
				output += stringFromCharCode(value >>> 10 & 0x3FF | 0xD800);
				value = 0xDC00 | value & 0x3FF;
			}
			output += stringFromCharCode(value);
			return output;
		}).join('');
	}

	/**
	 * Converts a basic code point into a digit/integer.
	 * @see `digitToBasic()`
	 * @private
	 * @param {Number} codePoint The basic numeric code point value.
	 * @returns {Number} The numeric value of a basic code point (for use in
	 * representing integers) in the range `0` to `base - 1`, or `base` if
	 * the code point does not represent a value.
	 */
	function basicToDigit(codePoint) {
		if (codePoint - 48 < 10) {
			return codePoint - 22;
		}
		if (codePoint - 65 < 26) {
			return codePoint - 65;
		}
		if (codePoint - 97 < 26) {
			return codePoint - 97;
		}
		return base;
	}

	/**
	 * Converts a digit/integer into a basic code point.
	 * @see `basicToDigit()`
	 * @private
	 * @param {Number} digit The numeric value of a basic code point.
	 * @returns {Number} The basic code point whose value (when used for
	 * representing integers) is `digit`, which needs to be in the range
	 * `0` to `base - 1`. If `flag` is non-zero, the uppercase form is
	 * used; else, the lowercase form is used. The behavior is undefined
	 * if `flag` is non-zero and `digit` has no uppercase form.
	 */
	function digitToBasic(digit, flag) {
		//  0..25 map to ASCII a..z or A..Z
		// 26..35 map to ASCII 0..9
		return digit + 22 + 75 * (digit < 26) - ((flag != 0) << 5);
	}

	/**
	 * Bias adaptation function as per section 3.4 of RFC 3492.
	 * https://tools.ietf.org/html/rfc3492#section-3.4
	 * @private
	 */
	function adapt(delta, numPoints, firstTime) {
		var k = 0;
		delta = firstTime ? floor(delta / damp) : delta >> 1;
		delta += floor(delta / numPoints);
		for (/* no initialization */; delta > baseMinusTMin * tMax >> 1; k += base) {
			delta = floor(delta / baseMinusTMin);
		}
		return floor(k + (baseMinusTMin + 1) * delta / (delta + skew));
	}

	/**
	 * Converts a Punycode string of ASCII-only symbols to a string of Unicode
	 * symbols.
	 * @memberOf punycode
	 * @param {String} input The Punycode string of ASCII-only symbols.
	 * @returns {String} The resulting string of Unicode symbols.
	 */
	function decode(input) {
		// Don't use UCS-2
		var output = [],
		    inputLength = input.length,
		    out,
		    i = 0,
		    n = initialN,
		    bias = initialBias,
		    basic,
		    j,
		    index,
		    oldi,
		    w,
		    k,
		    digit,
		    t,
		    /** Cached calculation results */
		    baseMinusT;

		// Handle the basic code points: let `basic` be the number of input code
		// points before the last delimiter, or `0` if there is none, then copy
		// the first basic code points to the output.

		basic = input.lastIndexOf(delimiter);
		if (basic < 0) {
			basic = 0;
		}

		for (j = 0; j < basic; ++j) {
			// if it's not a basic code point
			if (input.charCodeAt(j) >= 0x80) {
				error('not-basic');
			}
			output.push(input.charCodeAt(j));
		}

		// Main decoding loop: start just after the last delimiter if any basic code
		// points were copied; start at the beginning otherwise.

		for (index = basic > 0 ? basic + 1 : 0; index < inputLength; /* no final expression */) {

			// `index` is the index of the next character to be consumed.
			// Decode a generalized variable-length integer into `delta`,
			// which gets added to `i`. The overflow checking is easier
			// if we increase `i` as we go, then subtract off its starting
			// value at the end to obtain `delta`.
			for (oldi = i, w = 1, k = base; /* no condition */; k += base) {

				if (index >= inputLength) {
					error('invalid-input');
				}

				digit = basicToDigit(input.charCodeAt(index++));

				if (digit >= base || digit > floor((maxInt - i) / w)) {
					error('overflow');
				}

				i += digit * w;
				t = k <= bias ? tMin : (k >= bias + tMax ? tMax : k - bias);

				if (digit < t) {
					break;
				}

				baseMinusT = base - t;
				if (w > floor(maxInt / baseMinusT)) {
					error('overflow');
				}

				w *= baseMinusT;

			}

			out = output.length + 1;
			bias = adapt(i - oldi, out, oldi == 0);

			// `i` was supposed to wrap around from `out` to `0`,
			// incrementing `n` each time, so we'll fix that now:
			if (floor(i / out) > maxInt - n) {
				error('overflow');
			}

			n += floor(i / out);
			i %= out;

			// Insert `n` at position `i` of the output
			output.splice(i++, 0, n);

		}

		return ucs2encode(output);
	}

	/**
	 * Converts a string of Unicode symbols (e.g. a domain name label) to a
	 * Punycode string of ASCII-only symbols.
	 * @memberOf punycode
	 * @param {String} input The string of Unicode symbols.
	 * @returns {String} The resulting Punycode string of ASCII-only symbols.
	 */
	function encode(input) {
		var n,
		    delta,
		    handledCPCount,
		    basicLength,
		    bias,
		    j,
		    m,
		    q,
		    k,
		    t,
		    currentValue,
		    output = [],
		    /** `inputLength` will hold the number of code points in `input`. */
		    inputLength,
		    /** Cached calculation results */
		    handledCPCountPlusOne,
		    baseMinusT,
		    qMinusT;

		// Convert the input in UCS-2 to Unicode
		input = ucs2decode(input);

		// Cache the length
		inputLength = input.length;

		// Initialize the state
		n = initialN;
		delta = 0;
		bias = initialBias;

		// Handle the basic code points
		for (j = 0; j < inputLength; ++j) {
			currentValue = input[j];
			if (currentValue < 0x80) {
				output.push(stringFromCharCode(currentValue));
			}
		}

		handledCPCount = basicLength = output.length;

		// `handledCPCount` is the number of code points that have been handled;
		// `basicLength` is the number of basic code points.

		// Finish the basic string - if it is not empty - with a delimiter
		if (basicLength) {
			output.push(delimiter);
		}

		// Main encoding loop:
		while (handledCPCount < inputLength) {

			// All non-basic code points < n have been handled already. Find the next
			// larger one:
			for (m = maxInt, j = 0; j < inputLength; ++j) {
				currentValue = input[j];
				if (currentValue >= n && currentValue < m) {
					m = currentValue;
				}
			}

			// Increase `delta` enough to advance the decoder's <n,i> state to <m,0>,
			// but guard against overflow
			handledCPCountPlusOne = handledCPCount + 1;
			if (m - n > floor((maxInt - delta) / handledCPCountPlusOne)) {
				error('overflow');
			}

			delta += (m - n) * handledCPCountPlusOne;
			n = m;

			for (j = 0; j < inputLength; ++j) {
				currentValue = input[j];

				if (currentValue < n && ++delta > maxInt) {
					error('overflow');
				}

				if (currentValue == n) {
					// Represent delta as a generalized variable-length integer
					for (q = delta, k = base; /* no condition */; k += base) {
						t = k <= bias ? tMin : (k >= bias + tMax ? tMax : k - bias);
						if (q < t) {
							break;
						}
						qMinusT = q - t;
						baseMinusT = base - t;
						output.push(
							stringFromCharCode(digitToBasic(t + qMinusT % baseMinusT, 0))
						);
						q = floor(qMinusT / baseMinusT);
					}

					output.push(stringFromCharCode(digitToBasic(q, 0)));
					bias = adapt(delta, handledCPCountPlusOne, handledCPCount == basicLength);
					delta = 0;
					++handledCPCount;
				}
			}

			++delta;
			++n;

		}
		return output.join('');
	}

	/**
	 * Converts a Punycode string representing a domain name or an email address
	 * to Unicode. Only the Punycoded parts of the input will be converted, i.e.
	 * it doesn't matter if you call it on a string that has already been
	 * converted to Unicode.
	 * @memberOf punycode
	 * @param {String} input The Punycoded domain name or email address to
	 * convert to Unicode.
	 * @returns {String} The Unicode representation of the given Punycode
	 * string.
	 */
	function toUnicode(input) {
		return mapDomain(input, function(string) {
			return regexPunycode.test(string)
				? decode(string.slice(4).toLowerCase())
				: string;
		});
	}

	/**
	 * Converts a Unicode string representing a domain name or an email address to
	 * Punycode. Only the non-ASCII parts of the domain name will be converted,
	 * i.e. it doesn't matter if you call it with a domain that's already in
	 * ASCII.
	 * @memberOf punycode
	 * @param {String} input The domain name or email address to convert, as a
	 * Unicode string.
	 * @returns {String} The Punycode representation of the given domain name or
	 * email address.
	 */
	function toASCII(input) {
		return mapDomain(input, function(string) {
			return regexNonASCII.test(string)
				? 'xn--' + encode(string)
				: string;
		});
	}

	/*--------------------------------------------------------------------------*/

	/** Define the public API */
	punycode = {
		/**
		 * A string representing the current Punycode.js version number.
		 * @memberOf punycode
		 * @type String
		 */
		'version': '1.4.1',
		/**
		 * An object of methods to convert from JavaScript's internal character
		 * representation (UCS-2) to Unicode code points, and back.
		 * @see <https://mathiasbynens.be/notes/javascript-encoding>
		 * @memberOf punycode
		 * @type Object
		 */
		'ucs2': {
			'decode': ucs2decode,
			'encode': ucs2encode
		},
		'decode': decode,
		'encode': encode,
		'toASCII': toASCII,
		'toUnicode': toUnicode
	};

	/** Expose `punycode` */
	// Some AMD build optimizers, like r.js, check for specific condition patterns
	// like the following:
	if (
		typeof define == 'function' &&
		typeof define.amd == 'object' &&
		define.amd
	) {
		define('punycode', function() {
			return punycode;
		});
	} else if (freeExports && freeModule) {
		if (module.exports == freeExports) {
			// in Node.js, io.js, or RingoJS v0.8.0+
			freeModule.exports = punycode;
		} else {
			// in Narwhal or RingoJS v0.7.0-
			for (key in punycode) {
				punycode.hasOwnProperty(key) && (freeExports[key] = punycode[key]);
			}
		}
	} else {
		// in Rhino or a web browser
		root.punycode = punycode;
	}

}(this));

}).call(this,typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{}],76:[function(require,module,exports){
(function (Buffer){
/*!
 * The buffer module from node.js, for the browser.
 *
 * @author   Feross Aboukhadijeh <https://feross.org>
 * @license  MIT
 */
/* eslint-disable no-proto */

'use strict'

var base64 = require('base64-js')
var ieee754 = require('ieee754')

exports.Buffer = Buffer
exports.SlowBuffer = SlowBuffer
exports.INSPECT_MAX_BYTES = 50

var K_MAX_LENGTH = 0x7fffffff
exports.kMaxLength = K_MAX_LENGTH

/**
 * If `Buffer.TYPED_ARRAY_SUPPORT`:
 *   === true    Use Uint8Array implementation (fastest)
 *   === false   Print warning and recommend using `buffer` v4.x which has an Object
 *               implementation (most compatible, even IE6)
 *
 * Browsers that support typed arrays are IE 10+, Firefox 4+, Chrome 7+, Safari 5.1+,
 * Opera 11.6+, iOS 4.2+.
 *
 * We report that the browser does not support typed arrays if the are not subclassable
 * using __proto__. Firefox 4-29 lacks support for adding new properties to `Uint8Array`
 * (See: https://bugzilla.mozilla.org/show_bug.cgi?id=695438). IE 10 lacks support
 * for __proto__ and has a buggy typed array implementation.
 */
Buffer.TYPED_ARRAY_SUPPORT = typedArraySupport()

if (!Buffer.TYPED_ARRAY_SUPPORT && typeof console !== 'undefined' &&
    typeof console.error === 'function') {
  console.error(
    'This browser lacks typed array (Uint8Array) support which is required by ' +
    '`buffer` v5.x. Use `buffer` v4.x if you require old browser support.'
  )
}

function typedArraySupport () {
  // Can typed array instances can be augmented?
  try {
    var arr = new Uint8Array(1)
    arr.__proto__ = { __proto__: Uint8Array.prototype, foo: function () { return 42 } }
    return arr.foo() === 42
  } catch (e) {
    return false
  }
}

Object.defineProperty(Buffer.prototype, 'parent', {
  enumerable: true,
  get: function () {
    if (!Buffer.isBuffer(this)) return undefined
    return this.buffer
  }
})

Object.defineProperty(Buffer.prototype, 'offset', {
  enumerable: true,
  get: function () {
    if (!Buffer.isBuffer(this)) return undefined
    return this.byteOffset
  }
})

function createBuffer (length) {
  if (length > K_MAX_LENGTH) {
    throw new RangeError('The value "' + length + '" is invalid for option "size"')
  }
  // Return an augmented `Uint8Array` instance
  var buf = new Uint8Array(length)
  buf.__proto__ = Buffer.prototype
  return buf
}

/**
 * The Buffer constructor returns instances of `Uint8Array` that have their
 * prototype changed to `Buffer.prototype`. Furthermore, `Buffer` is a subclass of
 * `Uint8Array`, so the returned instances will have all the node `Buffer` methods
 * and the `Uint8Array` methods. Square bracket notation works as expected -- it
 * returns a single octet.
 *
 * The `Uint8Array` prototype remains unmodified.
 */

function Buffer (arg, encodingOrOffset, length) {
  // Common case.
  if (typeof arg === 'number') {
    if (typeof encodingOrOffset === 'string') {
      throw new TypeError(
        'The "string" argument must be of type string. Received type number'
      )
    }
    return allocUnsafe(arg)
  }
  return from(arg, encodingOrOffset, length)
}

// Fix subarray() in ES2016. See: https://github.com/feross/buffer/pull/97
if (typeof Symbol !== 'undefined' && Symbol.species != null &&
    Buffer[Symbol.species] === Buffer) {
  Object.defineProperty(Buffer, Symbol.species, {
    value: null,
    configurable: true,
    enumerable: false,
    writable: false
  })
}

Buffer.poolSize = 8192 // not used by this implementation

function from (value, encodingOrOffset, length) {
  if (typeof value === 'string') {
    return fromString(value, encodingOrOffset)
  }

  if (ArrayBuffer.isView(value)) {
    return fromArrayLike(value)
  }

  if (value == null) {
    throw TypeError(
      'The first argument must be one of type string, Buffer, ArrayBuffer, Array, ' +
      'or Array-like Object. Received type ' + (typeof value)
    )
  }

  if (isInstance(value, ArrayBuffer) ||
      (value && isInstance(value.buffer, ArrayBuffer))) {
    return fromArrayBuffer(value, encodingOrOffset, length)
  }

  if (typeof value === 'number') {
    throw new TypeError(
      'The "value" argument must not be of type number. Received type number'
    )
  }

  var valueOf = value.valueOf && value.valueOf()
  if (valueOf != null && valueOf !== value) {
    return Buffer.from(valueOf, encodingOrOffset, length)
  }

  var b = fromObject(value)
  if (b) return b

  if (typeof Symbol !== 'undefined' && Symbol.toPrimitive != null &&
      typeof value[Symbol.toPrimitive] === 'function') {
    return Buffer.from(
      value[Symbol.toPrimitive]('string'), encodingOrOffset, length
    )
  }

  throw new TypeError(
    'The first argument must be one of type string, Buffer, ArrayBuffer, Array, ' +
    'or Array-like Object. Received type ' + (typeof value)
  )
}

/**
 * Functionally equivalent to Buffer(arg, encoding) but throws a TypeError
 * if value is a number.
 * Buffer.from(str[, encoding])
 * Buffer.from(array)
 * Buffer.from(buffer)
 * Buffer.from(arrayBuffer[, byteOffset[, length]])
 **/
Buffer.from = function (value, encodingOrOffset, length) {
  return from(value, encodingOrOffset, length)
}

// Note: Change prototype *after* Buffer.from is defined to workaround Chrome bug:
// https://github.com/feross/buffer/pull/148
Buffer.prototype.__proto__ = Uint8Array.prototype
Buffer.__proto__ = Uint8Array

function assertSize (size) {
  if (typeof size !== 'number') {
    throw new TypeError('"size" argument must be of type number')
  } else if (size < 0) {
    throw new RangeError('The value "' + size + '" is invalid for option "size"')
  }
}

function alloc (size, fill, encoding) {
  assertSize(size)
  if (size <= 0) {
    return createBuffer(size)
  }
  if (fill !== undefined) {
    // Only pay attention to encoding if it's a string. This
    // prevents accidentally sending in a number that would
    // be interpretted as a start offset.
    return typeof encoding === 'string'
      ? createBuffer(size).fill(fill, encoding)
      : createBuffer(size).fill(fill)
  }
  return createBuffer(size)
}

/**
 * Creates a new filled Buffer instance.
 * alloc(size[, fill[, encoding]])
 **/
Buffer.alloc = function (size, fill, encoding) {
  return alloc(size, fill, encoding)
}

function allocUnsafe (size) {
  assertSize(size)
  return createBuffer(size < 0 ? 0 : checked(size) | 0)
}

/**
 * Equivalent to Buffer(num), by default creates a non-zero-filled Buffer instance.
 * */
Buffer.allocUnsafe = function (size) {
  return allocUnsafe(size)
}
/**
 * Equivalent to SlowBuffer(num), by default creates a non-zero-filled Buffer instance.
 */
Buffer.allocUnsafeSlow = function (size) {
  return allocUnsafe(size)
}

function fromString (string, encoding) {
  if (typeof encoding !== 'string' || encoding === '') {
    encoding = 'utf8'
  }

  if (!Buffer.isEncoding(encoding)) {
    throw new TypeError('Unknown encoding: ' + encoding)
  }

  var length = byteLength(string, encoding) | 0
  var buf = createBuffer(length)

  var actual = buf.write(string, encoding)

  if (actual !== length) {
    // Writing a hex string, for example, that contains invalid characters will
    // cause everything after the first invalid character to be ignored. (e.g.
    // 'abxxcd' will be treated as 'ab')
    buf = buf.slice(0, actual)
  }

  return buf
}

function fromArrayLike (array) {
  var length = array.length < 0 ? 0 : checked(array.length) | 0
  var buf = createBuffer(length)
  for (var i = 0; i < length; i += 1) {
    buf[i] = array[i] & 255
  }
  return buf
}

function fromArrayBuffer (array, byteOffset, length) {
  if (byteOffset < 0 || array.byteLength < byteOffset) {
    throw new RangeError('"offset" is outside of buffer bounds')
  }

  if (array.byteLength < byteOffset + (length || 0)) {
    throw new RangeError('"length" is outside of buffer bounds')
  }

  var buf
  if (byteOffset === undefined && length === undefined) {
    buf = new Uint8Array(array)
  } else if (length === undefined) {
    buf = new Uint8Array(array, byteOffset)
  } else {
    buf = new Uint8Array(array, byteOffset, length)
  }

  // Return an augmented `Uint8Array` instance
  buf.__proto__ = Buffer.prototype
  return buf
}

function fromObject (obj) {
  if (Buffer.isBuffer(obj)) {
    var len = checked(obj.length) | 0
    var buf = createBuffer(len)

    if (buf.length === 0) {
      return buf
    }

    obj.copy(buf, 0, 0, len)
    return buf
  }

  if (obj.length !== undefined) {
    if (typeof obj.length !== 'number' || numberIsNaN(obj.length)) {
      return createBuffer(0)
    }
    return fromArrayLike(obj)
  }

  if (obj.type === 'Buffer' && Array.isArray(obj.data)) {
    return fromArrayLike(obj.data)
  }
}

function checked (length) {
  // Note: cannot use `length < K_MAX_LENGTH` here because that fails when
  // length is NaN (which is otherwise coerced to zero.)
  if (length >= K_MAX_LENGTH) {
    throw new RangeError('Attempt to allocate Buffer larger than maximum ' +
                         'size: 0x' + K_MAX_LENGTH.toString(16) + ' bytes')
  }
  return length | 0
}

function SlowBuffer (length) {
  if (+length != length) { // eslint-disable-line eqeqeq
    length = 0
  }
  return Buffer.alloc(+length)
}

Buffer.isBuffer = function isBuffer (b) {
  return b != null && b._isBuffer === true &&
    b !== Buffer.prototype // so Buffer.isBuffer(Buffer.prototype) will be false
}

Buffer.compare = function compare (a, b) {
  if (isInstance(a, Uint8Array)) a = Buffer.from(a, a.offset, a.byteLength)
  if (isInstance(b, Uint8Array)) b = Buffer.from(b, b.offset, b.byteLength)
  if (!Buffer.isBuffer(a) || !Buffer.isBuffer(b)) {
    throw new TypeError(
      'The "buf1", "buf2" arguments must be one of type Buffer or Uint8Array'
    )
  }

  if (a === b) return 0

  var x = a.length
  var y = b.length

  for (var i = 0, len = Math.min(x, y); i < len; ++i) {
    if (a[i] !== b[i]) {
      x = a[i]
      y = b[i]
      break
    }
  }

  if (x < y) return -1
  if (y < x) return 1
  return 0
}

Buffer.isEncoding = function isEncoding (encoding) {
  switch (String(encoding).toLowerCase()) {
    case 'hex':
    case 'utf8':
    case 'utf-8':
    case 'ascii':
    case 'latin1':
    case 'binary':
    case 'base64':
    case 'ucs2':
    case 'ucs-2':
    case 'utf16le':
    case 'utf-16le':
      return true
    default:
      return false
  }
}

Buffer.concat = function concat (list, length) {
  if (!Array.isArray(list)) {
    throw new TypeError('"list" argument must be an Array of Buffers')
  }

  if (list.length === 0) {
    return Buffer.alloc(0)
  }

  var i
  if (length === undefined) {
    length = 0
    for (i = 0; i < list.length; ++i) {
      length += list[i].length
    }
  }

  var buffer = Buffer.allocUnsafe(length)
  var pos = 0
  for (i = 0; i < list.length; ++i) {
    var buf = list[i]
    if (isInstance(buf, Uint8Array)) {
      buf = Buffer.from(buf)
    }
    if (!Buffer.isBuffer(buf)) {
      throw new TypeError('"list" argument must be an Array of Buffers')
    }
    buf.copy(buffer, pos)
    pos += buf.length
  }
  return buffer
}

function byteLength (string, encoding) {
  if (Buffer.isBuffer(string)) {
    return string.length
  }
  if (ArrayBuffer.isView(string) || isInstance(string, ArrayBuffer)) {
    return string.byteLength
  }
  if (typeof string !== 'string') {
    throw new TypeError(
      'The "string" argument must be one of type string, Buffer, or ArrayBuffer. ' +
      'Received type ' + typeof string
    )
  }

  var len = string.length
  var mustMatch = (arguments.length > 2 && arguments[2] === true)
  if (!mustMatch && len === 0) return 0

  // Use a for loop to avoid recursion
  var loweredCase = false
  for (;;) {
    switch (encoding) {
      case 'ascii':
      case 'latin1':
      case 'binary':
        return len
      case 'utf8':
      case 'utf-8':
        return utf8ToBytes(string).length
      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return len * 2
      case 'hex':
        return len >>> 1
      case 'base64':
        return base64ToBytes(string).length
      default:
        if (loweredCase) {
          return mustMatch ? -1 : utf8ToBytes(string).length // assume utf8
        }
        encoding = ('' + encoding).toLowerCase()
        loweredCase = true
    }
  }
}
Buffer.byteLength = byteLength

function slowToString (encoding, start, end) {
  var loweredCase = false

  // No need to verify that "this.length <= MAX_UINT32" since it's a read-only
  // property of a typed array.

  // This behaves neither like String nor Uint8Array in that we set start/end
  // to their upper/lower bounds if the value passed is out of range.
  // undefined is handled specially as per ECMA-262 6th Edition,
  // Section 13.3.3.7 Runtime Semantics: KeyedBindingInitialization.
  if (start === undefined || start < 0) {
    start = 0
  }
  // Return early if start > this.length. Done here to prevent potential uint32
  // coercion fail below.
  if (start > this.length) {
    return ''
  }

  if (end === undefined || end > this.length) {
    end = this.length
  }

  if (end <= 0) {
    return ''
  }

  // Force coersion to uint32. This will also coerce falsey/NaN values to 0.
  end >>>= 0
  start >>>= 0

  if (end <= start) {
    return ''
  }

  if (!encoding) encoding = 'utf8'

  while (true) {
    switch (encoding) {
      case 'hex':
        return hexSlice(this, start, end)

      case 'utf8':
      case 'utf-8':
        return utf8Slice(this, start, end)

      case 'ascii':
        return asciiSlice(this, start, end)

      case 'latin1':
      case 'binary':
        return latin1Slice(this, start, end)

      case 'base64':
        return base64Slice(this, start, end)

      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return utf16leSlice(this, start, end)

      default:
        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)
        encoding = (encoding + '').toLowerCase()
        loweredCase = true
    }
  }
}

// This property is used by `Buffer.isBuffer` (and the `is-buffer` npm package)
// to detect a Buffer instance. It's not possible to use `instanceof Buffer`
// reliably in a browserify context because there could be multiple different
// copies of the 'buffer' package in use. This method works even for Buffer
// instances that were created from another copy of the `buffer` package.
// See: https://github.com/feross/buffer/issues/154
Buffer.prototype._isBuffer = true

function swap (b, n, m) {
  var i = b[n]
  b[n] = b[m]
  b[m] = i
}

Buffer.prototype.swap16 = function swap16 () {
  var len = this.length
  if (len % 2 !== 0) {
    throw new RangeError('Buffer size must be a multiple of 16-bits')
  }
  for (var i = 0; i < len; i += 2) {
    swap(this, i, i + 1)
  }
  return this
}

Buffer.prototype.swap32 = function swap32 () {
  var len = this.length
  if (len % 4 !== 0) {
    throw new RangeError('Buffer size must be a multiple of 32-bits')
  }
  for (var i = 0; i < len; i += 4) {
    swap(this, i, i + 3)
    swap(this, i + 1, i + 2)
  }
  return this
}

Buffer.prototype.swap64 = function swap64 () {
  var len = this.length
  if (len % 8 !== 0) {
    throw new RangeError('Buffer size must be a multiple of 64-bits')
  }
  for (var i = 0; i < len; i += 8) {
    swap(this, i, i + 7)
    swap(this, i + 1, i + 6)
    swap(this, i + 2, i + 5)
    swap(this, i + 3, i + 4)
  }
  return this
}

Buffer.prototype.toString = function toString () {
  var length = this.length
  if (length === 0) return ''
  if (arguments.length === 0) return utf8Slice(this, 0, length)
  return slowToString.apply(this, arguments)
}

Buffer.prototype.toLocaleString = Buffer.prototype.toString

Buffer.prototype.equals = function equals (b) {
  if (!Buffer.isBuffer(b)) throw new TypeError('Argument must be a Buffer')
  if (this === b) return true
  return Buffer.compare(this, b) === 0
}

Buffer.prototype.inspect = function inspect () {
  var str = ''
  var max = exports.INSPECT_MAX_BYTES
  str = this.toString('hex', 0, max).replace(/(.{2})/g, '$1 ').trim()
  if (this.length > max) str += ' ... '
  return '<Buffer ' + str + '>'
}

Buffer.prototype.compare = function compare (target, start, end, thisStart, thisEnd) {
  if (isInstance(target, Uint8Array)) {
    target = Buffer.from(target, target.offset, target.byteLength)
  }
  if (!Buffer.isBuffer(target)) {
    throw new TypeError(
      'The "target" argument must be one of type Buffer or Uint8Array. ' +
      'Received type ' + (typeof target)
    )
  }

  if (start === undefined) {
    start = 0
  }
  if (end === undefined) {
    end = target ? target.length : 0
  }
  if (thisStart === undefined) {
    thisStart = 0
  }
  if (thisEnd === undefined) {
    thisEnd = this.length
  }

  if (start < 0 || end > target.length || thisStart < 0 || thisEnd > this.length) {
    throw new RangeError('out of range index')
  }

  if (thisStart >= thisEnd && start >= end) {
    return 0
  }
  if (thisStart >= thisEnd) {
    return -1
  }
  if (start >= end) {
    return 1
  }

  start >>>= 0
  end >>>= 0
  thisStart >>>= 0
  thisEnd >>>= 0

  if (this === target) return 0

  var x = thisEnd - thisStart
  var y = end - start
  var len = Math.min(x, y)

  var thisCopy = this.slice(thisStart, thisEnd)
  var targetCopy = target.slice(start, end)

  for (var i = 0; i < len; ++i) {
    if (thisCopy[i] !== targetCopy[i]) {
      x = thisCopy[i]
      y = targetCopy[i]
      break
    }
  }

  if (x < y) return -1
  if (y < x) return 1
  return 0
}

// Finds either the first index of `val` in `buffer` at offset >= `byteOffset`,
// OR the last index of `val` in `buffer` at offset <= `byteOffset`.
//
// Arguments:
// - buffer - a Buffer to search
// - val - a string, Buffer, or number
// - byteOffset - an index into `buffer`; will be clamped to an int32
// - encoding - an optional encoding, relevant is val is a string
// - dir - true for indexOf, false for lastIndexOf
function bidirectionalIndexOf (buffer, val, byteOffset, encoding, dir) {
  // Empty buffer means no match
  if (buffer.length === 0) return -1

  // Normalize byteOffset
  if (typeof byteOffset === 'string') {
    encoding = byteOffset
    byteOffset = 0
  } else if (byteOffset > 0x7fffffff) {
    byteOffset = 0x7fffffff
  } else if (byteOffset < -0x80000000) {
    byteOffset = -0x80000000
  }
  byteOffset = +byteOffset // Coerce to Number.
  if (numberIsNaN(byteOffset)) {
    // byteOffset: it it's undefined, null, NaN, "foo", etc, search whole buffer
    byteOffset = dir ? 0 : (buffer.length - 1)
  }

  // Normalize byteOffset: negative offsets start from the end of the buffer
  if (byteOffset < 0) byteOffset = buffer.length + byteOffset
  if (byteOffset >= buffer.length) {
    if (dir) return -1
    else byteOffset = buffer.length - 1
  } else if (byteOffset < 0) {
    if (dir) byteOffset = 0
    else return -1
  }

  // Normalize val
  if (typeof val === 'string') {
    val = Buffer.from(val, encoding)
  }

  // Finally, search either indexOf (if dir is true) or lastIndexOf
  if (Buffer.isBuffer(val)) {
    // Special case: looking for empty string/buffer always fails
    if (val.length === 0) {
      return -1
    }
    return arrayIndexOf(buffer, val, byteOffset, encoding, dir)
  } else if (typeof val === 'number') {
    val = val & 0xFF // Search for a byte value [0-255]
    if (typeof Uint8Array.prototype.indexOf === 'function') {
      if (dir) {
        return Uint8Array.prototype.indexOf.call(buffer, val, byteOffset)
      } else {
        return Uint8Array.prototype.lastIndexOf.call(buffer, val, byteOffset)
      }
    }
    return arrayIndexOf(buffer, [ val ], byteOffset, encoding, dir)
  }

  throw new TypeError('val must be string, number or Buffer')
}

function arrayIndexOf (arr, val, byteOffset, encoding, dir) {
  var indexSize = 1
  var arrLength = arr.length
  var valLength = val.length

  if (encoding !== undefined) {
    encoding = String(encoding).toLowerCase()
    if (encoding === 'ucs2' || encoding === 'ucs-2' ||
        encoding === 'utf16le' || encoding === 'utf-16le') {
      if (arr.length < 2 || val.length < 2) {
        return -1
      }
      indexSize = 2
      arrLength /= 2
      valLength /= 2
      byteOffset /= 2
    }
  }

  function read (buf, i) {
    if (indexSize === 1) {
      return buf[i]
    } else {
      return buf.readUInt16BE(i * indexSize)
    }
  }

  var i
  if (dir) {
    var foundIndex = -1
    for (i = byteOffset; i < arrLength; i++) {
      if (read(arr, i) === read(val, foundIndex === -1 ? 0 : i - foundIndex)) {
        if (foundIndex === -1) foundIndex = i
        if (i - foundIndex + 1 === valLength) return foundIndex * indexSize
      } else {
        if (foundIndex !== -1) i -= i - foundIndex
        foundIndex = -1
      }
    }
  } else {
    if (byteOffset + valLength > arrLength) byteOffset = arrLength - valLength
    for (i = byteOffset; i >= 0; i--) {
      var found = true
      for (var j = 0; j < valLength; j++) {
        if (read(arr, i + j) !== read(val, j)) {
          found = false
          break
        }
      }
      if (found) return i
    }
  }

  return -1
}

Buffer.prototype.includes = function includes (val, byteOffset, encoding) {
  return this.indexOf(val, byteOffset, encoding) !== -1
}

Buffer.prototype.indexOf = function indexOf (val, byteOffset, encoding) {
  return bidirectionalIndexOf(this, val, byteOffset, encoding, true)
}

Buffer.prototype.lastIndexOf = function lastIndexOf (val, byteOffset, encoding) {
  return bidirectionalIndexOf(this, val, byteOffset, encoding, false)
}

function hexWrite (buf, string, offset, length) {
  offset = Number(offset) || 0
  var remaining = buf.length - offset
  if (!length) {
    length = remaining
  } else {
    length = Number(length)
    if (length > remaining) {
      length = remaining
    }
  }

  var strLen = string.length

  if (length > strLen / 2) {
    length = strLen / 2
  }
  for (var i = 0; i < length; ++i) {
    var parsed = parseInt(string.substr(i * 2, 2), 16)
    if (numberIsNaN(parsed)) return i
    buf[offset + i] = parsed
  }
  return i
}

function utf8Write (buf, string, offset, length) {
  return blitBuffer(utf8ToBytes(string, buf.length - offset), buf, offset, length)
}

function asciiWrite (buf, string, offset, length) {
  return blitBuffer(asciiToBytes(string), buf, offset, length)
}

function latin1Write (buf, string, offset, length) {
  return asciiWrite(buf, string, offset, length)
}

function base64Write (buf, string, offset, length) {
  return blitBuffer(base64ToBytes(string), buf, offset, length)
}

function ucs2Write (buf, string, offset, length) {
  return blitBuffer(utf16leToBytes(string, buf.length - offset), buf, offset, length)
}

Buffer.prototype.write = function write (string, offset, length, encoding) {
  // Buffer#write(string)
  if (offset === undefined) {
    encoding = 'utf8'
    length = this.length
    offset = 0
  // Buffer#write(string, encoding)
  } else if (length === undefined && typeof offset === 'string') {
    encoding = offset
    length = this.length
    offset = 0
  // Buffer#write(string, offset[, length][, encoding])
  } else if (isFinite(offset)) {
    offset = offset >>> 0
    if (isFinite(length)) {
      length = length >>> 0
      if (encoding === undefined) encoding = 'utf8'
    } else {
      encoding = length
      length = undefined
    }
  } else {
    throw new Error(
      'Buffer.write(string, encoding, offset[, length]) is no longer supported'
    )
  }

  var remaining = this.length - offset
  if (length === undefined || length > remaining) length = remaining

  if ((string.length > 0 && (length < 0 || offset < 0)) || offset > this.length) {
    throw new RangeError('Attempt to write outside buffer bounds')
  }

  if (!encoding) encoding = 'utf8'

  var loweredCase = false
  for (;;) {
    switch (encoding) {
      case 'hex':
        return hexWrite(this, string, offset, length)

      case 'utf8':
      case 'utf-8':
        return utf8Write(this, string, offset, length)

      case 'ascii':
        return asciiWrite(this, string, offset, length)

      case 'latin1':
      case 'binary':
        return latin1Write(this, string, offset, length)

      case 'base64':
        // Warning: maxLength not taken into account in base64Write
        return base64Write(this, string, offset, length)

      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return ucs2Write(this, string, offset, length)

      default:
        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)
        encoding = ('' + encoding).toLowerCase()
        loweredCase = true
    }
  }
}

Buffer.prototype.toJSON = function toJSON () {
  return {
    type: 'Buffer',
    data: Array.prototype.slice.call(this._arr || this, 0)
  }
}

function base64Slice (buf, start, end) {
  if (start === 0 && end === buf.length) {
    return base64.fromByteArray(buf)
  } else {
    return base64.fromByteArray(buf.slice(start, end))
  }
}

function utf8Slice (buf, start, end) {
  end = Math.min(buf.length, end)
  var res = []

  var i = start
  while (i < end) {
    var firstByte = buf[i]
    var codePoint = null
    var bytesPerSequence = (firstByte > 0xEF) ? 4
      : (firstByte > 0xDF) ? 3
        : (firstByte > 0xBF) ? 2
          : 1

    if (i + bytesPerSequence <= end) {
      var secondByte, thirdByte, fourthByte, tempCodePoint

      switch (bytesPerSequence) {
        case 1:
          if (firstByte < 0x80) {
            codePoint = firstByte
          }
          break
        case 2:
          secondByte = buf[i + 1]
          if ((secondByte & 0xC0) === 0x80) {
            tempCodePoint = (firstByte & 0x1F) << 0x6 | (secondByte & 0x3F)
            if (tempCodePoint > 0x7F) {
              codePoint = tempCodePoint
            }
          }
          break
        case 3:
          secondByte = buf[i + 1]
          thirdByte = buf[i + 2]
          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80) {
            tempCodePoint = (firstByte & 0xF) << 0xC | (secondByte & 0x3F) << 0x6 | (thirdByte & 0x3F)
            if (tempCodePoint > 0x7FF && (tempCodePoint < 0xD800 || tempCodePoint > 0xDFFF)) {
              codePoint = tempCodePoint
            }
          }
          break
        case 4:
          secondByte = buf[i + 1]
          thirdByte = buf[i + 2]
          fourthByte = buf[i + 3]
          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80 && (fourthByte & 0xC0) === 0x80) {
            tempCodePoint = (firstByte & 0xF) << 0x12 | (secondByte & 0x3F) << 0xC | (thirdByte & 0x3F) << 0x6 | (fourthByte & 0x3F)
            if (tempCodePoint > 0xFFFF && tempCodePoint < 0x110000) {
              codePoint = tempCodePoint
            }
          }
      }
    }

    if (codePoint === null) {
      // we did not generate a valid codePoint so insert a
      // replacement char (U+FFFD) and advance only 1 byte
      codePoint = 0xFFFD
      bytesPerSequence = 1
    } else if (codePoint > 0xFFFF) {
      // encode to utf16 (surrogate pair dance)
      codePoint -= 0x10000
      res.push(codePoint >>> 10 & 0x3FF | 0xD800)
      codePoint = 0xDC00 | codePoint & 0x3FF
    }

    res.push(codePoint)
    i += bytesPerSequence
  }

  return decodeCodePointsArray(res)
}

// Based on http://stackoverflow.com/a/22747272/680742, the browser with
// the lowest limit is Chrome, with 0x10000 args.
// We go 1 magnitude less, for safety
var MAX_ARGUMENTS_LENGTH = 0x1000

function decodeCodePointsArray (codePoints) {
  var len = codePoints.length
  if (len <= MAX_ARGUMENTS_LENGTH) {
    return String.fromCharCode.apply(String, codePoints) // avoid extra slice()
  }

  // Decode in chunks to avoid "call stack size exceeded".
  var res = ''
  var i = 0
  while (i < len) {
    res += String.fromCharCode.apply(
      String,
      codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)
    )
  }
  return res
}

function asciiSlice (buf, start, end) {
  var ret = ''
  end = Math.min(buf.length, end)

  for (var i = start; i < end; ++i) {
    ret += String.fromCharCode(buf[i] & 0x7F)
  }
  return ret
}

function latin1Slice (buf, start, end) {
  var ret = ''
  end = Math.min(buf.length, end)

  for (var i = start; i < end; ++i) {
    ret += String.fromCharCode(buf[i])
  }
  return ret
}

function hexSlice (buf, start, end) {
  var len = buf.length

  if (!start || start < 0) start = 0
  if (!end || end < 0 || end > len) end = len

  var out = ''
  for (var i = start; i < end; ++i) {
    out += toHex(buf[i])
  }
  return out
}

function utf16leSlice (buf, start, end) {
  var bytes = buf.slice(start, end)
  var res = ''
  for (var i = 0; i < bytes.length; i += 2) {
    res += String.fromCharCode(bytes[i] + (bytes[i + 1] * 256))
  }
  return res
}

Buffer.prototype.slice = function slice (start, end) {
  var len = this.length
  start = ~~start
  end = end === undefined ? len : ~~end

  if (start < 0) {
    start += len
    if (start < 0) start = 0
  } else if (start > len) {
    start = len
  }

  if (end < 0) {
    end += len
    if (end < 0) end = 0
  } else if (end > len) {
    end = len
  }

  if (end < start) end = start

  var newBuf = this.subarray(start, end)
  // Return an augmented `Uint8Array` instance
  newBuf.__proto__ = Buffer.prototype
  return newBuf
}

/*
 * Need to make sure that buffer isn't trying to write out of bounds.
 */
function checkOffset (offset, ext, length) {
  if ((offset % 1) !== 0 || offset < 0) throw new RangeError('offset is not uint')
  if (offset + ext > length) throw new RangeError('Trying to access beyond buffer length')
}

Buffer.prototype.readUIntLE = function readUIntLE (offset, byteLength, noAssert) {
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) checkOffset(offset, byteLength, this.length)

  var val = this[offset]
  var mul = 1
  var i = 0
  while (++i < byteLength && (mul *= 0x100)) {
    val += this[offset + i] * mul
  }

  return val
}

Buffer.prototype.readUIntBE = function readUIntBE (offset, byteLength, noAssert) {
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) {
    checkOffset(offset, byteLength, this.length)
  }

  var val = this[offset + --byteLength]
  var mul = 1
  while (byteLength > 0 && (mul *= 0x100)) {
    val += this[offset + --byteLength] * mul
  }

  return val
}

Buffer.prototype.readUInt8 = function readUInt8 (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 1, this.length)
  return this[offset]
}

Buffer.prototype.readUInt16LE = function readUInt16LE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 2, this.length)
  return this[offset] | (this[offset + 1] << 8)
}

Buffer.prototype.readUInt16BE = function readUInt16BE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 2, this.length)
  return (this[offset] << 8) | this[offset + 1]
}

Buffer.prototype.readUInt32LE = function readUInt32LE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)

  return ((this[offset]) |
      (this[offset + 1] << 8) |
      (this[offset + 2] << 16)) +
      (this[offset + 3] * 0x1000000)
}

Buffer.prototype.readUInt32BE = function readUInt32BE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)

  return (this[offset] * 0x1000000) +
    ((this[offset + 1] << 16) |
    (this[offset + 2] << 8) |
    this[offset + 3])
}

Buffer.prototype.readIntLE = function readIntLE (offset, byteLength, noAssert) {
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) checkOffset(offset, byteLength, this.length)

  var val = this[offset]
  var mul = 1
  var i = 0
  while (++i < byteLength && (mul *= 0x100)) {
    val += this[offset + i] * mul
  }
  mul *= 0x80

  if (val >= mul) val -= Math.pow(2, 8 * byteLength)

  return val
}

Buffer.prototype.readIntBE = function readIntBE (offset, byteLength, noAssert) {
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) checkOffset(offset, byteLength, this.length)

  var i = byteLength
  var mul = 1
  var val = this[offset + --i]
  while (i > 0 && (mul *= 0x100)) {
    val += this[offset + --i] * mul
  }
  mul *= 0x80

  if (val >= mul) val -= Math.pow(2, 8 * byteLength)

  return val
}

Buffer.prototype.readInt8 = function readInt8 (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 1, this.length)
  if (!(this[offset] & 0x80)) return (this[offset])
  return ((0xff - this[offset] + 1) * -1)
}

Buffer.prototype.readInt16LE = function readInt16LE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 2, this.length)
  var val = this[offset] | (this[offset + 1] << 8)
  return (val & 0x8000) ? val | 0xFFFF0000 : val
}

Buffer.prototype.readInt16BE = function readInt16BE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 2, this.length)
  var val = this[offset + 1] | (this[offset] << 8)
  return (val & 0x8000) ? val | 0xFFFF0000 : val
}

Buffer.prototype.readInt32LE = function readInt32LE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)

  return (this[offset]) |
    (this[offset + 1] << 8) |
    (this[offset + 2] << 16) |
    (this[offset + 3] << 24)
}

Buffer.prototype.readInt32BE = function readInt32BE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)

  return (this[offset] << 24) |
    (this[offset + 1] << 16) |
    (this[offset + 2] << 8) |
    (this[offset + 3])
}

Buffer.prototype.readFloatLE = function readFloatLE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)
  return ieee754.read(this, offset, true, 23, 4)
}

Buffer.prototype.readFloatBE = function readFloatBE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)
  return ieee754.read(this, offset, false, 23, 4)
}

Buffer.prototype.readDoubleLE = function readDoubleLE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 8, this.length)
  return ieee754.read(this, offset, true, 52, 8)
}

Buffer.prototype.readDoubleBE = function readDoubleBE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 8, this.length)
  return ieee754.read(this, offset, false, 52, 8)
}

function checkInt (buf, value, offset, ext, max, min) {
  if (!Buffer.isBuffer(buf)) throw new TypeError('"buffer" argument must be a Buffer instance')
  if (value > max || value < min) throw new RangeError('"value" argument is out of bounds')
  if (offset + ext > buf.length) throw new RangeError('Index out of range')
}

Buffer.prototype.writeUIntLE = function writeUIntLE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) {
    var maxBytes = Math.pow(2, 8 * byteLength) - 1
    checkInt(this, value, offset, byteLength, maxBytes, 0)
  }

  var mul = 1
  var i = 0
  this[offset] = value & 0xFF
  while (++i < byteLength && (mul *= 0x100)) {
    this[offset + i] = (value / mul) & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeUIntBE = function writeUIntBE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) {
    var maxBytes = Math.pow(2, 8 * byteLength) - 1
    checkInt(this, value, offset, byteLength, maxBytes, 0)
  }

  var i = byteLength - 1
  var mul = 1
  this[offset + i] = value & 0xFF
  while (--i >= 0 && (mul *= 0x100)) {
    this[offset + i] = (value / mul) & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeUInt8 = function writeUInt8 (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 1, 0xff, 0)
  this[offset] = (value & 0xff)
  return offset + 1
}

Buffer.prototype.writeUInt16LE = function writeUInt16LE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)
  this[offset] = (value & 0xff)
  this[offset + 1] = (value >>> 8)
  return offset + 2
}

Buffer.prototype.writeUInt16BE = function writeUInt16BE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)
  this[offset] = (value >>> 8)
  this[offset + 1] = (value & 0xff)
  return offset + 2
}

Buffer.prototype.writeUInt32LE = function writeUInt32LE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)
  this[offset + 3] = (value >>> 24)
  this[offset + 2] = (value >>> 16)
  this[offset + 1] = (value >>> 8)
  this[offset] = (value & 0xff)
  return offset + 4
}

Buffer.prototype.writeUInt32BE = function writeUInt32BE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)
  this[offset] = (value >>> 24)
  this[offset + 1] = (value >>> 16)
  this[offset + 2] = (value >>> 8)
  this[offset + 3] = (value & 0xff)
  return offset + 4
}

Buffer.prototype.writeIntLE = function writeIntLE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) {
    var limit = Math.pow(2, (8 * byteLength) - 1)

    checkInt(this, value, offset, byteLength, limit - 1, -limit)
  }

  var i = 0
  var mul = 1
  var sub = 0
  this[offset] = value & 0xFF
  while (++i < byteLength && (mul *= 0x100)) {
    if (value < 0 && sub === 0 && this[offset + i - 1] !== 0) {
      sub = 1
    }
    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeIntBE = function writeIntBE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) {
    var limit = Math.pow(2, (8 * byteLength) - 1)

    checkInt(this, value, offset, byteLength, limit - 1, -limit)
  }

  var i = byteLength - 1
  var mul = 1
  var sub = 0
  this[offset + i] = value & 0xFF
  while (--i >= 0 && (mul *= 0x100)) {
    if (value < 0 && sub === 0 && this[offset + i + 1] !== 0) {
      sub = 1
    }
    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeInt8 = function writeInt8 (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 1, 0x7f, -0x80)
  if (value < 0) value = 0xff + value + 1
  this[offset] = (value & 0xff)
  return offset + 1
}

Buffer.prototype.writeInt16LE = function writeInt16LE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)
  this[offset] = (value & 0xff)
  this[offset + 1] = (value >>> 8)
  return offset + 2
}

Buffer.prototype.writeInt16BE = function writeInt16BE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)
  this[offset] = (value >>> 8)
  this[offset + 1] = (value & 0xff)
  return offset + 2
}

Buffer.prototype.writeInt32LE = function writeInt32LE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)
  this[offset] = (value & 0xff)
  this[offset + 1] = (value >>> 8)
  this[offset + 2] = (value >>> 16)
  this[offset + 3] = (value >>> 24)
  return offset + 4
}

Buffer.prototype.writeInt32BE = function writeInt32BE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)
  if (value < 0) value = 0xffffffff + value + 1
  this[offset] = (value >>> 24)
  this[offset + 1] = (value >>> 16)
  this[offset + 2] = (value >>> 8)
  this[offset + 3] = (value & 0xff)
  return offset + 4
}

function checkIEEE754 (buf, value, offset, ext, max, min) {
  if (offset + ext > buf.length) throw new RangeError('Index out of range')
  if (offset < 0) throw new RangeError('Index out of range')
}

function writeFloat (buf, value, offset, littleEndian, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) {
    checkIEEE754(buf, value, offset, 4, 3.4028234663852886e+38, -3.4028234663852886e+38)
  }
  ieee754.write(buf, value, offset, littleEndian, 23, 4)
  return offset + 4
}

Buffer.prototype.writeFloatLE = function writeFloatLE (value, offset, noAssert) {
  return writeFloat(this, value, offset, true, noAssert)
}

Buffer.prototype.writeFloatBE = function writeFloatBE (value, offset, noAssert) {
  return writeFloat(this, value, offset, false, noAssert)
}

function writeDouble (buf, value, offset, littleEndian, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) {
    checkIEEE754(buf, value, offset, 8, 1.7976931348623157E+308, -1.7976931348623157E+308)
  }
  ieee754.write(buf, value, offset, littleEndian, 52, 8)
  return offset + 8
}

Buffer.prototype.writeDoubleLE = function writeDoubleLE (value, offset, noAssert) {
  return writeDouble(this, value, offset, true, noAssert)
}

Buffer.prototype.writeDoubleBE = function writeDoubleBE (value, offset, noAssert) {
  return writeDouble(this, value, offset, false, noAssert)
}

// copy(targetBuffer, targetStart=0, sourceStart=0, sourceEnd=buffer.length)
Buffer.prototype.copy = function copy (target, targetStart, start, end) {
  if (!Buffer.isBuffer(target)) throw new TypeError('argument should be a Buffer')
  if (!start) start = 0
  if (!end && end !== 0) end = this.length
  if (targetStart >= target.length) targetStart = target.length
  if (!targetStart) targetStart = 0
  if (end > 0 && end < start) end = start

  // Copy 0 bytes; we're done
  if (end === start) return 0
  if (target.length === 0 || this.length === 0) return 0

  // Fatal error conditions
  if (targetStart < 0) {
    throw new RangeError('targetStart out of bounds')
  }
  if (start < 0 || start >= this.length) throw new RangeError('Index out of range')
  if (end < 0) throw new RangeError('sourceEnd out of bounds')

  // Are we oob?
  if (end > this.length) end = this.length
  if (target.length - targetStart < end - start) {
    end = target.length - targetStart + start
  }

  var len = end - start

  if (this === target && typeof Uint8Array.prototype.copyWithin === 'function') {
    // Use built-in when available, missing from IE11
    this.copyWithin(targetStart, start, end)
  } else if (this === target && start < targetStart && targetStart < end) {
    // descending copy from end
    for (var i = len - 1; i >= 0; --i) {
      target[i + targetStart] = this[i + start]
    }
  } else {
    Uint8Array.prototype.set.call(
      target,
      this.subarray(start, end),
      targetStart
    )
  }

  return len
}

// Usage:
//    buffer.fill(number[, offset[, end]])
//    buffer.fill(buffer[, offset[, end]])
//    buffer.fill(string[, offset[, end]][, encoding])
Buffer.prototype.fill = function fill (val, start, end, encoding) {
  // Handle string cases:
  if (typeof val === 'string') {
    if (typeof start === 'string') {
      encoding = start
      start = 0
      end = this.length
    } else if (typeof end === 'string') {
      encoding = end
      end = this.length
    }
    if (encoding !== undefined && typeof encoding !== 'string') {
      throw new TypeError('encoding must be a string')
    }
    if (typeof encoding === 'string' && !Buffer.isEncoding(encoding)) {
      throw new TypeError('Unknown encoding: ' + encoding)
    }
    if (val.length === 1) {
      var code = val.charCodeAt(0)
      if ((encoding === 'utf8' && code < 128) ||
          encoding === 'latin1') {
        // Fast path: If `val` fits into a single byte, use that numeric value.
        val = code
      }
    }
  } else if (typeof val === 'number') {
    val = val & 255
  }

  // Invalid ranges are not set to a default, so can range check early.
  if (start < 0 || this.length < start || this.length < end) {
    throw new RangeError('Out of range index')
  }

  if (end <= start) {
    return this
  }

  start = start >>> 0
  end = end === undefined ? this.length : end >>> 0

  if (!val) val = 0

  var i
  if (typeof val === 'number') {
    for (i = start; i < end; ++i) {
      this[i] = val
    }
  } else {
    var bytes = Buffer.isBuffer(val)
      ? val
      : Buffer.from(val, encoding)
    var len = bytes.length
    if (len === 0) {
      throw new TypeError('The value "' + val +
        '" is invalid for argument "value"')
    }
    for (i = 0; i < end - start; ++i) {
      this[i + start] = bytes[i % len]
    }
  }

  return this
}

// HELPER FUNCTIONS
// ================

var INVALID_BASE64_RE = /[^+/0-9A-Za-z-_]/g

function base64clean (str) {
  // Node takes equal signs as end of the Base64 encoding
  str = str.split('=')[0]
  // Node strips out invalid characters like \n and \t from the string, base64-js does not
  str = str.trim().replace(INVALID_BASE64_RE, '')
  // Node converts strings with length < 2 to ''
  if (str.length < 2) return ''
  // Node allows for non-padded base64 strings (missing trailing ===), base64-js does not
  while (str.length % 4 !== 0) {
    str = str + '='
  }
  return str
}

function toHex (n) {
  if (n < 16) return '0' + n.toString(16)
  return n.toString(16)
}

function utf8ToBytes (string, units) {
  units = units || Infinity
  var codePoint
  var length = string.length
  var leadSurrogate = null
  var bytes = []

  for (var i = 0; i < length; ++i) {
    codePoint = string.charCodeAt(i)

    // is surrogate component
    if (codePoint > 0xD7FF && codePoint < 0xE000) {
      // last char was a lead
      if (!leadSurrogate) {
        // no lead yet
        if (codePoint > 0xDBFF) {
          // unexpected trail
          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
          continue
        } else if (i + 1 === length) {
          // unpaired lead
          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
          continue
        }

        // valid lead
        leadSurrogate = codePoint

        continue
      }

      // 2 leads in a row
      if (codePoint < 0xDC00) {
        if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
        leadSurrogate = codePoint
        continue
      }

      // valid surrogate pair
      codePoint = (leadSurrogate - 0xD800 << 10 | codePoint - 0xDC00) + 0x10000
    } else if (leadSurrogate) {
      // valid bmp char, but last char was a lead
      if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
    }

    leadSurrogate = null

    // encode utf8
    if (codePoint < 0x80) {
      if ((units -= 1) < 0) break
      bytes.push(codePoint)
    } else if (codePoint < 0x800) {
      if ((units -= 2) < 0) break
      bytes.push(
        codePoint >> 0x6 | 0xC0,
        codePoint & 0x3F | 0x80
      )
    } else if (codePoint < 0x10000) {
      if ((units -= 3) < 0) break
      bytes.push(
        codePoint >> 0xC | 0xE0,
        codePoint >> 0x6 & 0x3F | 0x80,
        codePoint & 0x3F | 0x80
      )
    } else if (codePoint < 0x110000) {
      if ((units -= 4) < 0) break
      bytes.push(
        codePoint >> 0x12 | 0xF0,
        codePoint >> 0xC & 0x3F | 0x80,
        codePoint >> 0x6 & 0x3F | 0x80,
        codePoint & 0x3F | 0x80
      )
    } else {
      throw new Error('Invalid code point')
    }
  }

  return bytes
}

function asciiToBytes (str) {
  var byteArray = []
  for (var i = 0; i < str.length; ++i) {
    // Node's code seems to be doing this and not & 0x7F..
    byteArray.push(str.charCodeAt(i) & 0xFF)
  }
  return byteArray
}

function utf16leToBytes (str, units) {
  var c, hi, lo
  var byteArray = []
  for (var i = 0; i < str.length; ++i) {
    if ((units -= 2) < 0) break

    c = str.charCodeAt(i)
    hi = c >> 8
    lo = c % 256
    byteArray.push(lo)
    byteArray.push(hi)
  }

  return byteArray
}

function base64ToBytes (str) {
  return base64.toByteArray(base64clean(str))
}

function blitBuffer (src, dst, offset, length) {
  for (var i = 0; i < length; ++i) {
    if ((i + offset >= dst.length) || (i >= src.length)) break
    dst[i + offset] = src[i]
  }
  return i
}

// ArrayBuffer or Uint8Array objects from other contexts (i.e. iframes) do not pass
// the `instanceof` check but they should be treated as of that type.
// See: https://github.com/feross/buffer/issues/166
function isInstance (obj, type) {
  return obj instanceof type ||
    (obj != null && obj.constructor != null && obj.constructor.name != null &&
      obj.constructor.name === type.name)
}
function numberIsNaN (obj) {
  // For IE11 support
  return obj !== obj // eslint-disable-line no-self-compare
}

}).call(this,require("buffer").Buffer)
},{"base64-js":72,"buffer":76,"ieee754":83}],77:[function(require,module,exports){
module.exports = {
  "100": "Continue",
  "101": "Switching Protocols",
  "102": "Processing",
  "200": "OK",
  "201": "Created",
  "202": "Accepted",
  "203": "Non-Authoritative Information",
  "204": "No Content",
  "205": "Reset Content",
  "206": "Partial Content",
  "207": "Multi-Status",
  "208": "Already Reported",
  "226": "IM Used",
  "300": "Multiple Choices",
  "301": "Moved Permanently",
  "302": "Found",
  "303": "See Other",
  "304": "Not Modified",
  "305": "Use Proxy",
  "307": "Temporary Redirect",
  "308": "Permanent Redirect",
  "400": "Bad Request",
  "401": "Unauthorized",
  "402": "Payment Required",
  "403": "Forbidden",
  "404": "Not Found",
  "405": "Method Not Allowed",
  "406": "Not Acceptable",
  "407": "Proxy Authentication Required",
  "408": "Request Timeout",
  "409": "Conflict",
  "410": "Gone",
  "411": "Length Required",
  "412": "Precondition Failed",
  "413": "Payload Too Large",
  "414": "URI Too Long",
  "415": "Unsupported Media Type",
  "416": "Range Not Satisfiable",
  "417": "Expectation Failed",
  "418": "I'm a teapot",
  "421": "Misdirected Request",
  "422": "Unprocessable Entity",
  "423": "Locked",
  "424": "Failed Dependency",
  "425": "Unordered Collection",
  "426": "Upgrade Required",
  "428": "Precondition Required",
  "429": "Too Many Requests",
  "431": "Request Header Fields Too Large",
  "451": "Unavailable For Legal Reasons",
  "500": "Internal Server Error",
  "501": "Not Implemented",
  "502": "Bad Gateway",
  "503": "Service Unavailable",
  "504": "Gateway Timeout",
  "505": "HTTP Version Not Supported",
  "506": "Variant Also Negotiates",
  "507": "Insufficient Storage",
  "508": "Loop Detected",
  "509": "Bandwidth Limit Exceeded",
  "510": "Not Extended",
  "511": "Network Authentication Required"
}

},{}],78:[function(require,module,exports){
(function(self) {

var irrelevant = (function (exports) {

  var support = {
    searchParams: 'URLSearchParams' in self,
    iterable: 'Symbol' in self && 'iterator' in Symbol,
    blob:
      'FileReader' in self &&
      'Blob' in self &&
      (function() {
        try {
          new Blob();
          return true
        } catch (e) {
          return false
        }
      })(),
    formData: 'FormData' in self,
    arrayBuffer: 'ArrayBuffer' in self
  };

  function isDataView(obj) {
    return obj && DataView.prototype.isPrototypeOf(obj)
  }

  if (support.arrayBuffer) {
    var viewClasses = [
      '[object Int8Array]',
      '[object Uint8Array]',
      '[object Uint8ClampedArray]',
      '[object Int16Array]',
      '[object Uint16Array]',
      '[object Int32Array]',
      '[object Uint32Array]',
      '[object Float32Array]',
      '[object Float64Array]'
    ];

    var isArrayBufferView =
      ArrayBuffer.isView ||
      function(obj) {
        return obj && viewClasses.indexOf(Object.prototype.toString.call(obj)) > -1
      };
  }

  function normalizeName(name) {
    if (typeof name !== 'string') {
      name = String(name);
    }
    if (/[^a-z0-9\-#$%&'*+.^_`|~]/i.test(name)) {
      throw new TypeError('Invalid character in header field name')
    }
    return name.toLowerCase()
  }

  function normalizeValue(value) {
    if (typeof value !== 'string') {
      value = String(value);
    }
    return value
  }

  // Build a destructive iterator for the value list
  function iteratorFor(items) {
    var iterator = {
      next: function() {
        var value = items.shift();
        return {done: value === undefined, value: value}
      }
    };

    if (support.iterable) {
      iterator[Symbol.iterator] = function() {
        return iterator
      };
    }

    return iterator
  }

  function Headers(headers) {
    this.map = {};

    if (headers instanceof Headers) {
      headers.forEach(function(value, name) {
        this.append(name, value);
      }, this);
    } else if (Array.isArray(headers)) {
      headers.forEach(function(header) {
        this.append(header[0], header[1]);
      }, this);
    } else if (headers) {
      Object.getOwnPropertyNames(headers).forEach(function(name) {
        this.append(name, headers[name]);
      }, this);
    }
  }

  Headers.prototype.append = function(name, value) {
    name = normalizeName(name);
    value = normalizeValue(value);
    var oldValue = this.map[name];
    this.map[name] = oldValue ? oldValue + ', ' + value : value;
  };

  Headers.prototype['delete'] = function(name) {
    delete this.map[normalizeName(name)];
  };

  Headers.prototype.get = function(name) {
    name = normalizeName(name);
    return this.has(name) ? this.map[name] : null
  };

  Headers.prototype.has = function(name) {
    return this.map.hasOwnProperty(normalizeName(name))
  };

  Headers.prototype.set = function(name, value) {
    this.map[normalizeName(name)] = normalizeValue(value);
  };

  Headers.prototype.forEach = function(callback, thisArg) {
    for (var name in this.map) {
      if (this.map.hasOwnProperty(name)) {
        callback.call(thisArg, this.map[name], name, this);
      }
    }
  };

  Headers.prototype.keys = function() {
    var items = [];
    this.forEach(function(value, name) {
      items.push(name);
    });
    return iteratorFor(items)
  };

  Headers.prototype.values = function() {
    var items = [];
    this.forEach(function(value) {
      items.push(value);
    });
    return iteratorFor(items)
  };

  Headers.prototype.entries = function() {
    var items = [];
    this.forEach(function(value, name) {
      items.push([name, value]);
    });
    return iteratorFor(items)
  };

  if (support.iterable) {
    Headers.prototype[Symbol.iterator] = Headers.prototype.entries;
  }

  function consumed(body) {
    if (body.bodyUsed) {
      return Promise.reject(new TypeError('Already read'))
    }
    body.bodyUsed = true;
  }

  function fileReaderReady(reader) {
    return new Promise(function(resolve, reject) {
      reader.onload = function() {
        resolve(reader.result);
      };
      reader.onerror = function() {
        reject(reader.error);
      };
    })
  }

  function readBlobAsArrayBuffer(blob) {
    var reader = new FileReader();
    var promise = fileReaderReady(reader);
    reader.readAsArrayBuffer(blob);
    return promise
  }

  function readBlobAsText(blob) {
    var reader = new FileReader();
    var promise = fileReaderReady(reader);
    reader.readAsText(blob);
    return promise
  }

  function readArrayBufferAsText(buf) {
    var view = new Uint8Array(buf);
    var chars = new Array(view.length);

    for (var i = 0; i < view.length; i++) {
      chars[i] = String.fromCharCode(view[i]);
    }
    return chars.join('')
  }

  function bufferClone(buf) {
    if (buf.slice) {
      return buf.slice(0)
    } else {
      var view = new Uint8Array(buf.byteLength);
      view.set(new Uint8Array(buf));
      return view.buffer
    }
  }

  function Body() {
    this.bodyUsed = false;

    this._initBody = function(body) {
      this._bodyInit = body;
      if (!body) {
        this._bodyText = '';
      } else if (typeof body === 'string') {
        this._bodyText = body;
      } else if (support.blob && Blob.prototype.isPrototypeOf(body)) {
        this._bodyBlob = body;
      } else if (support.formData && FormData.prototype.isPrototypeOf(body)) {
        this._bodyFormData = body;
      } else if (support.searchParams && URLSearchParams.prototype.isPrototypeOf(body)) {
        this._bodyText = body.toString();
      } else if (support.arrayBuffer && support.blob && isDataView(body)) {
        this._bodyArrayBuffer = bufferClone(body.buffer);
        // IE 10-11 can't handle a DataView body.
        this._bodyInit = new Blob([this._bodyArrayBuffer]);
      } else if (support.arrayBuffer && (ArrayBuffer.prototype.isPrototypeOf(body) || isArrayBufferView(body))) {
        this._bodyArrayBuffer = bufferClone(body);
      } else {
        this._bodyText = body = Object.prototype.toString.call(body);
      }

      if (!this.headers.get('content-type')) {
        if (typeof body === 'string') {
          this.headers.set('content-type', 'text/plain;charset=UTF-8');
        } else if (this._bodyBlob && this._bodyBlob.type) {
          this.headers.set('content-type', this._bodyBlob.type);
        } else if (support.searchParams && URLSearchParams.prototype.isPrototypeOf(body)) {
          this.headers.set('content-type', 'application/x-www-form-urlencoded;charset=UTF-8');
        }
      }
    };

    if (support.blob) {
      this.blob = function() {
        var rejected = consumed(this);
        if (rejected) {
          return rejected
        }

        if (this._bodyBlob) {
          return Promise.resolve(this._bodyBlob)
        } else if (this._bodyArrayBuffer) {
          return Promise.resolve(new Blob([this._bodyArrayBuffer]))
        } else if (this._bodyFormData) {
          throw new Error('could not read FormData body as blob')
        } else {
          return Promise.resolve(new Blob([this._bodyText]))
        }
      };

      this.arrayBuffer = function() {
        if (this._bodyArrayBuffer) {
          return consumed(this) || Promise.resolve(this._bodyArrayBuffer)
        } else {
          return this.blob().then(readBlobAsArrayBuffer)
        }
      };
    }

    this.text = function() {
      var rejected = consumed(this);
      if (rejected) {
        return rejected
      }

      if (this._bodyBlob) {
        return readBlobAsText(this._bodyBlob)
      } else if (this._bodyArrayBuffer) {
        return Promise.resolve(readArrayBufferAsText(this._bodyArrayBuffer))
      } else if (this._bodyFormData) {
        throw new Error('could not read FormData body as text')
      } else {
        return Promise.resolve(this._bodyText)
      }
    };

    if (support.formData) {
      this.formData = function() {
        return this.text().then(decode)
      };
    }

    this.json = function() {
      return this.text().then(JSON.parse)
    };

    return this
  }

  // HTTP methods whose capitalization should be normalized
  var methods = ['DELETE', 'GET', 'HEAD', 'OPTIONS', 'POST', 'PUT'];

  function normalizeMethod(method) {
    var upcased = method.toUpperCase();
    return methods.indexOf(upcased) > -1 ? upcased : method
  }

  function Request(input, options) {
    options = options || {};
    var body = options.body;

    if (input instanceof Request) {
      if (input.bodyUsed) {
        throw new TypeError('Already read')
      }
      this.url = input.url;
      this.credentials = input.credentials;
      if (!options.headers) {
        this.headers = new Headers(input.headers);
      }
      this.method = input.method;
      this.mode = input.mode;
      this.signal = input.signal;
      if (!body && input._bodyInit != null) {
        body = input._bodyInit;
        input.bodyUsed = true;
      }
    } else {
      this.url = String(input);
    }

    this.credentials = options.credentials || this.credentials || 'same-origin';
    if (options.headers || !this.headers) {
      this.headers = new Headers(options.headers);
    }
    this.method = normalizeMethod(options.method || this.method || 'GET');
    this.mode = options.mode || this.mode || null;
    this.signal = options.signal || this.signal;
    this.referrer = null;

    if ((this.method === 'GET' || this.method === 'HEAD') && body) {
      throw new TypeError('Body not allowed for GET or HEAD requests')
    }
    this._initBody(body);
  }

  Request.prototype.clone = function() {
    return new Request(this, {body: this._bodyInit})
  };

  function decode(body) {
    var form = new FormData();
    body
      .trim()
      .split('&')
      .forEach(function(bytes) {
        if (bytes) {
          var split = bytes.split('=');
          var name = split.shift().replace(/\+/g, ' ');
          var value = split.join('=').replace(/\+/g, ' ');
          form.append(decodeURIComponent(name), decodeURIComponent(value));
        }
      });
    return form
  }

  function parseHeaders(rawHeaders) {
    var headers = new Headers();
    // Replace instances of \r\n and \n followed by at least one space or horizontal tab with a space
    // https://tools.ietf.org/html/rfc7230#section-3.2
    var preProcessedHeaders = rawHeaders.replace(/\r?\n[\t ]+/g, ' ');
    preProcessedHeaders.split(/\r?\n/).forEach(function(line) {
      var parts = line.split(':');
      var key = parts.shift().trim();
      if (key) {
        var value = parts.join(':').trim();
        headers.append(key, value);
      }
    });
    return headers
  }

  Body.call(Request.prototype);

  function Response(bodyInit, options) {
    if (!options) {
      options = {};
    }

    this.type = 'default';
    this.status = options.status === undefined ? 200 : options.status;
    this.ok = this.status >= 200 && this.status < 300;
    this.statusText = 'statusText' in options ? options.statusText : 'OK';
    this.headers = new Headers(options.headers);
    this.url = options.url || '';
    this._initBody(bodyInit);
  }

  Body.call(Response.prototype);

  Response.prototype.clone = function() {
    return new Response(this._bodyInit, {
      status: this.status,
      statusText: this.statusText,
      headers: new Headers(this.headers),
      url: this.url
    })
  };

  Response.error = function() {
    var response = new Response(null, {status: 0, statusText: ''});
    response.type = 'error';
    return response
  };

  var redirectStatuses = [301, 302, 303, 307, 308];

  Response.redirect = function(url, status) {
    if (redirectStatuses.indexOf(status) === -1) {
      throw new RangeError('Invalid status code')
    }

    return new Response(null, {status: status, headers: {location: url}})
  };

  exports.DOMException = self.DOMException;
  try {
    new exports.DOMException();
  } catch (err) {
    exports.DOMException = function(message, name) {
      this.message = message;
      this.name = name;
      var error = Error(message);
      this.stack = error.stack;
    };
    exports.DOMException.prototype = Object.create(Error.prototype);
    exports.DOMException.prototype.constructor = exports.DOMException;
  }

  function fetch(input, init) {
    return new Promise(function(resolve, reject) {
      var request = new Request(input, init);

      if (request.signal && request.signal.aborted) {
        return reject(new exports.DOMException('Aborted', 'AbortError'))
      }

      var xhr = new XMLHttpRequest();

      function abortXhr() {
        xhr.abort();
      }

      xhr.onload = function() {
        var options = {
          status: xhr.status,
          statusText: xhr.statusText,
          headers: parseHeaders(xhr.getAllResponseHeaders() || '')
        };
        options.url = 'responseURL' in xhr ? xhr.responseURL : options.headers.get('X-Request-URL');
        var body = 'response' in xhr ? xhr.response : xhr.responseText;
        resolve(new Response(body, options));
      };

      xhr.onerror = function() {
        reject(new TypeError('Network request failed'));
      };

      xhr.ontimeout = function() {
        reject(new TypeError('Network request failed'));
      };

      xhr.onabort = function() {
        reject(new exports.DOMException('Aborted', 'AbortError'));
      };

      xhr.open(request.method, request.url, true);

      if (request.credentials === 'include') {
        xhr.withCredentials = true;
      } else if (request.credentials === 'omit') {
        xhr.withCredentials = false;
      }

      if ('responseType' in xhr && support.blob) {
        xhr.responseType = 'blob';
      }

      request.headers.forEach(function(value, name) {
        xhr.setRequestHeader(name, value);
      });

      if (request.signal) {
        request.signal.addEventListener('abort', abortXhr);

        xhr.onreadystatechange = function() {
          // DONE (success or failure)
          if (xhr.readyState === 4) {
            request.signal.removeEventListener('abort', abortXhr);
          }
        };
      }

      xhr.send(typeof request._bodyInit === 'undefined' ? null : request._bodyInit);
    })
  }

  fetch.polyfill = true;

  if (!self.fetch) {
    self.fetch = fetch;
    self.Headers = Headers;
    self.Request = Request;
    self.Response = Response;
  }

  exports.Headers = Headers;
  exports.Request = Request;
  exports.Response = Response;
  exports.fetch = fetch;

  return exports;

}({}));
})(typeof self !== 'undefined' ? self : this);

},{}],79:[function(require,module,exports){
exports.UINT32 = require('./lib/uint32')
exports.UINT64 = require('./lib/uint64')
},{"./lib/uint32":80,"./lib/uint64":81}],80:[function(require,module,exports){
/**
	C-like unsigned 32 bits integers in Javascript
	Copyright (C) 2013, Pierre Curto
	MIT license
 */
;(function (root) {

	// Local cache for typical radices
	var radixPowerCache = {
		36: UINT32( Math.pow(36, 5) )
	,	16: UINT32( Math.pow(16, 7) )
	,	10: UINT32( Math.pow(10, 9) )
	,	2:  UINT32( Math.pow(2, 30) )
	}
	var radixCache = {
		36: UINT32(36)
	,	16: UINT32(16)
	,	10: UINT32(10)
	,	2:  UINT32(2)
	}

	/**
	 *	Represents an unsigned 32 bits integer
	 * @constructor
	 * @param {Number|String|Number} low bits     | integer as a string 		 | integer as a number
	 * @param {Number|Number|Undefined} high bits | radix (optional, default=10)
	 * @return 
	 */
	function UINT32 (l, h) {
		if ( !(this instanceof UINT32) )
			return new UINT32(l, h)

		this._low = 0
		this._high = 0
		this.remainder = null
		if (typeof h == 'undefined')
			return fromNumber.call(this, l)

		if (typeof l == 'string')
			return fromString.call(this, l, h)

		fromBits.call(this, l, h)
	}

	/**
	 * Set the current _UINT32_ object with its low and high bits
	 * @method fromBits
	 * @param {Number} low bits
	 * @param {Number} high bits
	 * @return ThisExpression
	 */
	function fromBits (l, h) {
		this._low = l | 0
		this._high = h | 0

		return this
	}
	UINT32.prototype.fromBits = fromBits

	/**
	 * Set the current _UINT32_ object from a number
	 * @method fromNumber
	 * @param {Number} number
	 * @return ThisExpression
	 */
	function fromNumber (value) {
		this._low = value & 0xFFFF
		this._high = value >>> 16

		return this
	}
	UINT32.prototype.fromNumber = fromNumber

	/**
	 * Set the current _UINT32_ object from a string
	 * @method fromString
	 * @param {String} integer as a string
	 * @param {Number} radix (optional, default=10)
	 * @return ThisExpression
	 */
	function fromString (s, radix) {
		var value = parseInt(s, radix || 10)

		this._low = value & 0xFFFF
		this._high = value >>> 16

		return this
	}
	UINT32.prototype.fromString = fromString

	/**
	 * Convert this _UINT32_ to a number
	 * @method toNumber
	 * @return {Number} the converted UINT32
	 */
	UINT32.prototype.toNumber = function () {
		return (this._high * 65536) + this._low
	}

	/**
	 * Convert this _UINT32_ to a string
	 * @method toString
	 * @param {Number} radix (optional, default=10)
	 * @return {String} the converted UINT32
	 */
	UINT32.prototype.toString = function (radix) {
		return this.toNumber().toString(radix || 10)
	}

	/**
	 * Add two _UINT32_. The current _UINT32_ stores the result
	 * @method add
	 * @param {Object} other UINT32
	 * @return ThisExpression
	 */
	UINT32.prototype.add = function (other) {
		var a00 = this._low + other._low
		var a16 = a00 >>> 16

		a16 += this._high + other._high

		this._low = a00 & 0xFFFF
		this._high = a16 & 0xFFFF

		return this
	}

	/**
	 * Subtract two _UINT32_. The current _UINT32_ stores the result
	 * @method subtract
	 * @param {Object} other UINT32
	 * @return ThisExpression
	 */
	UINT32.prototype.subtract = function (other) {
		//TODO inline
		return this.add( other.clone().negate() )
	}

	/**
	 * Multiply two _UINT32_. The current _UINT32_ stores the result
	 * @method multiply
	 * @param {Object} other UINT32
	 * @return ThisExpression
	 */
	UINT32.prototype.multiply = function (other) {
		/*
			a = a00 + a16
			b = b00 + b16
			a*b = (a00 + a16)(b00 + b16)
				= a00b00 + a00b16 + a16b00 + a16b16

			a16b16 overflows the 32bits
		 */
		var a16 = this._high
		var a00 = this._low
		var b16 = other._high
		var b00 = other._low

/* Removed to increase speed under normal circumstances (i.e. not multiplying by 0 or 1)
		// this == 0 or other == 1: nothing to do
		if ((a00 == 0 && a16 == 0) || (b00 == 1 && b16 == 0)) return this

		// other == 0 or this == 1: this = other
		if ((b00 == 0 && b16 == 0) || (a00 == 1 && a16 == 0)) {
			this._low = other._low
			this._high = other._high
			return this
		}
*/

		var c16, c00
		c00 = a00 * b00
		c16 = c00 >>> 16

		c16 += a16 * b00
		c16 &= 0xFFFF		// Not required but improves performance
		c16 += a00 * b16

		this._low = c00 & 0xFFFF
		this._high = c16 & 0xFFFF

		return this
	}

	/**
	 * Divide two _UINT32_. The current _UINT32_ stores the result.
	 * The remainder is made available as the _remainder_ property on
	 * the _UINT32_ object. It can be null, meaning there are no remainder.
	 * @method div
	 * @param {Object} other UINT32
	 * @return ThisExpression
	 */
	UINT32.prototype.div = function (other) {
		if ( (other._low == 0) && (other._high == 0) ) throw Error('division by zero')

		// other == 1
		if (other._high == 0 && other._low == 1) {
			this.remainder = new UINT32(0)
			return this
		}

		// other > this: 0
		if ( other.gt(this) ) {
			this.remainder = this.clone()
			this._low = 0
			this._high = 0
			return this
		}
		// other == this: 1
		if ( this.eq(other) ) {
			this.remainder = new UINT32(0)
			this._low = 1
			this._high = 0
			return this
		}

		// Shift the divisor left until it is higher than the dividend
		var _other = other.clone()
		var i = -1
		while ( !this.lt(_other) ) {
			// High bit can overflow the default 16bits
			// Its ok since we right shift after this loop
			// The overflown bit must be kept though
			_other.shiftLeft(1, true)
			i++
		}

		// Set the remainder
		this.remainder = this.clone()
		// Initialize the current result to 0
		this._low = 0
		this._high = 0
		for (; i >= 0; i--) {
			_other.shiftRight(1)
			// If shifted divisor is smaller than the dividend
			// then subtract it from the dividend
			if ( !this.remainder.lt(_other) ) {
				this.remainder.subtract(_other)
				// Update the current result
				if (i >= 16) {
					this._high |= 1 << (i - 16)
				} else {
					this._low |= 1 << i
				}
			}
		}

		return this
	}

	/**
	 * Negate the current _UINT32_
	 * @method negate
	 * @return ThisExpression
	 */
	UINT32.prototype.negate = function () {
		var v = ( ~this._low & 0xFFFF ) + 1
		this._low = v & 0xFFFF
		this._high = (~this._high + (v >>> 16)) & 0xFFFF

		return this
	}

	/**
	 * Equals
	 * @method eq
	 * @param {Object} other UINT32
	 * @return {Boolean}
	 */
	UINT32.prototype.equals = UINT32.prototype.eq = function (other) {
		return (this._low == other._low) && (this._high == other._high)
	}

	/**
	 * Greater than (strict)
	 * @method gt
	 * @param {Object} other UINT32
	 * @return {Boolean}
	 */
	UINT32.prototype.greaterThan = UINT32.prototype.gt = function (other) {
		if (this._high > other._high) return true
		if (this._high < other._high) return false
		return this._low > other._low
	}

	/**
	 * Less than (strict)
	 * @method lt
	 * @param {Object} other UINT32
	 * @return {Boolean}
	 */
	UINT32.prototype.lessThan = UINT32.prototype.lt = function (other) {
		if (this._high < other._high) return true
		if (this._high > other._high) return false
		return this._low < other._low
	}

	/**
	 * Bitwise OR
	 * @method or
	 * @param {Object} other UINT32
	 * @return ThisExpression
	 */
	UINT32.prototype.or = function (other) {
		this._low |= other._low
		this._high |= other._high

		return this
	}

	/**
	 * Bitwise AND
	 * @method and
	 * @param {Object} other UINT32
	 * @return ThisExpression
	 */
	UINT32.prototype.and = function (other) {
		this._low &= other._low
		this._high &= other._high

		return this
	}

	/**
	 * Bitwise NOT
	 * @method not
	 * @return ThisExpression
	 */
	UINT32.prototype.not = function() {
		this._low = ~this._low & 0xFFFF
		this._high = ~this._high & 0xFFFF

		return this
	}

	/**
	 * Bitwise XOR
	 * @method xor
	 * @param {Object} other UINT32
	 * @return ThisExpression
	 */
	UINT32.prototype.xor = function (other) {
		this._low ^= other._low
		this._high ^= other._high

		return this
	}

	/**
	 * Bitwise shift right
	 * @method shiftRight
	 * @param {Number} number of bits to shift
	 * @return ThisExpression
	 */
	UINT32.prototype.shiftRight = UINT32.prototype.shiftr = function (n) {
		if (n > 16) {
			this._low = this._high >> (n - 16)
			this._high = 0
		} else if (n == 16) {
			this._low = this._high
			this._high = 0
		} else {
			this._low = (this._low >> n) | ( (this._high << (16-n)) & 0xFFFF )
			this._high >>= n
		}

		return this
	}

	/**
	 * Bitwise shift left
	 * @method shiftLeft
	 * @param {Number} number of bits to shift
	 * @param {Boolean} allow overflow
	 * @return ThisExpression
	 */
	UINT32.prototype.shiftLeft = UINT32.prototype.shiftl = function (n, allowOverflow) {
		if (n > 16) {
			this._high = this._low << (n - 16)
			this._low = 0
			if (!allowOverflow) {
				this._high &= 0xFFFF
			}
		} else if (n == 16) {
			this._high = this._low
			this._low = 0
		} else {
			this._high = (this._high << n) | (this._low >> (16-n))
			this._low = (this._low << n) & 0xFFFF
			if (!allowOverflow) {
				// Overflow only allowed on the high bits...
				this._high &= 0xFFFF
			}
		}

		return this
	}

	/**
	 * Bitwise rotate left
	 * @method rotl
	 * @param {Number} number of bits to rotate
	 * @return ThisExpression
	 */
	UINT32.prototype.rotateLeft = UINT32.prototype.rotl = function (n) {
		var v = (this._high << 16) | this._low
		v = (v << n) | (v >>> (32 - n))
		this._low = v & 0xFFFF
		this._high = v >>> 16

		return this
	}

	/**
	 * Bitwise rotate right
	 * @method rotr
	 * @param {Number} number of bits to rotate
	 * @return ThisExpression
	 */
	UINT32.prototype.rotateRight = UINT32.prototype.rotr = function (n) {
		var v = (this._high << 16) | this._low
		v = (v >>> n) | (v << (32 - n))
		this._low = v & 0xFFFF
		this._high = v >>> 16

		return this
	}

	/**
	 * Clone the current _UINT32_
	 * @method clone
	 * @return {Object} cloned UINT32
	 */
	UINT32.prototype.clone = function () {
		return new UINT32(this._low, this._high)
	}

	if (typeof define != 'undefined' && define.amd) {
		// AMD / RequireJS
		define([], function () {
			return UINT32
		})
	} else if (typeof module != 'undefined' && module.exports) {
		// Node.js
		module.exports = UINT32
	} else {
		// Browser
		root['UINT32'] = UINT32
	}

})(this)

},{}],81:[function(require,module,exports){
/**
	C-like unsigned 64 bits integers in Javascript
	Copyright (C) 2013, Pierre Curto
	MIT license
 */
;(function (root) {

	// Local cache for typical radices
	var radixPowerCache = {
		16: UINT64( Math.pow(16, 5) )
	,	10: UINT64( Math.pow(10, 5) )
	,	2:  UINT64( Math.pow(2, 5) )
	}
	var radixCache = {
		16: UINT64(16)
	,	10: UINT64(10)
	,	2:  UINT64(2)
	}

	/**
	 *	Represents an unsigned 64 bits integer
	 * @constructor
	 * @param {Number} first low bits (8)
	 * @param {Number} second low bits (8)
	 * @param {Number} first high bits (8)
	 * @param {Number} second high bits (8)
	 * or
	 * @param {Number} low bits (32)
	 * @param {Number} high bits (32)
	 * or
	 * @param {String|Number} integer as a string 		 | integer as a number
	 * @param {Number|Undefined} radix (optional, default=10)
	 * @return 
	 */
	function UINT64 (a00, a16, a32, a48) {
		if ( !(this instanceof UINT64) )
			return new UINT64(a00, a16, a32, a48)

		this.remainder = null
		if (typeof a00 == 'string')
			return fromString.call(this, a00, a16)

		if (typeof a16 == 'undefined')
			return fromNumber.call(this, a00)

		fromBits.apply(this, arguments)
	}

	/**
	 * Set the current _UINT64_ object with its low and high bits
	 * @method fromBits
	 * @param {Number} first low bits (8)
	 * @param {Number} second low bits (8)
	 * @param {Number} first high bits (8)
	 * @param {Number} second high bits (8)
	 * or
	 * @param {Number} low bits (32)
	 * @param {Number} high bits (32)
	 * @return ThisExpression
	 */
	function fromBits (a00, a16, a32, a48) {
		if (typeof a32 == 'undefined') {
			this._a00 = a00 & 0xFFFF
			this._a16 = a00 >>> 16
			this._a32 = a16 & 0xFFFF
			this._a48 = a16 >>> 16
			return this
		}

		this._a00 = a00 | 0
		this._a16 = a16 | 0
		this._a32 = a32 | 0
		this._a48 = a48 | 0

		return this
	}
	UINT64.prototype.fromBits = fromBits

	/**
	 * Set the current _UINT64_ object from a number
	 * @method fromNumber
	 * @param {Number} number
	 * @return ThisExpression
	 */
	function fromNumber (value) {
		this._a00 = value & 0xFFFF
		this._a16 = value >>> 16
		this._a32 = 0
		this._a48 = 0

		return this
	}
	UINT64.prototype.fromNumber = fromNumber

	/**
	 * Set the current _UINT64_ object from a string
	 * @method fromString
	 * @param {String} integer as a string
	 * @param {Number} radix (optional, default=10)
	 * @return ThisExpression
	 */
	function fromString (s, radix) {
		radix = radix || 10

		this._a00 = 0
		this._a16 = 0
		this._a32 = 0
		this._a48 = 0

		/*
			In Javascript, bitwise operators only operate on the first 32 bits 
			of a number, even though parseInt() encodes numbers with a 53 bits 
			mantissa.
			Therefore UINT64(<Number>) can only work on 32 bits.
			The radix maximum value is 36 (as per ECMA specs) (26 letters + 10 digits)
			maximum input value is m = 32bits as 1 = 2^32 - 1
			So the maximum substring length n is:
			36^(n+1) - 1 = 2^32 - 1
			36^(n+1) = 2^32
			(n+1)ln(36) = 32ln(2)
			n = 32ln(2)/ln(36) - 1
			n = 5.189644915687692
			n = 5
		 */
		var radixUint = radixPowerCache[radix] || new UINT64( Math.pow(radix, 5) )

		for (var i = 0, len = s.length; i < len; i += 5) {
			var size = Math.min(5, len - i)
			var value = parseInt( s.slice(i, i + size), radix )
			this.multiply(
					size < 5
						? new UINT64( Math.pow(radix, size) )
						: radixUint
				)
				.add( new UINT64(value) )
		}

		return this
	}
	UINT64.prototype.fromString = fromString

	/**
	 * Convert this _UINT64_ to a number (last 32 bits are dropped)
	 * @method toNumber
	 * @return {Number} the converted UINT64
	 */
	UINT64.prototype.toNumber = function () {
		return (this._a16 * 65536) + this._a00
	}

	/**
	 * Convert this _UINT64_ to a string
	 * @method toString
	 * @param {Number} radix (optional, default=10)
	 * @return {String} the converted UINT64
	 */
	UINT64.prototype.toString = function (radix) {
		radix = radix || 10
		var radixUint = radixCache[radix] || new UINT64(radix)

		if ( !this.gt(radixUint) ) return this.toNumber().toString(radix)

		var self = this.clone()
		var res = new Array(64)
		for (var i = 63; i >= 0; i--) {
			self.div(radixUint)
			res[i] = self.remainder.toNumber().toString(radix)
			if ( !self.gt(radixUint) ) break
		}
		res[i-1] = self.toNumber().toString(radix)

		return res.join('')
	}

	/**
	 * Add two _UINT64_. The current _UINT64_ stores the result
	 * @method add
	 * @param {Object} other UINT64
	 * @return ThisExpression
	 */
	UINT64.prototype.add = function (other) {
		var a00 = this._a00 + other._a00

		var a16 = a00 >>> 16
		a16 += this._a16 + other._a16

		var a32 = a16 >>> 16
		a32 += this._a32 + other._a32

		var a48 = a32 >>> 16
		a48 += this._a48 + other._a48

		this._a00 = a00 & 0xFFFF
		this._a16 = a16 & 0xFFFF
		this._a32 = a32 & 0xFFFF
		this._a48 = a48 & 0xFFFF

		return this
	}

	/**
	 * Subtract two _UINT64_. The current _UINT64_ stores the result
	 * @method subtract
	 * @param {Object} other UINT64
	 * @return ThisExpression
	 */
	UINT64.prototype.subtract = function (other) {
		return this.add( other.clone().negate() )
	}

	/**
	 * Multiply two _UINT64_. The current _UINT64_ stores the result
	 * @method multiply
	 * @param {Object} other UINT64
	 * @return ThisExpression
	 */
	UINT64.prototype.multiply = function (other) {
		/*
			a = a00 + a16 + a32 + a48
			b = b00 + b16 + b32 + b48
			a*b = (a00 + a16 + a32 + a48)(b00 + b16 + b32 + b48)
				= a00b00 + a00b16 + a00b32 + a00b48
				+ a16b00 + a16b16 + a16b32 + a16b48
				+ a32b00 + a32b16 + a32b32 + a32b48
				+ a48b00 + a48b16 + a48b32 + a48b48

			a16b48, a32b32, a48b16, a48b32 and a48b48 overflow the 64 bits
			so it comes down to:
			a*b	= a00b00 + a00b16 + a00b32 + a00b48
				+ a16b00 + a16b16 + a16b32
				+ a32b00 + a32b16
				+ a48b00
				= a00b00
				+ a00b16 + a16b00
				+ a00b32 + a16b16 + a32b00
				+ a00b48 + a16b32 + a32b16 + a48b00
		 */
		var a00 = this._a00
		var a16 = this._a16
		var a32 = this._a32
		var a48 = this._a48
		var b00 = other._a00
		var b16 = other._a16
		var b32 = other._a32
		var b48 = other._a48

		var c00 = a00 * b00

		var c16 = c00 >>> 16
		c16 += a00 * b16
		var c32 = c16 >>> 16
		c16 &= 0xFFFF
		c16 += a16 * b00

		c32 += c16 >>> 16
		c32 += a00 * b32
		var c48 = c32 >>> 16
		c32 &= 0xFFFF
		c32 += a16 * b16
		c48 += c32 >>> 16
		c32 &= 0xFFFF
		c32 += a32 * b00

		c48 += c32 >>> 16
		c48 += a00 * b48
		c48 &= 0xFFFF
		c48 += a16 * b32
		c48 &= 0xFFFF
		c48 += a32 * b16
		c48 &= 0xFFFF
		c48 += a48 * b00

		this._a00 = c00 & 0xFFFF
		this._a16 = c16 & 0xFFFF
		this._a32 = c32 & 0xFFFF
		this._a48 = c48 & 0xFFFF

		return this
	}

	/**
	 * Divide two _UINT64_. The current _UINT64_ stores the result.
	 * The remainder is made available as the _remainder_ property on
	 * the _UINT64_ object. It can be null, meaning there are no remainder.
	 * @method div
	 * @param {Object} other UINT64
	 * @return ThisExpression
	 */
	UINT64.prototype.div = function (other) {
		if ( (other._a16 == 0) && (other._a32 == 0) && (other._a48 == 0) ) {
			if (other._a00 == 0) throw Error('division by zero')

			// other == 1: this
			if (other._a00 == 1) {
				this.remainder = new UINT64(0)
				return this
			}
		}

		// other > this: 0
		if ( other.gt(this) ) {
			this.remainder = this.clone()
			this._a00 = 0
			this._a16 = 0
			this._a32 = 0
			this._a48 = 0
			return this
		}
		// other == this: 1
		if ( this.eq(other) ) {
			this.remainder = new UINT64(0)
			this._a00 = 1
			this._a16 = 0
			this._a32 = 0
			this._a48 = 0
			return this
		}

		// Shift the divisor left until it is higher than the dividend
		var _other = other.clone()
		var i = -1
		while ( !this.lt(_other) ) {
			// High bit can overflow the default 16bits
			// Its ok since we right shift after this loop
			// The overflown bit must be kept though
			_other.shiftLeft(1, true)
			i++
		}

		// Set the remainder
		this.remainder = this.clone()
		// Initialize the current result to 0
		this._a00 = 0
		this._a16 = 0
		this._a32 = 0
		this._a48 = 0
		for (; i >= 0; i--) {
			_other.shiftRight(1)
			// If shifted divisor is smaller than the dividend
			// then subtract it from the dividend
			if ( !this.remainder.lt(_other) ) {
				this.remainder.subtract(_other)
				// Update the current result
				if (i >= 48) {
					this._a48 |= 1 << (i - 48)
				} else if (i >= 32) {
					this._a32 |= 1 << (i - 32)
				} else if (i >= 16) {
					this._a16 |= 1 << (i - 16)
				} else {
					this._a00 |= 1 << i
				}
			}
		}

		return this
	}

	/**
	 * Negate the current _UINT64_
	 * @method negate
	 * @return ThisExpression
	 */
	UINT64.prototype.negate = function () {
		var v = ( ~this._a00 & 0xFFFF ) + 1
		this._a00 = v & 0xFFFF
		v = (~this._a16 & 0xFFFF) + (v >>> 16)
		this._a16 = v & 0xFFFF
		v = (~this._a32 & 0xFFFF) + (v >>> 16)
		this._a32 = v & 0xFFFF
		this._a48 = (~this._a48 + (v >>> 16)) & 0xFFFF

		return this
	}

	/**

	 * @method eq
	 * @param {Object} other UINT64
	 * @return {Boolean}
	 */
	UINT64.prototype.equals = UINT64.prototype.eq = function (other) {
		return (this._a48 == other._a48) && (this._a00 == other._a00)
			 && (this._a32 == other._a32) && (this._a16 == other._a16)
	}

	/**
	 * Greater than (strict)
	 * @method gt
	 * @param {Object} other UINT64
	 * @return {Boolean}
	 */
	UINT64.prototype.greaterThan = UINT64.prototype.gt = function (other) {
		if (this._a48 > other._a48) return true
		if (this._a48 < other._a48) return false
		if (this._a32 > other._a32) return true
		if (this._a32 < other._a32) return false
		if (this._a16 > other._a16) return true
		if (this._a16 < other._a16) return false
		return this._a00 > other._a00
	}

	/**
	 * Less than (strict)
	 * @method lt
	 * @param {Object} other UINT64
	 * @return {Boolean}
	 */
	UINT64.prototype.lessThan = UINT64.prototype.lt = function (other) {
		if (this._a48 < other._a48) return true
		if (this._a48 > other._a48) return false
		if (this._a32 < other._a32) return true
		if (this._a32 > other._a32) return false
		if (this._a16 < other._a16) return true
		if (this._a16 > other._a16) return false
		return this._a00 < other._a00
	}

	/**
	 * Bitwise OR
	 * @method or
	 * @param {Object} other UINT64
	 * @return ThisExpression
	 */
	UINT64.prototype.or = function (other) {
		this._a00 |= other._a00
		this._a16 |= other._a16
		this._a32 |= other._a32
		this._a48 |= other._a48

		return this
	}

	/**
	 * Bitwise AND
	 * @method and
	 * @param {Object} other UINT64
	 * @return ThisExpression
	 */
	UINT64.prototype.and = function (other) {
		this._a00 &= other._a00
		this._a16 &= other._a16
		this._a32 &= other._a32
		this._a48 &= other._a48

		return this
	}

	/**
	 * Bitwise XOR
	 * @method xor
	 * @param {Object} other UINT64
	 * @return ThisExpression
	 */
	UINT64.prototype.xor = function (other) {
		this._a00 ^= other._a00
		this._a16 ^= other._a16
		this._a32 ^= other._a32
		this._a48 ^= other._a48

		return this
	}

	/**
	 * Bitwise NOT
	 * @method not
	 * @return ThisExpression
	 */
	UINT64.prototype.not = function() {
		this._a00 = ~this._a00 & 0xFFFF
		this._a16 = ~this._a16 & 0xFFFF
		this._a32 = ~this._a32 & 0xFFFF
		this._a48 = ~this._a48 & 0xFFFF

		return this
	}

	/**
	 * Bitwise shift right
	 * @method shiftRight
	 * @param {Number} number of bits to shift
	 * @return ThisExpression
	 */
	UINT64.prototype.shiftRight = UINT64.prototype.shiftr = function (n) {
		n %= 64
		if (n >= 48) {
			this._a00 = this._a48 >> (n - 48)
			this._a16 = 0
			this._a32 = 0
			this._a48 = 0
		} else if (n >= 32) {
			n -= 32
			this._a00 = ( (this._a32 >> n) | (this._a48 << (16-n)) ) & 0xFFFF
			this._a16 = (this._a48 >> n) & 0xFFFF
			this._a32 = 0
			this._a48 = 0
		} else if (n >= 16) {
			n -= 16
			this._a00 = ( (this._a16 >> n) | (this._a32 << (16-n)) ) & 0xFFFF
			this._a16 = ( (this._a32 >> n) | (this._a48 << (16-n)) ) & 0xFFFF
			this._a32 = (this._a48 >> n) & 0xFFFF
			this._a48 = 0
		} else {
			this._a00 = ( (this._a00 >> n) | (this._a16 << (16-n)) ) & 0xFFFF
			this._a16 = ( (this._a16 >> n) | (this._a32 << (16-n)) ) & 0xFFFF
			this._a32 = ( (this._a32 >> n) | (this._a48 << (16-n)) ) & 0xFFFF
			this._a48 = (this._a48 >> n) & 0xFFFF
		}

		return this
	}

	/**
	 * Bitwise shift left
	 * @method shiftLeft
	 * @param {Number} number of bits to shift
	 * @param {Boolean} allow overflow
	 * @return ThisExpression
	 */
	UINT64.prototype.shiftLeft = UINT64.prototype.shiftl = function (n, allowOverflow) {
		n %= 64
		if (n >= 48) {
			this._a48 = this._a00 << (n - 48)
			this._a32 = 0
			this._a16 = 0
			this._a00 = 0
		} else if (n >= 32) {
			n -= 32
			this._a48 = (this._a16 << n) | (this._a00 >> (16-n))
			this._a32 = (this._a00 << n) & 0xFFFF
			this._a16 = 0
			this._a00 = 0
		} else if (n >= 16) {
			n -= 16
			this._a48 = (this._a32 << n) | (this._a16 >> (16-n))
			this._a32 = ( (this._a16 << n) | (this._a00 >> (16-n)) ) & 0xFFFF
			this._a16 = (this._a00 << n) & 0xFFFF
			this._a00 = 0
		} else {
			this._a48 = (this._a48 << n) | (this._a32 >> (16-n))
			this._a32 = ( (this._a32 << n) | (this._a16 >> (16-n)) ) & 0xFFFF
			this._a16 = ( (this._a16 << n) | (this._a00 >> (16-n)) ) & 0xFFFF
			this._a00 = (this._a00 << n) & 0xFFFF
		}
		if (!allowOverflow) {
			this._a48 &= 0xFFFF
		}

		return this
	}

	/**
	 * Bitwise rotate left
	 * @method rotl
	 * @param {Number} number of bits to rotate
	 * @return ThisExpression
	 */
	UINT64.prototype.rotateLeft = UINT64.prototype.rotl = function (n) {
		n %= 64
		if (n == 0) return this
		if (n >= 32) {
			// A.B.C.D
			// B.C.D.A rotl(16)
			// C.D.A.B rotl(32)
			var v = this._a00
			this._a00 = this._a32
			this._a32 = v
			v = this._a48
			this._a48 = this._a16
			this._a16 = v
			if (n == 32) return this
			n -= 32
		}

		var high = (this._a48 << 16) | this._a32
		var low = (this._a16 << 16) | this._a00

		var _high = (high << n) | (low >>> (32 - n))
		var _low = (low << n) | (high >>> (32 - n))

		this._a00 = _low & 0xFFFF
		this._a16 = _low >>> 16
		this._a32 = _high & 0xFFFF
		this._a48 = _high >>> 16

		return this
	}

	/**
	 * Bitwise rotate right
	 * @method rotr
	 * @param {Number} number of bits to rotate
	 * @return ThisExpression
	 */
	UINT64.prototype.rotateRight = UINT64.prototype.rotr = function (n) {
		n %= 64
		if (n == 0) return this
		if (n >= 32) {
			// A.B.C.D
			// D.A.B.C rotr(16)
			// C.D.A.B rotr(32)
			var v = this._a00
			this._a00 = this._a32
			this._a32 = v
			v = this._a48
			this._a48 = this._a16
			this._a16 = v
			if (n == 32) return this
			n -= 32
		}

		var high = (this._a48 << 16) | this._a32
		var low = (this._a16 << 16) | this._a00

		var _high = (high >>> n) | (low << (32 - n))
		var _low = (low >>> n) | (high << (32 - n))

		this._a00 = _low & 0xFFFF
		this._a16 = _low >>> 16
		this._a32 = _high & 0xFFFF
		this._a48 = _high >>> 16

		return this
	}

	/**
	 * Clone the current _UINT64_
	 * @method clone
	 * @return {Object} cloned UINT64
	 */
	UINT64.prototype.clone = function () {
		return new UINT64(this._a00, this._a16, this._a32, this._a48)
	}

	if (typeof define != 'undefined' && define.amd) {
		// AMD / RequireJS
		define([], function () {
			return UINT64
		})
	} else if (typeof module != 'undefined' && module.exports) {
		// Node.js
		module.exports = UINT64
	} else {
		// Browser
		root['UINT64'] = UINT64
	}

})(this)

},{}],82:[function(require,module,exports){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

var objectCreate = Object.create || objectCreatePolyfill
var objectKeys = Object.keys || objectKeysPolyfill
var bind = Function.prototype.bind || functionBindPolyfill

function EventEmitter() {
  if (!this._events || !Object.prototype.hasOwnProperty.call(this, '_events')) {
    this._events = objectCreate(null);
    this._eventsCount = 0;
  }

  this._maxListeners = this._maxListeners || undefined;
}
module.exports = EventEmitter;

// Backwards-compat with node 0.10.x
EventEmitter.EventEmitter = EventEmitter;

EventEmitter.prototype._events = undefined;
EventEmitter.prototype._maxListeners = undefined;

// By default EventEmitters will print a warning if more than 10 listeners are
// added to it. This is a useful default which helps finding memory leaks.
var defaultMaxListeners = 10;

var hasDefineProperty;
try {
  var o = {};
  if (Object.defineProperty) Object.defineProperty(o, 'x', { value: 0 });
  hasDefineProperty = o.x === 0;
} catch (err) { hasDefineProperty = false }
if (hasDefineProperty) {
  Object.defineProperty(EventEmitter, 'defaultMaxListeners', {
    enumerable: true,
    get: function() {
      return defaultMaxListeners;
    },
    set: function(arg) {
      // check whether the input is a positive number (whose value is zero or
      // greater and not a NaN).
      if (typeof arg !== 'number' || arg < 0 || arg !== arg)
        throw new TypeError('"defaultMaxListeners" must be a positive number');
      defaultMaxListeners = arg;
    }
  });
} else {
  EventEmitter.defaultMaxListeners = defaultMaxListeners;
}

// Obviously not all Emitters should be limited to 10. This function allows
// that to be increased. Set to zero for unlimited.
EventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {
  if (typeof n !== 'number' || n < 0 || isNaN(n))
    throw new TypeError('"n" argument must be a positive number');
  this._maxListeners = n;
  return this;
};

function $getMaxListeners(that) {
  if (that._maxListeners === undefined)
    return EventEmitter.defaultMaxListeners;
  return that._maxListeners;
}

EventEmitter.prototype.getMaxListeners = function getMaxListeners() {
  return $getMaxListeners(this);
};

// These standalone emit* functions are used to optimize calling of event
// handlers for fast cases because emit() itself often has a variable number of
// arguments and can be deoptimized because of that. These functions always have
// the same number of arguments and thus do not get deoptimized, so the code
// inside them can execute faster.
function emitNone(handler, isFn, self) {
  if (isFn)
    handler.call(self);
  else {
    var len = handler.length;
    var listeners = arrayClone(handler, len);
    for (var i = 0; i < len; ++i)
      listeners[i].call(self);
  }
}
function emitOne(handler, isFn, self, arg1) {
  if (isFn)
    handler.call(self, arg1);
  else {
    var len = handler.length;
    var listeners = arrayClone(handler, len);
    for (var i = 0; i < len; ++i)
      listeners[i].call(self, arg1);
  }
}
function emitTwo(handler, isFn, self, arg1, arg2) {
  if (isFn)
    handler.call(self, arg1, arg2);
  else {
    var len = handler.length;
    var listeners = arrayClone(handler, len);
    for (var i = 0; i < len; ++i)
      listeners[i].call(self, arg1, arg2);
  }
}
function emitThree(handler, isFn, self, arg1, arg2, arg3) {
  if (isFn)
    handler.call(self, arg1, arg2, arg3);
  else {
    var len = handler.length;
    var listeners = arrayClone(handler, len);
    for (var i = 0; i < len; ++i)
      listeners[i].call(self, arg1, arg2, arg3);
  }
}

function emitMany(handler, isFn, self, args) {
  if (isFn)
    handler.apply(self, args);
  else {
    var len = handler.length;
    var listeners = arrayClone(handler, len);
    for (var i = 0; i < len; ++i)
      listeners[i].apply(self, args);
  }
}

EventEmitter.prototype.emit = function emit(type) {
  var er, handler, len, args, i, events;
  var doError = (type === 'error');

  events = this._events;
  if (events)
    doError = (doError && events.error == null);
  else if (!doError)
    return false;

  // If there is no 'error' event listener then throw.
  if (doError) {
    if (arguments.length > 1)
      er = arguments[1];
    if (er instanceof Error) {
      throw er; // Unhandled 'error' event
    } else {
      // At least give some kind of context to the user
      var err = new Error('Unhandled "error" event. (' + er + ')');
      err.context = er;
      throw err;
    }
    return false;
  }

  handler = events[type];

  if (!handler)
    return false;

  var isFn = typeof handler === 'function';
  len = arguments.length;
  switch (len) {
      // fast cases
    case 1:
      emitNone(handler, isFn, this);
      break;
    case 2:
      emitOne(handler, isFn, this, arguments[1]);
      break;
    case 3:
      emitTwo(handler, isFn, this, arguments[1], arguments[2]);
      break;
    case 4:
      emitThree(handler, isFn, this, arguments[1], arguments[2], arguments[3]);
      break;
      // slower
    default:
      args = new Array(len - 1);
      for (i = 1; i < len; i++)
        args[i - 1] = arguments[i];
      emitMany(handler, isFn, this, args);
  }

  return true;
};

function _addListener(target, type, listener, prepend) {
  var m;
  var events;
  var existing;

  if (typeof listener !== 'function')
    throw new TypeError('"listener" argument must be a function');

  events = target._events;
  if (!events) {
    events = target._events = objectCreate(null);
    target._eventsCount = 0;
  } else {
    // To avoid recursion in the case that type === "newListener"! Before
    // adding it to the listeners, first emit "newListener".
    if (events.newListener) {
      target.emit('newListener', type,
          listener.listener ? listener.listener : listener);

      // Re-assign `events` because a newListener handler could have caused the
      // this._events to be assigned to a new object
      events = target._events;
    }
    existing = events[type];
  }

  if (!existing) {
    // Optimize the case of one listener. Don't need the extra array object.
    existing = events[type] = listener;
    ++target._eventsCount;
  } else {
    if (typeof existing === 'function') {
      // Adding the second element, need to change to array.
      existing = events[type] =
          prepend ? [listener, existing] : [existing, listener];
    } else {
      // If we've already got an array, just append.
      if (prepend) {
        existing.unshift(listener);
      } else {
        existing.push(listener);
      }
    }

    // Check for listener leak
    if (!existing.warned) {
      m = $getMaxListeners(target);
      if (m && m > 0 && existing.length > m) {
        existing.warned = true;
        var w = new Error('Possible EventEmitter memory leak detected. ' +
            existing.length + ' "' + String(type) + '" listeners ' +
            'added. Use emitter.setMaxListeners() to ' +
            'increase limit.');
        w.name = 'MaxListenersExceededWarning';
        w.emitter = target;
        w.type = type;
        w.count = existing.length;
        if (typeof console === 'object' && console.warn) {
          console.warn('%s: %s', w.name, w.message);
        }
      }
    }
  }

  return target;
}

EventEmitter.prototype.addListener = function addListener(type, listener) {
  return _addListener(this, type, listener, false);
};

EventEmitter.prototype.on = EventEmitter.prototype.addListener;

EventEmitter.prototype.prependListener =
    function prependListener(type, listener) {
      return _addListener(this, type, listener, true);
    };

function onceWrapper() {
  if (!this.fired) {
    this.target.removeListener(this.type, this.wrapFn);
    this.fired = true;
    switch (arguments.length) {
      case 0:
        return this.listener.call(this.target);
      case 1:
        return this.listener.call(this.target, arguments[0]);
      case 2:
        return this.listener.call(this.target, arguments[0], arguments[1]);
      case 3:
        return this.listener.call(this.target, arguments[0], arguments[1],
            arguments[2]);
      default:
        var args = new Array(arguments.length);
        for (var i = 0; i < args.length; ++i)
          args[i] = arguments[i];
        this.listener.apply(this.target, args);
    }
  }
}

function _onceWrap(target, type, listener) {
  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };
  var wrapped = bind.call(onceWrapper, state);
  wrapped.listener = listener;
  state.wrapFn = wrapped;
  return wrapped;
}

EventEmitter.prototype.once = function once(type, listener) {
  if (typeof listener !== 'function')
    throw new TypeError('"listener" argument must be a function');
  this.on(type, _onceWrap(this, type, listener));
  return this;
};

EventEmitter.prototype.prependOnceListener =
    function prependOnceListener(type, listener) {
      if (typeof listener !== 'function')
        throw new TypeError('"listener" argument must be a function');
      this.prependListener(type, _onceWrap(this, type, listener));
      return this;
    };

// Emits a 'removeListener' event if and only if the listener was removed.
EventEmitter.prototype.removeListener =
    function removeListener(type, listener) {
      var list, events, position, i, originalListener;

      if (typeof listener !== 'function')
        throw new TypeError('"listener" argument must be a function');

      events = this._events;
      if (!events)
        return this;

      list = events[type];
      if (!list)
        return this;

      if (list === listener || list.listener === listener) {
        if (--this._eventsCount === 0)
          this._events = objectCreate(null);
        else {
          delete events[type];
          if (events.removeListener)
            this.emit('removeListener', type, list.listener || listener);
        }
      } else if (typeof list !== 'function') {
        position = -1;

        for (i = list.length - 1; i >= 0; i--) {
          if (list[i] === listener || list[i].listener === listener) {
            originalListener = list[i].listener;
            position = i;
            break;
          }
        }

        if (position < 0)
          return this;

        if (position === 0)
          list.shift();
        else
          spliceOne(list, position);

        if (list.length === 1)
          events[type] = list[0];

        if (events.removeListener)
          this.emit('removeListener', type, originalListener || listener);
      }

      return this;
    };

EventEmitter.prototype.removeAllListeners =
    function removeAllListeners(type) {
      var listeners, events, i;

      events = this._events;
      if (!events)
        return this;

      // not listening for removeListener, no need to emit
      if (!events.removeListener) {
        if (arguments.length === 0) {
          this._events = objectCreate(null);
          this._eventsCount = 0;
        } else if (events[type]) {
          if (--this._eventsCount === 0)
            this._events = objectCreate(null);
          else
            delete events[type];
        }
        return this;
      }

      // emit removeListener for all listeners on all events
      if (arguments.length === 0) {
        var keys = objectKeys(events);
        var key;
        for (i = 0; i < keys.length; ++i) {
          key = keys[i];
          if (key === 'removeListener') continue;
          this.removeAllListeners(key);
        }
        this.removeAllListeners('removeListener');
        this._events = objectCreate(null);
        this._eventsCount = 0;
        return this;
      }

      listeners = events[type];

      if (typeof listeners === 'function') {
        this.removeListener(type, listeners);
      } else if (listeners) {
        // LIFO order
        for (i = listeners.length - 1; i >= 0; i--) {
          this.removeListener(type, listeners[i]);
        }
      }

      return this;
    };

function _listeners(target, type, unwrap) {
  var events = target._events;

  if (!events)
    return [];

  var evlistener = events[type];
  if (!evlistener)
    return [];

  if (typeof evlistener === 'function')
    return unwrap ? [evlistener.listener || evlistener] : [evlistener];

  return unwrap ? unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);
}

EventEmitter.prototype.listeners = function listeners(type) {
  return _listeners(this, type, true);
};

EventEmitter.prototype.rawListeners = function rawListeners(type) {
  return _listeners(this, type, false);
};

EventEmitter.listenerCount = function(emitter, type) {
  if (typeof emitter.listenerCount === 'function') {
    return emitter.listenerCount(type);
  } else {
    return listenerCount.call(emitter, type);
  }
};

EventEmitter.prototype.listenerCount = listenerCount;
function listenerCount(type) {
  var events = this._events;

  if (events) {
    var evlistener = events[type];

    if (typeof evlistener === 'function') {
      return 1;
    } else if (evlistener) {
      return evlistener.length;
    }
  }

  return 0;
}

EventEmitter.prototype.eventNames = function eventNames() {
  return this._eventsCount > 0 ? Reflect.ownKeys(this._events) : [];
};

// About 1.5x faster than the two-arg version of Array#splice().
function spliceOne(list, index) {
  for (var i = index, k = i + 1, n = list.length; k < n; i += 1, k += 1)
    list[i] = list[k];
  list.pop();
}

function arrayClone(arr, n) {
  var copy = new Array(n);
  for (var i = 0; i < n; ++i)
    copy[i] = arr[i];
  return copy;
}

function unwrapListeners(arr) {
  var ret = new Array(arr.length);
  for (var i = 0; i < ret.length; ++i) {
    ret[i] = arr[i].listener || arr[i];
  }
  return ret;
}

function objectCreatePolyfill(proto) {
  var F = function() {};
  F.prototype = proto;
  return new F;
}
function objectKeysPolyfill(obj) {
  var keys = [];
  for (var k in obj) if (Object.prototype.hasOwnProperty.call(obj, k)) {
    keys.push(k);
  }
  return k;
}
function functionBindPolyfill(context) {
  var fn = this;
  return function () {
    return fn.apply(context, arguments);
  };
}

},{}],83:[function(require,module,exports){
exports.read = function (buffer, offset, isLE, mLen, nBytes) {
  var e, m
  var eLen = (nBytes * 8) - mLen - 1
  var eMax = (1 << eLen) - 1
  var eBias = eMax >> 1
  var nBits = -7
  var i = isLE ? (nBytes - 1) : 0
  var d = isLE ? -1 : 1
  var s = buffer[offset + i]

  i += d

  e = s & ((1 << (-nBits)) - 1)
  s >>= (-nBits)
  nBits += eLen
  for (; nBits > 0; e = (e * 256) + buffer[offset + i], i += d, nBits -= 8) {}

  m = e & ((1 << (-nBits)) - 1)
  e >>= (-nBits)
  nBits += mLen
  for (; nBits > 0; m = (m * 256) + buffer[offset + i], i += d, nBits -= 8) {}

  if (e === 0) {
    e = 1 - eBias
  } else if (e === eMax) {
    return m ? NaN : ((s ? -1 : 1) * Infinity)
  } else {
    m = m + Math.pow(2, mLen)
    e = e - eBias
  }
  return (s ? -1 : 1) * m * Math.pow(2, e - mLen)
}

exports.write = function (buffer, value, offset, isLE, mLen, nBytes) {
  var e, m, c
  var eLen = (nBytes * 8) - mLen - 1
  var eMax = (1 << eLen) - 1
  var eBias = eMax >> 1
  var rt = (mLen === 23 ? Math.pow(2, -24) - Math.pow(2, -77) : 0)
  var i = isLE ? 0 : (nBytes - 1)
  var d = isLE ? 1 : -1
  var s = value < 0 || (value === 0 && 1 / value < 0) ? 1 : 0

  value = Math.abs(value)

  if (isNaN(value) || value === Infinity) {
    m = isNaN(value) ? 1 : 0
    e = eMax
  } else {
    e = Math.floor(Math.log(value) / Math.LN2)
    if (value * (c = Math.pow(2, -e)) < 1) {
      e--
      c *= 2
    }
    if (e + eBias >= 1) {
      value += rt / c
    } else {
      value += rt * Math.pow(2, 1 - eBias)
    }
    if (value * c >= 2) {
      e++
      c /= 2
    }

    if (e + eBias >= eMax) {
      m = 0
      e = eMax
    } else if (e + eBias >= 1) {
      m = ((value * c) - 1) * Math.pow(2, mLen)
      e = e + eBias
    } else {
      m = value * Math.pow(2, eBias - 1) * Math.pow(2, mLen)
      e = 0
    }
  }

  for (; mLen >= 8; buffer[offset + i] = m & 0xff, i += d, m /= 256, mLen -= 8) {}

  e = (e << mLen) | m
  eLen += mLen
  for (; eLen > 0; buffer[offset + i] = e & 0xff, i += d, e /= 256, eLen -= 8) {}

  buffer[offset + i - d] |= s * 128
}

},{}],84:[function(require,module,exports){
if (typeof Object.create === 'function') {
  // implementation from standard node.js 'util' module
  module.exports = function inherits(ctor, superCtor) {
    if (superCtor) {
      ctor.super_ = superCtor
      ctor.prototype = Object.create(superCtor.prototype, {
        constructor: {
          value: ctor,
          enumerable: false,
          writable: true,
          configurable: true
        }
      })
    }
  };
} else {
  // old school shim for old browsers
  module.exports = function inherits(ctor, superCtor) {
    if (superCtor) {
      ctor.super_ = superCtor
      var TempCtor = function () {}
      TempCtor.prototype = superCtor.prototype
      ctor.prototype = new TempCtor()
      ctor.prototype.constructor = ctor
    }
  }
}

},{}],85:[function(require,module,exports){
(function (process){
// .dirname, .basename, and .extname methods are extracted from Node.js v8.11.1,
// backported and transplited with Babel, with backwards-compat fixes

// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

// resolves . and .. elements in a path array with directory names there
// must be no slashes, empty elements, or device names (c:\) in the array
// (so also no leading and trailing slashes - it does not distinguish
// relative and absolute paths)
function normalizeArray(parts, allowAboveRoot) {
  // if the path tries to go above the root, `up` ends up > 0
  var up = 0;
  for (var i = parts.length - 1; i >= 0; i--) {
    var last = parts[i];
    if (last === '.') {
      parts.splice(i, 1);
    } else if (last === '..') {
      parts.splice(i, 1);
      up++;
    } else if (up) {
      parts.splice(i, 1);
      up--;
    }
  }

  // if the path is allowed to go above the root, restore leading ..s
  if (allowAboveRoot) {
    for (; up--; up) {
      parts.unshift('..');
    }
  }

  return parts;
}

// path.resolve([from ...], to)
// posix version
exports.resolve = function() {
  var resolvedPath = '',
      resolvedAbsolute = false;

  for (var i = arguments.length - 1; i >= -1 && !resolvedAbsolute; i--) {
    var path = (i >= 0) ? arguments[i] : process.cwd();

    // Skip empty and invalid entries
    if (typeof path !== 'string') {
      throw new TypeError('Arguments to path.resolve must be strings');
    } else if (!path) {
      continue;
    }

    resolvedPath = path + '/' + resolvedPath;
    resolvedAbsolute = path.charAt(0) === '/';
  }

  // At this point the path should be resolved to a full absolute path, but
  // handle relative paths to be safe (might happen when process.cwd() fails)

  // Normalize the path
  resolvedPath = normalizeArray(filter(resolvedPath.split('/'), function(p) {
    return !!p;
  }), !resolvedAbsolute).join('/');

  return ((resolvedAbsolute ? '/' : '') + resolvedPath) || '.';
};

// path.normalize(path)
// posix version
exports.normalize = function(path) {
  var isAbsolute = exports.isAbsolute(path),
      trailingSlash = substr(path, -1) === '/';

  // Normalize the path
  path = normalizeArray(filter(path.split('/'), function(p) {
    return !!p;
  }), !isAbsolute).join('/');

  if (!path && !isAbsolute) {
    path = '.';
  }
  if (path && trailingSlash) {
    path += '/';
  }

  return (isAbsolute ? '/' : '') + path;
};

// posix version
exports.isAbsolute = function(path) {
  return path.charAt(0) === '/';
};

// posix version
exports.join = function() {
  var paths = Array.prototype.slice.call(arguments, 0);
  return exports.normalize(filter(paths, function(p, index) {
    if (typeof p !== 'string') {
      throw new TypeError('Arguments to path.join must be strings');
    }
    return p;
  }).join('/'));
};


// path.relative(from, to)
// posix version
exports.relative = function(from, to) {
  from = exports.resolve(from).substr(1);
  to = exports.resolve(to).substr(1);

  function trim(arr) {
    var start = 0;
    for (; start < arr.length; start++) {
      if (arr[start] !== '') break;
    }

    var end = arr.length - 1;
    for (; end >= 0; end--) {
      if (arr[end] !== '') break;
    }

    if (start > end) return [];
    return arr.slice(start, end - start + 1);
  }

  var fromParts = trim(from.split('/'));
  var toParts = trim(to.split('/'));

  var length = Math.min(fromParts.length, toParts.length);
  var samePartsLength = length;
  for (var i = 0; i < length; i++) {
    if (fromParts[i] !== toParts[i]) {
      samePartsLength = i;
      break;
    }
  }

  var outputParts = [];
  for (var i = samePartsLength; i < fromParts.length; i++) {
    outputParts.push('..');
  }

  outputParts = outputParts.concat(toParts.slice(samePartsLength));

  return outputParts.join('/');
};

exports.sep = '/';
exports.delimiter = ':';

exports.dirname = function (path) {
  if (typeof path !== 'string') path = path + '';
  if (path.length === 0) return '.';
  var code = path.charCodeAt(0);
  var hasRoot = code === 47 /*/*/;
  var end = -1;
  var matchedSlash = true;
  for (var i = path.length - 1; i >= 1; --i) {
    code = path.charCodeAt(i);
    if (code === 47 /*/*/) {
        if (!matchedSlash) {
          end = i;
          break;
        }
      } else {
      // We saw the first non-path separator
      matchedSlash = false;
    }
  }

  if (end === -1) return hasRoot ? '/' : '.';
  if (hasRoot && end === 1) {
    // return '//';
    // Backwards-compat fix:
    return '/';
  }
  return path.slice(0, end);
};

function basename(path) {
  if (typeof path !== 'string') path = path + '';

  var start = 0;
  var end = -1;
  var matchedSlash = true;
  var i;

  for (i = path.length - 1; i >= 0; --i) {
    if (path.charCodeAt(i) === 47 /*/*/) {
        // If we reached a path separator that was not part of a set of path
        // separators at the end of the string, stop now
        if (!matchedSlash) {
          start = i + 1;
          break;
        }
      } else if (end === -1) {
      // We saw the first non-path separator, mark this as the end of our
      // path component
      matchedSlash = false;
      end = i + 1;
    }
  }

  if (end === -1) return '';
  return path.slice(start, end);
}

// Uses a mixed approach for backwards-compatibility, as ext behavior changed
// in new Node.js versions, so only basename() above is backported here
exports.basename = function (path, ext) {
  var f = basename(path);
  if (ext && f.substr(-1 * ext.length) === ext) {
    f = f.substr(0, f.length - ext.length);
  }
  return f;
};

exports.extname = function (path) {
  if (typeof path !== 'string') path = path + '';
  var startDot = -1;
  var startPart = 0;
  var end = -1;
  var matchedSlash = true;
  // Track the state of characters (if any) we see before our first dot and
  // after any path separator we find
  var preDotState = 0;
  for (var i = path.length - 1; i >= 0; --i) {
    var code = path.charCodeAt(i);
    if (code === 47 /*/*/) {
        // If we reached a path separator that was not part of a set of path
        // separators at the end of the string, stop now
        if (!matchedSlash) {
          startPart = i + 1;
          break;
        }
        continue;
      }
    if (end === -1) {
      // We saw the first non-path separator, mark this as the end of our
      // extension
      matchedSlash = false;
      end = i + 1;
    }
    if (code === 46 /*.*/) {
        // If this is our first dot, mark it as the start of our extension
        if (startDot === -1)
          startDot = i;
        else if (preDotState !== 1)
          preDotState = 1;
    } else if (startDot !== -1) {
      // We saw a non-dot and non-path separator before our dot, so we should
      // have a good chance at having a non-empty extension
      preDotState = -1;
    }
  }

  if (startDot === -1 || end === -1 ||
      // We saw a non-dot character immediately before the dot
      preDotState === 0 ||
      // The (right-most) trimmed path component is exactly '..'
      preDotState === 1 && startDot === end - 1 && startDot === startPart + 1) {
    return '';
  }
  return path.slice(startDot, end);
};

function filter (xs, f) {
    if (xs.filter) return xs.filter(f);
    var res = [];
    for (var i = 0; i < xs.length; i++) {
        if (f(xs[i], i, xs)) res.push(xs[i]);
    }
    return res;
}

// String.prototype.substr - negative index don't work in IE8
var substr = 'ab'.substr(-1) === 'b'
    ? function (str, start, len) { return str.substr(start, len) }
    : function (str, start, len) {
        if (start < 0) start = str.length + start;
        return str.substr(start, len);
    }
;

}).call(this,require('_process'))
},{"_process":86}],86:[function(require,module,exports){
// shim for using process in browser
var process = module.exports = {};

// cached from whatever global is present so that test runners that stub it
// don't break things.  But we need to wrap it in a try catch in case it is
// wrapped in strict mode code which doesn't define any globals.  It's inside a
// function because try/catches deoptimize in certain engines.

var cachedSetTimeout;
var cachedClearTimeout;

function defaultSetTimout() {
    throw new Error('setTimeout has not been defined');
}
function defaultClearTimeout () {
    throw new Error('clearTimeout has not been defined');
}
(function () {
    try {
        if (typeof setTimeout === 'function') {
            cachedSetTimeout = setTimeout;
        } else {
            cachedSetTimeout = defaultSetTimout;
        }
    } catch (e) {
        cachedSetTimeout = defaultSetTimout;
    }
    try {
        if (typeof clearTimeout === 'function') {
            cachedClearTimeout = clearTimeout;
        } else {
            cachedClearTimeout = defaultClearTimeout;
        }
    } catch (e) {
        cachedClearTimeout = defaultClearTimeout;
    }
} ())
function runTimeout(fun) {
    if (cachedSetTimeout === setTimeout) {
        //normal enviroments in sane situations
        return setTimeout(fun, 0);
    }
    // if setTimeout wasn't available but was latter defined
    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {
        cachedSetTimeout = setTimeout;
        return setTimeout(fun, 0);
    }
    try {
        // when when somebody has screwed with setTimeout but no I.E. maddness
        return cachedSetTimeout(fun, 0);
    } catch(e){
        try {
            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally
            return cachedSetTimeout.call(null, fun, 0);
        } catch(e){
            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error
            return cachedSetTimeout.call(this, fun, 0);
        }
    }


}
function runClearTimeout(marker) {
    if (cachedClearTimeout === clearTimeout) {
        //normal enviroments in sane situations
        return clearTimeout(marker);
    }
    // if clearTimeout wasn't available but was latter defined
    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {
        cachedClearTimeout = clearTimeout;
        return clearTimeout(marker);
    }
    try {
        // when when somebody has screwed with setTimeout but no I.E. maddness
        return cachedClearTimeout(marker);
    } catch (e){
        try {
            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally
            return cachedClearTimeout.call(null, marker);
        } catch (e){
            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.
            // Some versions of I.E. have different rules for clearTimeout vs setTimeout
            return cachedClearTimeout.call(this, marker);
        }
    }



}
var queue = [];
var draining = false;
var currentQueue;
var queueIndex = -1;

function cleanUpNextTick() {
    if (!draining || !currentQueue) {
        return;
    }
    draining = false;
    if (currentQueue.length) {
        queue = currentQueue.concat(queue);
    } else {
        queueIndex = -1;
    }
    if (queue.length) {
        drainQueue();
    }
}

function drainQueue() {
    if (draining) {
        return;
    }
    var timeout = runTimeout(cleanUpNextTick);
    draining = true;

    var len = queue.length;
    while(len) {
        currentQueue = queue;
        queue = [];
        while (++queueIndex < len) {
            if (currentQueue) {
                currentQueue[queueIndex].run();
            }
        }
        queueIndex = -1;
        len = queue.length;
    }
    currentQueue = null;
    draining = false;
    runClearTimeout(timeout);
}

process.nextTick = function (fun) {
    var args = new Array(arguments.length - 1);
    if (arguments.length > 1) {
        for (var i = 1; i < arguments.length; i++) {
            args[i - 1] = arguments[i];
        }
    }
    queue.push(new Item(fun, args));
    if (queue.length === 1 && !draining) {
        runTimeout(drainQueue);
    }
};

// v8 likes predictible objects
function Item(fun, array) {
    this.fun = fun;
    this.array = array;
}
Item.prototype.run = function () {
    this.fun.apply(null, this.array);
};
process.title = 'browser';
process.browser = true;
process.env = {};
process.argv = [];
process.version = ''; // empty string to avoid regexp issues
process.versions = {};

function noop() {}

process.on = noop;
process.addListener = noop;
process.once = noop;
process.off = noop;
process.removeListener = noop;
process.removeAllListeners = noop;
process.emit = noop;
process.prependListener = noop;
process.prependOnceListener = noop;

process.listeners = function (name) { return [] }

process.binding = function (name) {
    throw new Error('process.binding is not supported');
};

process.cwd = function () { return '/' };
process.chdir = function (dir) {
    throw new Error('process.chdir is not supported');
};
process.umask = function() { return 0; };

},{}],87:[function(require,module,exports){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

'use strict';

// If obj.hasOwnProperty has been overridden, then calling
// obj.hasOwnProperty(prop) will break.
// See: https://github.com/joyent/node/issues/1707
function hasOwnProperty(obj, prop) {
  return Object.prototype.hasOwnProperty.call(obj, prop);
}

module.exports = function(qs, sep, eq, options) {
  sep = sep || '&';
  eq = eq || '=';
  var obj = {};

  if (typeof qs !== 'string' || qs.length === 0) {
    return obj;
  }

  var regexp = /\+/g;
  qs = qs.split(sep);

  var maxKeys = 1000;
  if (options && typeof options.maxKeys === 'number') {
    maxKeys = options.maxKeys;
  }

  var len = qs.length;
  // maxKeys <= 0 means that we should not limit keys count
  if (maxKeys > 0 && len > maxKeys) {
    len = maxKeys;
  }

  for (var i = 0; i < len; ++i) {
    var x = qs[i].replace(regexp, '%20'),
        idx = x.indexOf(eq),
        kstr, vstr, k, v;

    if (idx >= 0) {
      kstr = x.substr(0, idx);
      vstr = x.substr(idx + 1);
    } else {
      kstr = x;
      vstr = '';
    }

    k = decodeURIComponent(kstr);
    v = decodeURIComponent(vstr);

    if (!hasOwnProperty(obj, k)) {
      obj[k] = v;
    } else if (isArray(obj[k])) {
      obj[k].push(v);
    } else {
      obj[k] = [obj[k], v];
    }
  }

  return obj;
};

var isArray = Array.isArray || function (xs) {
  return Object.prototype.toString.call(xs) === '[object Array]';
};

},{}],88:[function(require,module,exports){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

'use strict';

var stringifyPrimitive = function(v) {
  switch (typeof v) {
    case 'string':
      return v;

    case 'boolean':
      return v ? 'true' : 'false';

    case 'number':
      return isFinite(v) ? v : '';

    default:
      return '';
  }
};

module.exports = function(obj, sep, eq, name) {
  sep = sep || '&';
  eq = eq || '=';
  if (obj === null) {
    obj = undefined;
  }

  if (typeof obj === 'object') {
    return map(objectKeys(obj), function(k) {
      var ks = encodeURIComponent(stringifyPrimitive(k)) + eq;
      if (isArray(obj[k])) {
        return map(obj[k], function(v) {
          return ks + encodeURIComponent(stringifyPrimitive(v));
        }).join(sep);
      } else {
        return ks + encodeURIComponent(stringifyPrimitive(obj[k]));
      }
    }).join(sep);

  }

  if (!name) return '';
  return encodeURIComponent(stringifyPrimitive(name)) + eq +
         encodeURIComponent(stringifyPrimitive(obj));
};

var isArray = Array.isArray || function (xs) {
  return Object.prototype.toString.call(xs) === '[object Array]';
};

function map (xs, f) {
  if (xs.map) return xs.map(f);
  var res = [];
  for (var i = 0; i < xs.length; i++) {
    res.push(f(xs[i], i));
  }
  return res;
}

var objectKeys = Object.keys || function (obj) {
  var res = [];
  for (var key in obj) {
    if (Object.prototype.hasOwnProperty.call(obj, key)) res.push(key);
  }
  return res;
};

},{}],89:[function(require,module,exports){
'use strict';

exports.decode = exports.parse = require('./decode');
exports.encode = exports.stringify = require('./encode');

},{"./decode":87,"./encode":88}],90:[function(require,module,exports){
/*! safe-buffer. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */
/* eslint-disable node/no-deprecated-api */
var buffer = require('buffer')
var Buffer = buffer.Buffer

// alternative to using Object.keys for old browsers
function copyProps (src, dst) {
  for (var key in src) {
    dst[key] = src[key]
  }
}
if (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {
  module.exports = buffer
} else {
  // Copy properties from require('buffer')
  copyProps(buffer, exports)
  exports.Buffer = SafeBuffer
}

function SafeBuffer (arg, encodingOrOffset, length) {
  return Buffer(arg, encodingOrOffset, length)
}

SafeBuffer.prototype = Object.create(Buffer.prototype)

// Copy static methods from Buffer
copyProps(Buffer, SafeBuffer)

SafeBuffer.from = function (arg, encodingOrOffset, length) {
  if (typeof arg === 'number') {
    throw new TypeError('Argument must not be a number')
  }
  return Buffer(arg, encodingOrOffset, length)
}

SafeBuffer.alloc = function (size, fill, encoding) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  var buf = Buffer(size)
  if (fill !== undefined) {
    if (typeof encoding === 'string') {
      buf.fill(fill, encoding)
    } else {
      buf.fill(fill)
    }
  } else {
    buf.fill(0)
  }
  return buf
}

SafeBuffer.allocUnsafe = function (size) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  return Buffer(size)
}

SafeBuffer.allocUnsafeSlow = function (size) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  return buffer.SlowBuffer(size)
}

},{"buffer":76}],91:[function(require,module,exports){
(function (global){
var ClientRequest = require('./lib/request')
var response = require('./lib/response')
var extend = require('xtend')
var statusCodes = require('builtin-status-codes')
var url = require('url')

var http = exports

http.request = function (opts, cb) {
	if (typeof opts === 'string')
		opts = url.parse(opts)
	else
		opts = extend(opts)

	// Normally, the page is loaded from http or https, so not specifying a protocol
	// will result in a (valid) protocol-relative url. However, this won't work if
	// the protocol is something else, like 'file:'
	var defaultProtocol = global.location.protocol.search(/^https?:$/) === -1 ? 'http:' : ''

	var protocol = opts.protocol || defaultProtocol
	var host = opts.hostname || opts.host
	var port = opts.port
	var path = opts.path || '/'

	// Necessary for IPv6 addresses
	if (host && host.indexOf(':') !== -1)
		host = '[' + host + ']'

	// This may be a relative url. The browser should always be able to interpret it correctly.
	opts.url = (host ? (protocol + '//' + host) : '') + (port ? ':' + port : '') + path
	opts.method = (opts.method || 'GET').toUpperCase()
	opts.headers = opts.headers || {}

	// Also valid opts.auth, opts.mode

	var req = new ClientRequest(opts)
	if (cb)
		req.on('response', cb)
	return req
}

http.get = function get (opts, cb) {
	var req = http.request(opts, cb)
	req.end()
	return req
}

http.ClientRequest = ClientRequest
http.IncomingMessage = response.IncomingMessage

http.Agent = function () {}
http.Agent.defaultMaxSockets = 4

http.globalAgent = new http.Agent()

http.STATUS_CODES = statusCodes

http.METHODS = [
	'CHECKOUT',
	'CONNECT',
	'COPY',
	'DELETE',
	'GET',
	'HEAD',
	'LOCK',
	'M-SEARCH',
	'MERGE',
	'MKACTIVITY',
	'MKCOL',
	'MOVE',
	'NOTIFY',
	'OPTIONS',
	'PATCH',
	'POST',
	'PROPFIND',
	'PROPPATCH',
	'PURGE',
	'PUT',
	'REPORT',
	'SEARCH',
	'SUBSCRIBE',
	'TRACE',
	'UNLOCK',
	'UNSUBSCRIBE'
]
}).call(this,typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{"./lib/request":93,"./lib/response":94,"builtin-status-codes":77,"url":111,"xtend":127}],92:[function(require,module,exports){
(function (global){
exports.fetch = isFunction(global.fetch) && isFunction(global.ReadableStream)

exports.writableStream = isFunction(global.WritableStream)

exports.abortController = isFunction(global.AbortController)

// The xhr request to example.com may violate some restrictive CSP configurations,
// so if we're running in a browser that supports `fetch`, avoid calling getXHR()
// and assume support for certain features below.
var xhr
function getXHR () {
	// Cache the xhr value
	if (xhr !== undefined) return xhr

	if (global.XMLHttpRequest) {
		xhr = new global.XMLHttpRequest()
		// If XDomainRequest is available (ie only, where xhr might not work
		// cross domain), use the page location. Otherwise use example.com
		// Note: this doesn't actually make an http request.
		try {
			xhr.open('GET', global.XDomainRequest ? '/' : 'https://example.com')
		} catch(e) {
			xhr = null
		}
	} else {
		// Service workers don't have XHR
		xhr = null
	}
	return xhr
}

function checkTypeSupport (type) {
	var xhr = getXHR()
	if (!xhr) return false
	try {
		xhr.responseType = type
		return xhr.responseType === type
	} catch (e) {}
	return false
}

// If fetch is supported, then arraybuffer will be supported too. Skip calling
// checkTypeSupport(), since that calls getXHR().
exports.arraybuffer = exports.fetch || checkTypeSupport('arraybuffer')

// These next two tests unavoidably show warnings in Chrome. Since fetch will always
// be used if it's available, just return false for these to avoid the warnings.
exports.msstream = !exports.fetch && checkTypeSupport('ms-stream')
exports.mozchunkedarraybuffer = !exports.fetch && checkTypeSupport('moz-chunked-arraybuffer')

// If fetch is supported, then overrideMimeType will be supported too. Skip calling
// getXHR().
exports.overrideMimeType = exports.fetch || (getXHR() ? isFunction(getXHR().overrideMimeType) : false)

function isFunction (value) {
	return typeof value === 'function'
}

xhr = null // Help gc

}).call(this,typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{}],93:[function(require,module,exports){
(function (process,global,Buffer){
var capability = require('./capability')
var inherits = require('inherits')
var response = require('./response')
var stream = require('readable-stream')

var IncomingMessage = response.IncomingMessage
var rStates = response.readyStates

function decideMode (preferBinary, useFetch) {
	if (capability.fetch && useFetch) {
		return 'fetch'
	} else if (capability.mozchunkedarraybuffer) {
		return 'moz-chunked-arraybuffer'
	} else if (capability.msstream) {
		return 'ms-stream'
	} else if (capability.arraybuffer && preferBinary) {
		return 'arraybuffer'
	} else {
		return 'text'
	}
}

var ClientRequest = module.exports = function (opts) {
	var self = this
	stream.Writable.call(self)

	self._opts = opts
	self._body = []
	self._headers = {}
	if (opts.auth)
		self.setHeader('Authorization', 'Basic ' + Buffer.from(opts.auth).toString('base64'))
	Object.keys(opts.headers).forEach(function (name) {
		self.setHeader(name, opts.headers[name])
	})

	var preferBinary
	var useFetch = true
	if (opts.mode === 'disable-fetch' || ('requestTimeout' in opts && !capability.abortController)) {
		// If the use of XHR should be preferred. Not typically needed.
		useFetch = false
		preferBinary = true
	} else if (opts.mode === 'prefer-streaming') {
		// If streaming is a high priority but binary compatibility and
		// the accuracy of the 'content-type' header aren't
		preferBinary = false
	} else if (opts.mode === 'allow-wrong-content-type') {
		// If streaming is more important than preserving the 'content-type' header
		preferBinary = !capability.overrideMimeType
	} else if (!opts.mode || opts.mode === 'default' || opts.mode === 'prefer-fast') {
		// Use binary if text streaming may corrupt data or the content-type header, or for speed
		preferBinary = true
	} else {
		throw new Error('Invalid value for opts.mode')
	}
	self._mode = decideMode(preferBinary, useFetch)
	self._fetchTimer = null

	self.on('finish', function () {
		self._onFinish()
	})
}

inherits(ClientRequest, stream.Writable)

ClientRequest.prototype.setHeader = function (name, value) {
	var self = this
	var lowerName = name.toLowerCase()
	// This check is not necessary, but it prevents warnings from browsers about setting unsafe
	// headers. To be honest I'm not entirely sure hiding these warnings is a good thing, but
	// http-browserify did it, so I will too.
	if (unsafeHeaders.indexOf(lowerName) !== -1)
		return

	self._headers[lowerName] = {
		name: name,
		value: value
	}
}

ClientRequest.prototype.getHeader = function (name) {
	var header = this._headers[name.toLowerCase()]
	if (header)
		return header.value
	return null
}

ClientRequest.prototype.removeHeader = function (name) {
	var self = this
	delete self._headers[name.toLowerCase()]
}

ClientRequest.prototype._onFinish = function () {
	var self = this

	if (self._destroyed)
		return
	var opts = self._opts

	var headersObj = self._headers
	var body = null
	if (opts.method !== 'GET' && opts.method !== 'HEAD') {
        body = new Blob(self._body, {
            type: (headersObj['content-type'] || {}).value || ''
        });
    }

	// create flattened list of headers
	var headersList = []
	Object.keys(headersObj).forEach(function (keyName) {
		var name = headersObj[keyName].name
		var value = headersObj[keyName].value
		if (Array.isArray(value)) {
			value.forEach(function (v) {
				headersList.push([name, v])
			})
		} else {
			headersList.push([name, value])
		}
	})

	if (self._mode === 'fetch') {
		var signal = null
		if (capability.abortController) {
			var controller = new AbortController()
			signal = controller.signal
			self._fetchAbortController = controller

			if ('requestTimeout' in opts && opts.requestTimeout !== 0) {
				self._fetchTimer = global.setTimeout(function () {
					self.emit('requestTimeout')
					if (self._fetchAbortController)
						self._fetchAbortController.abort()
				}, opts.requestTimeout)
			}
		}

		global.fetch(self._opts.url, {
			method: self._opts.method,
			headers: headersList,
			body: body || undefined,
			mode: 'cors',
			credentials: opts.withCredentials ? 'include' : 'same-origin',
			signal: signal
		}).then(function (response) {
			self._fetchResponse = response
			self._connect()
		}, function (reason) {
			global.clearTimeout(self._fetchTimer)
			if (!self._destroyed)
				self.emit('error', reason)
		})
	} else {
		var xhr = self._xhr = new global.XMLHttpRequest()
		try {
			xhr.open(self._opts.method, self._opts.url, true)
		} catch (err) {
			process.nextTick(function () {
				self.emit('error', err)
			})
			return
		}

		// Can't set responseType on really old browsers
		if ('responseType' in xhr)
			xhr.responseType = self._mode

		if ('withCredentials' in xhr)
			xhr.withCredentials = !!opts.withCredentials

		if (self._mode === 'text' && 'overrideMimeType' in xhr)
			xhr.overrideMimeType('text/plain; charset=x-user-defined')

		if ('requestTimeout' in opts) {
			xhr.timeout = opts.requestTimeout
			xhr.ontimeout = function () {
				self.emit('requestTimeout')
			}
		}

		headersList.forEach(function (header) {
			xhr.setRequestHeader(header[0], header[1])
		})

		self._response = null
		xhr.onreadystatechange = function () {
			switch (xhr.readyState) {
				case rStates.LOADING:
				case rStates.DONE:
					self._onXHRProgress()
					break
			}
		}
		// Necessary for streaming in Firefox, since xhr.response is ONLY defined
		// in onprogress, not in onreadystatechange with xhr.readyState = 3
		if (self._mode === 'moz-chunked-arraybuffer') {
			xhr.onprogress = function () {
				self._onXHRProgress()
			}
		}

		xhr.onerror = function () {
			if (self._destroyed)
				return
			self.emit('error', new Error('XHR error'))
		}

		try {
			xhr.send(body)
		} catch (err) {
			process.nextTick(function () {
				self.emit('error', err)
			})
			return
		}
	}
}

/**
 * Checks if xhr.status is readable and non-zero, indicating no error.
 * Even though the spec says it should be available in readyState 3,
 * accessing it throws an exception in IE8
 */
function statusValid (xhr) {
	try {
		var status = xhr.status
		return (status !== null && status !== 0)
	} catch (e) {
		return false
	}
}

ClientRequest.prototype._onXHRProgress = function () {
	var self = this

	if (!statusValid(self._xhr) || self._destroyed)
		return

	if (!self._response)
		self._connect()

	self._response._onXHRProgress()
}

ClientRequest.prototype._connect = function () {
	var self = this

	if (self._destroyed)
		return

	self._response = new IncomingMessage(self._xhr, self._fetchResponse, self._mode, self._fetchTimer)
	self._response.on('error', function(err) {
		self.emit('error', err)
	})

	self.emit('response', self._response)
}

ClientRequest.prototype._write = function (chunk, encoding, cb) {
	var self = this

	self._body.push(chunk)
	cb()
}

ClientRequest.prototype.abort = ClientRequest.prototype.destroy = function () {
	var self = this
	self._destroyed = true
	global.clearTimeout(self._fetchTimer)
	if (self._response)
		self._response._destroyed = true
	if (self._xhr)
		self._xhr.abort()
	else if (self._fetchAbortController)
		self._fetchAbortController.abort()
}

ClientRequest.prototype.end = function (data, encoding, cb) {
	var self = this
	if (typeof data === 'function') {
		cb = data
		data = undefined
	}

	stream.Writable.prototype.end.call(self, data, encoding, cb)
}

ClientRequest.prototype.flushHeaders = function () {}
ClientRequest.prototype.setTimeout = function () {}
ClientRequest.prototype.setNoDelay = function () {}
ClientRequest.prototype.setSocketKeepAlive = function () {}

// Taken from http://www.w3.org/TR/XMLHttpRequest/#the-setrequestheader%28%29-method
var unsafeHeaders = [
	'accept-charset',
	'accept-encoding',
	'access-control-request-headers',
	'access-control-request-method',
	'connection',
	'content-length',
	'cookie',
	'cookie2',
	'date',
	'dnt',
	'expect',
	'host',
	'keep-alive',
	'origin',
	'referer',
	'te',
	'trailer',
	'transfer-encoding',
	'upgrade',
	'via'
]

}).call(this,require('_process'),typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {},require("buffer").Buffer)
},{"./capability":92,"./response":94,"_process":86,"buffer":76,"inherits":84,"readable-stream":109}],94:[function(require,module,exports){
(function (process,global,Buffer){
var capability = require('./capability')
var inherits = require('inherits')
var stream = require('readable-stream')

var rStates = exports.readyStates = {
	UNSENT: 0,
	OPENED: 1,
	HEADERS_RECEIVED: 2,
	LOADING: 3,
	DONE: 4
}

var IncomingMessage = exports.IncomingMessage = function (xhr, response, mode, fetchTimer) {
	var self = this
	stream.Readable.call(self)

	self._mode = mode
	self.headers = {}
	self.rawHeaders = []
	self.trailers = {}
	self.rawTrailers = []

	// Fake the 'close' event, but only once 'end' fires
	self.on('end', function () {
		// The nextTick is necessary to prevent the 'request' module from causing an infinite loop
		process.nextTick(function () {
			self.emit('close')
		})
	})

	if (mode === 'fetch') {
		self._fetchResponse = response

		self.url = response.url
		self.statusCode = response.status
		self.statusMessage = response.statusText
		
		response.headers.forEach(function (header, key){
			self.headers[key.toLowerCase()] = header
			self.rawHeaders.push(key, header)
		})

		if (capability.writableStream) {
			var writable = new WritableStream({
				write: function (chunk) {
					return new Promise(function (resolve, reject) {
						if (self._destroyed) {
							reject()
						} else if(self.push(Buffer.from(chunk))) {
							resolve()
						} else {
							self._resumeFetch = resolve
						}
					})
				},
				close: function () {
					global.clearTimeout(fetchTimer)
					if (!self._destroyed)
						self.push(null)
				},
				abort: function (err) {
					if (!self._destroyed)
						self.emit('error', err)
				}
			})

			try {
				response.body.pipeTo(writable).catch(function (err) {
					global.clearTimeout(fetchTimer)
					if (!self._destroyed)
						self.emit('error', err)
				})
				return
			} catch (e) {} // pipeTo method isn't defined. Can't find a better way to feature test this
		}
		// fallback for when writableStream or pipeTo aren't available
		var reader = response.body.getReader()
		function read () {
			reader.read().then(function (result) {
				if (self._destroyed)
					return
				if (result.done) {
					global.clearTimeout(fetchTimer)
					self.push(null)
					return
				}
				self.push(Buffer.from(result.value))
				read()
			}).catch(function (err) {
				global.clearTimeout(fetchTimer)
				if (!self._destroyed)
					self.emit('error', err)
			})
		}
		read()
	} else {
		self._xhr = xhr
		self._pos = 0

		self.url = xhr.responseURL
		self.statusCode = xhr.status
		self.statusMessage = xhr.statusText
		var headers = xhr.getAllResponseHeaders().split(/\r?\n/)
		headers.forEach(function (header) {
			var matches = header.match(/^([^:]+):\s*(.*)/)
			if (matches) {
				var key = matches[1].toLowerCase()
				if (key === 'set-cookie') {
					if (self.headers[key] === undefined) {
						self.headers[key] = []
					}
					self.headers[key].push(matches[2])
				} else if (self.headers[key] !== undefined) {
					self.headers[key] += ', ' + matches[2]
				} else {
					self.headers[key] = matches[2]
				}
				self.rawHeaders.push(matches[1], matches[2])
			}
		})

		self._charset = 'x-user-defined'
		if (!capability.overrideMimeType) {
			var mimeType = self.rawHeaders['mime-type']
			if (mimeType) {
				var charsetMatch = mimeType.match(/;\s*charset=([^;])(;|$)/)
				if (charsetMatch) {
					self._charset = charsetMatch[1].toLowerCase()
				}
			}
			if (!self._charset)
				self._charset = 'utf-8' // best guess
		}
	}
}

inherits(IncomingMessage, stream.Readable)

IncomingMessage.prototype._read = function () {
	var self = this

	var resolve = self._resumeFetch
	if (resolve) {
		self._resumeFetch = null
		resolve()
	}
}

IncomingMessage.prototype._onXHRProgress = function () {
	var self = this

	var xhr = self._xhr

	var response = null
	switch (self._mode) {
		case 'text':
			response = xhr.responseText
			if (response.length > self._pos) {
				var newData = response.substr(self._pos)
				if (self._charset === 'x-user-defined') {
					var buffer = Buffer.alloc(newData.length)
					for (var i = 0; i < newData.length; i++)
						buffer[i] = newData.charCodeAt(i) & 0xff

					self.push(buffer)
				} else {
					self.push(newData, self._charset)
				}
				self._pos = response.length
			}
			break
		case 'arraybuffer':
			if (xhr.readyState !== rStates.DONE || !xhr.response)
				break
			response = xhr.response
			self.push(Buffer.from(new Uint8Array(response)))
			break
		case 'moz-chunked-arraybuffer': // take whole
			response = xhr.response
			if (xhr.readyState !== rStates.LOADING || !response)
				break
			self.push(Buffer.from(new Uint8Array(response)))
			break
		case 'ms-stream':
			response = xhr.response
			if (xhr.readyState !== rStates.LOADING)
				break
			var reader = new global.MSStreamReader()
			reader.onprogress = function () {
				if (reader.result.byteLength > self._pos) {
					self.push(Buffer.from(new Uint8Array(reader.result.slice(self._pos))))
					self._pos = reader.result.byteLength
				}
			}
			reader.onload = function () {
				self.push(null)
			}
			// reader.onerror = ??? // TODO: this
			reader.readAsArrayBuffer(response)
			break
	}

	// The ms-stream case handles end separately in reader.onload()
	if (self._xhr.readyState === rStates.DONE && self._mode !== 'ms-stream') {
		self.push(null)
	}
}

}).call(this,require('_process'),typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {},require("buffer").Buffer)
},{"./capability":92,"_process":86,"buffer":76,"inherits":84,"readable-stream":109}],95:[function(require,module,exports){
'use strict';

function _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }

var codes = {};

function createErrorType(code, message, Base) {
  if (!Base) {
    Base = Error;
  }

  function getMessage(arg1, arg2, arg3) {
    if (typeof message === 'string') {
      return message;
    } else {
      return message(arg1, arg2, arg3);
    }
  }

  var NodeError =
  /*#__PURE__*/
  function (_Base) {
    _inheritsLoose(NodeError, _Base);

    function NodeError(arg1, arg2, arg3) {
      return _Base.call(this, getMessage(arg1, arg2, arg3)) || this;
    }

    return NodeError;
  }(Base);

  NodeError.prototype.name = Base.name;
  NodeError.prototype.code = code;
  codes[code] = NodeError;
} // https://github.com/nodejs/node/blob/v10.8.0/lib/internal/errors.js


function oneOf(expected, thing) {
  if (Array.isArray(expected)) {
    var len = expected.length;
    expected = expected.map(function (i) {
      return String(i);
    });

    if (len > 2) {
      return "one of ".concat(thing, " ").concat(expected.slice(0, len - 1).join(', '), ", or ") + expected[len - 1];
    } else if (len === 2) {
      return "one of ".concat(thing, " ").concat(expected[0], " or ").concat(expected[1]);
    } else {
      return "of ".concat(thing, " ").concat(expected[0]);
    }
  } else {
    return "of ".concat(thing, " ").concat(String(expected));
  }
} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/startsWith


function startsWith(str, search, pos) {
  return str.substr(!pos || pos < 0 ? 0 : +pos, search.length) === search;
} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/endsWith


function endsWith(str, search, this_len) {
  if (this_len === undefined || this_len > str.length) {
    this_len = str.length;
  }

  return str.substring(this_len - search.length, this_len) === search;
} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/includes


function includes(str, search, start) {
  if (typeof start !== 'number') {
    start = 0;
  }

  if (start + search.length > str.length) {
    return false;
  } else {
    return str.indexOf(search, start) !== -1;
  }
}

createErrorType('ERR_INVALID_OPT_VALUE', function (name, value) {
  return 'The value "' + value + '" is invalid for option "' + name + '"';
}, TypeError);
createErrorType('ERR_INVALID_ARG_TYPE', function (name, expected, actual) {
  // determiner: 'must be' or 'must not be'
  var determiner;

  if (typeof expected === 'string' && startsWith(expected, 'not ')) {
    determiner = 'must not be';
    expected = expected.replace(/^not /, '');
  } else {
    determiner = 'must be';
  }

  var msg;

  if (endsWith(name, ' argument')) {
    // For cases like 'first argument'
    msg = "The ".concat(name, " ").concat(determiner, " ").concat(oneOf(expected, 'type'));
  } else {
    var type = includes(name, '.') ? 'property' : 'argument';
    msg = "The \"".concat(name, "\" ").concat(type, " ").concat(determiner, " ").concat(oneOf(expected, 'type'));
  }

  msg += ". Received type ".concat(typeof actual);
  return msg;
}, TypeError);
createErrorType('ERR_STREAM_PUSH_AFTER_EOF', 'stream.push() after EOF');
createErrorType('ERR_METHOD_NOT_IMPLEMENTED', function (name) {
  return 'The ' + name + ' method is not implemented';
});
createErrorType('ERR_STREAM_PREMATURE_CLOSE', 'Premature close');
createErrorType('ERR_STREAM_DESTROYED', function (name) {
  return 'Cannot call ' + name + ' after a stream was destroyed';
});
createErrorType('ERR_MULTIPLE_CALLBACK', 'Callback called multiple times');
createErrorType('ERR_STREAM_CANNOT_PIPE', 'Cannot pipe, not readable');
createErrorType('ERR_STREAM_WRITE_AFTER_END', 'write after end');
createErrorType('ERR_STREAM_NULL_VALUES', 'May not write null values to stream', TypeError);
createErrorType('ERR_UNKNOWN_ENCODING', function (arg) {
  return 'Unknown encoding: ' + arg;
}, TypeError);
createErrorType('ERR_STREAM_UNSHIFT_AFTER_END_EVENT', 'stream.unshift() after end event');
module.exports.codes = codes;

},{}],96:[function(require,module,exports){
(function (process){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
// a duplex stream is just a stream that is both readable and writable.
// Since JS doesn't have multiple prototypal inheritance, this class
// prototypally inherits from Readable, and then parasitically from
// Writable.
'use strict';
/*<replacement>*/

var objectKeys = Object.keys || function (obj) {
  var keys = [];

  for (var key in obj) {
    keys.push(key);
  }

  return keys;
};
/*</replacement>*/


module.exports = Duplex;

var Readable = require('./_stream_readable');

var Writable = require('./_stream_writable');

require('inherits')(Duplex, Readable);

{
  // Allow the keys array to be GC'ed.
  var keys = objectKeys(Writable.prototype);

  for (var v = 0; v < keys.length; v++) {
    var method = keys[v];
    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];
  }
}

function Duplex(options) {
  if (!(this instanceof Duplex)) return new Duplex(options);
  Readable.call(this, options);
  Writable.call(this, options);
  this.allowHalfOpen = true;

  if (options) {
    if (options.readable === false) this.readable = false;
    if (options.writable === false) this.writable = false;

    if (options.allowHalfOpen === false) {
      this.allowHalfOpen = false;
      this.once('end', onend);
    }
  }
}

Object.defineProperty(Duplex.prototype, 'writableHighWaterMark', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._writableState.highWaterMark;
  }
});
Object.defineProperty(Duplex.prototype, 'writableBuffer', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._writableState && this._writableState.getBuffer();
  }
});
Object.defineProperty(Duplex.prototype, 'writableLength', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._writableState.length;
  }
}); // the no-half-open enforcer

function onend() {
  // If the writable side ended, then we're ok.
  if (this._writableState.ended) return; // no more data can be written.
  // But allow more writes to happen in this tick.

  process.nextTick(onEndNT, this);
}

function onEndNT(self) {
  self.end();
}

Object.defineProperty(Duplex.prototype, 'destroyed', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    if (this._readableState === undefined || this._writableState === undefined) {
      return false;
    }

    return this._readableState.destroyed && this._writableState.destroyed;
  },
  set: function set(value) {
    // we ignore the value if the stream
    // has not been initialized yet
    if (this._readableState === undefined || this._writableState === undefined) {
      return;
    } // backward compatibility, the user is explicitly
    // managing destroyed


    this._readableState.destroyed = value;
    this._writableState.destroyed = value;
  }
});
}).call(this,require('_process'))
},{"./_stream_readable":98,"./_stream_writable":100,"_process":86,"inherits":84}],97:[function(require,module,exports){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
// a passthrough stream.
// basically just the most minimal sort of Transform stream.
// Every written chunk gets output as-is.
'use strict';

module.exports = PassThrough;

var Transform = require('./_stream_transform');

require('inherits')(PassThrough, Transform);

function PassThrough(options) {
  if (!(this instanceof PassThrough)) return new PassThrough(options);
  Transform.call(this, options);
}

PassThrough.prototype._transform = function (chunk, encoding, cb) {
  cb(null, chunk);
};
},{"./_stream_transform":99,"inherits":84}],98:[function(require,module,exports){
(function (process,global){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
'use strict';

module.exports = Readable;
/*<replacement>*/

var Duplex;
/*</replacement>*/

Readable.ReadableState = ReadableState;
/*<replacement>*/

var EE = require('events').EventEmitter;

var EElistenerCount = function EElistenerCount(emitter, type) {
  return emitter.listeners(type).length;
};
/*</replacement>*/

/*<replacement>*/


var Stream = require('./internal/streams/stream');
/*</replacement>*/


var Buffer = require('buffer').Buffer;

var OurUint8Array = global.Uint8Array || function () {};

function _uint8ArrayToBuffer(chunk) {
  return Buffer.from(chunk);
}

function _isUint8Array(obj) {
  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;
}
/*<replacement>*/


var debugUtil = require('util');

var debug;

if (debugUtil && debugUtil.debuglog) {
  debug = debugUtil.debuglog('stream');
} else {
  debug = function debug() {};
}
/*</replacement>*/


var BufferList = require('./internal/streams/buffer_list');

var destroyImpl = require('./internal/streams/destroy');

var _require = require('./internal/streams/state'),
    getHighWaterMark = _require.getHighWaterMark;

var _require$codes = require('../errors').codes,
    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,
    ERR_STREAM_PUSH_AFTER_EOF = _require$codes.ERR_STREAM_PUSH_AFTER_EOF,
    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,
    ERR_STREAM_UNSHIFT_AFTER_END_EVENT = _require$codes.ERR_STREAM_UNSHIFT_AFTER_END_EVENT; // Lazy loaded to improve the startup performance.


var StringDecoder;
var createReadableStreamAsyncIterator;
var from;

require('inherits')(Readable, Stream);

var errorOrDestroy = destroyImpl.errorOrDestroy;
var kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];

function prependListener(emitter, event, fn) {
  // Sadly this is not cacheable as some libraries bundle their own
  // event emitter implementation with them.
  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn); // This is a hack to make sure that our error handler is attached before any
  // userland ones.  NEVER DO THIS. This is here only because this code needs
  // to continue to work with older versions of Node.js that do not include
  // the prependListener() method. The goal is to eventually remove this hack.

  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (Array.isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];
}

function ReadableState(options, stream, isDuplex) {
  Duplex = Duplex || require('./_stream_duplex');
  options = options || {}; // Duplex streams are both readable and writable, but share
  // the same options object.
  // However, some cases require setting options to different
  // values for the readable and the writable sides of the duplex stream.
  // These options can be provided separately as readableXXX and writableXXX.

  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag. Used to make read(n) ignore n and to
  // make all the buffer merging and length checks go away

  this.objectMode = !!options.objectMode;
  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode; // the point at which it stops calling _read() to fill the buffer
  // Note: 0 is a valid value, means "don't call _read preemptively ever"

  this.highWaterMark = getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex); // A linked list is used to store data chunks instead of an array because the
  // linked list can remove elements from the beginning faster than
  // array.shift()

  this.buffer = new BufferList();
  this.length = 0;
  this.pipes = null;
  this.pipesCount = 0;
  this.flowing = null;
  this.ended = false;
  this.endEmitted = false;
  this.reading = false; // a flag to be able to tell if the event 'readable'/'data' is emitted
  // immediately, or on a later tick.  We set this to true at first, because
  // any actions that shouldn't happen until "later" should generally also
  // not happen before the first read call.

  this.sync = true; // whenever we return null, then we set a flag to say
  // that we're awaiting a 'readable' event emission.

  this.needReadable = false;
  this.emittedReadable = false;
  this.readableListening = false;
  this.resumeScheduled = false;
  this.paused = true; // Should close be emitted on destroy. Defaults to true.

  this.emitClose = options.emitClose !== false; // Should .destroy() be called after 'end' (and potentially 'finish')

  this.autoDestroy = !!options.autoDestroy; // has it been destroyed

  this.destroyed = false; // Crypto is kind of old and crusty.  Historically, its default string
  // encoding is 'binary' so we have to make this configurable.
  // Everything else in the universe uses 'utf8', though.

  this.defaultEncoding = options.defaultEncoding || 'utf8'; // the number of writers that are awaiting a drain event in .pipe()s

  this.awaitDrain = 0; // if true, a maybeReadMore has been scheduled

  this.readingMore = false;
  this.decoder = null;
  this.encoding = null;

  if (options.encoding) {
    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;
    this.decoder = new StringDecoder(options.encoding);
    this.encoding = options.encoding;
  }
}

function Readable(options) {
  Duplex = Duplex || require('./_stream_duplex');
  if (!(this instanceof Readable)) return new Readable(options); // Checking for a Stream.Duplex instance is faster here instead of inside
  // the ReadableState constructor, at least with V8 6.5

  var isDuplex = this instanceof Duplex;
  this._readableState = new ReadableState(options, this, isDuplex); // legacy

  this.readable = true;

  if (options) {
    if (typeof options.read === 'function') this._read = options.read;
    if (typeof options.destroy === 'function') this._destroy = options.destroy;
  }

  Stream.call(this);
}

Object.defineProperty(Readable.prototype, 'destroyed', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    if (this._readableState === undefined) {
      return false;
    }

    return this._readableState.destroyed;
  },
  set: function set(value) {
    // we ignore the value if the stream
    // has not been initialized yet
    if (!this._readableState) {
      return;
    } // backward compatibility, the user is explicitly
    // managing destroyed


    this._readableState.destroyed = value;
  }
});
Readable.prototype.destroy = destroyImpl.destroy;
Readable.prototype._undestroy = destroyImpl.undestroy;

Readable.prototype._destroy = function (err, cb) {
  cb(err);
}; // Manually shove something into the read() buffer.
// This returns true if the highWaterMark has not been hit yet,
// similar to how Writable.write() returns true if you should
// write() some more.


Readable.prototype.push = function (chunk, encoding) {
  var state = this._readableState;
  var skipChunkCheck;

  if (!state.objectMode) {
    if (typeof chunk === 'string') {
      encoding = encoding || state.defaultEncoding;

      if (encoding !== state.encoding) {
        chunk = Buffer.from(chunk, encoding);
        encoding = '';
      }

      skipChunkCheck = true;
    }
  } else {
    skipChunkCheck = true;
  }

  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);
}; // Unshift should *always* be something directly out of read()


Readable.prototype.unshift = function (chunk) {
  return readableAddChunk(this, chunk, null, true, false);
};

function readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {
  debug('readableAddChunk', chunk);
  var state = stream._readableState;

  if (chunk === null) {
    state.reading = false;
    onEofChunk(stream, state);
  } else {
    var er;
    if (!skipChunkCheck) er = chunkInvalid(state, chunk);

    if (er) {
      errorOrDestroy(stream, er);
    } else if (state.objectMode || chunk && chunk.length > 0) {
      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {
        chunk = _uint8ArrayToBuffer(chunk);
      }

      if (addToFront) {
        if (state.endEmitted) errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT());else addChunk(stream, state, chunk, true);
      } else if (state.ended) {
        errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF());
      } else if (state.destroyed) {
        return false;
      } else {
        state.reading = false;

        if (state.decoder && !encoding) {
          chunk = state.decoder.write(chunk);
          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);
        } else {
          addChunk(stream, state, chunk, false);
        }
      }
    } else if (!addToFront) {
      state.reading = false;
      maybeReadMore(stream, state);
    }
  } // We can push more data if we are below the highWaterMark.
  // Also, if we have no data yet, we can stand some more bytes.
  // This is to work around cases where hwm=0, such as the repl.


  return !state.ended && (state.length < state.highWaterMark || state.length === 0);
}

function addChunk(stream, state, chunk, addToFront) {
  if (state.flowing && state.length === 0 && !state.sync) {
    state.awaitDrain = 0;
    stream.emit('data', chunk);
  } else {
    // update the buffer info.
    state.length += state.objectMode ? 1 : chunk.length;
    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);
    if (state.needReadable) emitReadable(stream);
  }

  maybeReadMore(stream, state);
}

function chunkInvalid(state, chunk) {
  var er;

  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {
    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk);
  }

  return er;
}

Readable.prototype.isPaused = function () {
  return this._readableState.flowing === false;
}; // backwards compatibility.


Readable.prototype.setEncoding = function (enc) {
  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;
  var decoder = new StringDecoder(enc);
  this._readableState.decoder = decoder; // If setEncoding(null), decoder.encoding equals utf8

  this._readableState.encoding = this._readableState.decoder.encoding; // Iterate over current buffer to convert already stored Buffers:

  var p = this._readableState.buffer.head;
  var content = '';

  while (p !== null) {
    content += decoder.write(p.data);
    p = p.next;
  }

  this._readableState.buffer.clear();

  if (content !== '') this._readableState.buffer.push(content);
  this._readableState.length = content.length;
  return this;
}; // Don't raise the hwm > 1GB


var MAX_HWM = 0x40000000;

function computeNewHighWaterMark(n) {
  if (n >= MAX_HWM) {
    // TODO(ronag): Throw ERR_VALUE_OUT_OF_RANGE.
    n = MAX_HWM;
  } else {
    // Get the next highest power of 2 to prevent increasing hwm excessively in
    // tiny amounts
    n--;
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    n++;
  }

  return n;
} // This function is designed to be inlinable, so please take care when making
// changes to the function body.


function howMuchToRead(n, state) {
  if (n <= 0 || state.length === 0 && state.ended) return 0;
  if (state.objectMode) return 1;

  if (n !== n) {
    // Only flow one buffer at a time
    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;
  } // If we're asking for more than the current hwm, then raise the hwm.


  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);
  if (n <= state.length) return n; // Don't have enough

  if (!state.ended) {
    state.needReadable = true;
    return 0;
  }

  return state.length;
} // you can override either this method, or the async _read(n) below.


Readable.prototype.read = function (n) {
  debug('read', n);
  n = parseInt(n, 10);
  var state = this._readableState;
  var nOrig = n;
  if (n !== 0) state.emittedReadable = false; // if we're doing read(0) to trigger a readable event, but we
  // already have a bunch of data in the buffer, then just trigger
  // the 'readable' event and move on.

  if (n === 0 && state.needReadable && ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)) {
    debug('read: emitReadable', state.length, state.ended);
    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);
    return null;
  }

  n = howMuchToRead(n, state); // if we've ended, and we're now clear, then finish it up.

  if (n === 0 && state.ended) {
    if (state.length === 0) endReadable(this);
    return null;
  } // All the actual chunk generation logic needs to be
  // *below* the call to _read.  The reason is that in certain
  // synthetic stream cases, such as passthrough streams, _read
  // may be a completely synchronous operation which may change
  // the state of the read buffer, providing enough data when
  // before there was *not* enough.
  //
  // So, the steps are:
  // 1. Figure out what the state of things will be after we do
  // a read from the buffer.
  //
  // 2. If that resulting state will trigger a _read, then call _read.
  // Note that this may be asynchronous, or synchronous.  Yes, it is
  // deeply ugly to write APIs this way, but that still doesn't mean
  // that the Readable class should behave improperly, as streams are
  // designed to be sync/async agnostic.
  // Take note if the _read call is sync or async (ie, if the read call
  // has returned yet), so that we know whether or not it's safe to emit
  // 'readable' etc.
  //
  // 3. Actually pull the requested chunks out of the buffer and return.
  // if we need a readable event, then we need to do some reading.


  var doRead = state.needReadable;
  debug('need readable', doRead); // if we currently have less than the highWaterMark, then also read some

  if (state.length === 0 || state.length - n < state.highWaterMark) {
    doRead = true;
    debug('length less than watermark', doRead);
  } // however, if we've ended, then there's no point, and if we're already
  // reading, then it's unnecessary.


  if (state.ended || state.reading) {
    doRead = false;
    debug('reading or ended', doRead);
  } else if (doRead) {
    debug('do read');
    state.reading = true;
    state.sync = true; // if the length is currently zero, then we *need* a readable event.

    if (state.length === 0) state.needReadable = true; // call internal read method

    this._read(state.highWaterMark);

    state.sync = false; // If _read pushed data synchronously, then `reading` will be false,
    // and we need to re-evaluate how much data we can return to the user.

    if (!state.reading) n = howMuchToRead(nOrig, state);
  }

  var ret;
  if (n > 0) ret = fromList(n, state);else ret = null;

  if (ret === null) {
    state.needReadable = state.length <= state.highWaterMark;
    n = 0;
  } else {
    state.length -= n;
    state.awaitDrain = 0;
  }

  if (state.length === 0) {
    // If we have nothing in the buffer, then we want to know
    // as soon as we *do* get something into the buffer.
    if (!state.ended) state.needReadable = true; // If we tried to read() past the EOF, then emit end on the next tick.

    if (nOrig !== n && state.ended) endReadable(this);
  }

  if (ret !== null) this.emit('data', ret);
  return ret;
};

function onEofChunk(stream, state) {
  debug('onEofChunk');
  if (state.ended) return;

  if (state.decoder) {
    var chunk = state.decoder.end();

    if (chunk && chunk.length) {
      state.buffer.push(chunk);
      state.length += state.objectMode ? 1 : chunk.length;
    }
  }

  state.ended = true;

  if (state.sync) {
    // if we are sync, wait until next tick to emit the data.
    // Otherwise we risk emitting data in the flow()
    // the readable code triggers during a read() call
    emitReadable(stream);
  } else {
    // emit 'readable' now to make sure it gets picked up.
    state.needReadable = false;

    if (!state.emittedReadable) {
      state.emittedReadable = true;
      emitReadable_(stream);
    }
  }
} // Don't emit readable right away in sync mode, because this can trigger
// another read() call => stack overflow.  This way, it might trigger
// a nextTick recursion warning, but that's not so bad.


function emitReadable(stream) {
  var state = stream._readableState;
  debug('emitReadable', state.needReadable, state.emittedReadable);
  state.needReadable = false;

  if (!state.emittedReadable) {
    debug('emitReadable', state.flowing);
    state.emittedReadable = true;
    process.nextTick(emitReadable_, stream);
  }
}

function emitReadable_(stream) {
  var state = stream._readableState;
  debug('emitReadable_', state.destroyed, state.length, state.ended);

  if (!state.destroyed && (state.length || state.ended)) {
    stream.emit('readable');
    state.emittedReadable = false;
  } // The stream needs another readable event if
  // 1. It is not flowing, as the flow mechanism will take
  //    care of it.
  // 2. It is not ended.
  // 3. It is below the highWaterMark, so we can schedule
  //    another readable later.


  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;
  flow(stream);
} // at this point, the user has presumably seen the 'readable' event,
// and called read() to consume some data.  that may have triggered
// in turn another _read(n) call, in which case reading = true if
// it's in progress.
// However, if we're not ended, or reading, and the length < hwm,
// then go ahead and try to read some more preemptively.


function maybeReadMore(stream, state) {
  if (!state.readingMore) {
    state.readingMore = true;
    process.nextTick(maybeReadMore_, stream, state);
  }
}

function maybeReadMore_(stream, state) {
  // Attempt to read more data if we should.
  //
  // The conditions for reading more data are (one of):
  // - Not enough data buffered (state.length < state.highWaterMark). The loop
  //   is responsible for filling the buffer with enough data if such data
  //   is available. If highWaterMark is 0 and we are not in the flowing mode
  //   we should _not_ attempt to buffer any extra data. We'll get more data
  //   when the stream consumer calls read() instead.
  // - No data in the buffer, and the stream is in flowing mode. In this mode
  //   the loop below is responsible for ensuring read() is called. Failing to
  //   call read here would abort the flow and there's no other mechanism for
  //   continuing the flow if the stream consumer has just subscribed to the
  //   'data' event.
  //
  // In addition to the above conditions to keep reading data, the following
  // conditions prevent the data from being read:
  // - The stream has ended (state.ended).
  // - There is already a pending 'read' operation (state.reading). This is a
  //   case where the the stream has called the implementation defined _read()
  //   method, but they are processing the call asynchronously and have _not_
  //   called push() with new data. In this case we skip performing more
  //   read()s. The execution ends in this method again after the _read() ends
  //   up calling push() with more data.
  while (!state.reading && !state.ended && (state.length < state.highWaterMark || state.flowing && state.length === 0)) {
    var len = state.length;
    debug('maybeReadMore read 0');
    stream.read(0);
    if (len === state.length) // didn't get any data, stop spinning.
      break;
  }

  state.readingMore = false;
} // abstract method.  to be overridden in specific implementation classes.
// call cb(er, data) where data is <= n in length.
// for virtual (non-string, non-buffer) streams, "length" is somewhat
// arbitrary, and perhaps not very meaningful.


Readable.prototype._read = function (n) {
  errorOrDestroy(this, new ERR_METHOD_NOT_IMPLEMENTED('_read()'));
};

Readable.prototype.pipe = function (dest, pipeOpts) {
  var src = this;
  var state = this._readableState;

  switch (state.pipesCount) {
    case 0:
      state.pipes = dest;
      break;

    case 1:
      state.pipes = [state.pipes, dest];
      break;

    default:
      state.pipes.push(dest);
      break;
  }

  state.pipesCount += 1;
  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);
  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;
  var endFn = doEnd ? onend : unpipe;
  if (state.endEmitted) process.nextTick(endFn);else src.once('end', endFn);
  dest.on('unpipe', onunpipe);

  function onunpipe(readable, unpipeInfo) {
    debug('onunpipe');

    if (readable === src) {
      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {
        unpipeInfo.hasUnpiped = true;
        cleanup();
      }
    }
  }

  function onend() {
    debug('onend');
    dest.end();
  } // when the dest drains, it reduces the awaitDrain counter
  // on the source.  This would be more elegant with a .once()
  // handler in flow(), but adding and removing repeatedly is
  // too slow.


  var ondrain = pipeOnDrain(src);
  dest.on('drain', ondrain);
  var cleanedUp = false;

  function cleanup() {
    debug('cleanup'); // cleanup event handlers once the pipe is broken

    dest.removeListener('close', onclose);
    dest.removeListener('finish', onfinish);
    dest.removeListener('drain', ondrain);
    dest.removeListener('error', onerror);
    dest.removeListener('unpipe', onunpipe);
    src.removeListener('end', onend);
    src.removeListener('end', unpipe);
    src.removeListener('data', ondata);
    cleanedUp = true; // if the reader is waiting for a drain event from this
    // specific writer, then it would cause it to never start
    // flowing again.
    // So, if this is awaiting a drain, then we just call it now.
    // If we don't know, then assume that we are waiting for one.

    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();
  }

  src.on('data', ondata);

  function ondata(chunk) {
    debug('ondata');
    var ret = dest.write(chunk);
    debug('dest.write', ret);

    if (ret === false) {
      // If the user unpiped during `dest.write()`, it is possible
      // to get stuck in a permanently paused state if that write
      // also returned false.
      // => Check whether `dest` is still a piping destination.
      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {
        debug('false write response, pause', state.awaitDrain);
        state.awaitDrain++;
      }

      src.pause();
    }
  } // if the dest has an error, then stop piping into it.
  // however, don't suppress the throwing behavior for this.


  function onerror(er) {
    debug('onerror', er);
    unpipe();
    dest.removeListener('error', onerror);
    if (EElistenerCount(dest, 'error') === 0) errorOrDestroy(dest, er);
  } // Make sure our error handler is attached before userland ones.


  prependListener(dest, 'error', onerror); // Both close and finish should trigger unpipe, but only once.

  function onclose() {
    dest.removeListener('finish', onfinish);
    unpipe();
  }

  dest.once('close', onclose);

  function onfinish() {
    debug('onfinish');
    dest.removeListener('close', onclose);
    unpipe();
  }

  dest.once('finish', onfinish);

  function unpipe() {
    debug('unpipe');
    src.unpipe(dest);
  } // tell the dest that it's being piped to


  dest.emit('pipe', src); // start the flow if it hasn't been started already.

  if (!state.flowing) {
    debug('pipe resume');
    src.resume();
  }

  return dest;
};

function pipeOnDrain(src) {
  return function pipeOnDrainFunctionResult() {
    var state = src._readableState;
    debug('pipeOnDrain', state.awaitDrain);
    if (state.awaitDrain) state.awaitDrain--;

    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {
      state.flowing = true;
      flow(src);
    }
  };
}

Readable.prototype.unpipe = function (dest) {
  var state = this._readableState;
  var unpipeInfo = {
    hasUnpiped: false
  }; // if we're not piping anywhere, then do nothing.

  if (state.pipesCount === 0) return this; // just one destination.  most common case.

  if (state.pipesCount === 1) {
    // passed in one, but it's not the right one.
    if (dest && dest !== state.pipes) return this;
    if (!dest) dest = state.pipes; // got a match.

    state.pipes = null;
    state.pipesCount = 0;
    state.flowing = false;
    if (dest) dest.emit('unpipe', this, unpipeInfo);
    return this;
  } // slow case. multiple pipe destinations.


  if (!dest) {
    // remove all.
    var dests = state.pipes;
    var len = state.pipesCount;
    state.pipes = null;
    state.pipesCount = 0;
    state.flowing = false;

    for (var i = 0; i < len; i++) {
      dests[i].emit('unpipe', this, {
        hasUnpiped: false
      });
    }

    return this;
  } // try to find the right one.


  var index = indexOf(state.pipes, dest);
  if (index === -1) return this;
  state.pipes.splice(index, 1);
  state.pipesCount -= 1;
  if (state.pipesCount === 1) state.pipes = state.pipes[0];
  dest.emit('unpipe', this, unpipeInfo);
  return this;
}; // set up data events if they are asked for
// Ensure readable listeners eventually get something


Readable.prototype.on = function (ev, fn) {
  var res = Stream.prototype.on.call(this, ev, fn);
  var state = this._readableState;

  if (ev === 'data') {
    // update readableListening so that resume() may be a no-op
    // a few lines down. This is needed to support once('readable').
    state.readableListening = this.listenerCount('readable') > 0; // Try start flowing on next tick if stream isn't explicitly paused

    if (state.flowing !== false) this.resume();
  } else if (ev === 'readable') {
    if (!state.endEmitted && !state.readableListening) {
      state.readableListening = state.needReadable = true;
      state.flowing = false;
      state.emittedReadable = false;
      debug('on readable', state.length, state.reading);

      if (state.length) {
        emitReadable(this);
      } else if (!state.reading) {
        process.nextTick(nReadingNextTick, this);
      }
    }
  }

  return res;
};

Readable.prototype.addListener = Readable.prototype.on;

Readable.prototype.removeListener = function (ev, fn) {
  var res = Stream.prototype.removeListener.call(this, ev, fn);

  if (ev === 'readable') {
    // We need to check if there is someone still listening to
    // readable and reset the state. However this needs to happen
    // after readable has been emitted but before I/O (nextTick) to
    // support once('readable', fn) cycles. This means that calling
    // resume within the same tick will have no
    // effect.
    process.nextTick(updateReadableListening, this);
  }

  return res;
};

Readable.prototype.removeAllListeners = function (ev) {
  var res = Stream.prototype.removeAllListeners.apply(this, arguments);

  if (ev === 'readable' || ev === undefined) {
    // We need to check if there is someone still listening to
    // readable and reset the state. However this needs to happen
    // after readable has been emitted but before I/O (nextTick) to
    // support once('readable', fn) cycles. This means that calling
    // resume within the same tick will have no
    // effect.
    process.nextTick(updateReadableListening, this);
  }

  return res;
};

function updateReadableListening(self) {
  var state = self._readableState;
  state.readableListening = self.listenerCount('readable') > 0;

  if (state.resumeScheduled && !state.paused) {
    // flowing needs to be set to true now, otherwise
    // the upcoming resume will not flow.
    state.flowing = true; // crude way to check if we should resume
  } else if (self.listenerCount('data') > 0) {
    self.resume();
  }
}

function nReadingNextTick(self) {
  debug('readable nexttick read 0');
  self.read(0);
} // pause() and resume() are remnants of the legacy readable stream API
// If the user uses them, then switch into old mode.


Readable.prototype.resume = function () {
  var state = this._readableState;

  if (!state.flowing) {
    debug('resume'); // we flow only if there is no one listening
    // for readable, but we still have to call
    // resume()

    state.flowing = !state.readableListening;
    resume(this, state);
  }

  state.paused = false;
  return this;
};

function resume(stream, state) {
  if (!state.resumeScheduled) {
    state.resumeScheduled = true;
    process.nextTick(resume_, stream, state);
  }
}

function resume_(stream, state) {
  debug('resume', state.reading);

  if (!state.reading) {
    stream.read(0);
  }

  state.resumeScheduled = false;
  stream.emit('resume');
  flow(stream);
  if (state.flowing && !state.reading) stream.read(0);
}

Readable.prototype.pause = function () {
  debug('call pause flowing=%j', this._readableState.flowing);

  if (this._readableState.flowing !== false) {
    debug('pause');
    this._readableState.flowing = false;
    this.emit('pause');
  }

  this._readableState.paused = true;
  return this;
};

function flow(stream) {
  var state = stream._readableState;
  debug('flow', state.flowing);

  while (state.flowing && stream.read() !== null) {
    ;
  }
} // wrap an old-style stream as the async data source.
// This is *not* part of the readable stream interface.
// It is an ugly unfortunate mess of history.


Readable.prototype.wrap = function (stream) {
  var _this = this;

  var state = this._readableState;
  var paused = false;
  stream.on('end', function () {
    debug('wrapped end');

    if (state.decoder && !state.ended) {
      var chunk = state.decoder.end();
      if (chunk && chunk.length) _this.push(chunk);
    }

    _this.push(null);
  });
  stream.on('data', function (chunk) {
    debug('wrapped data');
    if (state.decoder) chunk = state.decoder.write(chunk); // don't skip over falsy values in objectMode

    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;

    var ret = _this.push(chunk);

    if (!ret) {
      paused = true;
      stream.pause();
    }
  }); // proxy all the other methods.
  // important when wrapping filters and duplexes.

  for (var i in stream) {
    if (this[i] === undefined && typeof stream[i] === 'function') {
      this[i] = function methodWrap(method) {
        return function methodWrapReturnFunction() {
          return stream[method].apply(stream, arguments);
        };
      }(i);
    }
  } // proxy certain important events.


  for (var n = 0; n < kProxyEvents.length; n++) {
    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));
  } // when we try to consume some more bytes, simply unpause the
  // underlying stream.


  this._read = function (n) {
    debug('wrapped _read', n);

    if (paused) {
      paused = false;
      stream.resume();
    }
  };

  return this;
};

if (typeof Symbol === 'function') {
  Readable.prototype[Symbol.asyncIterator] = function () {
    if (createReadableStreamAsyncIterator === undefined) {
      createReadableStreamAsyncIterator = require('./internal/streams/async_iterator');
    }

    return createReadableStreamAsyncIterator(this);
  };
}

Object.defineProperty(Readable.prototype, 'readableHighWaterMark', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._readableState.highWaterMark;
  }
});
Object.defineProperty(Readable.prototype, 'readableBuffer', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._readableState && this._readableState.buffer;
  }
});
Object.defineProperty(Readable.prototype, 'readableFlowing', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._readableState.flowing;
  },
  set: function set(state) {
    if (this._readableState) {
      this._readableState.flowing = state;
    }
  }
}); // exposed for testing purposes only.

Readable._fromList = fromList;
Object.defineProperty(Readable.prototype, 'readableLength', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._readableState.length;
  }
}); // Pluck off n bytes from an array of buffers.
// Length is the combined lengths of all the buffers in the list.
// This function is designed to be inlinable, so please take care when making
// changes to the function body.

function fromList(n, state) {
  // nothing buffered
  if (state.length === 0) return null;
  var ret;
  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {
    // read it all, truncate the list
    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.first();else ret = state.buffer.concat(state.length);
    state.buffer.clear();
  } else {
    // read part of list
    ret = state.buffer.consume(n, state.decoder);
  }
  return ret;
}

function endReadable(stream) {
  var state = stream._readableState;
  debug('endReadable', state.endEmitted);

  if (!state.endEmitted) {
    state.ended = true;
    process.nextTick(endReadableNT, state, stream);
  }
}

function endReadableNT(state, stream) {
  debug('endReadableNT', state.endEmitted, state.length); // Check that we didn't get one last unshift.

  if (!state.endEmitted && state.length === 0) {
    state.endEmitted = true;
    stream.readable = false;
    stream.emit('end');

    if (state.autoDestroy) {
      // In case of duplex streams we need a way to detect
      // if the writable side is ready for autoDestroy as well
      var wState = stream._writableState;

      if (!wState || wState.autoDestroy && wState.finished) {
        stream.destroy();
      }
    }
  }
}

if (typeof Symbol === 'function') {
  Readable.from = function (iterable, opts) {
    if (from === undefined) {
      from = require('./internal/streams/from');
    }

    return from(Readable, iterable, opts);
  };
}

function indexOf(xs, x) {
  for (var i = 0, l = xs.length; i < l; i++) {
    if (xs[i] === x) return i;
  }

  return -1;
}
}).call(this,require('_process'),typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{"../errors":95,"./_stream_duplex":96,"./internal/streams/async_iterator":101,"./internal/streams/buffer_list":102,"./internal/streams/destroy":103,"./internal/streams/from":105,"./internal/streams/state":107,"./internal/streams/stream":108,"_process":86,"buffer":76,"events":82,"inherits":84,"string_decoder/":110,"util":73}],99:[function(require,module,exports){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
// a transform stream is a readable/writable stream where you do
// something with the data.  Sometimes it's called a "filter",
// but that's not a great name for it, since that implies a thing where
// some bits pass through, and others are simply ignored.  (That would
// be a valid example of a transform, of course.)
//
// While the output is causally related to the input, it's not a
// necessarily symmetric or synchronous transformation.  For example,
// a zlib stream might take multiple plain-text writes(), and then
// emit a single compressed chunk some time in the future.
//
// Here's how this works:
//
// The Transform stream has all the aspects of the readable and writable
// stream classes.  When you write(chunk), that calls _write(chunk,cb)
// internally, and returns false if there's a lot of pending writes
// buffered up.  When you call read(), that calls _read(n) until
// there's enough pending readable data buffered up.
//
// In a transform stream, the written data is placed in a buffer.  When
// _read(n) is called, it transforms the queued up data, calling the
// buffered _write cb's as it consumes chunks.  If consuming a single
// written chunk would result in multiple output chunks, then the first
// outputted bit calls the readcb, and subsequent chunks just go into
// the read buffer, and will cause it to emit 'readable' if necessary.
//
// This way, back-pressure is actually determined by the reading side,
// since _read has to be called to start processing a new chunk.  However,
// a pathological inflate type of transform can cause excessive buffering
// here.  For example, imagine a stream where every byte of input is
// interpreted as an integer from 0-255, and then results in that many
// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in
// 1kb of data being output.  In this case, you could write a very small
// amount of input, and end up with a very large amount of output.  In
// such a pathological inflating mechanism, there'd be no way to tell
// the system to stop doing the transform.  A single 4MB write could
// cause the system to run out of memory.
//
// However, even in such a pathological case, only a single written chunk
// would be consumed, and then the rest would wait (un-transformed) until
// the results of the previous transformed chunk were consumed.
'use strict';

module.exports = Transform;

var _require$codes = require('../errors').codes,
    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,
    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,
    ERR_TRANSFORM_ALREADY_TRANSFORMING = _require$codes.ERR_TRANSFORM_ALREADY_TRANSFORMING,
    ERR_TRANSFORM_WITH_LENGTH_0 = _require$codes.ERR_TRANSFORM_WITH_LENGTH_0;

var Duplex = require('./_stream_duplex');

require('inherits')(Transform, Duplex);

function afterTransform(er, data) {
  var ts = this._transformState;
  ts.transforming = false;
  var cb = ts.writecb;

  if (cb === null) {
    return this.emit('error', new ERR_MULTIPLE_CALLBACK());
  }

  ts.writechunk = null;
  ts.writecb = null;
  if (data != null) // single equals check for both `null` and `undefined`
    this.push(data);
  cb(er);
  var rs = this._readableState;
  rs.reading = false;

  if (rs.needReadable || rs.length < rs.highWaterMark) {
    this._read(rs.highWaterMark);
  }
}

function Transform(options) {
  if (!(this instanceof Transform)) return new Transform(options);
  Duplex.call(this, options);
  this._transformState = {
    afterTransform: afterTransform.bind(this),
    needTransform: false,
    transforming: false,
    writecb: null,
    writechunk: null,
    writeencoding: null
  }; // start out asking for a readable event once data is transformed.

  this._readableState.needReadable = true; // we have implemented the _read method, and done the other things
  // that Readable wants before the first _read call, so unset the
  // sync guard flag.

  this._readableState.sync = false;

  if (options) {
    if (typeof options.transform === 'function') this._transform = options.transform;
    if (typeof options.flush === 'function') this._flush = options.flush;
  } // When the writable side finishes, then flush out anything remaining.


  this.on('prefinish', prefinish);
}

function prefinish() {
  var _this = this;

  if (typeof this._flush === 'function' && !this._readableState.destroyed) {
    this._flush(function (er, data) {
      done(_this, er, data);
    });
  } else {
    done(this, null, null);
  }
}

Transform.prototype.push = function (chunk, encoding) {
  this._transformState.needTransform = false;
  return Duplex.prototype.push.call(this, chunk, encoding);
}; // This is the part where you do stuff!
// override this function in implementation classes.
// 'chunk' is an input chunk.
//
// Call `push(newChunk)` to pass along transformed output
// to the readable side.  You may call 'push' zero or more times.
//
// Call `cb(err)` when you are done with this chunk.  If you pass
// an error, then that'll put the hurt on the whole operation.  If you
// never call cb(), then you'll never get another chunk.


Transform.prototype._transform = function (chunk, encoding, cb) {
  cb(new ERR_METHOD_NOT_IMPLEMENTED('_transform()'));
};

Transform.prototype._write = function (chunk, encoding, cb) {
  var ts = this._transformState;
  ts.writecb = cb;
  ts.writechunk = chunk;
  ts.writeencoding = encoding;

  if (!ts.transforming) {
    var rs = this._readableState;
    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);
  }
}; // Doesn't matter what the args are here.
// _transform does all the work.
// That we got here means that the readable side wants more data.


Transform.prototype._read = function (n) {
  var ts = this._transformState;

  if (ts.writechunk !== null && !ts.transforming) {
    ts.transforming = true;

    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);
  } else {
    // mark that we need a transform, so that any data that comes in
    // will get processed, now that we've asked for it.
    ts.needTransform = true;
  }
};

Transform.prototype._destroy = function (err, cb) {
  Duplex.prototype._destroy.call(this, err, function (err2) {
    cb(err2);
  });
};

function done(stream, er, data) {
  if (er) return stream.emit('error', er);
  if (data != null) // single equals check for both `null` and `undefined`
    stream.push(data); // TODO(BridgeAR): Write a test for these two error cases
  // if there's nothing in the write buffer, then that means
  // that nothing more will ever be provided

  if (stream._writableState.length) throw new ERR_TRANSFORM_WITH_LENGTH_0();
  if (stream._transformState.transforming) throw new ERR_TRANSFORM_ALREADY_TRANSFORMING();
  return stream.push(null);
}
},{"../errors":95,"./_stream_duplex":96,"inherits":84}],100:[function(require,module,exports){
(function (process,global){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
// A bit simpler than readable streams.
// Implement an async ._write(chunk, encoding, cb), and it'll handle all
// the drain event emission and buffering.
'use strict';

module.exports = Writable;
/* <replacement> */

function WriteReq(chunk, encoding, cb) {
  this.chunk = chunk;
  this.encoding = encoding;
  this.callback = cb;
  this.next = null;
} // It seems a linked list but it is not
// there will be only 2 of these for each stream


function CorkedRequest(state) {
  var _this = this;

  this.next = null;
  this.entry = null;

  this.finish = function () {
    onCorkedFinish(_this, state);
  };
}
/* </replacement> */

/*<replacement>*/


var Duplex;
/*</replacement>*/

Writable.WritableState = WritableState;
/*<replacement>*/

var internalUtil = {
  deprecate: require('util-deprecate')
};
/*</replacement>*/

/*<replacement>*/

var Stream = require('./internal/streams/stream');
/*</replacement>*/


var Buffer = require('buffer').Buffer;

var OurUint8Array = global.Uint8Array || function () {};

function _uint8ArrayToBuffer(chunk) {
  return Buffer.from(chunk);
}

function _isUint8Array(obj) {
  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;
}

var destroyImpl = require('./internal/streams/destroy');

var _require = require('./internal/streams/state'),
    getHighWaterMark = _require.getHighWaterMark;

var _require$codes = require('../errors').codes,
    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,
    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,
    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,
    ERR_STREAM_CANNOT_PIPE = _require$codes.ERR_STREAM_CANNOT_PIPE,
    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED,
    ERR_STREAM_NULL_VALUES = _require$codes.ERR_STREAM_NULL_VALUES,
    ERR_STREAM_WRITE_AFTER_END = _require$codes.ERR_STREAM_WRITE_AFTER_END,
    ERR_UNKNOWN_ENCODING = _require$codes.ERR_UNKNOWN_ENCODING;

var errorOrDestroy = destroyImpl.errorOrDestroy;

require('inherits')(Writable, Stream);

function nop() {}

function WritableState(options, stream, isDuplex) {
  Duplex = Duplex || require('./_stream_duplex');
  options = options || {}; // Duplex streams are both readable and writable, but share
  // the same options object.
  // However, some cases require setting options to different
  // values for the readable and the writable sides of the duplex stream,
  // e.g. options.readableObjectMode vs. options.writableObjectMode, etc.

  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag to indicate whether or not this stream
  // contains buffers or objects.

  this.objectMode = !!options.objectMode;
  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode; // the point at which write() starts returning false
  // Note: 0 is a valid value, means that we always return false if
  // the entire buffer is not flushed immediately on write()

  this.highWaterMark = getHighWaterMark(this, options, 'writableHighWaterMark', isDuplex); // if _final has been called

  this.finalCalled = false; // drain event flag.

  this.needDrain = false; // at the start of calling end()

  this.ending = false; // when end() has been called, and returned

  this.ended = false; // when 'finish' is emitted

  this.finished = false; // has it been destroyed

  this.destroyed = false; // should we decode strings into buffers before passing to _write?
  // this is here so that some node-core streams can optimize string
  // handling at a lower level.

  var noDecode = options.decodeStrings === false;
  this.decodeStrings = !noDecode; // Crypto is kind of old and crusty.  Historically, its default string
  // encoding is 'binary' so we have to make this configurable.
  // Everything else in the universe uses 'utf8', though.

  this.defaultEncoding = options.defaultEncoding || 'utf8'; // not an actual buffer we keep track of, but a measurement
  // of how much we're waiting to get pushed to some underlying
  // socket or file.

  this.length = 0; // a flag to see when we're in the middle of a write.

  this.writing = false; // when true all writes will be buffered until .uncork() call

  this.corked = 0; // a flag to be able to tell if the onwrite cb is called immediately,
  // or on a later tick.  We set this to true at first, because any
  // actions that shouldn't happen until "later" should generally also
  // not happen before the first write call.

  this.sync = true; // a flag to know if we're processing previously buffered items, which
  // may call the _write() callback in the same tick, so that we don't
  // end up in an overlapped onwrite situation.

  this.bufferProcessing = false; // the callback that's passed to _write(chunk,cb)

  this.onwrite = function (er) {
    onwrite(stream, er);
  }; // the callback that the user supplies to write(chunk,encoding,cb)


  this.writecb = null; // the amount that is being written when _write is called.

  this.writelen = 0;
  this.bufferedRequest = null;
  this.lastBufferedRequest = null; // number of pending user-supplied write callbacks
  // this must be 0 before 'finish' can be emitted

  this.pendingcb = 0; // emit prefinish if the only thing we're waiting for is _write cbs
  // This is relevant for synchronous Transform streams

  this.prefinished = false; // True if the error was already emitted and should not be thrown again

  this.errorEmitted = false; // Should close be emitted on destroy. Defaults to true.

  this.emitClose = options.emitClose !== false; // Should .destroy() be called after 'finish' (and potentially 'end')

  this.autoDestroy = !!options.autoDestroy; // count buffered requests

  this.bufferedRequestCount = 0; // allocate the first CorkedRequest, there is always
  // one allocated and free to use, and we maintain at most two

  this.corkedRequestsFree = new CorkedRequest(this);
}

WritableState.prototype.getBuffer = function getBuffer() {
  var current = this.bufferedRequest;
  var out = [];

  while (current) {
    out.push(current);
    current = current.next;
  }

  return out;
};

(function () {
  try {
    Object.defineProperty(WritableState.prototype, 'buffer', {
      get: internalUtil.deprecate(function writableStateBufferGetter() {
        return this.getBuffer();
      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')
    });
  } catch (_) {}
})(); // Test _writableState for inheritance to account for Duplex streams,
// whose prototype chain only points to Readable.


var realHasInstance;

if (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {
  realHasInstance = Function.prototype[Symbol.hasInstance];
  Object.defineProperty(Writable, Symbol.hasInstance, {
    value: function value(object) {
      if (realHasInstance.call(this, object)) return true;
      if (this !== Writable) return false;
      return object && object._writableState instanceof WritableState;
    }
  });
} else {
  realHasInstance = function realHasInstance(object) {
    return object instanceof this;
  };
}

function Writable(options) {
  Duplex = Duplex || require('./_stream_duplex'); // Writable ctor is applied to Duplexes, too.
  // `realHasInstance` is necessary because using plain `instanceof`
  // would return false, as no `_writableState` property is attached.
  // Trying to use the custom `instanceof` for Writable here will also break the
  // Node.js LazyTransform implementation, which has a non-trivial getter for
  // `_writableState` that would lead to infinite recursion.
  // Checking for a Stream.Duplex instance is faster here instead of inside
  // the WritableState constructor, at least with V8 6.5

  var isDuplex = this instanceof Duplex;
  if (!isDuplex && !realHasInstance.call(Writable, this)) return new Writable(options);
  this._writableState = new WritableState(options, this, isDuplex); // legacy.

  this.writable = true;

  if (options) {
    if (typeof options.write === 'function') this._write = options.write;
    if (typeof options.writev === 'function') this._writev = options.writev;
    if (typeof options.destroy === 'function') this._destroy = options.destroy;
    if (typeof options.final === 'function') this._final = options.final;
  }

  Stream.call(this);
} // Otherwise people can pipe Writable streams, which is just wrong.


Writable.prototype.pipe = function () {
  errorOrDestroy(this, new ERR_STREAM_CANNOT_PIPE());
};

function writeAfterEnd(stream, cb) {
  var er = new ERR_STREAM_WRITE_AFTER_END(); // TODO: defer error events consistently everywhere, not just the cb

  errorOrDestroy(stream, er);
  process.nextTick(cb, er);
} // Checks that a user-supplied chunk is valid, especially for the particular
// mode the stream is in. Currently this means that `null` is never accepted
// and undefined/non-string values are only allowed in object mode.


function validChunk(stream, state, chunk, cb) {
  var er;

  if (chunk === null) {
    er = new ERR_STREAM_NULL_VALUES();
  } else if (typeof chunk !== 'string' && !state.objectMode) {
    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer'], chunk);
  }

  if (er) {
    errorOrDestroy(stream, er);
    process.nextTick(cb, er);
    return false;
  }

  return true;
}

Writable.prototype.write = function (chunk, encoding, cb) {
  var state = this._writableState;
  var ret = false;

  var isBuf = !state.objectMode && _isUint8Array(chunk);

  if (isBuf && !Buffer.isBuffer(chunk)) {
    chunk = _uint8ArrayToBuffer(chunk);
  }

  if (typeof encoding === 'function') {
    cb = encoding;
    encoding = null;
  }

  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;
  if (typeof cb !== 'function') cb = nop;
  if (state.ending) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {
    state.pendingcb++;
    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);
  }
  return ret;
};

Writable.prototype.cork = function () {
  this._writableState.corked++;
};

Writable.prototype.uncork = function () {
  var state = this._writableState;

  if (state.corked) {
    state.corked--;
    if (!state.writing && !state.corked && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);
  }
};

Writable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {
  // node::ParseEncoding() requires lower case.
  if (typeof encoding === 'string') encoding = encoding.toLowerCase();
  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new ERR_UNKNOWN_ENCODING(encoding);
  this._writableState.defaultEncoding = encoding;
  return this;
};

Object.defineProperty(Writable.prototype, 'writableBuffer', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._writableState && this._writableState.getBuffer();
  }
});

function decodeChunk(state, chunk, encoding) {
  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {
    chunk = Buffer.from(chunk, encoding);
  }

  return chunk;
}

Object.defineProperty(Writable.prototype, 'writableHighWaterMark', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._writableState.highWaterMark;
  }
}); // if we're already writing something, then just put this
// in the queue, and wait our turn.  Otherwise, call _write
// If we return false, then we need a drain event, so set that flag.

function writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {
  if (!isBuf) {
    var newChunk = decodeChunk(state, chunk, encoding);

    if (chunk !== newChunk) {
      isBuf = true;
      encoding = 'buffer';
      chunk = newChunk;
    }
  }

  var len = state.objectMode ? 1 : chunk.length;
  state.length += len;
  var ret = state.length < state.highWaterMark; // we must ensure that previous needDrain will not be reset to false.

  if (!ret) state.needDrain = true;

  if (state.writing || state.corked) {
    var last = state.lastBufferedRequest;
    state.lastBufferedRequest = {
      chunk: chunk,
      encoding: encoding,
      isBuf: isBuf,
      callback: cb,
      next: null
    };

    if (last) {
      last.next = state.lastBufferedRequest;
    } else {
      state.bufferedRequest = state.lastBufferedRequest;
    }

    state.bufferedRequestCount += 1;
  } else {
    doWrite(stream, state, false, len, chunk, encoding, cb);
  }

  return ret;
}

function doWrite(stream, state, writev, len, chunk, encoding, cb) {
  state.writelen = len;
  state.writecb = cb;
  state.writing = true;
  state.sync = true;
  if (state.destroyed) state.onwrite(new ERR_STREAM_DESTROYED('write'));else if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);
  state.sync = false;
}

function onwriteError(stream, state, sync, er, cb) {
  --state.pendingcb;

  if (sync) {
    // defer the callback if we are being called synchronously
    // to avoid piling up things on the stack
    process.nextTick(cb, er); // this can emit finish, and it will always happen
    // after error

    process.nextTick(finishMaybe, stream, state);
    stream._writableState.errorEmitted = true;
    errorOrDestroy(stream, er);
  } else {
    // the caller expect this to happen before if
    // it is async
    cb(er);
    stream._writableState.errorEmitted = true;
    errorOrDestroy(stream, er); // this can emit finish, but finish must
    // always follow error

    finishMaybe(stream, state);
  }
}

function onwriteStateUpdate(state) {
  state.writing = false;
  state.writecb = null;
  state.length -= state.writelen;
  state.writelen = 0;
}

function onwrite(stream, er) {
  var state = stream._writableState;
  var sync = state.sync;
  var cb = state.writecb;
  if (typeof cb !== 'function') throw new ERR_MULTIPLE_CALLBACK();
  onwriteStateUpdate(state);
  if (er) onwriteError(stream, state, sync, er, cb);else {
    // Check if we're actually ready to finish, but don't emit yet
    var finished = needFinish(state) || stream.destroyed;

    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {
      clearBuffer(stream, state);
    }

    if (sync) {
      process.nextTick(afterWrite, stream, state, finished, cb);
    } else {
      afterWrite(stream, state, finished, cb);
    }
  }
}

function afterWrite(stream, state, finished, cb) {
  if (!finished) onwriteDrain(stream, state);
  state.pendingcb--;
  cb();
  finishMaybe(stream, state);
} // Must force callback to be called on nextTick, so that we don't
// emit 'drain' before the write() consumer gets the 'false' return
// value, and has a chance to attach a 'drain' listener.


function onwriteDrain(stream, state) {
  if (state.length === 0 && state.needDrain) {
    state.needDrain = false;
    stream.emit('drain');
  }
} // if there's something in the buffer waiting, then process it


function clearBuffer(stream, state) {
  state.bufferProcessing = true;
  var entry = state.bufferedRequest;

  if (stream._writev && entry && entry.next) {
    // Fast case, write everything using _writev()
    var l = state.bufferedRequestCount;
    var buffer = new Array(l);
    var holder = state.corkedRequestsFree;
    holder.entry = entry;
    var count = 0;
    var allBuffers = true;

    while (entry) {
      buffer[count] = entry;
      if (!entry.isBuf) allBuffers = false;
      entry = entry.next;
      count += 1;
    }

    buffer.allBuffers = allBuffers;
    doWrite(stream, state, true, state.length, buffer, '', holder.finish); // doWrite is almost always async, defer these to save a bit of time
    // as the hot path ends with doWrite

    state.pendingcb++;
    state.lastBufferedRequest = null;

    if (holder.next) {
      state.corkedRequestsFree = holder.next;
      holder.next = null;
    } else {
      state.corkedRequestsFree = new CorkedRequest(state);
    }

    state.bufferedRequestCount = 0;
  } else {
    // Slow case, write chunks one-by-one
    while (entry) {
      var chunk = entry.chunk;
      var encoding = entry.encoding;
      var cb = entry.callback;
      var len = state.objectMode ? 1 : chunk.length;
      doWrite(stream, state, false, len, chunk, encoding, cb);
      entry = entry.next;
      state.bufferedRequestCount--; // if we didn't call the onwrite immediately, then
      // it means that we need to wait until it does.
      // also, that means that the chunk and cb are currently
      // being processed, so move the buffer counter past them.

      if (state.writing) {
        break;
      }
    }

    if (entry === null) state.lastBufferedRequest = null;
  }

  state.bufferedRequest = entry;
  state.bufferProcessing = false;
}

Writable.prototype._write = function (chunk, encoding, cb) {
  cb(new ERR_METHOD_NOT_IMPLEMENTED('_write()'));
};

Writable.prototype._writev = null;

Writable.prototype.end = function (chunk, encoding, cb) {
  var state = this._writableState;

  if (typeof chunk === 'function') {
    cb = chunk;
    chunk = null;
    encoding = null;
  } else if (typeof encoding === 'function') {
    cb = encoding;
    encoding = null;
  }

  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding); // .end() fully uncorks

  if (state.corked) {
    state.corked = 1;
    this.uncork();
  } // ignore unnecessary end() calls.


  if (!state.ending) endWritable(this, state, cb);
  return this;
};

Object.defineProperty(Writable.prototype, 'writableLength', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._writableState.length;
  }
});

function needFinish(state) {
  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;
}

function callFinal(stream, state) {
  stream._final(function (err) {
    state.pendingcb--;

    if (err) {
      errorOrDestroy(stream, err);
    }

    state.prefinished = true;
    stream.emit('prefinish');
    finishMaybe(stream, state);
  });
}

function prefinish(stream, state) {
  if (!state.prefinished && !state.finalCalled) {
    if (typeof stream._final === 'function' && !state.destroyed) {
      state.pendingcb++;
      state.finalCalled = true;
      process.nextTick(callFinal, stream, state);
    } else {
      state.prefinished = true;
      stream.emit('prefinish');
    }
  }
}

function finishMaybe(stream, state) {
  var need = needFinish(state);

  if (need) {
    prefinish(stream, state);

    if (state.pendingcb === 0) {
      state.finished = true;
      stream.emit('finish');

      if (state.autoDestroy) {
        // In case of duplex streams we need a way to detect
        // if the readable side is ready for autoDestroy as well
        var rState = stream._readableState;

        if (!rState || rState.autoDestroy && rState.endEmitted) {
          stream.destroy();
        }
      }
    }
  }

  return need;
}

function endWritable(stream, state, cb) {
  state.ending = true;
  finishMaybe(stream, state);

  if (cb) {
    if (state.finished) process.nextTick(cb);else stream.once('finish', cb);
  }

  state.ended = true;
  stream.writable = false;
}

function onCorkedFinish(corkReq, state, err) {
  var entry = corkReq.entry;
  corkReq.entry = null;

  while (entry) {
    var cb = entry.callback;
    state.pendingcb--;
    cb(err);
    entry = entry.next;
  } // reuse the free corkReq.


  state.corkedRequestsFree.next = corkReq;
}

Object.defineProperty(Writable.prototype, 'destroyed', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    if (this._writableState === undefined) {
      return false;
    }

    return this._writableState.destroyed;
  },
  set: function set(value) {
    // we ignore the value if the stream
    // has not been initialized yet
    if (!this._writableState) {
      return;
    } // backward compatibility, the user is explicitly
    // managing destroyed


    this._writableState.destroyed = value;
  }
});
Writable.prototype.destroy = destroyImpl.destroy;
Writable.prototype._undestroy = destroyImpl.undestroy;

Writable.prototype._destroy = function (err, cb) {
  cb(err);
};
}).call(this,require('_process'),typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{"../errors":95,"./_stream_duplex":96,"./internal/streams/destroy":103,"./internal/streams/state":107,"./internal/streams/stream":108,"_process":86,"buffer":76,"inherits":84,"util-deprecate":113}],101:[function(require,module,exports){
(function (process){
'use strict';

var _Object$setPrototypeO;

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

var finished = require('./end-of-stream');

var kLastResolve = Symbol('lastResolve');
var kLastReject = Symbol('lastReject');
var kError = Symbol('error');
var kEnded = Symbol('ended');
var kLastPromise = Symbol('lastPromise');
var kHandlePromise = Symbol('handlePromise');
var kStream = Symbol('stream');

function createIterResult(value, done) {
  return {
    value: value,
    done: done
  };
}

function readAndResolve(iter) {
  var resolve = iter[kLastResolve];

  if (resolve !== null) {
    var data = iter[kStream].read(); // we defer if data is null
    // we can be expecting either 'end' or
    // 'error'

    if (data !== null) {
      iter[kLastPromise] = null;
      iter[kLastResolve] = null;
      iter[kLastReject] = null;
      resolve(createIterResult(data, false));
    }
  }
}

function onReadable(iter) {
  // we wait for the next tick, because it might
  // emit an error with process.nextTick
  process.nextTick(readAndResolve, iter);
}

function wrapForNext(lastPromise, iter) {
  return function (resolve, reject) {
    lastPromise.then(function () {
      if (iter[kEnded]) {
        resolve(createIterResult(undefined, true));
        return;
      }

      iter[kHandlePromise](resolve, reject);
    }, reject);
  };
}

var AsyncIteratorPrototype = Object.getPrototypeOf(function () {});
var ReadableStreamAsyncIteratorPrototype = Object.setPrototypeOf((_Object$setPrototypeO = {
  get stream() {
    return this[kStream];
  },

  next: function next() {
    var _this = this;

    // if we have detected an error in the meanwhile
    // reject straight away
    var error = this[kError];

    if (error !== null) {
      return Promise.reject(error);
    }

    if (this[kEnded]) {
      return Promise.resolve(createIterResult(undefined, true));
    }

    if (this[kStream].destroyed) {
      // We need to defer via nextTick because if .destroy(err) is
      // called, the error will be emitted via nextTick, and
      // we cannot guarantee that there is no error lingering around
      // waiting to be emitted.
      return new Promise(function (resolve, reject) {
        process.nextTick(function () {
          if (_this[kError]) {
            reject(_this[kError]);
          } else {
            resolve(createIterResult(undefined, true));
          }
        });
      });
    } // if we have multiple next() calls
    // we will wait for the previous Promise to finish
    // this logic is optimized to support for await loops,
    // where next() is only called once at a time


    var lastPromise = this[kLastPromise];
    var promise;

    if (lastPromise) {
      promise = new Promise(wrapForNext(lastPromise, this));
    } else {
      // fast path needed to support multiple this.push()
      // without triggering the next() queue
      var data = this[kStream].read();

      if (data !== null) {
        return Promise.resolve(createIterResult(data, false));
      }

      promise = new Promise(this[kHandlePromise]);
    }

    this[kLastPromise] = promise;
    return promise;
  }
}, _defineProperty(_Object$setPrototypeO, Symbol.asyncIterator, function () {
  return this;
}), _defineProperty(_Object$setPrototypeO, "return", function _return() {
  var _this2 = this;

  // destroy(err, cb) is a private API
  // we can guarantee we have that here, because we control the
  // Readable class this is attached to
  return new Promise(function (resolve, reject) {
    _this2[kStream].destroy(null, function (err) {
      if (err) {
        reject(err);
        return;
      }

      resolve(createIterResult(undefined, true));
    });
  });
}), _Object$setPrototypeO), AsyncIteratorPrototype);

var createReadableStreamAsyncIterator = function createReadableStreamAsyncIterator(stream) {
  var _Object$create;

  var iterator = Object.create(ReadableStreamAsyncIteratorPrototype, (_Object$create = {}, _defineProperty(_Object$create, kStream, {
    value: stream,
    writable: true
  }), _defineProperty(_Object$create, kLastResolve, {
    value: null,
    writable: true
  }), _defineProperty(_Object$create, kLastReject, {
    value: null,
    writable: true
  }), _defineProperty(_Object$create, kError, {
    value: null,
    writable: true
  }), _defineProperty(_Object$create, kEnded, {
    value: stream._readableState.endEmitted,
    writable: true
  }), _defineProperty(_Object$create, kHandlePromise, {
    value: function value(resolve, reject) {
      var data = iterator[kStream].read();

      if (data) {
        iterator[kLastPromise] = null;
        iterator[kLastResolve] = null;
        iterator[kLastReject] = null;
        resolve(createIterResult(data, false));
      } else {
        iterator[kLastResolve] = resolve;
        iterator[kLastReject] = reject;
      }
    },
    writable: true
  }), _Object$create));
  iterator[kLastPromise] = null;
  finished(stream, function (err) {
    if (err && err.code !== 'ERR_STREAM_PREMATURE_CLOSE') {
      var reject = iterator[kLastReject]; // reject if we are waiting for data in the Promise
      // returned by next() and store the error

      if (reject !== null) {
        iterator[kLastPromise] = null;
        iterator[kLastResolve] = null;
        iterator[kLastReject] = null;
        reject(err);
      }

      iterator[kError] = err;
      return;
    }

    var resolve = iterator[kLastResolve];

    if (resolve !== null) {
      iterator[kLastPromise] = null;
      iterator[kLastResolve] = null;
      iterator[kLastReject] = null;
      resolve(createIterResult(undefined, true));
    }

    iterator[kEnded] = true;
  });
  stream.on('readable', onReadable.bind(null, iterator));
  return iterator;
};

module.exports = createReadableStreamAsyncIterator;
}).call(this,require('_process'))
},{"./end-of-stream":104,"_process":86}],102:[function(require,module,exports){
'use strict';

function ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); keys.push.apply(keys, symbols); } return keys; }

function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(Object(source), true).forEach(function (key) { _defineProperty(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError("Cannot call a class as a function"); } }

function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }

var _require = require('buffer'),
    Buffer = _require.Buffer;

var _require2 = require('util'),
    inspect = _require2.inspect;

var custom = inspect && inspect.custom || 'inspect';

function copyBuffer(src, target, offset) {
  Buffer.prototype.copy.call(src, target, offset);
}

module.exports =
/*#__PURE__*/
function () {
  function BufferList() {
    _classCallCheck(this, BufferList);

    this.head = null;
    this.tail = null;
    this.length = 0;
  }

  _createClass(BufferList, [{
    key: "push",
    value: function push(v) {
      var entry = {
        data: v,
        next: null
      };
      if (this.length > 0) this.tail.next = entry;else this.head = entry;
      this.tail = entry;
      ++this.length;
    }
  }, {
    key: "unshift",
    value: function unshift(v) {
      var entry = {
        data: v,
        next: this.head
      };
      if (this.length === 0) this.tail = entry;
      this.head = entry;
      ++this.length;
    }
  }, {
    key: "shift",
    value: function shift() {
      if (this.length === 0) return;
      var ret = this.head.data;
      if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;
      --this.length;
      return ret;
    }
  }, {
    key: "clear",
    value: function clear() {
      this.head = this.tail = null;
      this.length = 0;
    }
  }, {
    key: "join",
    value: function join(s) {
      if (this.length === 0) return '';
      var p = this.head;
      var ret = '' + p.data;

      while (p = p.next) {
        ret += s + p.data;
      }

      return ret;
    }
  }, {
    key: "concat",
    value: function concat(n) {
      if (this.length === 0) return Buffer.alloc(0);
      var ret = Buffer.allocUnsafe(n >>> 0);
      var p = this.head;
      var i = 0;

      while (p) {
        copyBuffer(p.data, ret, i);
        i += p.data.length;
        p = p.next;
      }

      return ret;
    } // Consumes a specified amount of bytes or characters from the buffered data.

  }, {
    key: "consume",
    value: function consume(n, hasStrings) {
      var ret;

      if (n < this.head.data.length) {
        // `slice` is the same for buffers and strings.
        ret = this.head.data.slice(0, n);
        this.head.data = this.head.data.slice(n);
      } else if (n === this.head.data.length) {
        // First chunk is a perfect match.
        ret = this.shift();
      } else {
        // Result spans more than one buffer.
        ret = hasStrings ? this._getString(n) : this._getBuffer(n);
      }

      return ret;
    }
  }, {
    key: "first",
    value: function first() {
      return this.head.data;
    } // Consumes a specified amount of characters from the buffered data.

  }, {
    key: "_getString",
    value: function _getString(n) {
      var p = this.head;
      var c = 1;
      var ret = p.data;
      n -= ret.length;

      while (p = p.next) {
        var str = p.data;
        var nb = n > str.length ? str.length : n;
        if (nb === str.length) ret += str;else ret += str.slice(0, n);
        n -= nb;

        if (n === 0) {
          if (nb === str.length) {
            ++c;
            if (p.next) this.head = p.next;else this.head = this.tail = null;
          } else {
            this.head = p;
            p.data = str.slice(nb);
          }

          break;
        }

        ++c;
      }

      this.length -= c;
      return ret;
    } // Consumes a specified amount of bytes from the buffered data.

  }, {
    key: "_getBuffer",
    value: function _getBuffer(n) {
      var ret = Buffer.allocUnsafe(n);
      var p = this.head;
      var c = 1;
      p.data.copy(ret);
      n -= p.data.length;

      while (p = p.next) {
        var buf = p.data;
        var nb = n > buf.length ? buf.length : n;
        buf.copy(ret, ret.length - n, 0, nb);
        n -= nb;

        if (n === 0) {
          if (nb === buf.length) {
            ++c;
            if (p.next) this.head = p.next;else this.head = this.tail = null;
          } else {
            this.head = p;
            p.data = buf.slice(nb);
          }

          break;
        }

        ++c;
      }

      this.length -= c;
      return ret;
    } // Make sure the linked list only shows the minimal necessary information.

  }, {
    key: custom,
    value: function value(_, options) {
      return inspect(this, _objectSpread({}, options, {
        // Only inspect one level.
        depth: 0,
        // It should not recurse.
        customInspect: false
      }));
    }
  }]);

  return BufferList;
}();
},{"buffer":76,"util":73}],103:[function(require,module,exports){
(function (process){
'use strict'; // undocumented cb() API, needed for core, not for public API

function destroy(err, cb) {
  var _this = this;

  var readableDestroyed = this._readableState && this._readableState.destroyed;
  var writableDestroyed = this._writableState && this._writableState.destroyed;

  if (readableDestroyed || writableDestroyed) {
    if (cb) {
      cb(err);
    } else if (err) {
      if (!this._writableState) {
        process.nextTick(emitErrorNT, this, err);
      } else if (!this._writableState.errorEmitted) {
        this._writableState.errorEmitted = true;
        process.nextTick(emitErrorNT, this, err);
      }
    }

    return this;
  } // we set destroyed to true before firing error callbacks in order
  // to make it re-entrance safe in case destroy() is called within callbacks


  if (this._readableState) {
    this._readableState.destroyed = true;
  } // if this is a duplex stream mark the writable part as destroyed as well


  if (this._writableState) {
    this._writableState.destroyed = true;
  }

  this._destroy(err || null, function (err) {
    if (!cb && err) {
      if (!_this._writableState) {
        process.nextTick(emitErrorAndCloseNT, _this, err);
      } else if (!_this._writableState.errorEmitted) {
        _this._writableState.errorEmitted = true;
        process.nextTick(emitErrorAndCloseNT, _this, err);
      } else {
        process.nextTick(emitCloseNT, _this);
      }
    } else if (cb) {
      process.nextTick(emitCloseNT, _this);
      cb(err);
    } else {
      process.nextTick(emitCloseNT, _this);
    }
  });

  return this;
}

function emitErrorAndCloseNT(self, err) {
  emitErrorNT(self, err);
  emitCloseNT(self);
}

function emitCloseNT(self) {
  if (self._writableState && !self._writableState.emitClose) return;
  if (self._readableState && !self._readableState.emitClose) return;
  self.emit('close');
}

function undestroy() {
  if (this._readableState) {
    this._readableState.destroyed = false;
    this._readableState.reading = false;
    this._readableState.ended = false;
    this._readableState.endEmitted = false;
  }

  if (this._writableState) {
    this._writableState.destroyed = false;
    this._writableState.ended = false;
    this._writableState.ending = false;
    this._writableState.finalCalled = false;
    this._writableState.prefinished = false;
    this._writableState.finished = false;
    this._writableState.errorEmitted = false;
  }
}

function emitErrorNT(self, err) {
  self.emit('error', err);
}

function errorOrDestroy(stream, err) {
  // We have tests that rely on errors being emitted
  // in the same tick, so changing this is semver major.
  // For now when you opt-in to autoDestroy we allow
  // the error to be emitted nextTick. In a future
  // semver major update we should change the default to this.
  var rState = stream._readableState;
  var wState = stream._writableState;
  if (rState && rState.autoDestroy || wState && wState.autoDestroy) stream.destroy(err);else stream.emit('error', err);
}

module.exports = {
  destroy: destroy,
  undestroy: undestroy,
  errorOrDestroy: errorOrDestroy
};
}).call(this,require('_process'))
},{"_process":86}],104:[function(require,module,exports){
// Ported from https://github.com/mafintosh/end-of-stream with
// permission from the author, Mathias Buus (@mafintosh).
'use strict';

var ERR_STREAM_PREMATURE_CLOSE = require('../../../errors').codes.ERR_STREAM_PREMATURE_CLOSE;

function once(callback) {
  var called = false;
  return function () {
    if (called) return;
    called = true;

    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {
      args[_key] = arguments[_key];
    }

    callback.apply(this, args);
  };
}

function noop() {}

function isRequest(stream) {
  return stream.setHeader && typeof stream.abort === 'function';
}

function eos(stream, opts, callback) {
  if (typeof opts === 'function') return eos(stream, null, opts);
  if (!opts) opts = {};
  callback = once(callback || noop);
  var readable = opts.readable || opts.readable !== false && stream.readable;
  var writable = opts.writable || opts.writable !== false && stream.writable;

  var onlegacyfinish = function onlegacyfinish() {
    if (!stream.writable) onfinish();
  };

  var writableEnded = stream._writableState && stream._writableState.finished;

  var onfinish = function onfinish() {
    writable = false;
    writableEnded = true;
    if (!readable) callback.call(stream);
  };

  var readableEnded = stream._readableState && stream._readableState.endEmitted;

  var onend = function onend() {
    readable = false;
    readableEnded = true;
    if (!writable) callback.call(stream);
  };

  var onerror = function onerror(err) {
    callback.call(stream, err);
  };

  var onclose = function onclose() {
    var err;

    if (readable && !readableEnded) {
      if (!stream._readableState || !stream._readableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();
      return callback.call(stream, err);
    }

    if (writable && !writableEnded) {
      if (!stream._writableState || !stream._writableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();
      return callback.call(stream, err);
    }
  };

  var onrequest = function onrequest() {
    stream.req.on('finish', onfinish);
  };

  if (isRequest(stream)) {
    stream.on('complete', onfinish);
    stream.on('abort', onclose);
    if (stream.req) onrequest();else stream.on('request', onrequest);
  } else if (writable && !stream._writableState) {
    // legacy streams
    stream.on('end', onlegacyfinish);
    stream.on('close', onlegacyfinish);
  }

  stream.on('end', onend);
  stream.on('finish', onfinish);
  if (opts.error !== false) stream.on('error', onerror);
  stream.on('close', onclose);
  return function () {
    stream.removeListener('complete', onfinish);
    stream.removeListener('abort', onclose);
    stream.removeListener('request', onrequest);
    if (stream.req) stream.req.removeListener('finish', onfinish);
    stream.removeListener('end', onlegacyfinish);
    stream.removeListener('close', onlegacyfinish);
    stream.removeListener('finish', onfinish);
    stream.removeListener('end', onend);
    stream.removeListener('error', onerror);
    stream.removeListener('close', onclose);
  };
}

module.exports = eos;
},{"../../../errors":95}],105:[function(require,module,exports){
module.exports = function () {
  throw new Error('Readable.from is not available in the browser')
};

},{}],106:[function(require,module,exports){
// Ported from https://github.com/mafintosh/pump with
// permission from the author, Mathias Buus (@mafintosh).
'use strict';

var eos;

function once(callback) {
  var called = false;
  return function () {
    if (called) return;
    called = true;
    callback.apply(void 0, arguments);
  };
}

var _require$codes = require('../../../errors').codes,
    ERR_MISSING_ARGS = _require$codes.ERR_MISSING_ARGS,
    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED;

function noop(err) {
  // Rethrow the error if it exists to avoid swallowing it
  if (err) throw err;
}

function isRequest(stream) {
  return stream.setHeader && typeof stream.abort === 'function';
}

function destroyer(stream, reading, writing, callback) {
  callback = once(callback);
  var closed = false;
  stream.on('close', function () {
    closed = true;
  });
  if (eos === undefined) eos = require('./end-of-stream');
  eos(stream, {
    readable: reading,
    writable: writing
  }, function (err) {
    if (err) return callback(err);
    closed = true;
    callback();
  });
  var destroyed = false;
  return function (err) {
    if (closed) return;
    if (destroyed) return;
    destroyed = true; // request.destroy just do .end - .abort is what we want

    if (isRequest(stream)) return stream.abort();
    if (typeof stream.destroy === 'function') return stream.destroy();
    callback(err || new ERR_STREAM_DESTROYED('pipe'));
  };
}

function call(fn) {
  fn();
}

function pipe(from, to) {
  return from.pipe(to);
}

function popCallback(streams) {
  if (!streams.length) return noop;
  if (typeof streams[streams.length - 1] !== 'function') return noop;
  return streams.pop();
}

function pipeline() {
  for (var _len = arguments.length, streams = new Array(_len), _key = 0; _key < _len; _key++) {
    streams[_key] = arguments[_key];
  }

  var callback = popCallback(streams);
  if (Array.isArray(streams[0])) streams = streams[0];

  if (streams.length < 2) {
    throw new ERR_MISSING_ARGS('streams');
  }

  var error;
  var destroys = streams.map(function (stream, i) {
    var reading = i < streams.length - 1;
    var writing = i > 0;
    return destroyer(stream, reading, writing, function (err) {
      if (!error) error = err;
      if (err) destroys.forEach(call);
      if (reading) return;
      destroys.forEach(call);
      callback(error);
    });
  });
  return streams.reduce(pipe);
}

module.exports = pipeline;
},{"../../../errors":95,"./end-of-stream":104}],107:[function(require,module,exports){
'use strict';

var ERR_INVALID_OPT_VALUE = require('../../../errors').codes.ERR_INVALID_OPT_VALUE;

function highWaterMarkFrom(options, isDuplex, duplexKey) {
  return options.highWaterMark != null ? options.highWaterMark : isDuplex ? options[duplexKey] : null;
}

function getHighWaterMark(state, options, duplexKey, isDuplex) {
  var hwm = highWaterMarkFrom(options, isDuplex, duplexKey);

  if (hwm != null) {
    if (!(isFinite(hwm) && Math.floor(hwm) === hwm) || hwm < 0) {
      var name = isDuplex ? duplexKey : 'highWaterMark';
      throw new ERR_INVALID_OPT_VALUE(name, hwm);
    }

    return Math.floor(hwm);
  } // Default value


  return state.objectMode ? 16 : 16 * 1024;
}

module.exports = {
  getHighWaterMark: getHighWaterMark
};
},{"../../../errors":95}],108:[function(require,module,exports){
module.exports = require('events').EventEmitter;

},{"events":82}],109:[function(require,module,exports){
exports = module.exports = require('./lib/_stream_readable.js');
exports.Stream = exports;
exports.Readable = exports;
exports.Writable = require('./lib/_stream_writable.js');
exports.Duplex = require('./lib/_stream_duplex.js');
exports.Transform = require('./lib/_stream_transform.js');
exports.PassThrough = require('./lib/_stream_passthrough.js');
exports.finished = require('./lib/internal/streams/end-of-stream.js');
exports.pipeline = require('./lib/internal/streams/pipeline.js');

},{"./lib/_stream_duplex.js":96,"./lib/_stream_passthrough.js":97,"./lib/_stream_readable.js":98,"./lib/_stream_transform.js":99,"./lib/_stream_writable.js":100,"./lib/internal/streams/end-of-stream.js":104,"./lib/internal/streams/pipeline.js":106}],110:[function(require,module,exports){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

'use strict';

/*<replacement>*/

var Buffer = require('safe-buffer').Buffer;
/*</replacement>*/

var isEncoding = Buffer.isEncoding || function (encoding) {
  encoding = '' + encoding;
  switch (encoding && encoding.toLowerCase()) {
    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':
      return true;
    default:
      return false;
  }
};

function _normalizeEncoding(enc) {
  if (!enc) return 'utf8';
  var retried;
  while (true) {
    switch (enc) {
      case 'utf8':
      case 'utf-8':
        return 'utf8';
      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return 'utf16le';
      case 'latin1':
      case 'binary':
        return 'latin1';
      case 'base64':
      case 'ascii':
      case 'hex':
        return enc;
      default:
        if (retried) return; // undefined
        enc = ('' + enc).toLowerCase();
        retried = true;
    }
  }
};

// Do not cache `Buffer.isEncoding` when checking encoding names as some
// modules monkey-patch it to support additional encodings
function normalizeEncoding(enc) {
  var nenc = _normalizeEncoding(enc);
  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);
  return nenc || enc;
}

// StringDecoder provides an interface for efficiently splitting a series of
// buffers into a series of JS strings without breaking apart multi-byte
// characters.
exports.StringDecoder = StringDecoder;
function StringDecoder(encoding) {
  this.encoding = normalizeEncoding(encoding);
  var nb;
  switch (this.encoding) {
    case 'utf16le':
      this.text = utf16Text;
      this.end = utf16End;
      nb = 4;
      break;
    case 'utf8':
      this.fillLast = utf8FillLast;
      nb = 4;
      break;
    case 'base64':
      this.text = base64Text;
      this.end = base64End;
      nb = 3;
      break;
    default:
      this.write = simpleWrite;
      this.end = simpleEnd;
      return;
  }
  this.lastNeed = 0;
  this.lastTotal = 0;
  this.lastChar = Buffer.allocUnsafe(nb);
}

StringDecoder.prototype.write = function (buf) {
  if (buf.length === 0) return '';
  var r;
  var i;
  if (this.lastNeed) {
    r = this.fillLast(buf);
    if (r === undefined) return '';
    i = this.lastNeed;
    this.lastNeed = 0;
  } else {
    i = 0;
  }
  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);
  return r || '';
};

StringDecoder.prototype.end = utf8End;

// Returns only complete characters in a Buffer
StringDecoder.prototype.text = utf8Text;

// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer
StringDecoder.prototype.fillLast = function (buf) {
  if (this.lastNeed <= buf.length) {
    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);
    return this.lastChar.toString(this.encoding, 0, this.lastTotal);
  }
  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);
  this.lastNeed -= buf.length;
};

// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a
// continuation byte. If an invalid byte is detected, -2 is returned.
function utf8CheckByte(byte) {
  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;
  return byte >> 6 === 0x02 ? -1 : -2;
}

// Checks at most 3 bytes at the end of a Buffer in order to detect an
// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)
// needed to complete the UTF-8 character (if applicable) are returned.
function utf8CheckIncomplete(self, buf, i) {
  var j = buf.length - 1;
  if (j < i) return 0;
  var nb = utf8CheckByte(buf[j]);
  if (nb >= 0) {
    if (nb > 0) self.lastNeed = nb - 1;
    return nb;
  }
  if (--j < i || nb === -2) return 0;
  nb = utf8CheckByte(buf[j]);
  if (nb >= 0) {
    if (nb > 0) self.lastNeed = nb - 2;
    return nb;
  }
  if (--j < i || nb === -2) return 0;
  nb = utf8CheckByte(buf[j]);
  if (nb >= 0) {
    if (nb > 0) {
      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;
    }
    return nb;
  }
  return 0;
}

// Validates as many continuation bytes for a multi-byte UTF-8 character as
// needed or are available. If we see a non-continuation byte where we expect
// one, we "replace" the validated continuation bytes we've seen so far with
// a single UTF-8 replacement character ('\ufffd'), to match v8's UTF-8 decoding
// behavior. The continuation byte check is included three times in the case
// where all of the continuation bytes for a character exist in the same buffer.
// It is also done this way as a slight performance increase instead of using a
// loop.
function utf8CheckExtraBytes(self, buf, p) {
  if ((buf[0] & 0xC0) !== 0x80) {
    self.lastNeed = 0;
    return '\ufffd';
  }
  if (self.lastNeed > 1 && buf.length > 1) {
    if ((buf[1] & 0xC0) !== 0x80) {
      self.lastNeed = 1;
      return '\ufffd';
    }
    if (self.lastNeed > 2 && buf.length > 2) {
      if ((buf[2] & 0xC0) !== 0x80) {
        self.lastNeed = 2;
        return '\ufffd';
      }
    }
  }
}

// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.
function utf8FillLast(buf) {
  var p = this.lastTotal - this.lastNeed;
  var r = utf8CheckExtraBytes(this, buf, p);
  if (r !== undefined) return r;
  if (this.lastNeed <= buf.length) {
    buf.copy(this.lastChar, p, 0, this.lastNeed);
    return this.lastChar.toString(this.encoding, 0, this.lastTotal);
  }
  buf.copy(this.lastChar, p, 0, buf.length);
  this.lastNeed -= buf.length;
}

// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a
// partial character, the character's bytes are buffered until the required
// number of bytes are available.
function utf8Text(buf, i) {
  var total = utf8CheckIncomplete(this, buf, i);
  if (!this.lastNeed) return buf.toString('utf8', i);
  this.lastTotal = total;
  var end = buf.length - (total - this.lastNeed);
  buf.copy(this.lastChar, 0, end);
  return buf.toString('utf8', i, end);
}

// For UTF-8, a replacement character is added when ending on a partial
// character.
function utf8End(buf) {
  var r = buf && buf.length ? this.write(buf) : '';
  if (this.lastNeed) return r + '\ufffd';
  return r;
}

// UTF-16LE typically needs two bytes per character, but even if we have an even
// number of bytes available, we need to check if we end on a leading/high
// surrogate. In that case, we need to wait for the next two bytes in order to
// decode the last character properly.
function utf16Text(buf, i) {
  if ((buf.length - i) % 2 === 0) {
    var r = buf.toString('utf16le', i);
    if (r) {
      var c = r.charCodeAt(r.length - 1);
      if (c >= 0xD800 && c <= 0xDBFF) {
        this.lastNeed = 2;
        this.lastTotal = 4;
        this.lastChar[0] = buf[buf.length - 2];
        this.lastChar[1] = buf[buf.length - 1];
        return r.slice(0, -1);
      }
    }
    return r;
  }
  this.lastNeed = 1;
  this.lastTotal = 2;
  this.lastChar[0] = buf[buf.length - 1];
  return buf.toString('utf16le', i, buf.length - 1);
}

// For UTF-16LE we do not explicitly append special replacement characters if we
// end on a partial character, we simply let v8 handle that.
function utf16End(buf) {
  var r = buf && buf.length ? this.write(buf) : '';
  if (this.lastNeed) {
    var end = this.lastTotal - this.lastNeed;
    return r + this.lastChar.toString('utf16le', 0, end);
  }
  return r;
}

function base64Text(buf, i) {
  var n = (buf.length - i) % 3;
  if (n === 0) return buf.toString('base64', i);
  this.lastNeed = 3 - n;
  this.lastTotal = 3;
  if (n === 1) {
    this.lastChar[0] = buf[buf.length - 1];
  } else {
    this.lastChar[0] = buf[buf.length - 2];
    this.lastChar[1] = buf[buf.length - 1];
  }
  return buf.toString('base64', i, buf.length - n);
}

function base64End(buf) {
  var r = buf && buf.length ? this.write(buf) : '';
  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);
  return r;
}

// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)
function simpleWrite(buf) {
  return buf.toString(this.encoding);
}

function simpleEnd(buf) {
  return buf && buf.length ? this.write(buf) : '';
}
},{"safe-buffer":90}],111:[function(require,module,exports){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

'use strict';

var punycode = require('punycode');
var util = require('./util');

exports.parse = urlParse;
exports.resolve = urlResolve;
exports.resolveObject = urlResolveObject;
exports.format = urlFormat;

exports.Url = Url;

function Url() {
  this.protocol = null;
  this.slashes = null;
  this.auth = null;
  this.host = null;
  this.port = null;
  this.hostname = null;
  this.hash = null;
  this.search = null;
  this.query = null;
  this.pathname = null;
  this.path = null;
  this.href = null;
}

// Reference: RFC 3986, RFC 1808, RFC 2396

// define these here so at least they only have to be
// compiled once on the first module load.
var protocolPattern = /^([a-z0-9.+-]+:)/i,
    portPattern = /:[0-9]*$/,

    // Special case for a simple path URL
    simplePathPattern = /^(\/\/?(?!\/)[^\?\s]*)(\?[^\s]*)?$/,

    // RFC 2396: characters reserved for delimiting URLs.
    // We actually just auto-escape these.
    delims = ['<', '>', '"', '`', ' ', '\r', '\n', '\t'],

    // RFC 2396: characters not allowed for various reasons.
    unwise = ['{', '}', '|', '\\', '^', '`'].concat(delims),

    // Allowed by RFCs, but cause of XSS attacks.  Always escape these.
    autoEscape = ['\''].concat(unwise),
    // Characters that are never ever allowed in a hostname.
    // Note that any invalid chars are also handled, but these
    // are the ones that are *expected* to be seen, so we fast-path
    // them.
    nonHostChars = ['%', '/', '?', ';', '#'].concat(autoEscape),
    hostEndingChars = ['/', '?', '#'],
    hostnameMaxLen = 255,
    hostnamePartPattern = /^[+a-z0-9A-Z_-]{0,63}$/,
    hostnamePartStart = /^([+a-z0-9A-Z_-]{0,63})(.*)$/,
    // protocols that can allow "unsafe" and "unwise" chars.
    unsafeProtocol = {
      'javascript': true,
      'javascript:': true
    },
    // protocols that never have a hostname.
    hostlessProtocol = {
      'javascript': true,
      'javascript:': true
    },
    // protocols that always contain a // bit.
    slashedProtocol = {
      'http': true,
      'https': true,
      'ftp': true,
      'gopher': true,
      'file': true,
      'http:': true,
      'https:': true,
      'ftp:': true,
      'gopher:': true,
      'file:': true
    },
    querystring = require('querystring');

function urlParse(url, parseQueryString, slashesDenoteHost) {
  if (url && util.isObject(url) && url instanceof Url) return url;

  var u = new Url;
  u.parse(url, parseQueryString, slashesDenoteHost);
  return u;
}

Url.prototype.parse = function(url, parseQueryString, slashesDenoteHost) {
  if (!util.isString(url)) {
    throw new TypeError("Parameter 'url' must be a string, not " + typeof url);
  }

  // Copy chrome, IE, opera backslash-handling behavior.
  // Back slashes before the query string get converted to forward slashes
  // See: https://code.google.com/p/chromium/issues/detail?id=25916
  var queryIndex = url.indexOf('?'),
      splitter =
          (queryIndex !== -1 && queryIndex < url.indexOf('#')) ? '?' : '#',
      uSplit = url.split(splitter),
      slashRegex = /\\/g;
  uSplit[0] = uSplit[0].replace(slashRegex, '/');
  url = uSplit.join(splitter);

  var rest = url;

  // trim before proceeding.
  // This is to support parse stuff like "  http://foo.com  \n"
  rest = rest.trim();

  if (!slashesDenoteHost && url.split('#').length === 1) {
    // Try fast path regexp
    var simplePath = simplePathPattern.exec(rest);
    if (simplePath) {
      this.path = rest;
      this.href = rest;
      this.pathname = simplePath[1];
      if (simplePath[2]) {
        this.search = simplePath[2];
        if (parseQueryString) {
          this.query = querystring.parse(this.search.substr(1));
        } else {
          this.query = this.search.substr(1);
        }
      } else if (parseQueryString) {
        this.search = '';
        this.query = {};
      }
      return this;
    }
  }

  var proto = protocolPattern.exec(rest);
  if (proto) {
    proto = proto[0];
    var lowerProto = proto.toLowerCase();
    this.protocol = lowerProto;
    rest = rest.substr(proto.length);
  }

  // figure out if it's got a host
  // user@server is *always* interpreted as a hostname, and url
  // resolution will treat //foo/bar as host=foo,path=bar because that's
  // how the browser resolves relative URLs.
  if (slashesDenoteHost || proto || rest.match(/^\/\/[^@\/]+@[^@\/]+/)) {
    var slashes = rest.substr(0, 2) === '//';
    if (slashes && !(proto && hostlessProtocol[proto])) {
      rest = rest.substr(2);
      this.slashes = true;
    }
  }

  if (!hostlessProtocol[proto] &&
      (slashes || (proto && !slashedProtocol[proto]))) {

    // there's a hostname.
    // the first instance of /, ?, ;, or # ends the host.
    //
    // If there is an @ in the hostname, then non-host chars *are* allowed
    // to the left of the last @ sign, unless some host-ending character
    // comes *before* the @-sign.
    // URLs are obnoxious.
    //
    // ex:
    // http://a@b@c/ => user:a@b host:c
    // http://a@b?@c => user:a host:c path:/?@c

    // v0.12 TODO(isaacs): This is not quite how Chrome does things.
    // Review our test case against browsers more comprehensively.

    // find the first instance of any hostEndingChars
    var hostEnd = -1;
    for (var i = 0; i < hostEndingChars.length; i++) {
      var hec = rest.indexOf(hostEndingChars[i]);
      if (hec !== -1 && (hostEnd === -1 || hec < hostEnd))
        hostEnd = hec;
    }

    // at this point, either we have an explicit point where the
    // auth portion cannot go past, or the last @ char is the decider.
    var auth, atSign;
    if (hostEnd === -1) {
      // atSign can be anywhere.
      atSign = rest.lastIndexOf('@');
    } else {
      // atSign must be in auth portion.
      // http://a@b/c@d => host:b auth:a path:/c@d
      atSign = rest.lastIndexOf('@', hostEnd);
    }

    // Now we have a portion which is definitely the auth.
    // Pull that off.
    if (atSign !== -1) {
      auth = rest.slice(0, atSign);
      rest = rest.slice(atSign + 1);
      this.auth = decodeURIComponent(auth);
    }

    // the host is the remaining to the left of the first non-host char
    hostEnd = -1;
    for (var i = 0; i < nonHostChars.length; i++) {
      var hec = rest.indexOf(nonHostChars[i]);
      if (hec !== -1 && (hostEnd === -1 || hec < hostEnd))
        hostEnd = hec;
    }
    // if we still have not hit it, then the entire thing is a host.
    if (hostEnd === -1)
      hostEnd = rest.length;

    this.host = rest.slice(0, hostEnd);
    rest = rest.slice(hostEnd);

    // pull out port.
    this.parseHost();

    // we've indicated that there is a hostname,
    // so even if it's empty, it has to be present.
    this.hostname = this.hostname || '';

    // if hostname begins with [ and ends with ]
    // assume that it's an IPv6 address.
    var ipv6Hostname = this.hostname[0] === '[' &&
        this.hostname[this.hostname.length - 1] === ']';

    // validate a little.
    if (!ipv6Hostname) {
      var hostparts = this.hostname.split(/\./);
      for (var i = 0, l = hostparts.length; i < l; i++) {
        var part = hostparts[i];
        if (!part) continue;
        if (!part.match(hostnamePartPattern)) {
          var newpart = '';
          for (var j = 0, k = part.length; j < k; j++) {
            if (part.charCodeAt(j) > 127) {
              // we replace non-ASCII char with a temporary placeholder
              // we need this to make sure size of hostname is not
              // broken by replacing non-ASCII by nothing
              newpart += 'x';
            } else {
              newpart += part[j];
            }
          }
          // we test again with ASCII char only
          if (!newpart.match(hostnamePartPattern)) {
            var validParts = hostparts.slice(0, i);
            var notHost = hostparts.slice(i + 1);
            var bit = part.match(hostnamePartStart);
            if (bit) {
              validParts.push(bit[1]);
              notHost.unshift(bit[2]);
            }
            if (notHost.length) {
              rest = '/' + notHost.join('.') + rest;
            }
            this.hostname = validParts.join('.');
            break;
          }
        }
      }
    }

    if (this.hostname.length > hostnameMaxLen) {
      this.hostname = '';
    } else {
      // hostnames are always lower case.
      this.hostname = this.hostname.toLowerCase();
    }

    if (!ipv6Hostname) {
      // IDNA Support: Returns a punycoded representation of "domain".
      // It only converts parts of the domain name that
      // have non-ASCII characters, i.e. it doesn't matter if
      // you call it with a domain that already is ASCII-only.
      this.hostname = punycode.toASCII(this.hostname);
    }

    var p = this.port ? ':' + this.port : '';
    var h = this.hostname || '';
    this.host = h + p;
    this.href += this.host;

    // strip [ and ] from the hostname
    // the host field still retains them, though
    if (ipv6Hostname) {
      this.hostname = this.hostname.substr(1, this.hostname.length - 2);
      if (rest[0] !== '/') {
        rest = '/' + rest;
      }
    }
  }

  // now rest is set to the post-host stuff.
  // chop off any delim chars.
  if (!unsafeProtocol[lowerProto]) {

    // First, make 100% sure that any "autoEscape" chars get
    // escaped, even if encodeURIComponent doesn't think they
    // need to be.
    for (var i = 0, l = autoEscape.length; i < l; i++) {
      var ae = autoEscape[i];
      if (rest.indexOf(ae) === -1)
        continue;
      var esc = encodeURIComponent(ae);
      if (esc === ae) {
        esc = escape(ae);
      }
      rest = rest.split(ae).join(esc);
    }
  }


  // chop off from the tail first.
  var hash = rest.indexOf('#');
  if (hash !== -1) {
    // got a fragment string.
    this.hash = rest.substr(hash);
    rest = rest.slice(0, hash);
  }
  var qm = rest.indexOf('?');
  if (qm !== -1) {
    this.search = rest.substr(qm);
    this.query = rest.substr(qm + 1);
    if (parseQueryString) {
      this.query = querystring.parse(this.query);
    }
    rest = rest.slice(0, qm);
  } else if (parseQueryString) {
    // no query string, but parseQueryString still requested
    this.search = '';
    this.query = {};
  }
  if (rest) this.pathname = rest;
  if (slashedProtocol[lowerProto] &&
      this.hostname && !this.pathname) {
    this.pathname = '/';
  }

  //to support http.request
  if (this.pathname || this.search) {
    var p = this.pathname || '';
    var s = this.search || '';
    this.path = p + s;
  }

  // finally, reconstruct the href based on what has been validated.
  this.href = this.format();
  return this;
};

// format a parsed object into a url string
function urlFormat(obj) {
  // ensure it's an object, and not a string url.
  // If it's an obj, this is a no-op.
  // this way, you can call url_format() on strings
  // to clean up potentially wonky urls.
  if (util.isString(obj)) obj = urlParse(obj);
  if (!(obj instanceof Url)) return Url.prototype.format.call(obj);
  return obj.format();
}

Url.prototype.format = function() {
  var auth = this.auth || '';
  if (auth) {
    auth = encodeURIComponent(auth);
    auth = auth.replace(/%3A/i, ':');
    auth += '@';
  }

  var protocol = this.protocol || '',
      pathname = this.pathname || '',
      hash = this.hash || '',
      host = false,
      query = '';

  if (this.host) {
    host = auth + this.host;
  } else if (this.hostname) {
    host = auth + (this.hostname.indexOf(':') === -1 ?
        this.hostname :
        '[' + this.hostname + ']');
    if (this.port) {
      host += ':' + this.port;
    }
  }

  if (this.query &&
      util.isObject(this.query) &&
      Object.keys(this.query).length) {
    query = querystring.stringify(this.query);
  }

  var search = this.search || (query && ('?' + query)) || '';

  if (protocol && protocol.substr(-1) !== ':') protocol += ':';

  // only the slashedProtocols get the //.  Not mailto:, xmpp:, etc.
  // unless they had them to begin with.
  if (this.slashes ||
      (!protocol || slashedProtocol[protocol]) && host !== false) {
    host = '//' + (host || '');
    if (pathname && pathname.charAt(0) !== '/') pathname = '/' + pathname;
  } else if (!host) {
    host = '';
  }

  if (hash && hash.charAt(0) !== '#') hash = '#' + hash;
  if (search && search.charAt(0) !== '?') search = '?' + search;

  pathname = pathname.replace(/[?#]/g, function(match) {
    return encodeURIComponent(match);
  });
  search = search.replace('#', '%23');

  return protocol + host + pathname + search + hash;
};

function urlResolve(source, relative) {
  return urlParse(source, false, true).resolve(relative);
}

Url.prototype.resolve = function(relative) {
  return this.resolveObject(urlParse(relative, false, true)).format();
};

function urlResolveObject(source, relative) {
  if (!source) return relative;
  return urlParse(source, false, true).resolveObject(relative);
}

Url.prototype.resolveObject = function(relative) {
  if (util.isString(relative)) {
    var rel = new Url();
    rel.parse(relative, false, true);
    relative = rel;
  }

  var result = new Url();
  var tkeys = Object.keys(this);
  for (var tk = 0; tk < tkeys.length; tk++) {
    var tkey = tkeys[tk];
    result[tkey] = this[tkey];
  }

  // hash is always overridden, no matter what.
  // even href="" will remove it.
  result.hash = relative.hash;

  // if the relative url is empty, then there's nothing left to do here.
  if (relative.href === '') {
    result.href = result.format();
    return result;
  }

  // hrefs like //foo/bar always cut to the protocol.
  if (relative.slashes && !relative.protocol) {
    // take everything except the protocol from relative
    var rkeys = Object.keys(relative);
    for (var rk = 0; rk < rkeys.length; rk++) {
      var rkey = rkeys[rk];
      if (rkey !== 'protocol')
        result[rkey] = relative[rkey];
    }

    //urlParse appends trailing / to urls like http://www.example.com
    if (slashedProtocol[result.protocol] &&
        result.hostname && !result.pathname) {
      result.path = result.pathname = '/';
    }

    result.href = result.format();
    return result;
  }

  if (relative.protocol && relative.protocol !== result.protocol) {
    // if it's a known url protocol, then changing
    // the protocol does weird things
    // first, if it's not file:, then we MUST have a host,
    // and if there was a path
    // to begin with, then we MUST have a path.
    // if it is file:, then the host is dropped,
    // because that's known to be hostless.
    // anything else is assumed to be absolute.
    if (!slashedProtocol[relative.protocol]) {
      var keys = Object.keys(relative);
      for (var v = 0; v < keys.length; v++) {
        var k = keys[v];
        result[k] = relative[k];
      }
      result.href = result.format();
      return result;
    }

    result.protocol = relative.protocol;
    if (!relative.host && !hostlessProtocol[relative.protocol]) {
      var relPath = (relative.pathname || '').split('/');
      while (relPath.length && !(relative.host = relPath.shift()));
      if (!relative.host) relative.host = '';
      if (!relative.hostname) relative.hostname = '';
      if (relPath[0] !== '') relPath.unshift('');
      if (relPath.length < 2) relPath.unshift('');
      result.pathname = relPath.join('/');
    } else {
      result.pathname = relative.pathname;
    }
    result.search = relative.search;
    result.query = relative.query;
    result.host = relative.host || '';
    result.auth = relative.auth;
    result.hostname = relative.hostname || relative.host;
    result.port = relative.port;
    // to support http.request
    if (result.pathname || result.search) {
      var p = result.pathname || '';
      var s = result.search || '';
      result.path = p + s;
    }
    result.slashes = result.slashes || relative.slashes;
    result.href = result.format();
    return result;
  }

  var isSourceAbs = (result.pathname && result.pathname.charAt(0) === '/'),
      isRelAbs = (
          relative.host ||
          relative.pathname && relative.pathname.charAt(0) === '/'
      ),
      mustEndAbs = (isRelAbs || isSourceAbs ||
                    (result.host && relative.pathname)),
      removeAllDots = mustEndAbs,
      srcPath = result.pathname && result.pathname.split('/') || [],
      relPath = relative.pathname && relative.pathname.split('/') || [],
      psychotic = result.protocol && !slashedProtocol[result.protocol];

  // if the url is a non-slashed url, then relative
  // links like ../.. should be able
  // to crawl up to the hostname, as well.  This is strange.
  // result.protocol has already been set by now.
  // Later on, put the first path part into the host field.
  if (psychotic) {
    result.hostname = '';
    result.port = null;
    if (result.host) {
      if (srcPath[0] === '') srcPath[0] = result.host;
      else srcPath.unshift(result.host);
    }
    result.host = '';
    if (relative.protocol) {
      relative.hostname = null;
      relative.port = null;
      if (relative.host) {
        if (relPath[0] === '') relPath[0] = relative.host;
        else relPath.unshift(relative.host);
      }
      relative.host = null;
    }
    mustEndAbs = mustEndAbs && (relPath[0] === '' || srcPath[0] === '');
  }

  if (isRelAbs) {
    // it's absolute.
    result.host = (relative.host || relative.host === '') ?
                  relative.host : result.host;
    result.hostname = (relative.hostname || relative.hostname === '') ?
                      relative.hostname : result.hostname;
    result.search = relative.search;
    result.query = relative.query;
    srcPath = relPath;
    // fall through to the dot-handling below.
  } else if (relPath.length) {
    // it's relative
    // throw away the existing file, and take the new path instead.
    if (!srcPath) srcPath = [];
    srcPath.pop();
    srcPath = srcPath.concat(relPath);
    result.search = relative.search;
    result.query = relative.query;
  } else if (!util.isNullOrUndefined(relative.search)) {
    // just pull out the search.
    // like href='?foo'.
    // Put this after the other two cases because it simplifies the booleans
    if (psychotic) {
      result.hostname = result.host = srcPath.shift();
      //occationaly the auth can get stuck only in host
      //this especially happens in cases like
      //url.resolveObject('mailto:local1@domain1', 'local2@domain2')
      var authInHost = result.host && result.host.indexOf('@') > 0 ?
                       result.host.split('@') : false;
      if (authInHost) {
        result.auth = authInHost.shift();
        result.host = result.hostname = authInHost.shift();
      }
    }
    result.search = relative.search;
    result.query = relative.query;
    //to support http.request
    if (!util.isNull(result.pathname) || !util.isNull(result.search)) {
      result.path = (result.pathname ? result.pathname : '') +
                    (result.search ? result.search : '');
    }
    result.href = result.format();
    return result;
  }

  if (!srcPath.length) {
    // no path at all.  easy.
    // we've already handled the other stuff above.
    result.pathname = null;
    //to support http.request
    if (result.search) {
      result.path = '/' + result.search;
    } else {
      result.path = null;
    }
    result.href = result.format();
    return result;
  }

  // if a url ENDs in . or .., then it must get a trailing slash.
  // however, if it ends in anything else non-slashy,
  // then it must NOT get a trailing slash.
  var last = srcPath.slice(-1)[0];
  var hasTrailingSlash = (
      (result.host || relative.host || srcPath.length > 1) &&
      (last === '.' || last === '..') || last === '');

  // strip single dots, resolve double dots to parent dir
  // if the path tries to go above the root, `up` ends up > 0
  var up = 0;
  for (var i = srcPath.length; i >= 0; i--) {
    last = srcPath[i];
    if (last === '.') {
      srcPath.splice(i, 1);
    } else if (last === '..') {
      srcPath.splice(i, 1);
      up++;
    } else if (up) {
      srcPath.splice(i, 1);
      up--;
    }
  }

  // if the path is allowed to go above the root, restore leading ..s
  if (!mustEndAbs && !removeAllDots) {
    for (; up--; up) {
      srcPath.unshift('..');
    }
  }

  if (mustEndAbs && srcPath[0] !== '' &&
      (!srcPath[0] || srcPath[0].charAt(0) !== '/')) {
    srcPath.unshift('');
  }

  if (hasTrailingSlash && (srcPath.join('/').substr(-1) !== '/')) {
    srcPath.push('');
  }

  var isAbsolute = srcPath[0] === '' ||
      (srcPath[0] && srcPath[0].charAt(0) === '/');

  // put the host back
  if (psychotic) {
    result.hostname = result.host = isAbsolute ? '' :
                                    srcPath.length ? srcPath.shift() : '';
    //occationaly the auth can get stuck only in host
    //this especially happens in cases like
    //url.resolveObject('mailto:local1@domain1', 'local2@domain2')
    var authInHost = result.host && result.host.indexOf('@') > 0 ?
                     result.host.split('@') : false;
    if (authInHost) {
      result.auth = authInHost.shift();
      result.host = result.hostname = authInHost.shift();
    }
  }

  mustEndAbs = mustEndAbs || (result.host && srcPath.length);

  if (mustEndAbs && !isAbsolute) {
    srcPath.unshift('');
  }

  if (!srcPath.length) {
    result.pathname = null;
    result.path = null;
  } else {
    result.pathname = srcPath.join('/');
  }

  //to support request.http
  if (!util.isNull(result.pathname) || !util.isNull(result.search)) {
    result.path = (result.pathname ? result.pathname : '') +
                  (result.search ? result.search : '');
  }
  result.auth = relative.auth || result.auth;
  result.slashes = result.slashes || relative.slashes;
  result.href = result.format();
  return result;
};

Url.prototype.parseHost = function() {
  var host = this.host;
  var port = portPattern.exec(host);
  if (port) {
    port = port[0];
    if (port !== ':') {
      this.port = port.substr(1);
    }
    host = host.substr(0, host.length - port.length);
  }
  if (host) this.hostname = host;
};

},{"./util":112,"punycode":75,"querystring":89}],112:[function(require,module,exports){
'use strict';

module.exports = {
  isString: function(arg) {
    return typeof(arg) === 'string';
  },
  isObject: function(arg) {
    return typeof(arg) === 'object' && arg !== null;
  },
  isNull: function(arg) {
    return arg === null;
  },
  isNullOrUndefined: function(arg) {
    return arg == null;
  }
};

},{}],113:[function(require,module,exports){
(function (global){

/**
 * Module exports.
 */

module.exports = deprecate;

/**
 * Mark that a method should not be used.
 * Returns a modified function which warns once by default.
 *
 * If `localStorage.noDeprecation = true` is set, then it is a no-op.
 *
 * If `localStorage.throwDeprecation = true` is set, then deprecated functions
 * will throw an Error when invoked.
 *
 * If `localStorage.traceDeprecation = true` is set, then deprecated functions
 * will invoke `console.trace()` instead of `console.error()`.
 *
 * @param {Function} fn - the function to deprecate
 * @param {String} msg - the string to print to the console when `fn` is invoked
 * @returns {Function} a new "deprecated" version of `fn`
 * @api public
 */

function deprecate (fn, msg) {
  if (config('noDeprecation')) {
    return fn;
  }

  var warned = false;
  function deprecated() {
    if (!warned) {
      if (config('throwDeprecation')) {
        throw new Error(msg);
      } else if (config('traceDeprecation')) {
        console.trace(msg);
      } else {
        console.warn(msg);
      }
      warned = true;
    }
    return fn.apply(this, arguments);
  }

  return deprecated;
}

/**
 * Checks `localStorage` for boolean values for the given `name`.
 *
 * @param {String} name
 * @returns {Boolean}
 * @api private
 */

function config (name) {
  // accessing global.localStorage can trigger a DOMException in sandboxed iframes
  try {
    if (!global.localStorage) return false;
  } catch (_) {
    return false;
  }
  var val = global.localStorage[name];
  if (null == val) return false;
  return String(val).toLowerCase() === 'true';
}

}).call(this,typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{}],114:[function(require,module,exports){
if (typeof Object.create === 'function') {
  // implementation from standard node.js 'util' module
  module.exports = function inherits(ctor, superCtor) {
    ctor.super_ = superCtor
    ctor.prototype = Object.create(superCtor.prototype, {
      constructor: {
        value: ctor,
        enumerable: false,
        writable: true,
        configurable: true
      }
    });
  };
} else {
  // old school shim for old browsers
  module.exports = function inherits(ctor, superCtor) {
    ctor.super_ = superCtor
    var TempCtor = function () {}
    TempCtor.prototype = superCtor.prototype
    ctor.prototype = new TempCtor()
    ctor.prototype.constructor = ctor
  }
}

},{}],115:[function(require,module,exports){
module.exports = function isBuffer(arg) {
  return arg && typeof arg === 'object'
    && typeof arg.copy === 'function'
    && typeof arg.fill === 'function'
    && typeof arg.readUInt8 === 'function';
}
},{}],116:[function(require,module,exports){
(function (process,global){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

var formatRegExp = /%[sdj%]/g;
exports.format = function(f) {
  if (!isString(f)) {
    var objects = [];
    for (var i = 0; i < arguments.length; i++) {
      objects.push(inspect(arguments[i]));
    }
    return objects.join(' ');
  }

  var i = 1;
  var args = arguments;
  var len = args.length;
  var str = String(f).replace(formatRegExp, function(x) {
    if (x === '%%') return '%';
    if (i >= len) return x;
    switch (x) {
      case '%s': return String(args[i++]);
      case '%d': return Number(args[i++]);
      case '%j':
        try {
          return JSON.stringify(args[i++]);
        } catch (_) {
          return '[Circular]';
        }
      default:
        return x;
    }
  });
  for (var x = args[i]; i < len; x = args[++i]) {
    if (isNull(x) || !isObject(x)) {
      str += ' ' + x;
    } else {
      str += ' ' + inspect(x);
    }
  }
  return str;
};


// Mark that a method should not be used.
// Returns a modified function which warns once by default.
// If --no-deprecation is set, then it is a no-op.
exports.deprecate = function(fn, msg) {
  // Allow for deprecating things in the process of starting up.
  if (isUndefined(global.process)) {
    return function() {
      return exports.deprecate(fn, msg).apply(this, arguments);
    };
  }

  if (process.noDeprecation === true) {
    return fn;
  }

  var warned = false;
  function deprecated() {
    if (!warned) {
      if (process.throwDeprecation) {
        throw new Error(msg);
      } else if (process.traceDeprecation) {
        console.trace(msg);
      } else {
        console.error(msg);
      }
      warned = true;
    }
    return fn.apply(this, arguments);
  }

  return deprecated;
};


var debugs = {};
var debugEnviron;
exports.debuglog = function(set) {
  if (isUndefined(debugEnviron))
    debugEnviron = process.env.NODE_DEBUG || '';
  set = set.toUpperCase();
  if (!debugs[set]) {
    if (new RegExp('\\b' + set + '\\b', 'i').test(debugEnviron)) {
      var pid = process.pid;
      debugs[set] = function() {
        var msg = exports.format.apply(exports, arguments);
        console.error('%s %d: %s', set, pid, msg);
      };
    } else {
      debugs[set] = function() {};
    }
  }
  return debugs[set];
};


/**
 * Echos the value of a value. Trys to print the value out
 * in the best way possible given the different types.
 *
 * @param {Object} obj The object to print out.
 * @param {Object} opts Optional options object that alters the output.
 */
/* legacy: obj, showHidden, depth, colors*/
function inspect(obj, opts) {
  // default options
  var ctx = {
    seen: [],
    stylize: stylizeNoColor
  };
  // legacy...
  if (arguments.length >= 3) ctx.depth = arguments[2];
  if (arguments.length >= 4) ctx.colors = arguments[3];
  if (isBoolean(opts)) {
    // legacy...
    ctx.showHidden = opts;
  } else if (opts) {
    // got an "options" object
    exports._extend(ctx, opts);
  }
  // set default options
  if (isUndefined(ctx.showHidden)) ctx.showHidden = false;
  if (isUndefined(ctx.depth)) ctx.depth = 2;
  if (isUndefined(ctx.colors)) ctx.colors = false;
  if (isUndefined(ctx.customInspect)) ctx.customInspect = true;
  if (ctx.colors) ctx.stylize = stylizeWithColor;
  return formatValue(ctx, obj, ctx.depth);
}
exports.inspect = inspect;


// http://en.wikipedia.org/wiki/ANSI_escape_code#graphics
inspect.colors = {
  'bold' : [1, 22],
  'italic' : [3, 23],
  'underline' : [4, 24],
  'inverse' : [7, 27],
  'white' : [37, 39],
  'grey' : [90, 39],
  'black' : [30, 39],
  'blue' : [34, 39],
  'cyan' : [36, 39],
  'green' : [32, 39],
  'magenta' : [35, 39],
  'red' : [31, 39],
  'yellow' : [33, 39]
};

// Don't use 'blue' not visible on cmd.exe
inspect.styles = {
  'special': 'cyan',
  'number': 'yellow',
  'boolean': 'yellow',
  'undefined': 'grey',
  'null': 'bold',
  'string': 'green',
  'date': 'magenta',
  // "name": intentionally not styling
  'regexp': 'red'
};


function stylizeWithColor(str, styleType) {
  var style = inspect.styles[styleType];

  if (style) {
    return '\u001b[' + inspect.colors[style][0] + 'm' + str +
           '\u001b[' + inspect.colors[style][1] + 'm';
  } else {
    return str;
  }
}


function stylizeNoColor(str, styleType) {
  return str;
}


function arrayToHash(array) {
  var hash = {};

  array.forEach(function(val, idx) {
    hash[val] = true;
  });

  return hash;
}


function formatValue(ctx, value, recurseTimes) {
  // Provide a hook for user-specified inspect functions.
  // Check that value is an object with an inspect function on it
  if (ctx.customInspect &&
      value &&
      isFunction(value.inspect) &&
      // Filter out the util module, it's inspect function is special
      value.inspect !== exports.inspect &&
      // Also filter out any prototype objects using the circular check.
      !(value.constructor && value.constructor.prototype === value)) {
    var ret = value.inspect(recurseTimes, ctx);
    if (!isString(ret)) {
      ret = formatValue(ctx, ret, recurseTimes);
    }
    return ret;
  }

  // Primitive types cannot have properties
  var primitive = formatPrimitive(ctx, value);
  if (primitive) {
    return primitive;
  }

  // Look up the keys of the object.
  var keys = Object.keys(value);
  var visibleKeys = arrayToHash(keys);

  if (ctx.showHidden) {
    keys = Object.getOwnPropertyNames(value);
  }

  // IE doesn't make error fields non-enumerable
  // http://msdn.microsoft.com/en-us/library/ie/dww52sbt(v=vs.94).aspx
  if (isError(value)
      && (keys.indexOf('message') >= 0 || keys.indexOf('description') >= 0)) {
    return formatError(value);
  }

  // Some type of object without properties can be shortcutted.
  if (keys.length === 0) {
    if (isFunction(value)) {
      var name = value.name ? ': ' + value.name : '';
      return ctx.stylize('[Function' + name + ']', 'special');
    }
    if (isRegExp(value)) {
      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');
    }
    if (isDate(value)) {
      return ctx.stylize(Date.prototype.toString.call(value), 'date');
    }
    if (isError(value)) {
      return formatError(value);
    }
  }

  var base = '', array = false, braces = ['{', '}'];

  // Make Array say that they are Array
  if (isArray(value)) {
    array = true;
    braces = ['[', ']'];
  }

  // Make functions say that they are functions
  if (isFunction(value)) {
    var n = value.name ? ': ' + value.name : '';
    base = ' [Function' + n + ']';
  }

  // Make RegExps say that they are RegExps
  if (isRegExp(value)) {
    base = ' ' + RegExp.prototype.toString.call(value);
  }

  // Make dates with properties first say the date
  if (isDate(value)) {
    base = ' ' + Date.prototype.toUTCString.call(value);
  }

  // Make error with message first say the error
  if (isError(value)) {
    base = ' ' + formatError(value);
  }

  if (keys.length === 0 && (!array || value.length == 0)) {
    return braces[0] + base + braces[1];
  }

  if (recurseTimes < 0) {
    if (isRegExp(value)) {
      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');
    } else {
      return ctx.stylize('[Object]', 'special');
    }
  }

  ctx.seen.push(value);

  var output;
  if (array) {
    output = formatArray(ctx, value, recurseTimes, visibleKeys, keys);
  } else {
    output = keys.map(function(key) {
      return formatProperty(ctx, value, recurseTimes, visibleKeys, key, array);
    });
  }

  ctx.seen.pop();

  return reduceToSingleString(output, base, braces);
}


function formatPrimitive(ctx, value) {
  if (isUndefined(value))
    return ctx.stylize('undefined', 'undefined');
  if (isString(value)) {
    var simple = '\'' + JSON.stringify(value).replace(/^"|"$/g, '')
                                             .replace(/'/g, "\\'")
                                             .replace(/\\"/g, '"') + '\'';
    return ctx.stylize(simple, 'string');
  }
  if (isNumber(value))
    return ctx.stylize('' + value, 'number');
  if (isBoolean(value))
    return ctx.stylize('' + value, 'boolean');
  // For some reason typeof null is "object", so special case here.
  if (isNull(value))
    return ctx.stylize('null', 'null');
}


function formatError(value) {
  return '[' + Error.prototype.toString.call(value) + ']';
}


function formatArray(ctx, value, recurseTimes, visibleKeys, keys) {
  var output = [];
  for (var i = 0, l = value.length; i < l; ++i) {
    if (hasOwnProperty(value, String(i))) {
      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,
          String(i), true));
    } else {
      output.push('');
    }
  }
  keys.forEach(function(key) {
    if (!key.match(/^\d+$/)) {
      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,
          key, true));
    }
  });
  return output;
}


function formatProperty(ctx, value, recurseTimes, visibleKeys, key, array) {
  var name, str, desc;
  desc = Object.getOwnPropertyDescriptor(value, key) || { value: value[key] };
  if (desc.get) {
    if (desc.set) {
      str = ctx.stylize('[Getter/Setter]', 'special');
    } else {
      str = ctx.stylize('[Getter]', 'special');
    }
  } else {
    if (desc.set) {
      str = ctx.stylize('[Setter]', 'special');
    }
  }
  if (!hasOwnProperty(visibleKeys, key)) {
    name = '[' + key + ']';
  }
  if (!str) {
    if (ctx.seen.indexOf(desc.value) < 0) {
      if (isNull(recurseTimes)) {
        str = formatValue(ctx, desc.value, null);
      } else {
        str = formatValue(ctx, desc.value, recurseTimes - 1);
      }
      if (str.indexOf('\n') > -1) {
        if (array) {
          str = str.split('\n').map(function(line) {
            return '  ' + line;
          }).join('\n').substr(2);
        } else {
          str = '\n' + str.split('\n').map(function(line) {
            return '   ' + line;
          }).join('\n');
        }
      }
    } else {
      str = ctx.stylize('[Circular]', 'special');
    }
  }
  if (isUndefined(name)) {
    if (array && key.match(/^\d+$/)) {
      return str;
    }
    name = JSON.stringify('' + key);
    if (name.match(/^"([a-zA-Z_][a-zA-Z_0-9]*)"$/)) {
      name = name.substr(1, name.length - 2);
      name = ctx.stylize(name, 'name');
    } else {
      name = name.replace(/'/g, "\\'")
                 .replace(/\\"/g, '"')
                 .replace(/(^"|"$)/g, "'");
      name = ctx.stylize(name, 'string');
    }
  }

  return name + ': ' + str;
}


function reduceToSingleString(output, base, braces) {
  var numLinesEst = 0;
  var length = output.reduce(function(prev, cur) {
    numLinesEst++;
    if (cur.indexOf('\n') >= 0) numLinesEst++;
    return prev + cur.replace(/\u001b\[\d\d?m/g, '').length + 1;
  }, 0);

  if (length > 60) {
    return braces[0] +
           (base === '' ? '' : base + '\n ') +
           ' ' +
           output.join(',\n  ') +
           ' ' +
           braces[1];
  }

  return braces[0] + base + ' ' + output.join(', ') + ' ' + braces[1];
}


// NOTE: These type checking functions intentionally don't use `instanceof`
// because it is fragile and can be easily faked with `Object.create()`.
function isArray(ar) {
  return Array.isArray(ar);
}
exports.isArray = isArray;

function isBoolean(arg) {
  return typeof arg === 'boolean';
}
exports.isBoolean = isBoolean;

function isNull(arg) {
  return arg === null;
}
exports.isNull = isNull;

function isNullOrUndefined(arg) {
  return arg == null;
}
exports.isNullOrUndefined = isNullOrUndefined;

function isNumber(arg) {
  return typeof arg === 'number';
}
exports.isNumber = isNumber;

function isString(arg) {
  return typeof arg === 'string';
}
exports.isString = isString;

function isSymbol(arg) {
  return typeof arg === 'symbol';
}
exports.isSymbol = isSymbol;

function isUndefined(arg) {
  return arg === void 0;
}
exports.isUndefined = isUndefined;

function isRegExp(re) {
  return isObject(re) && objectToString(re) === '[object RegExp]';
}
exports.isRegExp = isRegExp;

function isObject(arg) {
  return typeof arg === 'object' && arg !== null;
}
exports.isObject = isObject;

function isDate(d) {
  return isObject(d) && objectToString(d) === '[object Date]';
}
exports.isDate = isDate;

function isError(e) {
  return isObject(e) &&
      (objectToString(e) === '[object Error]' || e instanceof Error);
}
exports.isError = isError;

function isFunction(arg) {
  return typeof arg === 'function';
}
exports.isFunction = isFunction;

function isPrimitive(arg) {
  return arg === null ||
         typeof arg === 'boolean' ||
         typeof arg === 'number' ||
         typeof arg === 'string' ||
         typeof arg === 'symbol' ||  // ES6 symbol
         typeof arg === 'undefined';
}
exports.isPrimitive = isPrimitive;

exports.isBuffer = require('./support/isBuffer');

function objectToString(o) {
  return Object.prototype.toString.call(o);
}


function pad(n) {
  return n < 10 ? '0' + n.toString(10) : n.toString(10);
}


var months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep',
              'Oct', 'Nov', 'Dec'];

// 26 Feb 16:19:34
function timestamp() {
  var d = new Date();
  var time = [pad(d.getHours()),
              pad(d.getMinutes()),
              pad(d.getSeconds())].join(':');
  return [d.getDate(), months[d.getMonth()], time].join(' ');
}


// log is just a thin wrapper to console.log that prepends a timestamp
exports.log = function() {
  console.log('%s - %s', timestamp(), exports.format.apply(exports, arguments));
};


/**
 * Inherit the prototype methods from one constructor into another.
 *
 * The Function.prototype.inherits from lang.js rewritten as a standalone
 * function (not on Function.prototype). NOTE: If this file is to be loaded
 * during bootstrapping this function needs to be rewritten using some native
 * functions as prototype setup using normal JavaScript does not work as
 * expected during bootstrapping (see mirror.js in r114903).
 *
 * @param {function} ctor Constructor function which needs to inherit the
 *     prototype.
 * @param {function} superCtor Constructor function to inherit prototype from.
 */
exports.inherits = require('inherits');

exports._extend = function(origin, add) {
  // Don't do anything if add isn't an object
  if (!add || !isObject(add)) return origin;

  var keys = Object.keys(add);
  var i = keys.length;
  while (i--) {
    origin[keys[i]] = add[keys[i]];
  }
  return origin;
};

function hasOwnProperty(obj, prop) {
  return Object.prototype.hasOwnProperty.call(obj, prop);
}

}).call(this,require('_process'),typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{"./support/isBuffer":115,"_process":86,"inherits":114}],117:[function(require,module,exports){
"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = void 0;

/**
 * Convert array of 16 byte values to UUID string format of the form:
 * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX
 */
const byteToHex = [];

for (let i = 0; i < 256; ++i) {
  byteToHex.push((i + 0x100).toString(16).substr(1));
}

function bytesToUuid(buf, offset) {
  const i = offset || 0;
  const bth = byteToHex; // Note: Be careful editing this code!  It's been tuned for performance
  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434

  return (bth[buf[i + 0]] + bth[buf[i + 1]] + bth[buf[i + 2]] + bth[buf[i + 3]] + '-' + bth[buf[i + 4]] + bth[buf[i + 5]] + '-' + bth[buf[i + 6]] + bth[buf[i + 7]] + '-' + bth[buf[i + 8]] + bth[buf[i + 9]] + '-' + bth[buf[i + 10]] + bth[buf[i + 11]] + bth[buf[i + 12]] + bth[buf[i + 13]] + bth[buf[i + 14]] + bth[buf[i + 15]]).toLowerCase();
}

var _default = bytesToUuid;
exports.default = _default;
},{}],118:[function(require,module,exports){
"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
Object.defineProperty(exports, "v1", {
  enumerable: true,
  get: function () {
    return _v.default;
  }
});
Object.defineProperty(exports, "v3", {
  enumerable: true,
  get: function () {
    return _v2.default;
  }
});
Object.defineProperty(exports, "v4", {
  enumerable: true,
  get: function () {
    return _v3.default;
  }
});
Object.defineProperty(exports, "v5", {
  enumerable: true,
  get: function () {
    return _v4.default;
  }
});

var _v = _interopRequireDefault(require("./v1.js"));

var _v2 = _interopRequireDefault(require("./v3.js"));

var _v3 = _interopRequireDefault(require("./v4.js"));

var _v4 = _interopRequireDefault(require("./v5.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }
},{"./v1.js":122,"./v3.js":123,"./v4.js":125,"./v5.js":126}],119:[function(require,module,exports){
"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = void 0;

/*
 * Browser-compatible JavaScript MD5
 *
 * Modification of JavaScript MD5
 * https://github.com/blueimp/JavaScript-MD5
 *
 * Copyright 2011, Sebastian Tschan
 * https://blueimp.net
 *
 * Licensed under the MIT license:
 * https://opensource.org/licenses/MIT
 *
 * Based on
 * A JavaScript implementation of the RSA Data Security, Inc. MD5 Message
 * Digest Algorithm, as defined in RFC 1321.
 * Version 2.2 Copyright (C) Paul Johnston 1999 - 2009
 * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet
 * Distributed under the BSD License
 * See http://pajhome.org.uk/crypt/md5 for more info.
 */
function md5(bytes) {
  if (typeof bytes === 'string') {
    const msg = unescape(encodeURIComponent(bytes)); // UTF8 escape

    bytes = new Uint8Array(msg.length);

    for (let i = 0; i < msg.length; ++i) {
      bytes[i] = msg.charCodeAt(i);
    }
  }

  return md5ToHexEncodedArray(wordsToMd5(bytesToWords(bytes), bytes.length * 8));
}
/*
 * Convert an array of little-endian words to an array of bytes
 */


function md5ToHexEncodedArray(input) {
  const output = [];
  const length32 = input.length * 32;
  const hexTab = '0123456789abcdef';

  for (let i = 0; i < length32; i += 8) {
    const x = input[i >> 5] >>> i % 32 & 0xff;
    const hex = parseInt(hexTab.charAt(x >>> 4 & 0x0f) + hexTab.charAt(x & 0x0f), 16);
    output.push(hex);
  }

  return output;
}
/**
 * Calculate output length with padding and bit length
 */


function getOutputLength(inputLength8) {
  return (inputLength8 + 64 >>> 9 << 4) + 14 + 1;
}
/*
 * Calculate the MD5 of an array of little-endian words, and a bit length.
 */


function wordsToMd5(x, len) {
  /* append padding */
  x[len >> 5] |= 0x80 << len % 32;
  x[getOutputLength(len) - 1] = len;
  let a = 1732584193;
  let b = -271733879;
  let c = -1732584194;
  let d = 271733878;

  for (let i = 0; i < x.length; i += 16) {
    const olda = a;
    const oldb = b;
    const oldc = c;
    const oldd = d;
    a = md5ff(a, b, c, d, x[i], 7, -680876936);
    d = md5ff(d, a, b, c, x[i + 1], 12, -389564586);
    c = md5ff(c, d, a, b, x[i + 2], 17, 606105819);
    b = md5ff(b, c, d, a, x[i + 3], 22, -1044525330);
    a = md5ff(a, b, c, d, x[i + 4], 7, -176418897);
    d = md5ff(d, a, b, c, x[i + 5], 12, 1200080426);
    c = md5ff(c, d, a, b, x[i + 6], 17, -1473231341);
    b = md5ff(b, c, d, a, x[i + 7], 22, -45705983);
    a = md5ff(a, b, c, d, x[i + 8], 7, 1770035416);
    d = md5ff(d, a, b, c, x[i + 9], 12, -1958414417);
    c = md5ff(c, d, a, b, x[i + 10], 17, -42063);
    b = md5ff(b, c, d, a, x[i + 11], 22, -1990404162);
    a = md5ff(a, b, c, d, x[i + 12], 7, 1804603682);
    d = md5ff(d, a, b, c, x[i + 13], 12, -40341101);
    c = md5ff(c, d, a, b, x[i + 14], 17, -1502002290);
    b = md5ff(b, c, d, a, x[i + 15], 22, 1236535329);
    a = md5gg(a, b, c, d, x[i + 1], 5, -165796510);
    d = md5gg(d, a, b, c, x[i + 6], 9, -1069501632);
    c = md5gg(c, d, a, b, x[i + 11], 14, 643717713);
    b = md5gg(b, c, d, a, x[i], 20, -373897302);
    a = md5gg(a, b, c, d, x[i + 5], 5, -701558691);
    d = md5gg(d, a, b, c, x[i + 10], 9, 38016083);
    c = md5gg(c, d, a, b, x[i + 15], 14, -660478335);
    b = md5gg(b, c, d, a, x[i + 4], 20, -405537848);
    a = md5gg(a, b, c, d, x[i + 9], 5, 568446438);
    d = md5gg(d, a, b, c, x[i + 14], 9, -1019803690);
    c = md5gg(c, d, a, b, x[i + 3], 14, -187363961);
    b = md5gg(b, c, d, a, x[i + 8], 20, 1163531501);
    a = md5gg(a, b, c, d, x[i + 13], 5, -1444681467);
    d = md5gg(d, a, b, c, x[i + 2], 9, -51403784);
    c = md5gg(c, d, a, b, x[i + 7], 14, 1735328473);
    b = md5gg(b, c, d, a, x[i + 12], 20, -1926607734);
    a = md5hh(a, b, c, d, x[i + 5], 4, -378558);
    d = md5hh(d, a, b, c, x[i + 8], 11, -2022574463);
    c = md5hh(c, d, a, b, x[i + 11], 16, 1839030562);
    b = md5hh(b, c, d, a, x[i + 14], 23, -35309556);
    a = md5hh(a, b, c, d, x[i + 1], 4, -1530992060);
    d = md5hh(d, a, b, c, x[i + 4], 11, 1272893353);
    c = md5hh(c, d, a, b, x[i + 7], 16, -155497632);
    b = md5hh(b, c, d, a, x[i + 10], 23, -1094730640);
    a = md5hh(a, b, c, d, x[i + 13], 4, 681279174);
    d = md5hh(d, a, b, c, x[i], 11, -358537222);
    c = md5hh(c, d, a, b, x[i + 3], 16, -722521979);
    b = md5hh(b, c, d, a, x[i + 6], 23, 76029189);
    a = md5hh(a, b, c, d, x[i + 9], 4, -640364487);
    d = md5hh(d, a, b, c, x[i + 12], 11, -421815835);
    c = md5hh(c, d, a, b, x[i + 15], 16, 530742520);
    b = md5hh(b, c, d, a, x[i + 2], 23, -995338651);
    a = md5ii(a, b, c, d, x[i], 6, -198630844);
    d = md5ii(d, a, b, c, x[i + 7], 10, 1126891415);
    c = md5ii(c, d, a, b, x[i + 14], 15, -1416354905);
    b = md5ii(b, c, d, a, x[i + 5], 21, -57434055);
    a = md5ii(a, b, c, d, x[i + 12], 6, 1700485571);
    d = md5ii(d, a, b, c, x[i + 3], 10, -1894986606);
    c = md5ii(c, d, a, b, x[i + 10], 15, -1051523);
    b = md5ii(b, c, d, a, x[i + 1], 21, -2054922799);
    a = md5ii(a, b, c, d, x[i + 8], 6, 1873313359);
    d = md5ii(d, a, b, c, x[i + 15], 10, -30611744);
    c = md5ii(c, d, a, b, x[i + 6], 15, -1560198380);
    b = md5ii(b, c, d, a, x[i + 13], 21, 1309151649);
    a = md5ii(a, b, c, d, x[i + 4], 6, -145523070);
    d = md5ii(d, a, b, c, x[i + 11], 10, -1120210379);
    c = md5ii(c, d, a, b, x[i + 2], 15, 718787259);
    b = md5ii(b, c, d, a, x[i + 9], 21, -343485551);
    a = safeAdd(a, olda);
    b = safeAdd(b, oldb);
    c = safeAdd(c, oldc);
    d = safeAdd(d, oldd);
  }

  return [a, b, c, d];
}
/*
 * Convert an array bytes to an array of little-endian words
 * Characters >255 have their high-byte silently ignored.
 */


function bytesToWords(input) {
  if (input.length === 0) {
    return [];
  }

  const length8 = input.length * 8;
  const output = new Uint32Array(getOutputLength(length8));

  for (let i = 0; i < length8; i += 8) {
    output[i >> 5] |= (input[i / 8] & 0xff) << i % 32;
  }

  return output;
}
/*
 * Add integers, wrapping at 2^32. This uses 16-bit operations internally
 * to work around bugs in some JS interpreters.
 */


function safeAdd(x, y) {
  const lsw = (x & 0xffff) + (y & 0xffff);
  const msw = (x >> 16) + (y >> 16) + (lsw >> 16);
  return msw << 16 | lsw & 0xffff;
}
/*
 * Bitwise rotate a 32-bit number to the left.
 */


function bitRotateLeft(num, cnt) {
  return num << cnt | num >>> 32 - cnt;
}
/*
 * These functions implement the four basic operations the algorithm uses.
 */


function md5cmn(q, a, b, x, s, t) {
  return safeAdd(bitRotateLeft(safeAdd(safeAdd(a, q), safeAdd(x, t)), s), b);
}

function md5ff(a, b, c, d, x, s, t) {
  return md5cmn(b & c | ~b & d, a, b, x, s, t);
}

function md5gg(a, b, c, d, x, s, t) {
  return md5cmn(b & d | c & ~d, a, b, x, s, t);
}

function md5hh(a, b, c, d, x, s, t) {
  return md5cmn(b ^ c ^ d, a, b, x, s, t);
}

function md5ii(a, b, c, d, x, s, t) {
  return md5cmn(c ^ (b | ~d), a, b, x, s, t);
}

var _default = md5;
exports.default = _default;
},{}],120:[function(require,module,exports){
"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = rng;
// Unique ID creation requires a high quality random # generator. In the browser we therefore
// require the crypto API and do not support built-in fallback to lower quality random number
// generators (like Math.random()).
// getRandomValues needs to be invoked in a context where "this" is a Crypto implementation. Also,
// find the complete implementation of crypto (msCrypto) on IE11.
const getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto) || typeof msCrypto !== 'undefined' && typeof msCrypto.getRandomValues === 'function' && msCrypto.getRandomValues.bind(msCrypto);
const rnds8 = new Uint8Array(16);

function rng() {
  if (!getRandomValues) {
    throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');
  }

  return getRandomValues(rnds8);
}
},{}],121:[function(require,module,exports){
"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = void 0;

// Adapted from Chris Veness' SHA1 code at
// http://www.movable-type.co.uk/scripts/sha1.html
function f(s, x, y, z) {
  switch (s) {
    case 0:
      return x & y ^ ~x & z;

    case 1:
      return x ^ y ^ z;

    case 2:
      return x & y ^ x & z ^ y & z;

    case 3:
      return x ^ y ^ z;
  }
}

function ROTL(x, n) {
  return x << n | x >>> 32 - n;
}

function sha1(bytes) {
  const K = [0x5a827999, 0x6ed9eba1, 0x8f1bbcdc, 0xca62c1d6];
  const H = [0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476, 0xc3d2e1f0];

  if (typeof bytes === 'string') {
    const msg = unescape(encodeURIComponent(bytes)); // UTF8 escape

    bytes = [];

    for (let i = 0; i < msg.length; ++i) {
      bytes.push(msg.charCodeAt(i));
    }
  }

  bytes.push(0x80);
  const l = bytes.length / 4 + 2;
  const N = Math.ceil(l / 16);
  const M = new Array(N);

  for (let i = 0; i < N; ++i) {
    const arr = new Uint32Array(16);

    for (let j = 0; j < 16; ++j) {
      arr[j] = bytes[i * 64 + j * 4] << 24 | bytes[i * 64 + j * 4 + 1] << 16 | bytes[i * 64 + j * 4 + 2] << 8 | bytes[i * 64 + j * 4 + 3];
    }

    M[i] = arr;
  }

  M[N - 1][14] = (bytes.length - 1) * 8 / Math.pow(2, 32);
  M[N - 1][14] = Math.floor(M[N - 1][14]);
  M[N - 1][15] = (bytes.length - 1) * 8 & 0xffffffff;

  for (let i = 0; i < N; ++i) {
    const W = new Uint32Array(80);

    for (let t = 0; t < 16; ++t) {
      W[t] = M[i][t];
    }

    for (let t = 16; t < 80; ++t) {
      W[t] = ROTL(W[t - 3] ^ W[t - 8] ^ W[t - 14] ^ W[t - 16], 1);
    }

    let a = H[0];
    let b = H[1];
    let c = H[2];
    let d = H[3];
    let e = H[4];

    for (let t = 0; t < 80; ++t) {
      const s = Math.floor(t / 20);
      const T = ROTL(a, 5) + f(s, b, c, d) + e + K[s] + W[t] >>> 0;
      e = d;
      d = c;
      c = ROTL(b, 30) >>> 0;
      b = a;
      a = T;
    }

    H[0] = H[0] + a >>> 0;
    H[1] = H[1] + b >>> 0;
    H[2] = H[2] + c >>> 0;
    H[3] = H[3] + d >>> 0;
    H[4] = H[4] + e >>> 0;
  }

  return [H[0] >> 24 & 0xff, H[0] >> 16 & 0xff, H[0] >> 8 & 0xff, H[0] & 0xff, H[1] >> 24 & 0xff, H[1] >> 16 & 0xff, H[1] >> 8 & 0xff, H[1] & 0xff, H[2] >> 24 & 0xff, H[2] >> 16 & 0xff, H[2] >> 8 & 0xff, H[2] & 0xff, H[3] >> 24 & 0xff, H[3] >> 16 & 0xff, H[3] >> 8 & 0xff, H[3] & 0xff, H[4] >> 24 & 0xff, H[4] >> 16 & 0xff, H[4] >> 8 & 0xff, H[4] & 0xff];
}

var _default = sha1;
exports.default = _default;
},{}],122:[function(require,module,exports){
"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = void 0;

var _rng = _interopRequireDefault(require("./rng.js"));

var _bytesToUuid = _interopRequireDefault(require("./bytesToUuid.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

// **`v1()` - Generate time-based UUID**
//
// Inspired by https://github.com/LiosK/UUID.js
// and http://docs.python.org/library/uuid.html
let _nodeId;

let _clockseq; // Previous uuid creation time


let _lastMSecs = 0;
let _lastNSecs = 0; // See https://github.com/uuidjs/uuid for API details

function v1(options, buf, offset) {
  let i = buf && offset || 0;
  const b = buf || [];
  options = options || {};
  let node = options.node || _nodeId;
  let clockseq = options.clockseq !== undefined ? options.clockseq : _clockseq; // node and clockseq need to be initialized to random values if they're not
  // specified.  We do this lazily to minimize issues related to insufficient
  // system entropy.  See #189

  if (node == null || clockseq == null) {
    const seedBytes = options.random || (options.rng || _rng.default)();

    if (node == null) {
      // Per 4.5, create and 48-bit node id, (47 random bits + multicast bit = 1)
      node = _nodeId = [seedBytes[0] | 0x01, seedBytes[1], seedBytes[2], seedBytes[3], seedBytes[4], seedBytes[5]];
    }

    if (clockseq == null) {
      // Per 4.2.2, randomize (14 bit) clockseq
      clockseq = _clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 0x3fff;
    }
  } // UUID timestamps are 100 nano-second units since the Gregorian epoch,
  // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so
  // time is handled internally as 'msecs' (integer milliseconds) and 'nsecs'
  // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.


  let msecs = options.msecs !== undefined ? options.msecs : Date.now(); // Per 4.2.1.2, use count of uuid's generated during the current clock
  // cycle to simulate higher resolution clock

  let nsecs = options.nsecs !== undefined ? options.nsecs : _lastNSecs + 1; // Time since last uuid creation (in msecs)

  const dt = msecs - _lastMSecs + (nsecs - _lastNSecs) / 10000; // Per 4.2.1.2, Bump clockseq on clock regression

  if (dt < 0 && options.clockseq === undefined) {
    clockseq = clockseq + 1 & 0x3fff;
  } // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new
  // time interval


  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {
    nsecs = 0;
  } // Per 4.2.1.2 Throw error if too many uuids are requested


  if (nsecs >= 10000) {
    throw new Error("uuid.v1(): Can't create more than 10M uuids/sec");
  }

  _lastMSecs = msecs;
  _lastNSecs = nsecs;
  _clockseq = clockseq; // Per 4.1.4 - Convert from unix epoch to Gregorian epoch

  msecs += 12219292800000; // `time_low`

  const tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;
  b[i++] = tl >>> 24 & 0xff;
  b[i++] = tl >>> 16 & 0xff;
  b[i++] = tl >>> 8 & 0xff;
  b[i++] = tl & 0xff; // `time_mid`

  const tmh = msecs / 0x100000000 * 10000 & 0xfffffff;
  b[i++] = tmh >>> 8 & 0xff;
  b[i++] = tmh & 0xff; // `time_high_and_version`

  b[i++] = tmh >>> 24 & 0xf | 0x10; // include version

  b[i++] = tmh >>> 16 & 0xff; // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)

  b[i++] = clockseq >>> 8 | 0x80; // `clock_seq_low`

  b[i++] = clockseq & 0xff; // `node`

  for (let n = 0; n < 6; ++n) {
    b[i + n] = node[n];
  }

  return buf || (0, _bytesToUuid.default)(b);
}

var _default = v1;
exports.default = _default;
},{"./bytesToUuid.js":117,"./rng.js":120}],123:[function(require,module,exports){
"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = void 0;

var _v = _interopRequireDefault(require("./v35.js"));

var _md = _interopRequireDefault(require("./md5.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

const v3 = (0, _v.default)('v3', 0x30, _md.default);
var _default = v3;
exports.default = _default;
},{"./md5.js":119,"./v35.js":124}],124:[function(require,module,exports){
"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = _default;
exports.URL = exports.DNS = void 0;

var _bytesToUuid = _interopRequireDefault(require("./bytesToUuid.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

function uuidToBytes(uuid) {
  // Note: We assume we're being passed a valid uuid string
  const bytes = [];
  uuid.replace(/[a-fA-F0-9]{2}/g, function (hex) {
    bytes.push(parseInt(hex, 16));
  });
  return bytes;
}

function stringToBytes(str) {
  str = unescape(encodeURIComponent(str)); // UTF8 escape

  const bytes = [];

  for (let i = 0; i < str.length; ++i) {
    bytes.push(str.charCodeAt(i));
  }

  return bytes;
}

const DNS = '6ba7b810-9dad-11d1-80b4-00c04fd430c8';
exports.DNS = DNS;
const URL = '6ba7b811-9dad-11d1-80b4-00c04fd430c8';
exports.URL = URL;

function _default(name, version, hashfunc) {
  function generateUUID(value, namespace, buf, offset) {
    const off = buf && offset || 0;
    if (typeof value === 'string') value = stringToBytes(value);
    if (typeof namespace === 'string') namespace = uuidToBytes(namespace);

    if (!Array.isArray(value)) {
      throw TypeError('value must be an array of bytes');
    }

    if (!Array.isArray(namespace) || namespace.length !== 16) {
      throw TypeError('namespace must be uuid string or an Array of 16 byte values');
    } // Per 4.3


    const bytes = hashfunc(namespace.concat(value));
    bytes[6] = bytes[6] & 0x0f | version;
    bytes[8] = bytes[8] & 0x3f | 0x80;

    if (buf) {
      for (let idx = 0; idx < 16; ++idx) {
        buf[off + idx] = bytes[idx];
      }
    }

    return buf || (0, _bytesToUuid.default)(bytes);
  } // Function#name is not settable on some platforms (#270)


  try {
    generateUUID.name = name; // eslint-disable-next-line no-empty
  } catch (err) {} // For CommonJS default export support


  generateUUID.DNS = DNS;
  generateUUID.URL = URL;
  return generateUUID;
}
},{"./bytesToUuid.js":117}],125:[function(require,module,exports){
"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = void 0;

var _rng = _interopRequireDefault(require("./rng.js"));

var _bytesToUuid = _interopRequireDefault(require("./bytesToUuid.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

function v4(options, buf, offset) {
  if (typeof options === 'string') {
    buf = options === 'binary' ? new Uint8Array(16) : null;
    options = null;
  }

  options = options || {};

  const rnds = options.random || (options.rng || _rng.default)(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`


  rnds[6] = rnds[6] & 0x0f | 0x40;
  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided

  if (buf) {
    const start = offset || 0;

    for (let i = 0; i < 16; ++i) {
      buf[start + i] = rnds[i];
    }

    return buf;
  }

  return (0, _bytesToUuid.default)(rnds);
}

var _default = v4;
exports.default = _default;
},{"./bytesToUuid.js":117,"./rng.js":120}],126:[function(require,module,exports){
"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = void 0;

var _v = _interopRequireDefault(require("./v35.js"));

var _sha = _interopRequireDefault(require("./sha1.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

const v5 = (0, _v.default)('v5', 0x50, _sha.default);
var _default = v5;
exports.default = _default;
},{"./sha1.js":121,"./v35.js":124}],127:[function(require,module,exports){
module.exports = extend

var hasOwnProperty = Object.prototype.hasOwnProperty;

function extend() {
    var target = {}

    for (var i = 0; i < arguments.length; i++) {
        var source = arguments[i]

        for (var key in source) {
            if (hasOwnProperty.call(source, key)) {
                target[key] = source[key]
            }
        }
    }

    return target
}

},{}],128:[function(require,module,exports){
module.exports = {
	h32: require("./xxhash")
,	h64: require("./xxhash64")
}

},{"./xxhash":129,"./xxhash64":130}],129:[function(require,module,exports){
(function (Buffer){
/**
xxHash implementation in pure Javascript

Copyright (C) 2013, Pierre Curto
MIT license
*/
var UINT32 = require('cuint').UINT32

/*
	Merged this sequence of method calls as it speeds up
	the calculations by a factor of 2
 */
// this.v1.add( other.multiply(PRIME32_2) ).rotl(13).multiply(PRIME32_1);
UINT32.prototype.xxh_update = function (low, high) {
	var b00 = PRIME32_2._low
	var b16 = PRIME32_2._high

	var c16, c00
	c00 = low * b00
	c16 = c00 >>> 16

	c16 += high * b00
	c16 &= 0xFFFF		// Not required but improves performance
	c16 += low * b16

	var a00 = this._low + (c00 & 0xFFFF)
	var a16 = a00 >>> 16

	a16 += this._high + (c16 & 0xFFFF)

	var v = (a16 << 16) | (a00 & 0xFFFF)
	v = (v << 13) | (v >>> 19)

	a00 = v & 0xFFFF
	a16 = v >>> 16

	b00 = PRIME32_1._low
	b16 = PRIME32_1._high

	c00 = a00 * b00
	c16 = c00 >>> 16

	c16 += a16 * b00
	c16 &= 0xFFFF		// Not required but improves performance
	c16 += a00 * b16

	this._low = c00 & 0xFFFF
	this._high = c16 & 0xFFFF
}

/*
 * Constants
 */
var PRIME32_1 = UINT32( '2654435761' )
var PRIME32_2 = UINT32( '2246822519' )
var PRIME32_3 = UINT32( '3266489917' )
var PRIME32_4 = UINT32(  '668265263' )
var PRIME32_5 = UINT32(  '374761393' )

/**
* Convert string to proper UTF-8 array
* @param str Input string
* @returns {Uint8Array} UTF8 array is returned as uint8 array
*/
function toUTF8Array (str) {
	var utf8 = []
	for (var i=0, n=str.length; i < n; i++) {
		var charcode = str.charCodeAt(i)
		if (charcode < 0x80) utf8.push(charcode)
		else if (charcode < 0x800) {
			utf8.push(0xc0 | (charcode >> 6),
			0x80 | (charcode & 0x3f))
		}
		else if (charcode < 0xd800 || charcode >= 0xe000) {
			utf8.push(0xe0 | (charcode >> 12),
			0x80 | ((charcode>>6) & 0x3f),
			0x80 | (charcode & 0x3f))
		}
		// surrogate pair
		else {
			i++;
			// UTF-16 encodes 0x10000-0x10FFFF by
			// subtracting 0x10000 and splitting the
			// 20 bits of 0x0-0xFFFFF into two halves
			charcode = 0x10000 + (((charcode & 0x3ff)<<10)
			| (str.charCodeAt(i) & 0x3ff))
			utf8.push(0xf0 | (charcode >>18),
			0x80 | ((charcode>>12) & 0x3f),
			0x80 | ((charcode>>6) & 0x3f),
			0x80 | (charcode & 0x3f))
		}
	}

	return new Uint8Array(utf8)
}

/**
 * XXH object used as a constructor or a function
 * @constructor
 * or
 * @param {Object|String} input data
 * @param {Number|UINT32} seed
 * @return ThisExpression
 * or
 * @return {UINT32} xxHash
 */
function XXH () {
	if (arguments.length == 2)
		return new XXH( arguments[1] ).update( arguments[0] ).digest()

	if (!(this instanceof XXH))
		return new XXH( arguments[0] )

	init.call(this, arguments[0])
}

/**
 * Initialize the XXH instance with the given seed
 * @method init
 * @param {Number|Object} seed as a number or an unsigned 32 bits integer
 * @return ThisExpression
 */
 function init (seed) {
	this.seed = seed instanceof UINT32 ? seed.clone() : UINT32(seed)
	this.v1 = this.seed.clone().add(PRIME32_1).add(PRIME32_2)
	this.v2 = this.seed.clone().add(PRIME32_2)
	this.v3 = this.seed.clone()
	this.v4 = this.seed.clone().subtract(PRIME32_1)
	this.total_len = 0
	this.memsize = 0
	this.memory = null

	return this
}
XXH.prototype.init = init

/**
 * Add data to be computed for the XXH hash
 * @method update
 * @param {String|Buffer|ArrayBuffer} input as a string or nodejs Buffer or ArrayBuffer
 * @return ThisExpression
 */
XXH.prototype.update = function (input) {
	var isString = typeof input == 'string'
	var isArrayBuffer

	// Convert all strings to utf-8 first (issue #5)
	if (isString) {
		input = toUTF8Array(input)
		isString = false
		isArrayBuffer = true
	}

	if (typeof ArrayBuffer !== "undefined" && input instanceof ArrayBuffer)
	{
		isArrayBuffer = true
		input = new Uint8Array(input);
	}

	var p = 0
	var len = input.length
	var bEnd = p + len

	if (len == 0) return this

	this.total_len += len

	if (this.memsize == 0)
	{
		if (isString) {
			this.memory = ''
		} else if (isArrayBuffer) {
			this.memory = new Uint8Array(16)
		} else {
			this.memory = new Buffer(16)
		}
	}

	if (this.memsize + len < 16)   // fill in tmp buffer
	{
		// XXH_memcpy(this.memory + this.memsize, input, len)
		if (isString) {
			this.memory += input
		} else if (isArrayBuffer) {
			this.memory.set( input.subarray(0, len), this.memsize )
		} else {
			input.copy( this.memory, this.memsize, 0, len )
		}

		this.memsize += len
		return this
	}

	if (this.memsize > 0)   // some data left from previous update
	{
		// XXH_memcpy(this.memory + this.memsize, input, 16-this.memsize);
		if (isString) {
			this.memory += input.slice(0, 16 - this.memsize)
		} else if (isArrayBuffer) {
			this.memory.set( input.subarray(0, 16 - this.memsize), this.memsize )
		} else {
			input.copy( this.memory, this.memsize, 0, 16 - this.memsize )
		}

		var p32 = 0
		if (isString) {
			this.v1.xxh_update(
				(this.memory.charCodeAt(p32+1) << 8) | this.memory.charCodeAt(p32)
			,	(this.memory.charCodeAt(p32+3) << 8) | this.memory.charCodeAt(p32+2)
			)
			p32 += 4
			this.v2.xxh_update(
				(this.memory.charCodeAt(p32+1) << 8) | this.memory.charCodeAt(p32)
			,	(this.memory.charCodeAt(p32+3) << 8) | this.memory.charCodeAt(p32+2)
			)
			p32 += 4
			this.v3.xxh_update(
				(this.memory.charCodeAt(p32+1) << 8) | this.memory.charCodeAt(p32)
			,	(this.memory.charCodeAt(p32+3) << 8) | this.memory.charCodeAt(p32+2)
			)
			p32 += 4
			this.v4.xxh_update(
				(this.memory.charCodeAt(p32+1) << 8) | this.memory.charCodeAt(p32)
			,	(this.memory.charCodeAt(p32+3) << 8) | this.memory.charCodeAt(p32+2)
			)
		} else {
			this.v1.xxh_update(
				(this.memory[p32+1] << 8) | this.memory[p32]
			,	(this.memory[p32+3] << 8) | this.memory[p32+2]
			)
			p32 += 4
			this.v2.xxh_update(
				(this.memory[p32+1] << 8) | this.memory[p32]
			,	(this.memory[p32+3] << 8) | this.memory[p32+2]
			)
			p32 += 4
			this.v3.xxh_update(
				(this.memory[p32+1] << 8) | this.memory[p32]
			,	(this.memory[p32+3] << 8) | this.memory[p32+2]
			)
			p32 += 4
			this.v4.xxh_update(
				(this.memory[p32+1] << 8) | this.memory[p32]
			,	(this.memory[p32+3] << 8) | this.memory[p32+2]
			)
		}

		p += 16 - this.memsize
		this.memsize = 0
		if (isString) this.memory = ''
	}

	if (p <= bEnd - 16)
	{
		var limit = bEnd - 16

		do
		{
			if (isString) {
				this.v1.xxh_update(
					(input.charCodeAt(p+1) << 8) | input.charCodeAt(p)
				,	(input.charCodeAt(p+3) << 8) | input.charCodeAt(p+2)
				)
				p += 4
				this.v2.xxh_update(
					(input.charCodeAt(p+1) << 8) | input.charCodeAt(p)
				,	(input.charCodeAt(p+3) << 8) | input.charCodeAt(p+2)
				)
				p += 4
				this.v3.xxh_update(
					(input.charCodeAt(p+1) << 8) | input.charCodeAt(p)
				,	(input.charCodeAt(p+3) << 8) | input.charCodeAt(p+2)
				)
				p += 4
				this.v4.xxh_update(
					(input.charCodeAt(p+1) << 8) | input.charCodeAt(p)
				,	(input.charCodeAt(p+3) << 8) | input.charCodeAt(p+2)
				)
			} else {
				this.v1.xxh_update(
					(input[p+1] << 8) | input[p]
				,	(input[p+3] << 8) | input[p+2]
				)
				p += 4
				this.v2.xxh_update(
					(input[p+1] << 8) | input[p]
				,	(input[p+3] << 8) | input[p+2]
				)
				p += 4
				this.v3.xxh_update(
					(input[p+1] << 8) | input[p]
				,	(input[p+3] << 8) | input[p+2]
				)
				p += 4
				this.v4.xxh_update(
					(input[p+1] << 8) | input[p]
				,	(input[p+3] << 8) | input[p+2]
				)
			}
			p += 4
		} while (p <= limit)
	}

	if (p < bEnd)
	{
		// XXH_memcpy(this.memory, p, bEnd-p);
		if (isString) {
			this.memory += input.slice(p)
		} else if (isArrayBuffer) {
			this.memory.set( input.subarray(p, bEnd), this.memsize )
		} else {
			input.copy( this.memory, this.memsize, p, bEnd )
		}

		this.memsize = bEnd - p
	}

	return this
}

/**
 * Finalize the XXH computation. The XXH instance is ready for reuse for the given seed
 * @method digest
 * @return {UINT32} xxHash
 */
XXH.prototype.digest = function () {
	var input = this.memory
	var isString = typeof input == 'string'
	var p = 0
	var bEnd = this.memsize
	var h32, h
	var u = new UINT32

	if (this.total_len >= 16)
	{
		h32 = this.v1.rotl(1).add( this.v2.rotl(7).add( this.v3.rotl(12).add( this.v4.rotl(18) ) ) )
	}
	else
	{
		h32  = this.seed.clone().add( PRIME32_5 )
	}

	h32.add( u.fromNumber(this.total_len) )

	while (p <= bEnd - 4)
	{
		if (isString) {
			u.fromBits(
				(input.charCodeAt(p+1) << 8) | input.charCodeAt(p)
			,	(input.charCodeAt(p+3) << 8) | input.charCodeAt(p+2)
			)
		} else {
			u.fromBits(
				(input[p+1] << 8) | input[p]
			,	(input[p+3] << 8) | input[p+2]
			)
		}
		h32
			.add( u.multiply(PRIME32_3) )
			.rotl(17)
			.multiply( PRIME32_4 )
		p += 4
	}

	while (p < bEnd)
	{
		u.fromBits( isString ? input.charCodeAt(p++) : input[p++], 0 )
		h32
			.add( u.multiply(PRIME32_5) )
			.rotl(11)
			.multiply(PRIME32_1)
	}

	h = h32.clone().shiftRight(15)
	h32.xor(h).multiply(PRIME32_2)

	h = h32.clone().shiftRight(13)
	h32.xor(h).multiply(PRIME32_3)

	h = h32.clone().shiftRight(16)
	h32.xor(h)

	// Reset the state
	this.init( this.seed )

	return h32
}

module.exports = XXH

}).call(this,require("buffer").Buffer)
},{"buffer":76,"cuint":79}],130:[function(require,module,exports){
(function (Buffer){
/**
xxHash64 implementation in pure Javascript

Copyright (C) 2016, Pierre Curto
MIT license
*/
var UINT64 = require('cuint').UINT64

/*
 * Constants
 */
var PRIME64_1 = UINT64( '11400714785074694791' )
var PRIME64_2 = UINT64( '14029467366897019727' )
var PRIME64_3 = UINT64(  '1609587929392839161' )
var PRIME64_4 = UINT64(  '9650029242287828579' )
var PRIME64_5 = UINT64(  '2870177450012600261' )

/**
* Convert string to proper UTF-8 array
* @param str Input string
* @returns {Uint8Array} UTF8 array is returned as uint8 array
*/
function toUTF8Array (str) {
	var utf8 = []
	for (var i=0, n=str.length; i < n; i++) {
		var charcode = str.charCodeAt(i)
		if (charcode < 0x80) utf8.push(charcode)
		else if (charcode < 0x800) {
			utf8.push(0xc0 | (charcode >> 6),
			0x80 | (charcode & 0x3f))
		}
		else if (charcode < 0xd800 || charcode >= 0xe000) {
			utf8.push(0xe0 | (charcode >> 12),
			0x80 | ((charcode>>6) & 0x3f),
			0x80 | (charcode & 0x3f))
		}
		// surrogate pair
		else {
			i++;
			// UTF-16 encodes 0x10000-0x10FFFF by
			// subtracting 0x10000 and splitting the
			// 20 bits of 0x0-0xFFFFF into two halves
			charcode = 0x10000 + (((charcode & 0x3ff)<<10)
			| (str.charCodeAt(i) & 0x3ff))
			utf8.push(0xf0 | (charcode >>18),
			0x80 | ((charcode>>12) & 0x3f),
			0x80 | ((charcode>>6) & 0x3f),
			0x80 | (charcode & 0x3f))
		}
	}

	return new Uint8Array(utf8)
}

/**
 * XXH64 object used as a constructor or a function
 * @constructor
 * or
 * @param {Object|String} input data
 * @param {Number|UINT64} seed
 * @return ThisExpression
 * or
 * @return {UINT64} xxHash
 */
function XXH64 () {
	if (arguments.length == 2)
		return new XXH64( arguments[1] ).update( arguments[0] ).digest()

	if (!(this instanceof XXH64))
		return new XXH64( arguments[0] )

	init.call(this, arguments[0])
}

/**
 * Initialize the XXH64 instance with the given seed
 * @method init
 * @param {Number|Object} seed as a number or an unsigned 32 bits integer
 * @return ThisExpression
 */
 function init (seed) {
	this.seed = seed instanceof UINT64 ? seed.clone() : UINT64(seed)
	this.v1 = this.seed.clone().add(PRIME64_1).add(PRIME64_2)
	this.v2 = this.seed.clone().add(PRIME64_2)
	this.v3 = this.seed.clone()
	this.v4 = this.seed.clone().subtract(PRIME64_1)
	this.total_len = 0
	this.memsize = 0
	this.memory = null

	return this
}
XXH64.prototype.init = init

/**
 * Add data to be computed for the XXH64 hash
 * @method update
 * @param {String|Buffer|ArrayBuffer} input as a string or nodejs Buffer or ArrayBuffer
 * @return ThisExpression
 */
XXH64.prototype.update = function (input) {
	var isString = typeof input == 'string'
	var isArrayBuffer

	// Convert all strings to utf-8 first (issue #5)
	if (isString) {
		input = toUTF8Array(input)
		isString = false
		isArrayBuffer = true
	}

	if (typeof ArrayBuffer !== "undefined" && input instanceof ArrayBuffer)
	{
		isArrayBuffer = true
		input = new Uint8Array(input);
	}

	var p = 0
	var len = input.length
	var bEnd = p + len

	if (len == 0) return this

	this.total_len += len

	if (this.memsize == 0)
	{
		if (isString) {
			this.memory = ''
		} else if (isArrayBuffer) {
			this.memory = new Uint8Array(32)
		} else {
			this.memory = new Buffer(32)
		}
	}

	if (this.memsize + len < 32)   // fill in tmp buffer
	{
		// XXH64_memcpy(this.memory + this.memsize, input, len)
		if (isString) {
			this.memory += input
		} else if (isArrayBuffer) {
			this.memory.set( input.subarray(0, len), this.memsize )
		} else {
			input.copy( this.memory, this.memsize, 0, len )
		}

		this.memsize += len
		return this
	}

	if (this.memsize > 0)   // some data left from previous update
	{
		// XXH64_memcpy(this.memory + this.memsize, input, 16-this.memsize);
		if (isString) {
			this.memory += input.slice(0, 32 - this.memsize)
		} else if (isArrayBuffer) {
			this.memory.set( input.subarray(0, 32 - this.memsize), this.memsize )
		} else {
			input.copy( this.memory, this.memsize, 0, 32 - this.memsize )
		}

		var p64 = 0
		if (isString) {
			var other
			other = UINT64(
					(this.memory.charCodeAt(p64+1) << 8) | this.memory.charCodeAt(p64)
				,	(this.memory.charCodeAt(p64+3) << 8) | this.memory.charCodeAt(p64+2)
				,	(this.memory.charCodeAt(p64+5) << 8) | this.memory.charCodeAt(p64+4)
				,	(this.memory.charCodeAt(p64+7) << 8) | this.memory.charCodeAt(p64+6)
				)
			this.v1.add( other.multiply(PRIME64_2) ).rotl(31).multiply(PRIME64_1);
			p64 += 8
			other = UINT64(
					(this.memory.charCodeAt(p64+1) << 8) | this.memory.charCodeAt(p64)
				,	(this.memory.charCodeAt(p64+3) << 8) | this.memory.charCodeAt(p64+2)
				,	(this.memory.charCodeAt(p64+5) << 8) | this.memory.charCodeAt(p64+4)
				,	(this.memory.charCodeAt(p64+7) << 8) | this.memory.charCodeAt(p64+6)
				)
			this.v2.add( other.multiply(PRIME64_2) ).rotl(31).multiply(PRIME64_1);
			p64 += 8
			other = UINT64(
					(this.memory.charCodeAt(p64+1) << 8) | this.memory.charCodeAt(p64)
				,	(this.memory.charCodeAt(p64+3) << 8) | this.memory.charCodeAt(p64+2)
				,	(this.memory.charCodeAt(p64+5) << 8) | this.memory.charCodeAt(p64+4)
				,	(this.memory.charCodeAt(p64+7) << 8) | this.memory.charCodeAt(p64+6)
				)
			this.v3.add( other.multiply(PRIME64_2) ).rotl(31).multiply(PRIME64_1);
			p64 += 8
			other = UINT64(
					(this.memory.charCodeAt(p64+1) << 8) | this.memory.charCodeAt(p64)
				,	(this.memory.charCodeAt(p64+3) << 8) | this.memory.charCodeAt(p64+2)
				,	(this.memory.charCodeAt(p64+5) << 8) | this.memory.charCodeAt(p64+4)
				,	(this.memory.charCodeAt(p64+7) << 8) | this.memory.charCodeAt(p64+6)
				)
			this.v4.add( other.multiply(PRIME64_2) ).rotl(31).multiply(PRIME64_1);
		} else {
			var other
			other = UINT64(
					(this.memory[p64+1] << 8) | this.memory[p64]
				,	(this.memory[p64+3] << 8) | this.memory[p64+2]
				,	(this.memory[p64+5] << 8) | this.memory[p64+4]
				,	(this.memory[p64+7] << 8) | this.memory[p64+6]
				)
			this.v1.add( other.multiply(PRIME64_2) ).rotl(31).multiply(PRIME64_1);
			p64 += 8
			other = UINT64(
					(this.memory[p64+1] << 8) | this.memory[p64]
				,	(this.memory[p64+3] << 8) | this.memory[p64+2]
				,	(this.memory[p64+5] << 8) | this.memory[p64+4]
				,	(this.memory[p64+7] << 8) | this.memory[p64+6]
				)
			this.v2.add( other.multiply(PRIME64_2) ).rotl(31).multiply(PRIME64_1);
			p64 += 8
			other = UINT64(
					(this.memory[p64+1] << 8) | this.memory[p64]
				,	(this.memory[p64+3] << 8) | this.memory[p64+2]
				,	(this.memory[p64+5] << 8) | this.memory[p64+4]
				,	(this.memory[p64+7] << 8) | this.memory[p64+6]
				)
			this.v3.add( other.multiply(PRIME64_2) ).rotl(31).multiply(PRIME64_1);
			p64 += 8
			other = UINT64(
					(this.memory[p64+1] << 8) | this.memory[p64]
				,	(this.memory[p64+3] << 8) | this.memory[p64+2]
				,	(this.memory[p64+5] << 8) | this.memory[p64+4]
				,	(this.memory[p64+7] << 8) | this.memory[p64+6]
				)
			this.v4.add( other.multiply(PRIME64_2) ).rotl(31).multiply(PRIME64_1);
		}

		p += 32 - this.memsize
		this.memsize = 0
		if (isString) this.memory = ''
	}

	if (p <= bEnd - 32)
	{
		var limit = bEnd - 32

		do
		{
			if (isString) {
				var other
				other = UINT64(
						(input.charCodeAt(p+1) << 8) | input.charCodeAt(p)
					,	(input.charCodeAt(p+3) << 8) | input.charCodeAt(p+2)
					,	(input.charCodeAt(p+5) << 8) | input.charCodeAt(p+4)
					,	(input.charCodeAt(p+7) << 8) | input.charCodeAt(p+6)
					)
				this.v1.add( other.multiply(PRIME64_2) ).rotl(31).multiply(PRIME64_1);
				p += 8
				other = UINT64(
						(input.charCodeAt(p+1) << 8) | input.charCodeAt(p)
					,	(input.charCodeAt(p+3) << 8) | input.charCodeAt(p+2)
					,	(input.charCodeAt(p+5) << 8) | input.charCodeAt(p+4)
					,	(input.charCodeAt(p+7) << 8) | input.charCodeAt(p+6)
					)
				this.v2.add( other.multiply(PRIME64_2) ).rotl(31).multiply(PRIME64_1);
				p += 8
				other = UINT64(
						(input.charCodeAt(p+1) << 8) | input.charCodeAt(p)
					,	(input.charCodeAt(p+3) << 8) | input.charCodeAt(p+2)
					,	(input.charCodeAt(p+5) << 8) | input.charCodeAt(p+4)
					,	(input.charCodeAt(p+7) << 8) | input.charCodeAt(p+6)
					)
				this.v3.add( other.multiply(PRIME64_2) ).rotl(31).multiply(PRIME64_1);
				p += 8
				other = UINT64(
						(input.charCodeAt(p+1) << 8) | input.charCodeAt(p)
					,	(input.charCodeAt(p+3) << 8) | input.charCodeAt(p+2)
					,	(input.charCodeAt(p+5) << 8) | input.charCodeAt(p+4)
					,	(input.charCodeAt(p+7) << 8) | input.charCodeAt(p+6)
					)
				this.v4.add( other.multiply(PRIME64_2) ).rotl(31).multiply(PRIME64_1);
			} else {
				var other
				other = UINT64(
						(input[p+1] << 8) | input[p]
					,	(input[p+3] << 8) | input[p+2]
					,	(input[p+5] << 8) | input[p+4]
					,	(input[p+7] << 8) | input[p+6]
					)
				this.v1.add( other.multiply(PRIME64_2) ).rotl(31).multiply(PRIME64_1);
				p += 8
				other = UINT64(
						(input[p+1] << 8) | input[p]
					,	(input[p+3] << 8) | input[p+2]
					,	(input[p+5] << 8) | input[p+4]
					,	(input[p+7] << 8) | input[p+6]
					)
				this.v2.add( other.multiply(PRIME64_2) ).rotl(31).multiply(PRIME64_1);
				p += 8
				other = UINT64(
						(input[p+1] << 8) | input[p]
					,	(input[p+3] << 8) | input[p+2]
					,	(input[p+5] << 8) | input[p+4]
					,	(input[p+7] << 8) | input[p+6]
					)
				this.v3.add( other.multiply(PRIME64_2) ).rotl(31).multiply(PRIME64_1);
				p += 8
				other = UINT64(
						(input[p+1] << 8) | input[p]
					,	(input[p+3] << 8) | input[p+2]
					,	(input[p+5] << 8) | input[p+4]
					,	(input[p+7] << 8) | input[p+6]
					)
				this.v4.add( other.multiply(PRIME64_2) ).rotl(31).multiply(PRIME64_1);
			}
			p += 8
		} while (p <= limit)
	}

	if (p < bEnd)
	{
		// XXH64_memcpy(this.memory, p, bEnd-p);
		if (isString) {
			this.memory += input.slice(p)
		} else if (isArrayBuffer) {
			this.memory.set( input.subarray(p, bEnd), this.memsize )
		} else {
			input.copy( this.memory, this.memsize, p, bEnd )
		}

		this.memsize = bEnd - p
	}

	return this
}

/**
 * Finalize the XXH64 computation. The XXH64 instance is ready for reuse for the given seed
 * @method digest
 * @return {UINT64} xxHash
 */
XXH64.prototype.digest = function () {
	var input = this.memory
	var isString = typeof input == 'string'
	var p = 0
	var bEnd = this.memsize
	var h64, h
	var u = new UINT64

	if (this.total_len >= 32)
	{
		h64 = this.v1.clone().rotl(1)
		h64.add( this.v2.clone().rotl(7) )
		h64.add( this.v3.clone().rotl(12) )
		h64.add( this.v4.clone().rotl(18) )

		h64.xor( this.v1.multiply(PRIME64_2).rotl(31).multiply(PRIME64_1) )
		h64.multiply(PRIME64_1).add(PRIME64_4)

		h64.xor( this.v2.multiply(PRIME64_2).rotl(31).multiply(PRIME64_1) )
		h64.multiply(PRIME64_1).add(PRIME64_4)

		h64.xor( this.v3.multiply(PRIME64_2).rotl(31).multiply(PRIME64_1) )
		h64.multiply(PRIME64_1).add(PRIME64_4)

		h64.xor( this.v4.multiply(PRIME64_2).rotl(31).multiply(PRIME64_1) )
		h64.multiply(PRIME64_1).add(PRIME64_4)
	}
	else
	{
		h64  = this.seed.clone().add( PRIME64_5 )
	}

	h64.add( u.fromNumber(this.total_len) )

	while (p <= bEnd - 8)
	{
		if (isString) {
			u.fromBits(
				(input.charCodeAt(p+1) << 8) | input.charCodeAt(p)
			,	(input.charCodeAt(p+3) << 8) | input.charCodeAt(p+2)
			,	(input.charCodeAt(p+5) << 8) | input.charCodeAt(p+4)
			,	(input.charCodeAt(p+7) << 8) | input.charCodeAt(p+6)
			)
		} else {
			u.fromBits(
				(input[p+1] << 8) | input[p]
			,	(input[p+3] << 8) | input[p+2]
			,	(input[p+5] << 8) | input[p+4]
			,	(input[p+7] << 8) | input[p+6]
			)
		}
		u.multiply(PRIME64_2).rotl(31).multiply(PRIME64_1)
		h64
			.xor(u)
			.rotl(27)
			.multiply( PRIME64_1 )
			.add( PRIME64_4 )
		p += 8
	}

	if (p + 4 <= bEnd) {
		if (isString) {
			u.fromBits(
				(input.charCodeAt(p+1) << 8) | input.charCodeAt(p)
			,	(input.charCodeAt(p+3) << 8) | input.charCodeAt(p+2)
			,	0
			,	0
			)
		} else {
			u.fromBits(
				(input[p+1] << 8) | input[p]
			,	(input[p+3] << 8) | input[p+2]
			,	0
			,	0
			)
		}
		h64
			.xor( u.multiply(PRIME64_1) )
			.rotl(23)
			.multiply( PRIME64_2 )
			.add( PRIME64_3 )
		p += 4
	}

	while (p < bEnd)
	{
		u.fromBits( isString ? input.charCodeAt(p++) : input[p++], 0, 0, 0 )
		h64
			.xor( u.multiply(PRIME64_5) )
			.rotl(11)
			.multiply(PRIME64_1)
	}

	h = h64.clone().shiftRight(33)
	h64.xor(h).multiply(PRIME64_2)

	h = h64.clone().shiftRight(29)
	h64.xor(h).multiply(PRIME64_3)

	h = h64.clone().shiftRight(32)
	h64.xor(h)

	// Reset the state
	this.init( this.seed )

	return h64
}

module.exports = XXH64

}).call(this,require("buffer").Buffer)
},{"buffer":76,"cuint":79}],"alan-compiler":[function(require,module,exports){
const { default: buildPipeline, } = require('./dist/pipeline')
const ammtojs = require('./dist/ammtojs')
const lntoamm = require('./dist/lntoamm')
const ammtoaga = require('./dist/ammtoaga')

// We won't support AGC for now because of the complexities of moving off the Buffer API
const convert = buildPipeline([
  ['ln', 'amm', lntoamm],
  ['amm', 'aga', ammtoaga],
  ['amm', 'js', ammtojs],
])

module.exports = (inFormat, outFormat, text) => {
  if (convert[inFormat] && convert[inFormat][outFormat]) {
    const out = convert[inFormat][outFormat].fromString(text)
    if (outFormat === 'js') { // Hackery for browserify for now, will clean this up later
      return out.replace(/alan-js-runtime/g, 'alan-runtime')
    }
    return out
  } else {
    throw new Error(`${inFormat} to ${outFormat} is not supported`)
  }
}

},{"./dist/ammtoaga":4,"./dist/ammtojs":5,"./dist/lntoamm":21,"./dist/pipeline":24}],"alan-js-runtime":[function(require,module,exports){
(function (process){
require('cross-fetch/polyfill')
const EventEmitter = require('events')
const http = require('http')
const util = require('util')

const xxh = require('xxhashjs')

const exec = util.promisify ? util.promisify(require('child_process').exec) : () => {} // browsers

const e = new EventEmitter()

// Hashing opcodes (hashv is recursive, needs to be defined outside of the export object)
const hashcore = (hasher, a) => {
  // TODO: We have to turn these values into ArrayBuffers of the right type. There's currently an
  // issue if a floating point number that is also an integer is provided -- the duck typing here
  // will treat it as an i64 instead of an f64 so the hash will be different between the JS and
  // Rust implementations. There are a few ways to solve this, but they all have tradeoffs. Will
  // revisit this in the future.
  let buffer = new ArrayBuffer(8)
  if (typeof a === 'number') {
    if (a === parseInt(a)) {
      const view = new BigInt64Array(buffer)
      view.set([BigInt(a)], 0)
    } else {
      const view = new Float64Array(buffer)
      view.set([a], 0)
    }
  } else if (typeof a === 'string') {
    // If it's a string, we treat it like an array of 64-bit integers with a prefixed 64-bit length
    // to match the behavior of the Rust runtime
    const len = a.length
    const len8 = Math.ceil(len / 8) * 8
    buffer = new ArrayBuffer(8 + len8)
    const lenview = new BigInt64Array(buffer)
    lenview.set([BigInt(len)], 0)
    const strview = new Int8Array(buffer)
    // The following only works in the ASCII subset for now, since JS chose to use utf16 instead of
    // utf8. TODO: Find a pure Javascript library that converts utf16 codepoints to utf8, or write
    // one. :/
    strview.set(a.split('').map(s => s.charCodeAt(0)), 8)
  } else {
    // Booleans are treated as if they are 64-bit integers
    const val = a ? BigInt(1) : BigInt(0)
    const view = new BigInt64Array(buffer)
    view.set([val], 0)
  }
  for (let i = 0; i < buffer.byteLength; i += 8) {
    const piece = buffer.slice(i, i + 8)
    hasher.update(piece)
  }
  return hasher
}
const hashf = a => Number(BigInt.asIntN(64, hashcore(xxh.h64().init(0xfa57), a).digest()))
const hashv = arr => {
  // The Rust runtime considers strings a variable type, but they are more like a fixed type for JS
  if (typeof arr === 'string') return hashf(arr)
  const hasher = xxh.h64().init(0xfa57)
  let stack = [arr]
  while (stack.length > 0) {
    let arr = stack.pop()
    for (const elem of arr) {
      if (elem instanceof Array) {
        stack.push(elem)
      } else {
        hashcore(hasher, elem)
      }
    }
  }
  return Number(BigInt.asIntN(64, hasher.digest())) // TODO: Move all i64 to BigInt?
}

// Not very OOP, but since the HTTP server is a singleton right now, store open connections here
const httpConns = {}

// The shared mutable state for the datastore library
const ds = {}

module.exports = {
  // Type conversion opcodes (mostly no-ops in JS, unless we implement a strict mode)
  i8f64:    a => a,
  i16f64:   a => a,
  i32f64:   a => a,
  i64f64:   a => a,
  f32f64:   a => a,
  strf64:   a => parseFloat(a),
  boolf64:  a => a ? 1.0 : 0.0,

  i8f32:    a => a,
  i16f32:   a => a,
  i32f32:   a => a,
  i64f32:   a => a,
  f64f32:   a => a,
  strf32:   a => parseFloat(a),
  boolf32:  a => a ? 1.0 : 0.0,

  i8i64:    a => a,
  i16i64:   a => a,
  i32i64:   a => a,
  f32i64:   a => Math.floor(a),
  f64i64:   a => Math.floor(a),
  stri64:   a => parseInt(a), // intentionally allowing other bases here
  booli64:  a => a ? 1 : 0,

  i8i32:    a => a,
  i16i32:   a => a,
  i64i32:   a => a,
  f32i32:   a => Math.floor(a),
  f64i32:   a => Math.floor(a),
  stri32:   a => parseInt(a),
  booli64:  a => a ? 1 : 0,

  i8i16:    a => a,
  i32i16:   a => a,
  i64i16:   a => a,
  f32i16:   a => Math.floor(a),
  f64i16:   a => Math.floor(a),
  stri16:   a => parseInt(a),
  booli16:  a => a ? 1 : 0,

  i16i8:    a => a,
  i32i8:    a => a,
  i64i8:    a => a,
  f32i8:    a => Math.floor(a),
  f64i8:    a => Math.floor(a),
  stri8:    a => parseInt(a),
  booli8:   a => a ? 1 : 0,

  i8bool:   a => a !== 0,
  i16bool:  a => a !== 0,
  i32bool:  a => a !== 0,
  i64bool:  a => a !== 0,
  f32bool:  a => a !== 0.0,
  f64bool:  a => a !== 0.0,
  strbool:  a => a === "true",

  i8str:    a => a.toString(),
  i16str:   a => a.toString(),
  i32str:   a => a.toString(),
  i64str:   a => a.toString(),
  f32str:   a => a.toString(),
  f64str:   a => a.toString(),
  boolstr:  a => a.toString(),

  // Arithmetic opcodes
  addi8:   (a, b) => a + b,
  addi16:  (a, b) => a + b,
  addi32:  (a, b) => a + b,
  addi64:  (a, b) => a + b,
  addf32:  (a, b) => a + b,
  addf64:  (a, b) => a + b,

  subi8:   (a, b) => a - b,
  subi16:  (a, b) => a - b,
  subi32:  (a, b) => a - b,
  subi64:  (a, b) => a - b,
  subf32:  (a, b) => a - b,
  subf64:  (a, b) => a - b,

  negi8:    a => 0 - a,
  negi16:   a => 0 - a,
  negi32:   a => 0 - a,
  negi64:   a => 0 - a,
  negf32:   a => 0.0 - a,
  negf64:   a => 0.0 - a,

  absi8:    a => Math.abs(a),
  absi16:   a => Math.abs(a),
  absi32:   a => Math.abs(a),
  absi64:   a => Math.abs(a),
  absf32:   a => Math.abs(a),
  absf64:   a => Math.abs(a),

  muli8:   (a, b) => a * b,
  muli16:  (a, b) => a * b,
  muli32:  (a, b) => a * b,
  muli64:  (a, b) => a * b,
  mulf32:  (a, b) => a * b,
  mulf64:  (a, b) => a * b,

  divi8:   (a, b) => Math.floor(a / b),
  divi16:  (a, b) => Math.floor(a / b),
  divi32:  (a, b) => Math.floor(a / b),
  divi64:  (a, b) => Math.floor(a / b),
  divf32:  (a, b) => a / b,
  divf64:  (a, b) => a / b,

  modi8:   (a, b) => a % b,
  modi16:  (a, b) => a % b,
  modi32:  (a, b) => a % b,
  modi64:  (a, b) => a % b,

  powi8:   (a, b) => Math.floor(a ** b), // If 'b' is negative, it would produce a fraction
  powi16:  (a, b) => Math.floor(a ** b),
  powi32:  (a, b) => Math.floor(a ** b),
  powi64:  (a, b) => Math.floor(a ** b),
  powf32:  (a, b) => a ** b,
  powf64:  (a, b) => a ** b,

  sqrtf32:  a => Math.sqrt(a),
  sqrtf64:  a => Math.sqrt(a),

  // Boolean and bitwise opcodes
  andi8:   (a, b) => a & b,
  andi16:  (a, b) => a & b,
  andi32:  (a, b) => a & b,
  andi64:  (a, b) => a & b,
  andbool: (a, b) => a && b,

  ori8:    (a, b) => a | b,
  ori16:   (a, b) => a | b,
  ori32:   (a, b) => a | b,
  ori64:   (a, b) => a | b,
  orbool:  (a, b) => a || b,

  xori8:   (a, b) => a ^ b,
  xori16:  (a, b) => a ^ b,
  xori32:  (a, b) => a ^ b,
  xori64:  (a, b) => a ^ b,
  xorbool: (a, b) => !!(a ^ b),

  noti8:    a => ~a,
  noti16:   a => ~a,
  noti32:   a => ~a,
  noti64:   a => ~a,
  notbool:  a => !a,

  nandi8:  (a, b) => ~(a & b),
  nandi16: (a, b) => ~(a & b),
  nandi32: (a, b) => ~(a & b),
  nandi64: (a, b) => ~(a & b),
  nandboo: (a, b) => !(a && b),

  nori8:   (a, b) => ~(a | b),
  nori16:  (a, b) => ~(a | b),
  nori32:  (a, b) => ~(a | b),
  nori64:  (a, b) => ~(a | b),
  norbool: (a, b) => !(a || b),

  xnori8:  (a, b) => ~(a ^ b),
  xnori16: (a, b) => ~(a ^ b),
  xnori32: (a, b) => ~(a ^ b),
  xnori64: (a, b) => ~(a ^ b),
  xnorboo: (a, b) => !(a ^ b),

  // Equality and order opcodes
  eqi8:    (a, b) => a === b,
  eqi16:   (a, b) => a === b,
  eqi32:   (a, b) => a === b,
  eqi64:   (a, b) => a === b,
  eqf32:   (a, b) => a === b,
  eqf64:   (a, b) => a === b,
  eqstr:   (a, b) => a === b,
  eqbool:  (a, b) => a === b,

  neqi8:   (a, b) => a !== b,
  neqi16:  (a, b) => a !== b,
  neqi32:  (a, b) => a !== b,
  neqi64:  (a, b) => a !== b,
  neqf32:  (a, b) => a !== b,
  neqf64:  (a, b) => a !== b,
  neqstr:  (a, b) => a !== b,
  neqbool: (a, b) => a !== b,

  lti8:    (a, b) => a < b,
  lti16:   (a, b) => a < b,
  lti32:   (a, b) => a < b,
  lti64:   (a, b) => a < b,
  ltf32:   (a, b) => a < b,
  ltf64:   (a, b) => a < b,
  ltstr:   (a, b) => a < b,

  ltei8:   (a, b) => a <= b,
  ltei16:  (a, b) => a <= b,
  ltei32:  (a, b) => a <= b,
  ltei64:  (a, b) => a <= b,
  ltef32:  (a, b) => a <= b,
  ltef64:  (a, b) => a <= b,
  ltestr:  (a, b) => a <= b,

  gti8:    (a, b) => a > b,
  gti16:   (a, b) => a > b,
  gti32:   (a, b) => a > b,
  gti64:   (a, b) => a > b,
  gtf32:   (a, b) => a > b,
  gtf64:   (a, b) => a > b,
  gtstr:   (a, b) => a > b,

  gtei8:   (a, b) => a >= b,
  gtei16:  (a, b) => a >= b,
  gtei32:  (a, b) => a >= b,
  gtei64:  (a, b) => a >= b,
  gtef32:  (a, b) => a >= b,
  gtef64:  (a, b) => a >= b,
  gtestr:  (a, b) => a >= b,

  // String opcodes
  catstr:  (a, b) => a.concat(b),
  split:   (a, b) => a.split(b),
  repstr:  (a, b) => new Array(b).fill(a).join(''),
  // TODO: templ, after maps are figured out
  matches: (a, b) => RegExp(b).test(a),
  indstr:  (a, b) => {
    const ind = a.indexOf(b)
    return ind > -1 ? [ true, ind, ] : [ false, 'substring not found', ]
  },
  lenstr:   a => a.length,
  trim:     a => a.trim(),
  copyfrom:(arr, ind) => JSON.parse(JSON.stringify(arr[ind])),
  copytof: (arr, ind, val) => { arr[ind] = val }, // These do the same thing in JS
  copytov: (arr, ind, val) => { arr[ind] = val },
  register:(arr, ind) => arr[ind], // Only on references to inner arrays

  // Array opcodes TODO more to come
  newarr:   size => new Array(), // Ignored because JS push doesn't behave as desired
  pusharr: (arr, val, size) => arr.push(val),
  poparr:   arr => arr.length > 0 ? [ true, arr.pop(), ] : [ false, 'cannot pop empty array', ],
  lenarr:   arr => arr.length,
  indarrf: (arr, val) => {
    const ind = arr.indexOf(val)
    return ind > -1 ? [ true, ind, ] : [ false, 'element not found', ]
  },
  indarrv: (arr, val) => {
    const ind = arr.indexOf(val)
    return ind > -1 ? [ true, ind, ] : [ false, 'element not found', ]
  },
  delindx: (arr, idx) => {
    const spliced = arr.splice(idx, 1)
    if (spliced.length === 1 && idx >= 0) {
      return [ true, spliced[0] ]
    } else {
      return [ false, `cannot remove idx ${idx} from array with length ${arr.length}` ]
    }
  },
  join:    (arr, sep) => arr.join(sep),
  map:     async (arr, fn) => await Promise.all(arr.map(fn)),
  mapl:    async (arr, fn) => await Promise.all(arr.map(fn)),
  reparr:  (arr, n) => Array.from(new Array(n * arr.length)).map((_, i) => JSON.parse(JSON.stringify(arr[i % arr.length]))),
  each:    async (arr, fn) => {
    await Promise.all(arr.map(fn)) // Thrown away but awaited to maintain consistent execution
  },
  eachl:   async (arr, fn) => {
    await Promise.all(arr.map(fn)) // Thrown away but awaited to maintain consistent execution
  },
  find:    async (arr, fn) => {
    let val = undefined
    const len = arr.length
    for (let i = 0; i < len && val === undefined; i++) {
      if (await fn(arr[i])) {
        val = arr[i]
      }
    }
    if (val === undefined) {
      return [
        false,
        'no element matches',
      ]
    } else {
      return [
        true,
        val,
      ]
    }
  },
  findl:   async (arr, fn) => {
    let val = undefined
    const len = arr.length
    for (let i = 0; i < len && val === undefined; i++) {
      if (await fn(arr[i])) {
        val = arr[i]
      }
    }
    if (val === undefined) {
      return [
        false,
        'no element matches',
      ]
    } else {
      return [
        true,
        val,
      ]
    }
  },
  every:   async (arr, fn) => {
    const len = arr.length
    for (let i = 0; i < len; i++) {
      if (!await fn(arr[i])) return false
    }
    return true
  },
  everyl:  async (arr, fn) => {
    const len = arr.length
    for (let i = 0; i < len; i++) {
      if (!await fn(arr[i])) return false
    }
    return true
  },
  some:    async (arr, fn) => {
    const len = arr.length
    for (let i = 0; i < len; i++) {
      if (await fn(arr[i])) return true
    }
    return false
  },
  somel:    async (arr, fn) => {
    const len = arr.length
    for (let i = 0; i < len; i++) {
      if (await fn(arr[i])) return true
    }
    return false
  },
  filter:  async (arr, fn) => {
    let out = []
    let len = arr.length
    for (let i = 0; i < len; i++) {
      if (await fn(arr[i])) out.push(arr[i])
    }
    return out
  },
  filterl: async (arr, fn) => {
    let out = []
    let len = arr.length
    for (let i = 0; i < len; i++) {
      if (await fn(arr[i])) out.push(arr[i])
    }
    return out
  },
  reducel: async (arr, fn) => {
    let cumu = arr[0]
    let len = arr.length
    for (let i = 1; i < len; i++) {
      cumu = await fn(cumu, arr[i])
    }
    return cumu
  },
  reducep: async (arr, fn) => {
    let cumu = arr[0]
    let len = arr.length
    for (let i = 1; i < len; i++) {
      cumu = await fn(cumu, arr[i])
    }
    return cumu
  },
  foldl:   async (obj, fn) => {
    const [arr, init] = obj
    let cumu = init
    let len = arr.length
    for (let i = 0; i < len; i++) {
      cumu = await fn(cumu, arr[i])
    }
    return cumu
  },
  foldp:   async (obj, fn) => {
    const [arr, init] = obj
    let cumu = init
    let len = arr.length
    for (let i = 0; i < len; i++) {
      cumu = await fn(cumu, arr[i])
    }
    return [cumu] // This path is expected to return an array of folded values per thread
  },
  catarr:  (a, b) => [...a, ...b],

  // Map opcodes TODO after maps are figured out

  // Ternary functions
  // TODO: pair and condarr after arrays are figured out
  condfn:  async (cond, fn) => cond ? await fn() : undefined,

  // Copy opcodes (for let reassignment)
  copyi8:   a => JSON.parse(JSON.stringify(a)),
  copyi16:  a => JSON.parse(JSON.stringify(a)),
  copyi32:  a => JSON.parse(JSON.stringify(a)),
  copyi64:  a => JSON.parse(JSON.stringify(a)),
  copyvoid: a => JSON.parse(JSON.stringify(a)),
  copyf32:  a => JSON.parse(JSON.stringify(a)),
  copyf64:  a => JSON.parse(JSON.stringify(a)),
  copybool: a => JSON.parse(JSON.stringify(a)),
  copystr:  a => JSON.parse(JSON.stringify(a)),
  // Actually the recommended deep clone mechanism: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/assign#Deep_Clone
  copyarr:  a => JSON.parse(JSON.stringify(a)),
  zeroed:  () => null,

  // Trig opcodes
  lnf64:    a => Math.log(a),
  logf64:   a => Math.log(a) / Math.log(10),
  sinf64:   a => Math.sin(a),
  cosf64:   a => Math.cos(a),
  tanf64:   a => Math.tan(a),
  asinf64:  a => Math.asin(a),
  acosf64:  a => Math.acos(a),
  atanf64:  a => Math.atan(a),
  sinhf64:  a => Math.sinh(a),
  coshf64:  a => Math.cosh(a),
  tanhf64:  a => Math.tanh(a),

  // Error, Maybe, Result, Either opcodes
  error:    a => a,
  reff:      a => a, // Just an alias for error but without the type mangling in the compiler
  refv:      a => a, // Just an alias for error but without the type mangling in the compiler
  noerr:   () => '',
  errorstr: a => a.toString(),
  someM:    a => [
    true,
    a,
  ],
  noneM:   () => [
    false,
  ],
  isSome:   a => a[0],
  isNone:   a => !a[0],
  getOrM:  (a, b) => a[0] ? a[1] : b,
  okR:      a => [
    true,
    a,
  ],
  err:      a => [
    false,
    a,
  ],
  isOk:     a => a[0],
  isErr:    a => !a[0],
  getOrR:  (a, b) => a[0] ? a[1] : b,
  getOrRS: (a, b) => a[0] ? a[1] : b,
  getR:    (a) => {
    if (a[0]) {
      return a[1]
    } else {
      throw new Error('runtime error: illegal access')
    }
  },
  getErr:  (a, b) => a[0] ? b : a[1],
  resfrom: (arr, ind) => ind >= 0 && ind < arr.length ? [
    true,
    arr[ind],
  ] : [
    false,
    'out-of-bounds access',
  ],
  mainE:    a => [
    true,
    a,
  ],
  altE:     a => [
    false,
    a,
  ],
  isMain:   a => a[0],
  isAlt:    a => !a[0],
  mainOr:  (a, b) => a[0] ? a[1] : b,
  altOr:   (a, b) => a[0] ? b : a[1],

  // Hashing opcodes (hashv is recursive, needs to be defined elsewhere)
  hashf,
  hashv,

  // In Node.js the datastore opcodes don't have to be IO opcodes, but in the Rust runtime they do,
  // because of the multithreaded nature of the Rust runtime. Not sure if they should be "fake"
  // async here or not.
  dssetf:  (ns, key, val) => {
    ds[`${ns}:${key}`] = val
  },
  dssetv:  (ns, key, val) => {
    ds[`${ns}:${key}`] = val
  },
  dshas:   (ns, key) => ds.hasOwnProperty(`${ns}:${key}`),
  dsdel:   (ns, key) => {
    const fullKey = `${ns}:${key}`
    const toDelete = ds.hasOwnProperty(fullKey)
    if (toDelete) delete ds[fullKey]
    return toDelete
  },
  dsgetf:  (ns, key) => {
    const fullKey = `${ns}:${key}`
    if (ds.hasOwnProperty(fullKey)) {
      return [ true, ds[`${ns}:${key}`], ]
    } else {
      return [ false, 'namespace-key pair not found', ]
    }
  },
  dsgetv:  (ns, key) => {
    const fullKey = `${ns}:${key}`
    if (ds.hasOwnProperty(fullKey)) {
      return [ true, ds[`${ns}:${key}`], ]
    } else {
      return [ false, 'namespace-key pair not found', ]
    }
  },
  newseq:  (limit) => [0, limit],
  seqnext: (seq) => {
    if (seq[0] < seq[1]) {
      const out = [true, seq[0]]
      seq[0]++
      return out
    } else {
      return [false, 'error: sequence out-of-bounds']
    }
  },
  seqeach: async (seq, func) => {
    while (seq[0] < seq[1]) {
      await func(seq[0])
      seq[0]++
    }
  },
  seqwhile:async (seq, condFn, bodyFn) => {
    while (seq[0] < seq[1] && await condFn()) {
      await bodyFn()
      seq[0]++
    }
  },
  seqdo:   async (seq, bodyFn) => {
    let ok = true
    do {
      ok = await bodyFn()
      seq[0]++
    } while (seq[0] < seq[1] && ok)
  },
  selfrec: async (self, arg) => {
    const [seq, recurseFn] = self
    if (seq[0] < seq[1]) {
      seq[0]++
      return recurseFn(self, arg)
    } else {
      return [false, 'error: sequence out-of-bounds']
    }
  },
  seqrec: (seq, recurseFn) => [seq, recurseFn],

  // IO opcodes
  httpget:  async url => {
    try {
      const response = await fetch(url)
      const result = await response.text()
      return [ true, result ]
    } catch (e) {
      return [ false, e.toString() ]
    }
  },
  httppost: async (url, body) => {
    try {
      const response = await fetch(url, { method: 'POST', body })
      const result = await response.text()
      return [ true, result ]
    } catch (e) {
      return [ false, e.toString() ]
    }
  },
  httplsn:  async (port) => {
    const server = http.createServer((req, res) => {
      const connId = hashf(Math.random().toString())
      httpConns[connId] = {
        req,
        res,
      }
      let body = ''
      req.on('data', d => {
        body += d
      })
      req.on('end', () => {
        e.emit('__conn', [
          req.url,
          Object.entries(req.headers),
          body,
          connId,
        ])
      })
    })
    return await new Promise(resolve => {
      server.on('error', e => resolve([ false, e.code, ]))
      server.listen({
        port,
      }, () => resolve([ true, 'ok', ]))
    })
  },
  httpsend: ires => {
    const [ status, headers, body, connId, ] = ires
    const conn = httpConns[connId]
    if (!conn) return [ false, 'connection not found', ]
    delete httpConns[connId]
    return new Promise(resolve => {
      conn.res.on('close', () => resolve([ false, 'client hangup', ]))
      conn.res
        .writeHead(status, headers.reduce((acc, kv) => {
          acc[kv[0]] = kv[1]
          return acc
        }, {}))
        .end(body, () => resolve([ true, 'ok', ]))
    })
  },
  waitop:   async (a) => await new Promise(resolve => setTimeout(resolve, a)),
  execop:   async (cmd) => {
    try {
      const res = await exec(cmd)
      const { stdout, stderr } = res
      return [ 0, stdout, stderr ]
    } catch (e) {
      return [ e.signal, e.stdout, e.stderr ]
    }
  },

  // "Special" opcodes
  stdoutp:  out => process.stdout.write(out),
  stderrp:  err => process.stderr.write(err),
  exitop:   code => process.exit(code),

  // Event bookkeeping
  emit:    (name, payload) => e.emit(name, payload),
  on:      (name, cb) => e.on(name, cb),
  emitter:  e,
}

module.exports.asyncopcodes = Object.keys(module.exports).filter(k => module.exports[k].constructor.name === 'AsyncFunction')

}).call(this,require('_process'))
},{"_process":86,"child_process":74,"cross-fetch/polyfill":78,"events":82,"http":91,"util":116,"xxhashjs":128}],"alan-runtime":[function(require,module,exports){
const r = require('alan-js-runtime')

// Redefined stdoutp and exitop to work in the browser
module.exports = {
  ...r,
  stdoutp: (...args) => console.log(...args), // Lazy binding to replace `console.log` at will
  stderrp: (...args) => console.error(...args), // Lazy binding to replace `console.error` at will
  exitop: () => {
    r.emitter.removeAllListeners()
  }, // Clean up the event emitter, later we'll want a hook into the playground to show this
}

},{"alan-js-runtime":"alan-js-runtime"}]},{},[]);
